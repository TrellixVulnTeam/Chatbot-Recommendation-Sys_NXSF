It is recommended to keep firmware, Logical Domains Manager and AIX up to date.
Performance enhancements are continually added to AIX OS, it is recommended to keep updating for latest operating system versions.
It is observed that in UBPS App Server 215 has around 138 active OS services while other App Servers have more active Services. We feel that 138 OS services count in the UBPS App Servers are on the higher side.
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
Currently Network Related Parameters are not being monitored.
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
Currently memory utilization benchmarks are not available from UBPS vendor.
To gather memory utilizaiton benchmarks from UBPS software vendor
High executions of below queries\nDate 8th December 2016\n\nA>3fxatuj5jdhzu \nB>fb4hvrd9g44sa\nC>1bhkm76p82uzd\nD>2gzfkfv52rry0\nE>g9t2tuana15nn
Performnace Improvement
High wait events
'Recommended to append the NOWAIT or WAIT(X) parameters to these queries to avoid the contention\nRefer: Q002 in SQL_QUERIES'
Performance
Test to be re-run to re-produce the observations for further analysis
Query Optimization
This query is going for an FTS even though the Indexes are present on the search condition. This contains an implicit data type conversion on indexed  column "USER_ID". This implicit data type conversion prevents the optimizer  from selecting indices on table "SSOADM"."SSO_MODULE_ACCESS_TBL".\nCreate a functional index for optimizer to pick up the correct execution plan
Query Optimization
Option 1 - Evaluate possibility of reducing the commit interval at application layer \nOption 2 - Increase the INI_TRANS from 1 to atleast 64
Configuration
Need to increase the pga_aggregate_target to a suitable value. You can set it up to 2 GB and have a test run.
Memory Analysis
"We suggest that we have a common file for stopping and starting the services\ \ where we have a sleep of 30 secs after the stop sevice is executed. This will\ \ ensure that all services are brought down, and there are no service in the hung\ \ state. \\nTo validate further, we can have a ps \u2013ef |grep lisrvr|grep maria|grep\ \ limo to check if all the services have been brought down before a restart is initiated."
Query Optimization
Recommended in memory parsing of XML messages instead of current mechanism of doing a filesystem operation
Configuration
Recommended a lower thread connection setting (reduce from current setting of 500 to 50-75 threads per ESB node).
Query Optimization
1.Index on utr field needs to be created.\n2. Sequence Cache size increased to 20. \n(Alter sequence owner.sequence_name cache 20) -\nSequence Names - \nTrasanctionidsequence \njob_id_seq\nonline_job_id_seq
Query Optimization
Index creation needed on utr as well as on routing_ref_num
Query Optimization
The cache size of the sequences were increased from 0 to 40.\n(Alter sequence owner.sequence_name cache 40) -\nSequence Names - \nADT_REF_NUM_SEQ_IB\nFT_TRAN_NUM_SEQ_IB\nFTTRAN_NUM_SEQ_20120601_IB\nRTGS_SEQ_NUM_SEQ_IB\nPORH_SEQ_NUM_SEQ_IB
Query Optimization
1.Temporary Tablespace got full and as the Resumable_Parameter was set to 1800, it was waiting for the tablespace to be increased, and not giving any error to the end user. This led to slowness of the upload program. After adding the temp file, this issue was addressed.\n2. Stats Gathering is happening in middle of the upload program. This needs to be disabled.\n3. 3. We have observed that there is a query which is being run on the database which is taking more than 2 secs per execution. The total no. of executions are over 30,000 records.\n4. /finundo mount point is 100% utilized. Though there is sufficient free space available on the undo tablespace, we propose to create new undo tablespace and drop the older one which will free up the space on the mount point.
Query Optimization
1. Deployments at 107 and 108 are not in synch.(product exes are not in synch)Prima facie, it needs to be ascertained that all nodes are in synch to rule out any issues due to difference in deployments\n2.  We opine that there could have been a memory clog on the application due to high no. of records processed. When the next run is done, we would want to have the NMON running on the application as well as DB server to ascertain the same.
Configuration
Avekshaa has tuned these queries and the redundant data has been removed. Also queries have been written in a more optimized manner.
Query Optimization
There is a query on DTD which is going for a full table scan with the below query. Create index on dtd.ref_num or check for the functionality of this query, to understand why this query is being used. If this query has to be used, the index on ref_num is required.
Query Optimization
CSIS, ESB and MQ should be isolated from the current architecture setup and should be hosted on separate dedicated hardware for better fail-over handling
Configuration
Infosys should recommend appropriate value for process parameter based on the expected workload .
NoData
There was a noise because of which these queries were being run. These sessions were killed.
Configuration
The server has only 4GB ram with so many components. These components needs to be configured in separate servers.Recommended to increase the server's physical memory which is currently only 4GB
Configuration
CBC,Uniser logs are enabled. Also script traces are enabled leading to higher response on Finacle side. Needs to be disabled.
Configuration
Mount points to be created on separate disks to improve IO performance
Configuration
Recommended to have maxsize defined as 4gb for  datafiles and add more datafiles to tablespaces to avoid space outage. This will help in IO distribution of the system as data size increases
Query Optimization
FTS on TAM table.Instead of sol_id, bank_id is being used in the query. As Bank_id has only one value, the table will have a FTS. Wrong configuration done for TD-Receipt printing.
Configuration
Need to have stats to be gathered on fixed objects using "dbms_stats.GATHER_FIXED_OBJECTS_STATS" package of oracle.
Query Optimization
This query was fired from the customized Interface finacle script /finacle/appln/Finacle/FC10.2.9/app/cust/01/INFENG/scripts/INT8023Post.scr. Infosys to analyze and apply the fix.
Design
Compression of all static files needs to done for all the static contents serverd
Design
All javascript which are currently placed in <HEAD> Tag of the html page needs to be moved to bottom of <BODY> html element if these javascripts are not used for rendering objects on the page. Java scripts are blocking the page to render the page.
Design
All Jar files which are related to Finacle Product needs to be added to white list in Macafee scan policy.
Design
PMR to be raised with IBM and apply the patch for AIX which would fix the issue
Design
This process needs to be automated, to avoid any manual intervention during actual failover
High CPU Utilisation and High IO Writes
Logging is reduced
It was observed that threads consuming the maximum CPU were looping over a Hashmap Object used in CommonCodeCache class.
It is recommended to use ConcurrentHashmap in multithreaded environments instead of Hashmap/Hashtable
JVM parameters were Analyzed and it was found out that certain parameters were not optimal .
Default garbage collection policy was changed to Gencon and Maximum heap size was reduced to 2gb .
Method "private void SOAFinalCall(Map<String, String> mphdtls){". There is an "if block" that has some processing logic to invoke SOA service. This "if block" is a dead code and should be removed.\nCurrent code:\n// fileDeatilsSet variable below is always empty and hence its a dead code...\nif(!fileDeatilsSet.isEmpty()){
Dead code needs to be remove for easy maintenance of the application.
Huge 3400+ lines long class file without comments in the code.
Comments should be written in the code as per the code functionality for easy maintenance of the application.
String is used for concatenation. This is less performant and puts exta burden on GC.
Use StringBuffer or StringBuilder whichever is appropriate for string concatenation.
Uses LinkedHashMap as key-value pair. This will incur cost of maintaining insertion order and will also consume more memory.
Use Hashmap rather than LinkedHashMap, where insertion order is not relevant.
Initial heap is set to 4 GB and Max heap is set to 8 GB. There is an extra proccessing cost that is incurred while dynamically growing heap allocation to 8 GB from initial 4 GB while GC is happening at the same time.
Set both initial and max heap size to 8 GB. Use -Xms 8192M -Xmx 8192M
Fields in rows of the file are inserted into OTC database as CLOBs. Fields are formatted and concatenated to form a CLOB object. This incurs extra CPU cost for concatenating all these string fields. It will also put extra stress on JVM GC.
Insert all fileds as separate columns in OTC database. This will save on heavy string concatenation which is currnetly being done to form a CLOB. If currently, the CLOB is built in a format that is exactly as required by GA, then it is OK to stick with current design. If SOA needs to do transformation of this COLB to a format required by GA, then current design should be abandoned and each field should be saved as a separate column in the database rather than as a single CLOB.
File records are updated in OTC database for each row in the dump table. For each row, it makes call to OTC Database and updates the form data, it is inefficient to make database call for every record. For a file with 20k records it will update database 20k times.
Batching logic needs to be implement while performing the database operations. Database update needs to be performed in a batch of 100 or 1000 or so.
Method processXLSXFile is always returing 1 and hence all the logic of file handling is not needed.
Check the logic of method and remove unnecessary code if needed.
Observed "gc cr block lost" wait event from AWR analysis as top wait event with high DB TIME for SOA database.\n\nDetailed observations:\n1. Too many lost global cache block transfers can hamper the application performance because the block needs to be re-sent. This leads to wait for the second transfer to complete.\n2. On analysis we observed there is latency (Approx 4 ms) in network ping for interconnect IP 169.254.59.28 and private IP 192.168.10.35 \n3. This network latency causing for "gc cr block lost" wait event.
We recommend to raise the issue to network team.
It is observed that  the under sized  memory_target parameter impacting the performance of the database for the SOA database.
We suggest to set memory_target  and memory_max_target parameter to 67GB from current value of 47 GB
It is observed that the OTC database is having approx 3300 tables with 44 schemas and  SOA database is having approx  7000 tables and 82 schemas on SOA database.
We suggest to drop the unwanted schemas and tables from the live database.
It is observed that ,some tables are highly fragmented  for the SOA database.
Defrag the high fragmented tables, which will release the space and improve the performance of the database. Tables list mentioned in "FRAGMENTED_TABLE_LIST_SOA" sheet.
Based on Dynatrace Data, CPU utilization on SOA Servers is minimal (~10%). Other resources like Network and IO also look under utilized.
SOA Server Thread Pool that interacts with GA and SOA DB should be increased by atleast 5X. If current max size is provided to us, we can suggest the optimal size for this thread pool.
JMS MessageListener is used to read the JMS Queue "jms/OTC_BULKREQUEST_Q" for processing Bulk Upload File. On Parner App Server 28, due to some issue with this listener configuration/deployment, this processing is not happenning since 6th September.
Rather than using MDB, it is recommended to start a new thread to process Bulk Upload File. There is no need to have any JMS Queue for this processing.
'File System Errors were observed in OS Kernel Logs of CRMDB1 Database Server. Around 60K such error instances were observed for the Logs of 12th and 13th October 2017.\n\nError Details:\nEXT4-fs error (device dm-8): ext4_lookup:1044: inode #1183475: comm java: deleted inode referenced: 1183519\nEXT4-fs error (device dm-8): ext4_lookup:1044: inode #1183475: comm ologgerd: deleted inode referenced: 1183519\nEXT4-fs error (device dm-8): ext4_lookup:1044: inode #395360: comm updatedb: deleted inode referenced: 525266\nEXT4-fs error (device dm-8): ext4_lookup:1044: inode #395360: comm java: deleted inode referenced: 525266\nEXT4-fs (dm-0): initial error at 1470201788: ext4_mb_generate_buddy:736\nEXT4-fs (dm-0): last error at 1504937203: ext4_mb_generate_buddy:736\nEXT4-fs (dm-11): initial error at 1463625680: ext4_mb_generate_buddy:736\nEXT4-fs (dm-11): last error at 1463625680: ext4_mb_generate_buddy:736\nEXT4-fs (dm-6): initial error at 1463591423: ext4_mb_generate_buddy:736\nEXT4-fs (dm-6): last error at 1504889102: ext4_mb_generate_buddy:736\nEXT4-fs (dm-8): initial error at 1463591420: ext4_mb_generate_buddy:736\nEXT4-fs (dm-8): last error at 1507830355: ext4_lookup:1044: inode 1183475\nEXT4-fs (dm-8): last error at 1507917055: ext4_lookup:1044: inode 1183475'
Please raise the issue to Linux Server Team.\nPlease check, whether the issue still persist on OS Kernel Logs. If yes, then check/repair the file system using fsck command.
Large number of static hits on Portal server. Static pages make up for more than 85% of hits and 72% of bandwidth
Static content can be cached to reduce bandwidth utilization, reduce server hits and improve end user experience.
Failed requests constitute over 10% hits on CRM server
Eliminate the 404 errors. This will reduce about 10% hits on the server once the static content is cached.
VM restarts
Oracle patch is recommended but cant be tested out due to year end freeze
Strong coupling between View and Model - \nMVC1 Architecture has been implemented. Strong coupling between the View and the Model was observed. This can lead to Maintainability issues and is error prone. Any changes in the Db can results in changes in the View layer (which is un-desirable)
An additional layer for handling database related logic must be added to disassociate the View from Model. The database layer can invoke Hibernate/ JPA/ etc at the back-end.
"Batch uploads are processed in a Serial manner \u2013 \\nBatch\ \ upload process currently blocks a worker thread (per upload) and is synchronously\ \ processed (making the user wait). The current design will not scale beyond a point\ \ as the number of uploads and the volume of records in each batch increase.  Hw\ \ may not be getting optimally utilized (need to confirm after analyzing the utilization\ \ levels)"
Design a batch scale-out framework by leveraging open-source batch frameworks like Spring Batch, Quartz. \nIdentify batches that contain transactions which can be atomically processed as candidates for the batch scale out framework .
Scope for Data caching at the application layer- \nStatic relationships like Product/Product types, Group/Countries need not be loaded from the database for every request.  The data can be cached avoiding the IO to the database and improving the response time of the page.
Identify data elements that change in-frequently .  Introduce caching framework (like EHCache, Memcache) or implement a simple caching structure like Hashtable to cache the data. Data refreshing mechanisms must be put in place.
Web Pages to be optimized (specifically to help branches on low bandwidth) .\nUsers from branches connected with 64 kbps link are consitently complaining of performanance issues. It is crucial to reduce the network chatinness as well size of data to
Techniques like Image compression, Image/ JS /CSS Caching, CSS Image sprites to be  implemented to reduce network IO and load on the web server to  complete http page loading request. \nFor Weblogic, introduce web server (like apache) for compression.
Vectors are heavily used in the application - \nVectors are ideal for multi-threaded access  where synchronized call execution is required on the collection. Vectors can otherwise add an over-head If such an access is not required.
Replace Vectors with ArrayList
Implementing New I/O at SFA and Gateway Component\nThe new I/O (NIO) APIs introduced in v 1.4 provide new features and improved performance in the areas of buffer management, scalable network and file I/O.
Implementing New I/O at SFA and Gateway Component
In procedure "SVC_SP_ENQTRXN", OR and ISNULL were used for columns "TxnRefNum" and "CustomerRefNum". These operations are resource intensive.\n\nCurrent code:\n((TxnRefNum = @RefNum OR ISNULL(@RefNum, '') = '') OR (TR.CustomerRefNum = @RefNum OR ISNULL(@RefNum, '') = ''))
Check for @RefNum should be handled before calling the procedure. And OR and ISNULL should be removed from the query.\n\nCode should be:\n(TxnRefNum = @RefNum OR TR.CustomerRefNum = @RefNum)
It is observed the procedure 'BC_SP_ValidateLimit' running during the transaction process going with FTS on table.
It is suggested to create index on 'Svc_Stg_Txn' table with RESERVE5,Txnmode columns with include amount,rem_mobileno,Trn_status
High CPU Utilisation and High IO Writes
Logging is reduced
High CPU Utilisation and High IO Writes
String objects removed for unwanted logging
High Response Time
Executor Thread Pool is used
High Response Time
Its recommended to use StringBuilder instead of StringBuffer after careful evaluation of multithreadedness of the piece of code.
High Response Time
It is recommended to use Stringbuilder instead of String class where there are lot of concatentations used . Stringbuffer can also be used in multithreaded environments
High Response Time
It is recommended to compute the length/size value at the start of the loop and assign it to a variable . This variable then can be used in the loops
High Response Time
It is recommended to log / process an exception .
High Response Time
It is widely recommended to separate multiplex redo and control files on different disks(raid 1).
High Response Time
It is recommended to use String.isEmpty() for checking for an empty string.
High Response Time
It is recommended to catch specific exceptions eg Catch (FileNotFoundException e) first.
High Response Time
It is recommended to set debug="false"
High Response Time
It is recommended to create index on table "User_AccountLink" on columns "UserId", "CustomerId"
High Response Time
It is recommended to create index on table "TrnDetails" on columns "CustomerID", "CustomerRefNum", "EnteredDt"
High Response Time
'Recommended to append the NOWAIT or WAIT(X) parameters to these queries to avoid the contention\nRefer: Q002 in SQL_QUERIES'
High CPU Utilisation
Core dump on LISVR to be analyzed.
High Response Time
Change the MQ Channel manager count to 1000 (CFSMGRCHL Manager)
High Response Time
We have analyzed that WebMethods Admin threads are blocked by an operation which is converting ISO messages to XMLs.\nThe stack trace is -\nIndusInd_ISO8583/utils.convertISOToXML(utils.java:89)\nSource code to be analyzed
NoData
NoData
High Response Time
Message broker needs to be tuned for the required load. SoftwareAG to change the configuration as per the load.
High Response Time
Avekshaa has shared the details of the queries along with the recommendations with the bank.\nQ003 - This query is going for an FTS (on "WASADM"."SESSIONS") even though the Indexes are present on the search condition. \nQuery fired from WAS.
High Response Time
This query is going for an FTS even though the Indexes are present on the search condition. This contains an implicit data type conversion on indexed  column "USER_ID". This implicit data type conversion prevents the optimizer  from selecting indices on table "SSOADM"."SSO_MODULE_ACCESS_TBL".\nCreate a functional index for optimizer to pick up the correct execution plan
High Response Time
Q005 - This query is going for an FTS even though the Indexes are present on the search condition. Thiscontains an implicit data type conversion on\n  indexed column "USER_ID". This implicit data type conversion prevents the\n  optimizer from selecting indices on table "SSOADM"."SSO_RESOURCE_ACCESS_TBL".
Load Distribution
Option 1 - It is proposed to use IP aliases to resolve the IP stickness configured on the Load Balancer.\nOption 2 - IP stickiness between WAS and Finacle App server.\nOption 2 was implemented.
Multiple Inserts in signle table
Option 1 - Evaluate possibility of reducing the commit interval at application layer \nOption 2 - Increase the INI_TRANS from 1 to atleast 64
Multiple times property file is read
If the changes in properties files are not expected to change very often then it is not necessary to load the file every time. The same ResourceBundle can be used across requests. It can be controlled through a Singleton
NoData
Need to increase the pga_aggregate_target to a suitable value. You can set it up to 2 GB and have a test run.
NoData
We had earlier recommended Singleton usage for  Resource Bundles loading. This issue has to be fixed before SVS tests can be resumed.
NoData
Recommended in memory parsing of XML messages instead of current mechanism of doing a filesystem operation
NoData
Removal of un-wanted logging. Currently all incomming messages, messages processed at ESB and response messages from Finacle and converted messages are stored in database. Recommended softwareag to remove all these unnecessary loggings and to keep the messages stored only in case there are any failures or timeouts.
NoData
Recommended a lower thread connection setting (reduce from current setting of 500 to 50-75 threads per ESB node).
NoData
The CPU utilization on ESB has come down to acceptable limits. To assess where is the time being spent, Avekshaa's has suggested softwareAG to log the time spent on ESB.
NoData
Evaluate useage of lpad,rpad. Pasting the query below for your ready reference.
NoData
The credit account was not mapped as the settlement account because of which the script was throwing an error.
sequence exceeds MAXVALUE
1. Max value for this sequence can be set to higher in order to avoid such issues in future.\n        2. This also could be handled during EOD run (Finacle to confirm on this) in this case the data to be flushed out in the relevant table and reset the next value to 1.
Tablespace was full
1.Temporary Tablespace got full and as the Resumable_Parameter was set to 1800, it was waiting for the tablespace to be increased, and not giving any error to the end user. This led to slowness of the upload program. After adding the temp file, this issue was addressed.\n2. Stats Gathering is happening in middle of the upload program. This needs to be disabled.\n3. 3. We have observed that there is a query which is being run on the database which is taking more than 2 secs per execution. The total no. of executions are over 30,000 records.\n4. /finundo mount point is 100% utilized. Though there is sufficient free space available on the undo tablespace, we propose to create new undo tablespace and drop the older one which will free up the space on the mount point.
Slowness in Scripts
Avekshaa has tuned these queries and the redundant data has been removed. Also queries have been written in a more optimized manner.
NoData
There is a query on DTD which is going for a full table scan with the below query. Create index on dtd.ref_num or check for the functionality of this query, to understand why this query is being used. If this query has to be used, the index on ref_num is required.
3 different applications were installed in sampe physical box
CSIS, ESB and MQ should be isolated from the current architecture setup and should be hosted on separate dedicated hardware for better fail-over handling
OS limit was set to 100 for DB Node
Infosys should recommend appropriate value for process parameter based on the expected workload .
Unwanted logging were observed
Inode which is shared across all app servers got full, which is why there were fatal logs generated. The inode was increased from 3lacs to 6lacs. Traces needs to be off which is eating up the disk space.
Swaps due to low memory
The server has only 4GB ram with so many components. These components needs to be configured in separate servers.Recommended to increase the server's physical memory which is currently only 4GB
Unwanted traces were enabled
CBC,Uniser logs are enabled. Also script traces are enabled leading to higher response on Finacle side. Needs to be disabled.
DB stas were not gathered
Stats gathering needs to be done judiously. (Stats gathering should not be done during peak hours)
Mountpoints of tablespace on same disk
Mount points to be created on separate disks to improve IO performance
DBA Role was available in database
Confirm from Infosys team and remove DBA roles and assign only required privileges to users. This will help in better security measures for the database. (User List is shared with Suman)
Database DataFiles autoextend size was very high
Recommended to have maxsize defined as 4gb for  datafiles and add more datafiles to tablespaces to avoid space outage. This will help in IO distribution of the system as data size increases
Table lock observed
Row lock contention on  fiusb_message_table. Probably a case of Duprec happening. Infosys to explore if the commit interval can be reduced.
Stored Procedure was not optimised
Changes in the query to not include predicate in the query, as this will not use the index on addr_id.The procedure needs to be reviewed  to fix all such cases where wrong predicate is used.
NoData
Need to check with application logic behind running such queries concurrently. Also nowait can be appended to 'select for update' query to reduce row lock contention.
NoData
The root cause of the performance issue is that there are lot of transaction on the frozen accounts which are going into entered state. Infosys will internally explore this further. If the transactions are posted for these frozen accounts without the need of proxy posting, there is a huge time and effort saved on this batch program which will lead to reduction of total TAT of the EOD process.
NoData
FTS on TAM table.Instead of sol_id, bank_id is being used in the query. As Bank_id has only one value, the table will have a FTS. Wrong configuration done for TD-Receipt printing.
OS Limits was less
Identify connection leak from livsvr processes , since DB has defined parameter to 2000, which worked fine in earlier tests with 10K users
NoData
All javascript which are currently placed in <HEAD> Tag of the html page needs to be moved to bottom of <BODY> html element if these javascripts are not used for rendering objects on the page. Java scripts are blocking the page to render the page.
NoData
All Jar files which are related to Finacle Product needs to be added to white list in Macafee scan policy.
NoData
PMR to be raised with IBM and apply the patch for AIX which would fix the issue
Unnecessary logical block is written
Recommended to remove the unwanted operations from the source file. This will help in faster execution of logical blocks and hence improve the performance. Also the objects created inside this block will get eliminate which result in low memory consumption.
Multiple unused package imports
Avoid the use of unused import statements to prevent unwanted dependencies.
Use of StringBuffer
Use StringBuilder instead of StringBuffer if expensive thread-safe operations are not required. StringBuilders is faster than StringBuffer for strings concatenation.
String comparison not handled properly
'Use Position literals first in String comparisons for equals/equalsIgnoreCase. \nExample: obj.equalsIgnoreCase("AnyString"); // should be "AnyString".equalsIgnoreCase(obj)'
printStackTrace() is written in catch blocks
Avoid printStackTrace(); use a logger call instead. call printStackTrace() on an exception the trace is written to System.err and it's hard to route it elsewhere (or filter it). Instead of doing this use a logger call instead.
Unnecessary objects created
Comment out the unwanted instance of StringBuffer object.
Observed Hard coded IP address
Avoid using hard coded IP. Externalizing IP addresses is preferable.
knockout.js if binding causing frequent re-renders
One choice to avoid these re-renders would be to instead use the visible binding on a container element around our section or on the individual elements.\nIf we prefer to use if binding in this case, then we need to make sure that it is only triggered when the number of items in our array moves between 0 and 1
knockout.js Pushing items to an observableArray  in a loop
A better pattern is to get a reference to our underlying array, push to it, then call .valueHasMutated(). So that the subscribers will only receive one notification indicating that the array has changed.
'File: Reports\THAccountStatement\nMethod: ExportToXLWithLogo\nFollowing error observed in application logs: "The process cannot access the file ''C:\Windows\TEMP\AlignPicture1.xlsx'' because it is being used by another process"\n\nSame file is used to generate report for all users. When multiple users tries to generate report at a same time, then this error will occur and the report generation failed.'
Please use the same method for excel file creation that is used in other places.\nOr needs to append UserId in the file name to make unique file for every user.
The indexes and the tables are in the same file group.
We suggest to create separate file group for the indexes which will split the IO on different mount points. We can start with important tables like TrnDetails and det_TrnAuthDetails
It is observed that the query running on UploadTracking is going with FTS on procedure ID_SP_DSC_LockFile.
We suggest to create index on column IsLocked with include LockedBy on UploadTracking table.
Error "Process cannot access the log file" observed in "WriteLog" method of file "App_Code\BBPSAppLogger.vb" during load on Bill Payment.
It is recommended to remove "Throw ex" from "Catch" block.\nSuggestion for better logging during high load:\n1. Log File name based on date and userid\n2. High Performance Logging Technique such as log4net
Below looping/logic is sub-optimal:\n\nfor (int lPtr = lRecordStart; lPtr < lTotalRecCount; lPtr++) {\n    String lRecord = lRecords[lPtr].trim();\n    if (lRecord.length() == 0)\n     continue;\n    if (lIsTransactionUpload) {\n     String[] lContents = CommonUtilities.splitString(lRecord, lFieldSeperator);\n     boolean lFoundBlank = false;\n     for (int lCount = 0; lCount < lContents.length; lCount++) {\n      if (!CommonUtilities.hasValue(lContents[0]) && lCount > 0) // if first element is blank then\n                     // scan other elements\n      {\n       if (!CommonUtilities.hasValue(lContents[lCount])) {\n        lFoundBlank = true;// if found blank then scan next elements\n        continue;\n       } else {\n        lFoundBlank = false; // if found non blank then break\n        break;\n       }\n      }\n     }\n     if (lFoundBlank)\n      continue;\n    }
1. Each loop iteration is reading first array entry only. This can be extracted only once outside the loop.\n2. When first element is non-empty,  it will loop through foe all elements and will check for first entry again and again. \n3. Also, looks like  else block can be added to below if block and break the loop. This will avoid uncessary looping through all elements within records.\n\nif (!CommonUtilities.hasValue(lContents[0]) && lCount > 0) // if first element is blank then scan other elements\n      {\n\n4. The entire logic looks unnecssary as it is not achieving any meaningful result.
Caching (resource expiry duration) is not enabled at Web server.
All static web resources like (images, CSS, JS etc)  should be set expiry dates so that clients can cache these resoucres till the expiry time rather than picking from the web server each time. This avoids unnecessary trip to the server.
Bulk file upload related threads are seen only on App1 server's thread dumps, but not on App2 server. \nAlso total HTTP requests in Web1 access logs are 9,658 while the same on Web2 access logs are 2,404.
Check the load balancer configuration and its routing alogorithm. If routing algorithm is round robin the load on both app servers should be balanced.  Once load is properly balanced, both app servers utilization levels will match up.
Default GC policy is being set for the JVM. This may not be ideal for all application usage scenarios (especially for a throughput based scenario like, bulk file upload).
'Since the production Java version is greater than 1.7.0_u4 (1.7.0_u76) the adaptive GC policy of G1 is recommended. Since core funtionality of the application caters to Bulk File Upload, which is primarily throughput driven rather than response time, the GC policy of G1 is best suited in this case.\n\nAdd G1 setting to JVM parameters as shown below:\nset JAVA_OPTS=-Xmx4G -Xms1G -XX:+UseG1GC -DSource=. -DAPP=EIPO1\n\nNote : Add above parameter on UAT first and then move it to both PROD App servers, App1 & App2.'
Query is fired to fetch lMemberEntityBean but it is nevr used. This query is unnecessary.
Remove call to lAppEntityDAO.findById().
It is obsered that the query running high on BatchFileRecords table with high cost.
Create index on table BatchFileRecords with BFRBFId column.
It is obsered that the query running high on ASBAApplicationTransactions table with high cost.
Create index on table BatchFileRecords with AATUsId  column.
It is observed that the one query running on BroadcastMessages table is running with high execution count. Approx 9 per second, i.e approx 32000 per hour.
Please check for reducing the frequency of this query.
High Execution Count
'Recommendation: Create index on table TBL_APPLICATION_TEMP with column ACCOUNT_NUMBER'
NoData
'Set thread pool size as follows (min = 100, Max = 100)\nExpected Improvement: Throttling will improve'
NoData
'Set JDBC Thread Pool size as follows (100).\nExpected Improvement: Throttling will improve'
NoData
To be implemented. Query times will come down by at-least a half
NoData
Response Time of some transactions (posting) were brought down to half
NoData
Overall system performance was observed when Heap Size was increased to 2GB
NoData
Needs to avoid opening & closing connection for each login steps
NoData
Is compression enabled/disable?  If enabled, then disable the compression and measure the performance.  If disable, then enable the compression and measure the performance.
NoData
Enable client caching for javascript ( *.js)
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
"CallSummaryReport.aspx:-1. Perform only client side validation.\\n2. Restrict\ \ the date range From to To. The application now allows free date rage, which will\ \ end of selecting huge records. It would rather allow at a given time or a click\ \ can only take 30 days data\u2019s or range is restrict by commonly accepted.\\\ n3. Avoid displaying more records, provide the proper paging algorithm to avoid\ \ the response time and SQL"
Overall response Time of the entire SI component was very bad.
Suggested to make some optimization in the transformations performed on records received from STUB
Nakshatra lookup took huge time
Suggested some optimization techniques & XML marshelling technique for Nakshatra calling
Supplier & Operation lookup takes place in this layer
We could just point out method names that are consuming time.However a ticket is raised with Oracle for the same
We also pro-actively suggested LB config
Currently , we are analyzing trial & errors for various confuguration changes to Suppoert & LB team & then testing to look for the behavious of the issue.\nAnalysis of this still underway.
Single user test case of higher payload
Suggested Wrapper implementation, that would split the high payloads to multiple request of smaller payloads
BRMS migration from 6.4 to 7.1
Highlighted this alongwith jersey marshelling warning encountered in logs.\nRedhat suggested some config changes & got better performance
There are multiple inter-dependant calls
Suggested to remove the unconditional calls to user module
There are multiple inter-dependant calls
Recommended to put user module to cluster mode for better scalability
There are multiple inter-dependant calls
LB team were unable to understand the issue, required some config changes.
There are multiple inter-dependant calls
Proved same methods are called repeatatively, suggested to remove
There are multiple inter-dependant calls
Query been fired at MDM layer were of too large payloads, suggested to get only required data.
There are multiple inter-dependant calls
Too large queries been fired on DB. Suggested to optimize queries fired & pass on common data if required to reduce number of joins on the query
Huge time for a single request
Suggested to optimise the threads involved for Kafka + Breakdown of time taken at each layer proved optimisation required at SI , MDM & Commercial Cache components
Temporary table space identified on DB server
If you know total block size, bytes/block then you can find out,you're limited to individual data/ temp files of upto\n[total blocks * no. of bytes/ block / 1024^3)] Gb.
Found stale stats for the perticular table.
No stale stats should be observed for the transaction tables.
ORA-01555 (Snapshot too old) causes when the rollback records are needed by reader for consistent read are overwritten by other writers.
We can minimize the error using optimal parameter values.
High row cache lock wait event.
Check the cache size value for the sequences.
'enq : index contention was observed in TOP wait events in AWR reports.'
NoData
High enq SQ-contention was observed in TOP wait events in AWR reports.
Check the cache size value for the sequences.
wait event Log file switch observed in AWR.
NoData
Query was doing full table scan due to which it started taking time for execution.
NoData
Multiple threads waiting to get a connection from the connection pool on the Web Server.
The connection pool size needs to be increased
Static content served from portal servers were taking time.
Recommended to serve static contents from Web (OHS) servers.
No version control tools used.
"Automated patch deBetter patch deployment management \u2013 Use Version\ \ control tools like TortoiseSVN.\\nployment instead of manual patch deployment\ \ \u2013 Can use Maven/Hudson."
Manual patch deployment.
"Automated patch deployment instead of manual patch deployment \u2013 Can\ \ use Maven/Hudson."
No debuging enabled.
"Create a debug patch with more loggings onto the Application Server to\ \ check the exact cause of issue \u2013 Debug patch can be deployed in case of any\ \ issue."
Tail utility is not installed on all servers.
Install the tail utility for windows on all servers to debug bigger logs.
Maintenance
Create roll overs every hours rather than everyday, for easier referencing to the log.
Manual start and stop services.
Automated Scripts to start and stop services on all components.
Maintenance
Do a soft boot everyday, hard boot (preferably Sunday)once a week.
Maintenance
Run, Avekshaa Memory identifications scripts whenever high memory consumption is observed.
Maintenance
Continue to run Avekshaa Monitoring Perfmon Counters through Task Scheduler.
Maintenance
Run Avekshaa Monitoring netstat and tracecert scripts in case component failure is observed.
NoData
Netty based asynch communication
One thread per connection. No thread pool.
16 Netty worker thread pool to cater to current load.
Only 1 socket was opened between NAC and Host
16 concurrent sockets are opened between NAC and Host.
Single-threaded NAC Client Listener was a bottleneck.
Multi-threaded NAC Client listeners to improve throughput.
1 MQ session is created per ISO message. Creating MQ session is a costly operation and creating 1 per message is a bottleneck.
MQ session pool is created at the server startup. This improves throughput of the system.
Loop count calculation in if condition
This will cause the operations to execute on every iteration. So it is recommended to store the calculated value into a variable and then use it within the for loop condition.
Unnecessary Operation On Immutable Objects
Remove all such operations from code
String Replace method call and split on new character
Split the String directly with "@" character.
Unnecessary clear function call on empty map.
The map will be empty after this call returns. - This is not required as map is already empty. Performance overhead.
Unnecessary calls constructor.
These are not required, removing this will improve performance
Multiple trim calls on same string object
Only one call is enough as the string is already trimmed.
Redundant Call from Client App to Back-end
Change the if condition to some variable flag rather than on pastpaynorep html element
Redundant Call from Client App to Back-end
Change the if condition to some variable. And use the cached data.
Redundant Call from Client App to Back-end
Change the if condition to some variable flag rather than accsum.length
Redundant Call from Client App to Back-end
Change the if condition to some variable flag rather than cardlessPayeeList().length.
Hard coded user-agent value
This is not required and may cause issues in content-targeting. So proper user-agent value should be passed as the application is targeted to Android and iOS platforms.
Unnecessary String Concatenation
This is not required and operationId itself can be used further.
Unnecessary String Value check
These are not required, removing this will improve performance
Unnecessary getSafeValue method call
Remove the method call.
Unnecessary call to generateFailureResponse() method
Check the else condition and if not required remove the call made to generateFailureResponse
Unnecessary calls to StringUtils methods
Remove these redundant calls
Unnecessary If condition
Validate the logic here and remove the if condition as it seems to be Unnecessary
Sql queries with no column name.
Replace select * queries with the required column name.
Missing null check on object holding data received from external systems.
Put a null check on such objects (here goals) before performing any operations on it.
Setting attribute after logic ends
Since HttpServeletRequest is immutable. So these attribute changes should be removed.\n\nThis need to be discussed with development team for understanding why this is being done. As no oveeriden method was found to map these immutable entries.
NoData
Check the connectivity and performance of CDCI Component
NoData
NoData
NoData
Need to review the indexes on the tables in detail.
NoData
1.Distribute the datafiles on different diskgroups. \n2. Redistribute the objects based on utilization frequency. Move highly utilized objects(Tables/Indexes/Partitions) to seperate tablesopaces.\n2. Define a keep pool and pin the highly accessed indexes and small tables in the keep pool.
NoData
NoData
NoData
Follow below steps to get chained rows details.\n1. execute the UTLCHAIN.SQL to create the table to store chained row's rowid's.\n2. ANALYZE TABLE table_name LIST CHAINED ROWS INTO CHAINED_ROWS;\n3. Then query the CHAINED_ROWS table to find out the details.\n\nRectify these chained rows by moving the tables to another location using uncompress clause.
HTM credit amount tab hangs intermittently.
NoData
Application not able to scale with 4000 concurrent users
NoData
Index reached to MAX_EXTENT
The MAX_EXTENT should be increased by bank.
Currently Data compression is not enabled at OHS
Page size data is currently being tracked through loadrunner web page diagnostic feature. Enable compression at OHS.
High response time with frontend load balancer
Optimize the configuration of frontend load balancer to handle failures and high response time in transactions.
High Error Percentage
NoData
High Error Percentage
Finlistval services instances to be reduced from the previous count of 200 to 100
NA
Set the current cahce value present in production database. We will fine tune based on further testing results
Users unable to login
Extend the tablespace size by 32GB. However we are parallely checking on a policy to truncate this table on regular intervals for better maintenance
Latch free event was found in BBY database
1) To check the functionality of the query to retrive only one tran id since all the fetched tran id are not allocated to a variable through cursor             2) To use acid instead of foracid and avoid a subquery on GAM table
Query taking high cost for execution
In the where clause of the query a wrong condition to pick up the index on sol_id is specified.(sol_id >= '!'). This is to be corrected according to the funcationality requirement
Could not read response from the server'
None
High response timein transactions when tested with load balancer
NoData
SQL statement consuming more CPU
The SQL can be re-write for less CPU consumption.
Large number of TIME_WAIT connections
NoData
High response time due to latch free event
NoData
Fatal errors in HDDMI-ADD transaction
NoData
High response time during ramp-up stage
NoData
High failures and high response time for select_fincore transaction in 3rd node
NoData
Issues in new menus
NoData
High response time
NoData
Full table scan on SWIFT_MSG_HISTORY_TABLE table
Check with infy about functionality if (tran_id, tran_date) columns can be added in WHERE clause. It will reduce cost to 1.\nElse create inde on BANK_ID, utr columns.
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
WL_SERVLET_SESSIONS table of WASADM schema not getting populated
NoData
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
High Page Download size for Login page
NoData
High Page Download size for Select Fincore
NoData
High Page Download size for HTM actions
NoData
Calender.gif is not fetched from browser cache
NoData
High Page Download size for HCASHWD transaction
NoData
Application hangs after tabout to enter amount
NoData
MQ Broker creation was throwing IOException causing less numbers of brokers to be created. This will be a bottleneck.
Exception removed so that all MQ brokers are created and throughput is improved.
Single-threaded MQ reply message listener is a bottleneck.
Multi-threaded (16 threads) MQ reply message listeners configured to improve throughput.
300 MQ request message listeners configured to process incoming messages. This was consuming more resources without any throughput gain.
Optimal value of 120 request message queue listeners is set to reduce resource utilization.
No Caching.
Caching is introduced. Queries which are seeking the same data multiple times are being cached now.
Columns of many tables were using very large data type. This consumes a lot more memory and ad overhead to the indexes which use these column
Each column was evaluated and correct data type was identified. This helps with faster index lookup. Lesser space taken by indexes.
Stored procedure not using NoCount hint. This leads to additional return of row information which is never used in a stored procedure.
Enabled the hint NoCount to reduce additional overhead.
"Stored procedures were using exec or execute to Tsql. This isn\u2019\ t as efficient"
"Changed to using \u2018sp_executesql\u2019. This is Microsoft certified\ \ way of running Transactional Sqls."
Read queries in Stored procedure were running without lock hints leading to unnecessary locks on tables.
Read queries now run with NoLock hint to reduce locks on database and make the query execution faster.
Unnecessary use of drop table commands at end of stored procedure. This adds to little overhead since all temporary tables are anyways deleted by sqlserver at the end of a session.
Removed drop temp table commands. This avoids overheads.
Design
"1 \u2013 Horizontally scale the JVM\u2019s i.e. add more number of JVM\ \ components to sustain the load. This will\\nhave to be done along with hardware\ \ augmentation (mainly memory). \\n2 \u2013 Add another web server to handle the\ \ load. Failure of one server will not over-load other server."
Design
"\u2013 Deploy the AHS component on the other web servers as well. Start\ \ the component if there is a failure\\non the reporting server."
Design
"\u2013 Augment the memory component on the Web server 2 to at least 8 GB"
Design
"\u2013 Add separate JVM instances for MPI for handling Online e-com transactions\ \ that are NOT initiated from \\nIVR"
Design
"1 \u2013 Horizontally scale the JVM\u2019s i.e. add more number of JVM\ \ components to sustain the load. This will\\nhave to be done along with hardware\ \ augmentation (mainly memory). \\n2 \u2013 Add another app server to handle the\ \ load. Failure of one server will not over-load other server."
Design
Implement Oracle RAC
Design
Vertically scale the Reporting App server by adding another server instance if the availability is critical
Design
This area needs a review of the entire batch design and a solution cannot be proposed in isolation. The current solution is not scalable.
NoData
Asynchronous and Parallel processing must be leveraged to handle the process of email creation and delivery.
NoData
Connection pooling to be implemented as a part of the overall email solution.
NoData
Add indexes and change logic so that the indexes can be utilized
NoData
Range partitions proposed on the CP_PAYMENT_DETAIL table.
High Availability.
Add more JVM instances on both the web server 1 and webserver 2. \nStart the additional instances only if one of the webserver fails.
NoData
Combine all the js files into one and reference it at the bottom of the html
NoData
The comments from these two pages needs to be removed as these pages has the maximum hits.
NoData
The query once is being executed with status in the where clause and again without it. Please look at the logic of executing this query.
NoData
Set Minimum Heap Size to 1 Gb and Maximum Heap Size tp 2 Gb\nJAVA_OPTS="-Xms1024m -Xmx2048m"
NoData
Running multiple instances (20) of HttptoKafka
NoData
Setting following in sysctl.conf:\nnet.core.somaxconn = 65536\nnet.core.netdev_max_backlog = 65536\nnet.netfilter.nf_conntrack_max=1024000\nnet.netfilter.nf_conntrack_generic_timeout=120
NoData
Creating more Partitions (10) in Kafka
NoData
Code of HttptoKafka needs to be fixed accordingly
NoData
Code of HttptoKafka needs to be modified to allow to configure Partitions per Topic
NoData
'Introduction of Apache/ Nginx as a Reverse proxy in addition to the Hardware Load balancer to take care of Caching/ compression of data was recommended in week #1. However, Citrix team has confirmed that Caching/ Compression can be enabled at Netscalar as well. We recommend that these features be enabled on Netscalar to reduce hits on Application server.'
NoData
agEncoder instance is running only on one application server. This is a single point of failure.
NoData
CCM instance is running only on one application server. This is a single point of failure.
NoData
Changes are recommended for distributing files across disks for optimal IO activity
NoData
Setting optimal value of SDU parameter will help to reduce the wait events..  To set the optimal SDU value ,  further more PT test and analysis need to be conducted in the NFR environment
NoData
Application logic needs to be changed to fetch required no. of records.
NoData
All the end users of the system will be authenticated and Access Control List will be configured through the use of Spring Security.
NoData
We recommend Log4J be used as the logging framework in the application.
NoData
Given that there are quite a few batches that move data between source systems like Finacle/ CAR/ CDOC and CMART/CCM we recommend that a comprehensive framework like Quartz be implemented.
NoData
We recommend that Hibernate be used as a ORM tool for the persistence layer
NoData
"Markdown services in  case of unavailability:- End point monitor \u2013\ \ analyzes logs to identify consistent failures (eg. ConnectException)\\n Monitor\ \ marks-down services if end point is not available. Alerts admins.\\n Application\ \ \u2013 must have capabilities to enable/disable features based on end point \\\ navailability\\n Should have capability to mark-up services and re-instate features\ \ as they become \\navailable"
NoData
"Reduced IO by pre-fetching data during high load duration :-Pre-fetch data\ \ that is static/ almost static before the high load duration (start of month)\\\ nfrom the end points (example, User relations \u2013 cards/ loans from CAR)\\n Data\ \ can be maintained in memory at each JVM OR as a distributed memory cache\\n Will\ \ help in reducing the IO operations during high loads and reduce load on other\ \ \\nSystems\\n Synchronize cache based on load on the system"
NoData
Reduce Db reads by caching master data:-The Db server is currently handling both Read/ Write operations for Transactional\nas well as Master data\n It is handling load from all the app server nodes. In the absence of scalability option\n(RAC) it is critical to reduce the load on the db so that it does not become a \n bottleneck device. \n Depending on the frequency at which Master data changes, can the master data \nbe maintained in Cache (either distributed memory cache like Memcached/Jboss \nCache or per JVM cache)?
NoData
Reduce IO ops at  the web server:-Compressing static content,Reduce IO ops at  the web server:-Cache expiry must be optimally set, as per this report from Page Speed (Google tool), Reduce IO ops at  the web server:-Introduce caching at Load Balancer or Web server level to reduce the number of \nhits to the application server. Will lead to better bandwidth utilization.  \n Enable web browser caching by adding expiry headers for static content (Java script, \nCSS, images)\n Introduce compression for static content like JS, CSS, HTML
NoData
The code should be removed from the jsp which removed the delay of downloading the capicom.cab file and octget.dll from different Microsoft mirror sites. SignonScript.js was an external Javascript file which had functionalities for CAPICOM, this javascript was also removed for this fix.
NoData
The issue was studied from all layers, All networking components were studied using \ntracert to see if the issue is with any of the components in the network. The \nRoot cause analysis uncovered that the virus scan is causing the delay as \nFinEcEcApplet.jar which is the applet used for retail login forces McAfee OnAccess \nscan to scan even the base class files and archive files in class path which ended up in \n1.5 minutes of delay in Response of Retail Login Page access for first time. Discussion \nwith Infosys product team and architecture team was done and a solution which \nwould exclude the applet was provided which solved the 1.5 minutes of response \ntime issue completely
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
CRM not configured in some of the nodes
NoData
High Page Download size for HPORDM-Add transaction
NoData
Not able to achieve targetted TPS
NoData
Connections are not persistent for multiple requests after tabout at account number field.
Check http connection persistance at NLB.
High Page Download size for HDDMI-Add transaction
NoData
High Page Download size for HDDMI-Post transaction
NoData
Shortage of swap memory issue
Increase the swap size from 500 MB to 51 GB
Large size of .css file
File size of all .css files can be reduced considerably by compressing  them. Page size can further be improved if all .css files are clubbed into maximum one or two css files. This will help in reducing number of round trips and will help improve response time . Also comments should be removed.
High Page Download size for HACM Verify transaction
NoData
High Page Download size for CIF Address Modify transaction
NoData
High Page Download size for HFTI  transaction
NoData
Use of literal rather then bind variable
Explore the feasibility of using bind  variables.
Rule based scan on Oracle 11G
Perform gather stats on user schema CRMUSER.
Connection Leak
Analyse the code to validate whether all connection and related objects are being closed properly in both success and exception conditions.\nQueries need to be tuned (already reported).\nConnection pool settings need to be revisited for harvesting the idel/unused connections so that they are returned to the pool quickly
Query taking high cost for execution
Index present on PAYSYS_ID and BANK_IDENTIFIER. But the WHERE clause contains only BANK_IDENTIFIER. PAYSYS_ID is available in the script. This should be added in the WHERE CLAUSE of the query
High Page Download size for CIF Phone/Email Modify transaction
NoData
High Page Download size for HBDTM Modify transaction
NoData
Fatal Error in HACM - Verify
NoData
High Page Download size for ICIANWCS-Verify transaction
NoData
High Page Download size for HOAACSB-Add transaction
NoData
High Page Download size for HOAACLA-Add transaction
NoData
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
High Response Time and not able to scale up the TPS
NoData
Full table scan on ACCOUNTS_MOD table
Recommend to analyzed below tables ASAP.\nACCOUNTS_MOD\nPARTNER_REP\nPERSON\nPHONEEMAIL_MOD
Deadlock detected
NoData
Batch job execution
NoData
Batch job execution
NoData
Batch job execution
NoData
NoData
Explore possibility of adding new machines to reduce the load on 8 GB RAM machines. Check page fault behavior after hardware augmentation.
NoData
"Reduce the amount of exceptions getting triggered and logged in the log\ \ files. \\nRoll-over the file at the end of every day/ every 100 MB\u2019s."
NoData
Evaluate if scripts in top 10 pages or so can be externalized and then minified, compressed and cached for optimizing the download time and network bandwidth utilization
NoData
Evaluate if java scripts used in top 10 pages or so can be combined into 3-4 scripts based on the functionality. Infosys involvement required for the analysis
NoData
"Reduce size of applet \u2013 \\n- Remove the class file - TBAProcessor.class_30JUNE2008.class\ \ - from the jar. This is an invalid class file and cannot be used. This will reduce\ \ the size by about\_ 13% since the size of the file is about 37 KB.\\n- Compile\ \ the source with -g:none option to remove the debugging information. This reduces\ \ the size between 5-15%.\_\\n- Use tools like PMD to identify and remove unused\ \ classes and methods from the jar file."
NoData
Evaluate the option of storing the static content on a couple of web server accessed through a load balancer. Static content will thus be downloaded only once from a web server.
NoData
There is an opportunity to reduce the response time at the Load Balancer end. Currently, the Load Balancer reads through FAB_Master.txt file for every request and creates a multi-dimensional array (holding items like url, port, max-users etc against the FAB Id).\n\nBased on single user test on my machine I am observing that this process consumes almost 90% of the total time taken by the Load Balancer. I am proposing that since the file does not change often, we should not read and build the array for every request. The array should be re-built only if the file changes. Based on tests on my machine, I think this will cut the over-all response time by more than 80%.\nCan we have this approach reviewed by the development team?
NoData
CPU's are getting stressed significantly when the EOD/ BOD batches are executed. Very high queue length is observed. Need to check if the batch load can be re-distributed before the server saturation starts affecting batch windows.
NoData
Number of interrupts on CPU 512 was very high compared to other processors. Its in the range of 8-10K while others are less than 1000. This can slow down the processes attached to this CPU. \nNeed to log a call with SUN Admin to analyze further. This has been discussed with the production team (Nitin Gupta)
NoData
Machine with 32 GB RAM machine is showing signs of low memory.  High paging activity was noticed. Server needs to be augmented with memory. \nAlternatively, the load on the server can be reduced so that the number of processes are reduced
NoData
OS level:\nIn Veritas enable VxFS  options (e.g. "mincache=direct" and "convosync=direct") for Direct I/O or Quick I/O feature ONLY for ALL Oracle filesystem files.\nDisable Veritas filesystem cache.\nOR\nEnable VxFS Direct I/O or Quick I/O feature on a per-file basis to bypass the above problem.
NoData
"\u201Clog file sync\u201D is as high as 15% DB time\\n- Redo logs in faster\ \ sub system required (RAID 0) \\n-LGWR and ARCH should be reading separate disks\ \ \u2013 needs to be reconfigured"
NoData
"1) \"cursor: pin S\". This is a Oracle Bug\\nBug with Oracle \u2013 touch\ \ base with Oracle support to get fix \\n2) \"latch: session allocation\". Highest\ \ users # 18,454\\nDB is hitting sessions limit and will cross the limit soon. Review\ \ following parameters\\nshared_server_sessions is set as 17500.\\nlicense_max_sessions\ \  is set as 21000\\nlicense_max_users is set as 13500\\nlicense_sessions_warning\ \ is set as 1900"
A worker can handle no more than 1024 simultaneous connections.
It is strongly recommended that to deploy Nginx on Linux OS for better Performance and High Scalability.
Slow queries affects database performance and overall application performance.
The slow query log feature needs to be enabled in MySQL Database. This feature in MySQL enables logging of queries that exceed a predefined time limit. This greatly simplifies the task of finding inefficient or time-consuming queries. The long query time should be set to 1 second. Periodic monitoring of slow logs needs to be required for fine tuning of the application.
Opening and Closing Database Connection for every request adds an overhead on MySQL Database and impact the response time of the APIs.
Database connection should be persistent and same connection should be used for multiple requests communicating to the MySQL Database.
IFoundry Application is hosted on the Genie Application Server (162). Sharing the environment of Genie Application with other applications
It is strongly recommendaded that to move other applications to a diiferent server.
Other Applications are hosted on the MySQL Database (81)
It is strongly recommendaded that to move other applications to a diiferent server.
Upstream Connection between Nginx and App Server are not persistent
Upstream Connnection should be persistent and same connection should be used for multiple requests communicating to the App Server. Connection KeepAlive needs to be configured on Nginx Configuration.
multiple database on the server Low memory available
1) We suggest to increase 50%  memory on the server inorder to handel 3x load.\n2) Also need to move any other application database present  on the server to a different server inorder to reduce the resource crunch
Control file are not mutiplexed
The control file should ideally be stored on different location (multiplexed ) as to protect the database in case of any media coruption on the disk .
Risk of losing both Datafiles and Redo Log
1) We recommend to separate Datafiles from On-line Redo Log Files as this reduces LGWR and DBWn contention.\n2) It also reduces the risk of losing both Datafiles and Redo Log Files if a disk crash occurs.
Average Execution time of 299- 520 secs.
The Query is executed on the AUD$ table hourly, which can be executed only when needed.
High resource consumption
The reporting queries are heavy and need to be executed post business hours or on the DR site to avoid resource consumption and to create more headroom for the production queries.
Average Execution time ranges between 250 -370 sec.
This query is executed from the OEM (Oracle Enterprise Manager),Ideally this queries the audit table and if the table has high number of records then the audit table needs to reduced periodically .
High Resource consumption
Output of getUserDetails API needs to be cached on Nginx or Im-Memory-Cache for better Performance. Nginx can be used as a caching layer and these requests will be served from Nginx itself.
High Resource consumption
Output of getProduct API needs to be cached on In-Memory-Cache for better Performance. And these requests will be served from App Server itself.
Duplicate calls
Implementation needs to check and Redundant calls needs to be removed to improve the performance.
Duplicate calls
Implementation needs to check and Redundant calls needs to be removed to improve the performance.
High resource consumption
For high performance applications, Debug Mode should be disabled. Please set this value to debug="false" on production web.config file.
High resource consumption
For high performance applications, Debug Mode should be disabled. Please set this value to debug="false" on production web.config file.
High resource consumption
For high performance applications, Debug Mode should be disabled. Please set this value to debug="false" on production web.config file.
high memory consumption
1) We suggest to increasing the SGA  memory by 6 GB on  server for  handeling  the current load.\n2)Also once the SGA memory for the database is increased, then available memory on server will be limited so inorder to support the expected 3X load the memory needs to be increased by 30 %.
Availaibility Issues
1)We recommend to separate Datafiles from On-line Redo Log Files as this reduces LGWR and DBWn contention.\n2)  It also reduces the risk of losing both Datafiles and Redo Log Files if a disk crash occurs.
Availaibility Issues
1)These queries with high resource consumption &  execution time need to tuned and corresponding indexing need to be validated .\n2) Also need to consider data purging where it is possible. Partitioning of the table will also be helpful but this may need additional license
High resource consumption
Important to have statistics updated as it helps to improve the   query executions . So we suggest to check statistics bi -weekly and schedule the stats gather activity in non working hours.
Risk of losing both Datafiles and Redo Log Files if a disk crash occurs
1)We recommend to separate Datafiles from On-line Redo Log Files as this reduces LGWR and DBWn contention.\n2)  It also reduces the risk of losing both Datafiles and Redo Log Files if a disk crash occurs.
Database slowness
The table fragmentation needs be to taken care as the query execution is hampered  .
Database slowness
1)These queries with high resource consumption &  execution time need to tuned and corresponding indexing need to be validated .\n2) Also need to consider data purging where it is possible.\n Partitioning of the table will also be helpful but this may need additional license
Database slowness
Important to have statistics updated as it helps to improve the   query executions . So we suggest to check statistics bi -weekly and schedule the stats gather activity in non working hours.
Availaibility Issues
1)We recommend to separate Datafiles from On-line Redo Log Files as this reduces LGWR and DBWn contention.\n2)  It also reduces the risk of losing both Datafiles and Redo Log Files if a disk crash occurs.
Workflow Delay
Open Source alternatives are available which can replace Filenet system. We propose adoption of OpenKM or Apache Jack Rabbit which fits the requirement of TeBT. The application can be hosted on AWS and AWS-S3 can be used as storage to store the physical documents. However, both these alternatives do not support OCR. In our assessment, OCR feature is not used in Filenet (in the current TeBT platform).
Workflow Delay
Need to convert this batch process as web service integrating with TeBT application so that it can be called dynamically. And it should appear as bucket list on TeBT OPS portal for each scrutiny user for the scrutiny process, so that he/she can act immediately on assigned applications.
Workflow Delay
1. There are a lot of adhoc requests which are not getting tracked. We strongly recommend that for any adhoc request on running these batches, it should documented and published so that there is an accountability on execution of each batch job and its impact on the system as a whole.\n\n2. It is also recommended that for batches which takes higher time for processing, there is a clear case for converting them into real time service. In case of jobs running in a batch, it is observed that the job will wait in the process queue, until the batch is triggered. This means that the job will be waiting idle until it qualifies to be executed in the particular batch. This in result will lead to jobs getting delayed in the entire workflow. If these batches are converted into real time service, the job will be executed then and there and will be made available to the next process queue. This will benefit in total turn around time of the jobs.
Workflow Delay
It is recommended that the batch execution frequency is reduced from 30 mins to 10 mins. Next workflow task for scrutiny will be available 20 mins faster than the current scenario.
High CPU Utilisation and High IO Writes
This is a known bug and we have  raised a PMR (service request) with IBM on the same.  PMR number is TS001340458\n\n1. We need a patch for the current BPM version - 8.0.0.5 (This patch has been provided for 8.0.1. Pls see if this can be retrofitted for 8.0.0.5).\n\n2. We propose an upgradation of the current BPM version to the latest stable version (8.5 or greater). This will also ensure we have support from IBM as the current version is desupported. \n\nThe patch will ensure the email notifications are not locking the table, in result impacting slowness in BPM and TeBT platform as a whole.
Workflow Delay
We propose an upgradation of the current BPM version to the latest stable version (8.5 or greater). This will also ensure we have support from IBM as the current version is desupported. \n\nThe application currently writes around 300 records per second. This is impacting the input/output streams. This will be optimised and the BPM application response time is expected to improve further.
Workflow Delay
It is a product bug and the fix will be available in next release.
High Response Time
The OEM license and setup is already available with HDFC Life. It is highly recommened that we start utilising the OEM capabilities to monitor the heath of all Oracle Databases.\n\nThis will benefits us in the following :\n1. To do database administartion activities for RAC database and clusterware.\n2. To identify the performance issues quickly.\n3. To tune the bad performing SQL's using Oracle's SQL Auto Tune feature.\n\nHowever, pls note that the performance tuning pack in OEM is a paid feature in OEM and need a spperate licence for that. We suggest to also procure license for the performance tuning pack as well.
High Response Time
'We propose to increase JDBC connection pool across all the SOA layers (Front office, back office, Branch and BPM - WAS clusters). \nThe proposed increase is by 50% where existing connection pool value is less than 110. For values more than 110, there is NO change is required.\nNote: \n1) Please make changes to only those data sources which are related to TeBT application flow, other need not be changed.\n2) Please make one changes to one WAS cluster at a time. Once it''s stabilized then proceed for the next cluster. \n3) Also, do not make more than one change at time to ensure that it can be rolled back\nThis will ensure the system has higher pipeline to accommodate more connections/requests. In the embedded image, proposed plan to implement the connection pool across all the related servers have been highlighted.'
System lags statbility and tracebility.
Use APM tool to monitor the systems, alerts.
Old Framework used for .Net
It is recommended to use .Net 4.5 framework
No process document available.
In SDLC Process we must prepare HLD, DLD, Sequence Diagrams of each workflow and User Manual documents.
NoData
Maintain NFR document.
Maintenance
Please enable the index monitoring on the tables like DET_TRADE,DET_TRADE_DELETED. Please drop the indexes if not used by any queries. It will release the space and improve the performance of the related queries significantly.
Maintenance
1. Please gather the statistics for important tables on reguler intervals..\n2. For highly transactional tables, reduce the frequency(Interval) of the gather stats.\n3. Instead of collecting the stats for entire table, we can collect the stats on partition only which is stale stats(In case of Partition tables).
Maintenance
Defrag the high fragmented tables, which will release the space and improve the performance of the database. Tables list attached.
Server Configuration.
'It is recommended to set Thread pool settings in Machine.config as given below:\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs'
Large size of Files.
It is recommended to use pdf file formats for better compression. It is also recommended to use Black and White Form and in that also there should not be any background filled block and Century Gothic font should be used.
High cost Query.
We suggest to create composite  index on DET_TRADES table with column  TRXN_TYPE and TRXN_STATUS.
High cost Query.
The index suggested in previous recommendations will reduce the cost significantly.\n1. The index on DET_TRADES with TRXN_TYPE and TRXN_STATUS.\n2. The index on DET_TRADES_DELETED with REDEEMED_FLAG.
Design
1. It is recommended to create new databases for BLOB images and move all the scanned images BLOB data in it. (We can keep 2 DB Server having BLOB data into it)\n2.It is also recommended to create the tablespace  with 16 K block size for new BLOB database for image data for faster retrival.\n3. It is recommended to keep one month data (Depending upon requirement) on OLTP  database and purge the BLOB data from OLTP database to BLOB database on Monthly / Weekly basis using custom scripts.
Design
It is recommended to take RMAN full backup and RMAN increamental backup.
Design
once split the IMAGE database and OLTP database with dfferent databases then create new databases w.r.t each schema for OLTP.\nIn single server we can have 6 databases. The server configuration will remain same.
Design
It is recommended  that every database should have unique database names while going with spliting of the database.
Design
It is recommended to  check the possibity/other alternatives for eliminiting the use of FOR UPDATE statement according to your business logic.
High count execution.
1. It is recommended to create index on SCHEME_CODE on table POSTING_DATES.\n2. The cost of the query will be reduced 1/3 of the existing cost which will result in faster execution of the query.
High cost Query.
1. It is recommended to create the index on INVESTOR_MASTER table with UPDATE_SERIAL column for the MFAMFI  schema.
No proper Naming convention.
'it is recommended to give proper names to each table for easy identification and maintenance.\nExample: ITNET_MODULE_WORKFLOW_TABLE\nITNET_ADMIN_USER_MASTER\nITNET_SIP_DAILY_TRANSACTIONS'
High cost Query.
It is recommended to create index on DET_TRADES table with TRXN_TYPE andTRXN_STATUS column.
High cost Query.
Check the logic of the queries and reduce the cost of the queries listed.
High Availability
It is recommended to implement RAC Database for handling the future load and for better scalability.
Design
It is recommended to to convert IT.Net in  3 Tier Architecture for better scalability and maintainability.
Design
It is recommended to check all required OS Services in UAT environment and enable only those required services in Production Servers.
Design
An index on foracid,inst_alpha and inst_num to be added.The TRIM function on the WHERE clause fields needs o be removed.
Design
The result set which is joined between GAM and DHT should be less to reduce the high temp space utilization. Please check with the vendor as to why two WHERE clauses of the same nature (APPLICABLE DATE field) is present in the query.Also please check the feasibility of reducing the data fetched for JOIN by extracting data between two dates instead of extracting data which is less than a given data
Design
The data type of EMPLOYEE_NUMBER to be changed to varchar of the same size of USER_ID field of LGT table
Design
Bank to check to check the functional index usage and recreate the index with the respective functional index on sol_id field
Design
An additional sol_id condition by joining the GAM table with SST table for set_id ALL to be added in the WHERE clause
Design
The TRIM funtion in main WHERE clause needs to be removed, Subsequently the data storage of column TRAN_ID of AXIS_CREDIT_CARD should be left padded as in DTD table by using LPAD function. Currently this data is right padded
Design
Increase parallelism for the job groups in the application. HSCOD parallelization to 60 and BJE jobs parallelization to 70 and common env parameter to 50 from current value of 40
Design
Recreate the index with revise column position as per below.\nTO_NUMBER(SOL_ID),TRAN_DATE,SENT_FLG
Design
Perform De-Fragmentation operation e.g. CTAS, Table movement, export-import, DBMS_REDEFINITION
Design
It is recommanded to use compressed image to load and view in Formware application. We have tested the same image after using compression and observed that the total time taken to load and view image has come down to 11 secs from 14 secs for a 1.4 MB file. (Apprach document has also been shared).
Design
Indexes needs to be created on column ORN for table TBLDEMATNSDLDATA
Design
Indexes needs to be created on column ORN for table TBLDEMATNSDLDATA
Design
Index on ORN,NSDL_Batch needs to be created on table tblDematData
Design
Index needs to be created on tblCaseStatus on ORN column and on tblHoldReason table for PassNo and SrNo.
Design
Index needs to be created on TBLFWIMPORTDTLS on FORMTYPE column.
Design
The business logic should be checked to see if any where clause can be added along with the joins. Table TBL_STEP should be defragmented.
Maintenance
These tables needs to be defragmented.
No Parallelism used.
As TBMS application supports multithreading, Large size files need to be split into smaller files and need tobe  processed in parallel.
Maintenance
Large Volume tables needs to analyzed frequently before the month end operation.
Maintenance
Analyse REP_MATURITY_REPORT table before generating this report.
Design
'1) The query needs to be modified to tune the view. \nAn index is already present on cbl_disc_date, however it is not being used because the column is being used in a decode function -- DECODE (cbl_tenor_id, ''B'', cbl_bill_date, cbl_disc_date).\n2) Functional index can be created on this function\n\nE.g :     create index temp2 on cfs_bill_log (DECODE (cbl_tenor_id, ''B'', cbl_bill_date, cbl_disc_date))'
Design
Please modify the query to add jl_start_time is the query for the current index to be used or create an index on JL_STATUS.
Design
The view needs to be rewritten to either not use this table or use a join instead of not exist as it will help eliminate FTS on this big table.
Design
The view needs to be recreated to use the indexes involved. It needs to be checked if the order by is really needed.
Design
Create  indexes on CM_OPEN_DATE and CM_CLOSING_DATE columns or modify the query to use current indexes.
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
Currently autoconfig option in IIS is used so IIS will take default configurations for handling concurrent request which is very less for handling more more concurrent requests and headroom is available in all the servers as per hardware kpi details so this can be increased as per recommendations for handling more concurrent users.
'It is recommended to disable autoconfig and use custom thread pooling  setting in Machine.config as given below for handling more concurrent requests, below settings needs to be tested in UAT environment in high load before moving into production. \n\nautoconfig : false\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs \nminIoThreads 50\nminWorkerThreads 50'
The predictability of the system performance is compromised if constant monitoring is not being carried out. Besides, the time taken for providing a RCA is delayed because the IT teams are not able to have a larger view of the systems. There should be tight integration between the development and the operations (IT) team where the APM tool could be the ammunition available with both the development and operations team to have higher preditability of the applications and system as a whole.
It is recommended to use APM tool which can monitor all the application metrics and hardware KPIs in production environments.
Static contents are taking more time and caching unavailability will hit the systems each time for static content downloading
It is recommended to keep these images, js, css and font files to AMS server and serve from there keeping static caching as given in Sr. No. 6
Unproper timeouts can cause thread blocking for specified period of time which in turn create problems in handling more concurrent user requests.
It is recommended to keep the timeout values  as follows and test these settings in UAT environment :\ncloseTimeout="00:01:00" receiveTimeout="00:10:00" sendTimeout="00:01:00"
Unwanted consumption of resources by other wesbsites which are not relevent to AMS
It is recommnded to move all unwanted websites in other environment
Leads to system hand, system slowness if proper capacity planning and failover testing is not done.
It is recommended to perform fail over testing and do better capacity planning based on given NFRs.
leads to high cpu consumption during code compilations and it can then leads to system slowness
"It is recommended to remove visual studio from all production environment\ \ and don\u2019t do any copilation operations in production environment."
High number of inserts utilizing the resources from the database server.
It is recommended  to reduce the inserts on the ActivityLog table which is really required.
High cost query impacting the performance of the database.
it is recommended to check from which services this query is calling and stop if not required as this is already created in stored procedure.
This will lead to utilize more  space from the storage end and will took more time and resources for AMS database backup.
It is reccommneded to remove the duplicate / backup tables from the AMS database.
This will lead to utilize more space from the storage end and will took more time and resources for AMD database backup.
It is recommended to remove the the tables with zero count if not required.
If the statistics of the table is stale then query optimizer will create plan using misinformation and which will be result in it not choosing the optimal query plan.
It is recommended to update the statistics daily or on alternate days(Depend on the usage of tables) for important tables where more than 20 percent rows changed of the table.
Static content will be downloded from server and unwanted hits will go to server which can be avoided by putting static content configuration and setting its age. Currently proposed 365 days as application runs continuously 24x7 and 365 days.
It is recommended to set Static Content Caching as -\n<staticContent>\n      <clientCache cacheControlMode="UseMaxAge" cacheControlMaxAge="365.00:00:00" /> \n    </staticContent>
Unwanted CSS and JS increases the rendering time of the html pages.
It is recommended to remove unused CSS from the Applicaton.\nAlso for finding unused JS, please comment one by one JS in the UAT environment and check accordingly.
Calling JS on top of the page will increase the rendering time of the html pages.
It is recommended to declare the JS in bottom of the page.
Currently autoconfig option in IIS is used so IIS will take default configurations for handling concurrent request which is very less for handling more more concurrent requests and headroom is available in all the servers as per hardware kpi details so this can be increased as per recommendations for handling more concurrent users.
'It is recommended to disable autoconfig and use custom thread pooling  setting in Machine.config as given below for handling more concurrent requests, below settings needs to be tested in UAT environment in high load before moving into production, it will be further tuned based on performance testing results. \n\nautoconfig : false\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs \nminIoThreads 50\nminWorkerThreads 50'
Unwanted memory will be consumed by all these variables and classes.
It is recommended to remove unused references, classes, methods, variables from the Code.
Processing of  DB calls for all the requests will increase the response time.
It is recommended to use internal cache or hash table to store temporary data from db, in the methods which are used multiple times for reteriving data from database.
Slowness and timeout error observed for end users for the GA application for R1 mission.
It is recommended modify the logic from the code end so that multiple number of same Scheduler should not run on the single server at same time.
Page rendering time increases if static content caching is not present.
It is strongly recommended that after making any changes cross validate that the static content policy should not be overwritten so that caching should work fine.
Unwanted DB Call increases system utilization and decreases the response time of the methods.
It is recommended to remove unwanted DB calls from the Codebase.
The encryption and decryption methods are cpu intensive tasks.
It is recommended to first store the data for mission.Encrypt(), country.Encrypt() and center.Encrypt() in the string variable and used that string variable wherever required.
The response time of login page increases  for each logins as db call is used for getting the configuration data to check whether captcha is enabled or not.
It is recommened to store the configuration values for Google Captcha in the configuration file.
Unwanted DB Call increases  system utilization and decreases the response time of the methods.
It is recommended to remove unwanted DB calls from the Codebase.
This is imapcting quering performance
Deadlocks are bound to occur if the resources are not processed in a well defined order. To minimize deadlocks, all the concurrent transactions should access objects in a well defined orders.\nThere are update  statement on Applicant  table and update is causing the deadlock issue in the database\nQuery=update [dbo].[Applicant] set [FirstName] = @0, [LastName] = @1, [ContactNumber] = @2, [PassportNumber] = @3, [DateOfBirth] = @4, [Gender] = @5, [PassportExpiryDate] = @6, [SubmissionDate] = @7, [IPAddress] = @8 where ([Id] = @9)</
Placing both data , log files and backup on the same device can cuase contention in that disk and resulting poor performance.
It is recommended to use different disks for data and log files.
Application errors caused increase in the system utilization and also increases the response time of the methods.
It is highly recommended to weekly check application log files and resolve any errors found in the log files.
The page rendering time is high since css, js and images are not optimized.
It is recommended to optimize css, js and images as mentioned in the frontend optimization document.
Everytime processing of  DB calls on the pages  increases the system utilization and also increases the response time of methods.
It is recommended to store the output value for GetDownTimeDetails() inside the Session variable or internal cache.
This will lead to more utilization of system resources.
Below are list of some unwanted windows services which needs to be disabled after confirmation from concerned team:\n(Application Information,Application Management,Background Intelligent Transfer Service,Carbon Black Sensor,CNG Key Isolation,Computer Browser,\nDebug Diagnostic Service,Distributed Transaction Coordinator (b0a5e3e1-4843-4dd5-bf68-2cc4ad62d8cb),InMage Scout FX Agent,\nInMage Scout VX Agent - Sentinel/Outpost,Microsoft Software Shadow Copy Provider,NetBackup Deduplication Multi-Threaded Agent,\nPA Collector,Print Spooler,Smart Card Device Enumeration Service,Symantec CCS Agent, Volume Shadow Copy,Windows Connection Manager,\nWinHTTP Web Proxy Auto-Discovery Service,Windows Modules Installer,Windows Update,WMI Performance Adapter).
The predictability of the system performance is compromised if constant monitoring is not being carried out. Besides, It will be very difficult to provide the root cause in case of any issues because the IT teams are not able to have a larger view of the systems. There should be tight integration between the development and the operations (IT) team where the APM tool could be the ammunition available with both the development and operations team to have higher preditability of the applications and system as a whole.
It is recommended to use APM tool which can monitor all the application metrics and hardware KPIs in production environments.
Two different types of similar code needs to be maintained for single web application.
It is recommended to keep only single GA App codebase running in production environment after confirmation with concerned team.
The high elapsed time and CPU utilization.
"It is recommended to create index on  Applicant table as mentioned below.\\\ nCREATE NONCLUSTERED INDEX [Index_Name] ON [dbo].[Applicant]\\n(\\n\t[MissionId]\ \ ASC,\\n\t[CountryId] ASC\\n)\\nINCLUDE ( \t[Id],\\n\t[ApplicantGroupId],\\n\t\ [CenterId],\\n\t[FirstName],\\n\t[LastName],\\n\t[PassportNumber],\\n\t[DateOfBirth],\\\ n\t[EmailId],\\n\t[PassportIssueDate],\\n\t[GWFNumber])"
Synchrounous logging increases the response time with more concurrent user requests.
It is recommended to implement ascynhronous logging using log4net.
Unwanted memory will be consumed by all these variables and classes
It is recommended to remove unused references, classes, methods, variables from the Code.
Recompilation of code to be done if any hard coded values are changed which need system downtime in production environment.
It is recommended to read the hard coded values from the Config files.
Difficult to trace end user journey if no logging pattern is followed.
'It is recommended to use given below logging pattern:\n\n<DATE TIME> <LOGLEVEL> <THREAD ID> <CLASS NAME> <REQUEST SENDING TO> <COMPONENT-NAME> <REQUEST DATA WITH MOBILE AND CUSTOMER ID/PASSPORT NO> <TIME TAKEN IN PROCESSING REQUEST> <TIME IN SECONDS>\n\n<DATE TIME> <LOGLEVEL> <THREAD ID> <CLASS NAME> <RESPONSE RECEIVED FROM> <COMPONENT-NAME> <RESPONSE DATA WITH MOBILE AND  CUSTOMER ID/PASSPORT NO > <TIME TAKEN IN PROCESSING RESPONSE> <TIME IN SECONDS>\n\nNOTE: Exception should be printed completely in different log file.'
The predictability of the system performance is compromised if constant monitoring is not being carried out. Besides, the time taken for providing a RCA is delayed because the IT teams are not able to have a larger view of the systems. There should be tight integration between the development and the operations (IT) team where the APM tool could be the ammunition available with both the development and operations team to have higher preditability of the applications and system as a whole.
It is recommended to use APM tool which can monitor all the application metrics and hardware KPIs in production environments.
The parallel execution of the query will be restricted with the defined value.
It is recommended  to set the value of max degree of parallelism to 0. With this sql server will detect the best degree of parallesim to use for the query execution.
Unwanted database are consuming resources like CPU and Memory
It is recommended  to check all the database and remove unwanted database instance from DB server
Uwanted processing of Queue with 0 length, IO is increased in this function and also unwanted iteration is done.
It is recommended to optimise this function with proper logic with proper Unit Test
Unwanted execution of Timer will consume the system resources un-necessarily.
It is recommended to remove unwanted Timer from the application.
Design
Create  indexes on SPH_FROM_TIME and SPH_TO_TIME  columns or modify the query to use current indexes.
Design
Create  indexes on CMH_FROM_TIME  and CMH_TO_TIME  columns or modify the query to use current indexes.
Design
The View needs to be rewritten to use the indexed column UT_LABEL_ID which is indexed.
Design
The View needs to be rewritten to use the where clause. Currently there are no where clause being used.
Design
Calling URLs needs to be modified to comment out the lines calling non existing pages.
Design
As these are static files which can be picked from the client rather than the server when recalled, these files should be cached.
Design
Images stored in PNG formats are the lightest extensions for images. All the images should be converted into PNG files
Design
JS files needs to be placed at the bottom. Common js files called sequentially can be placed in a single js file and called.
Design
Js files should be minified.
Improper RAID level.
Use RAID 1 + 0  for transaction logs & Datafiles
Design
Remove ToString.ToUpper method call for such cases.\nFor eg. (flag != null && flag.ToUpper().Equals("Y".ToString.ToUpper())) can be written as (flag != null && flag.ToUpper().Equals("Y"))
Design
Instead compare can be used which will internally check for case sensitivity. (str1.ToString.ToUpper().Equals(str2.ToString.ToUpper())) can be written as (string.Compare(str1, str2, true) == 0), it will work well and efficiently.
Design
All resources should be closed in finally block only.
Design
Check for null before accessing cache items.  This will help in avoiding any exceptions which are caused by null objects.
Design
Fetch static data from cache outside the loop.
Design
1. index to be created on  central_brd_drct_tax table on pmt_status on column.\n2. index to be created on  pmts table on pmt_stat on column.
Maintenance
CUSR table needs to be defragmented.
Maintenance
acct_master table needs to be defragmented.
Design
index to be created on user_report_table table on columns act_code,access_channel
Design
create index on payment_vat table on pid column
Slow Rendering of page
These need to be converted to js files. Which can be moved to bottom of body
Slow Rendering of page
Specifying a width and height for all images allows for faster rendering by eliminating the need for unnecessary reflows and repaints.
Slow Rendering of page
Check if js and css files can be combined and compressed. For small background images CSS sprite can be used. ( Pt 5 to 11 apply for other webpages of portal application )
Process
To ensure CSS files are downloaded in parallel, always include external CSS before external JavaScript.
Process
Configure CDN to deliver static contents ( css,images,js )
404 Error
Fix paths or deploy documents to avoid 404 errors
404 Error
The referrer pages need to have the block commented which is calling these not found pages. Alternatively, the objects needs to be placed in the path where it is being referred to so that 404 hits are eliminated.
No Load Balancer used
It is recommended to have load balancing in place, so that the load is evenly distributed across all vm instances
Compression not used.
Compression of javascripts, css, jpegs, gifs files.\nPlease refer below sheets for compression details:\n1. CSS_Compression\n2. JS_Compression\n3. Image_Compression
404 Error
Remove links from application responsible for 404 errors or fix the path to the static contents shared. \nPlease refer 404_Bandwidth sheet for more details.
Unncessary links in the code
For enabling caching, on the web server, we suggest you to make some modifications in the httpd.conf file in the web server.The caching can be done for the frequency defined by you. For now, we have made it as 1 week. This frequency will depend on the frequency of modifications that is generally made on these static objects.\nPlease test this extensively on one of the UAT server, and if results found okay, can be put in production.\n#Enabling Caching for Static Objects\nLoadModule expires_module modules/mod_expires.so\n#Enabling Caching for Static Objects\n<IfModule mod_expires.c>\nExpiresActive On\nExpiresByType image/gif "access plus 1 week"\nExpiresByType image/jpg "access plus 1 week"\nExpiresByType image/jpeg "access plus 1 week"\nExpiresByType image/png "access plus 1 week"\nExpiresByType text/css "access plus 1 week"\nExpiresByType text/html "access plus 1 week"\n</IfModule>
No Backup policy.
Need to configure backup policy since servers are in production environment
Memory Leak
We have identified pattern for connection leaks. As per our discussion, development team will provide us files for review in which connection leaks are fixed, team have commenced work on the same already. Also connection pooling implementation needs to considered
Design
'Approach to handle this : The Transaction is created at GBM but not at Finacle, so whenever the user tries to create another transaction at GBM, the system should indicate that a transaction is already created for a the same account and same amount, and finacle transaction pending for the GBM tran id. The user should be given an option to go ahead and create a new tran or delete the pending tran at GBM.'
Design
Connection has to be closed, otherwise the sessions will keep increasing on the database.
Design
The data type of EMPLOYEE_NUMBER to be changed to varchar of the same size of USER_ID field of LGT table
Maitenance
Perform De-Fragmentation operation e.g. CTAS, Table movement, export-import, DBMS_REDEFINITION
Design
For these tables stats to be gathered in regular interval. Database should be monitored that no table goes for stale stats
Design
Check for null before accessing cache items.  This will help in avoiding any exceptions which are caused by null objects.
Design
1. index to be created on  central_brd_drct_tax table on pmt_status on column.\n2. index to be created on  pmts table on pmt_stat on column.
Maitenance
acct_master table needs to be defragmented.
Maintenance
Duplicate indexes on payee_master table are observed one can be removed.( pmt_id , del_flg /del_flg,pmt_id).  defragmentation on pmts and payee_master table is required.
Design
create index on payment_vat table on pid column
Maintenance
PLOG table needs to be defragmented.
Maintenance
customer_payee table needs to be defragmented.
Maintenance
customer_payee table needs to be defragmented.
Design
The business logic lies with Infosys. Need to understand for such volumes why so much time is spent for batch execution.
Design
Need to understand the reson for executing update over the insert on same columns
Design
'Fetch static data outside the loop, do data modification there itself(if require) and store it in a new object for further processing.\n\nReference : Srl 6.\nInt primAccount;\nif(cm.getString("userAccountIndex") != null)\n{\nprimAccount = cm.getInt("userAccountIndex");\n}// if close\nfor(condition) // loop start\n//some code\nString refValue = Convert.ToString(primAccount); // code marked in red can be move before loop start inside if condition\n//some code\n} //loop end\n\nReferences : Srl 7.\nfor(condition) // loop start\n{\nfield125 = "SCH" + vo.getCIDN() + cache.getString("stdntRegId").PadRight(10) + cache.getString("schlid1").padRight(6) // code marked in red can be move before loop start\n} // loop end'
Design
Such method calls needs to call first before loop starts rather than calling it inside loop.\nfor(int i = 0; i < ba.count; i++)\n{\nGUCTVO guctchallanvo = (GUCTVO)ba[i];\nDebitAcNo = guctchallanvo.getDEBT_ACID().ToString().Substring(0,4);\nBranchID = BranchCodeDescription.getDesc(userInfo.bankId(), solid, cache); // code marked in red can be move before loop start \nGuctchallanvo.setbranch_ID(BranchID);\nbaList.Add(guctchallanvo);\n}\n\nBranchID = BranchCodeDescription.getDesc(userInfo.bankId(), solid, cache);\nfor(int i = 0; i < ba.count; i++)\n{\nGUCTVO guctchallanvo = (GUCTVO)ba[i];\nDebitAcNo = guctchallanvo.getDEBT_ACID().ToString().Substring(0,4);\nGuctchallanvo.setbranch_ID(BranchID);\nbaList.Add(guctchallanvo);\n}
Design
Application needs to be restructuring to more generalized/parameterized structure to avoid lots of code file creation and also to avoid more memory consumption.
Design
Use StringBuilder.Append() method once to generate query. No need to call StringBuilder.Append() method 3 times on 3 different lines to generate query.
Design
Order by clause not required in query to fetch data in ascending order. Default order is ascending.
Design
Place one copy of faq page in Corporate domain and fetch the same from that location.
Design
There should be an intermediary landing page, which should only show the details for the primary account (Saving Account), and there should be a link for the other schemes.\n On clicking this, it should highlight all the other accounts linked.
Design
Bill Desk Vendor needs to tune this.
Design
"a. The js functions are written inline in the aspx page. The js file should\ \ be written outside and should be called through a link in the aspx file. This\ \ will load the page faster.\\nb. Check why there are so many js validations done\ \ for a static page. Eg. For disclaimer page, there are only two buttons \u201C\ I Agree\u201D/\u201DI Disagree\u201D but there are multiple js validations written\ \ on the page.  \\nc. There are multiple js files being called sequentially one\ \ after another. This should be collated into a single file so that the on load\ \ of these js files happens just once. Eg. RetailShoppingMallLogin.aspx has multiple\ \ js files loaded sequentially one after another."
Design
Need to understand from Infosys, why does it take such high time for first time loading.
High 404 Status Errors
Source Code at DirectRates Application should be corrected to remove reference path of scwblank.html
Less Secure
Enable security on Dealer.xml, Margin.xml and Currency.xml Files, So that files are not accessible without Authentication. Also please check the feasibility of Encryption for these files. Reference http://support.microsoft.com/kb/815152
High Bandwidth Usage
Please compress XML Files on creation and decompress it at the time of consumption. Also please check the feasibility of replacing XML Files by Ajax Call for filling Dropdown Controls.
High IO
Please set this value to debug="false"
Pocket loss
Win 32 status 64 from IIS logs suggests that the network packet is being lost. To be taken up with the network team.
Deadlock Errors
Use Hint With NoLock in Select Statements for Table DealSlip_IntermediateBlotter and DealSlip_CounterParty
404 Errors in IIS Logs
web.config file should be corrected to remove reference path of the files from the `customErrors` tag.
NoData
Please change the data type of variable `mailtable` from String to StringBuilder.
NoData
Integration of all schedulers into one common scheduler will help in solving the problem. Recommended Architecture is described in the next sheet.
NoData
Please use list parameter to fetch and update records of all the clients in a single operation. Recommended Interface is described in the next sheet.
NoData
Please use configuration file to store the database schema name.
Compilation Setting in web.config
Please set this value to debug="false"
InvalidCastException in Event Viewer
In `frmFwdUtiliazationDeals.aspx.cs` File, Please check the following condition before Line numbers 1367, 1368, 1372 and 1373:\nif (!(dr["ColumnName"] == DBNull.Value))
Application Code Review
'Please remove the commented javascript code from following pages: frmDealDetails.aspx, frmDealReport.aspx, frmDeals.aspx, frmFwdContractDeals.aspx, Logout.aspx, frmFwdContractDealsDetails.aspx, frmFwdUtiliazationDeals.aspx, frmFwdContractDealReport.aspx, frmDealReportKplus.aspx and jsDeal.js'
Response Time high
Only selective columns should be included in select query from product, this reduces the data transfer from DB to APP
Response Time high
These needs to be moved to the bottom of the body. This would allow the browser to download all contents in the page in a non-blocking manner.
Response Time high
Configure CDN to deliver static contents ( css,images,js )
Workflow Delay
Analysis of storage performance logs need to carried out, Data from storage team is awaited
Workflow Delay
The referrer pages need to have the block commented which is calling these not found pages. Alternatively, the objects needs to be placed in the path where it is being referred to so that 404 hits are eliminated.
Response Time high
Remove links from application responsible for 404 errors or fix the path to the static contents shared. \nPlease refer 404_Bandwidth sheet for more details.
Workflow Delay
For enabling caching, on the web server, we suggest you to make some modifications in the httpd.conf file in the web server.The caching can be done for the frequency defined by you. For now, we have made it as 1 week. This frequency will depend on the frequency of modifications that is generally made on these static objects.\nPlease test this extensively on one of the UAT server, and if results found okay, can be put in production.\n#Enabling Caching for Static Objects\nLoadModule expires_module modules/mod_expires.so\n#Enabling Caching for Static Objects\n<IfModule mod_expires.c>\nExpiresActive On\nExpiresByType image/gif "access plus 1 week"\nExpiresByType image/jpg "access plus 1 week"\nExpiresByType image/jpeg "access plus 1 week"\nExpiresByType image/png "access plus 1 week"\nExpiresByType text/css "access plus 1 week"\nExpiresByType text/html "access plus 1 week"\n</IfModule>
Workflow Delay
"To improve the Response time of these pages,  below steps needs to be carried\ \ out\\n1. Compress js files, css files and images - Please refer below sheets for\ \ compression details:\\n1. CSS_Compression\\n2. JS_Compression\\n3. Image_Compression\\\ n\\n2. Enable caching for static elements which doesn\u2019t change for a long time\ \ like css, images.\\n\\n3. Remove unwanted links ( 404 errors ) from pages"
Workflow Delay
Need to configure backup policy since servers are in production environment
Response Time high
'-  There are no bind variables being used for the query, it is recommended to use bind variables so that query can reuse the cached plan. The query is coming from "PHP freetds" application.\n   -  The view View_enquiry_bookinghistory used in query refers to another view view_liaisonbookingqt which is having booking id column of bkbookingmaster table. This column is primary key and view definition checks for "not null " constraint on this column, which is not required and can be removed from view definition.\n   -  There are like operators in where clause and as confirmed by team, these can be removed. Since like operators are expensive to use in where clause.\n   -  Team has confirmed we can use table joins to get data out of this query instead of using the view.'
architecture
After discussion on 24-Dec-14,  details from database table to validate inserts and accessed pages will be provided by team for further analysis. Also need understanding on ckcontent inserts pattern change.
Workflow Delay
We have identified pattern for connection leaks. As per our discussion, development team will provide us files for review in which connection leaks are fixed, Gurpreet and team have commenced work on the same already. Also connection pooling implementation needs to considered
architecture
CNK team has confirmed as part of procedure optimization, this condition has already been removed and instead of temp tables, temp variables are being used now
Response Time high
Need to involve network team to have discussion on this.
architecture
Create index on bkservicesbooking table on booking_id column
Configuration
1. The long running processes - (Heavy queries highlighted below in the tracker) needs to be tuned so that the active no. of processes is limited. \n2. There are queries which are in inactive state which is basically leading to process hog. There is one query on the DB which has been observed to be contributing to 70% of the inactive session count. Refer Inactive Statistics every 15 min and Inactive-Query Reference tracker for the details.\n3.If the workload is increasing, the processes and session parameters on the DB should be increased. The values from v$session and V$process needs to monitored at high loads to arrive at the exact figure. The session value should be 1.5 times the process value.\n4. Look at all possible cases where connections has been left open, and put a connection close at the finally block. Start with the queries which are in inactive state throughout the day.
Query Optimization
The SP should be modified to add exceptions. With the absence of exceptions, transaction failures are not getting captured. The exceptions can be added to process such cases seperately.
Maitenance
the referrer pages need to have the block commented which is calling these not found pages. Alternatively, the objects needs to be placed in the path where it is being referred to so that 404 hits are eliminated.
Configuration
To avoid slowness in Paypro Application, make sure c3p0.debugUnreturnedConnectionStackTraces value is set to false on all application server. debugUnreturnedConnectionStackTraces is intended to be used only for debugging, as capturing a stack trace can slow down Connection check-out.
Maitenance
"Complete List has been shared with the team. We would need to carry out\ \ the following steps :\\n\\n\u2022 Identify the tables which are not being used\ \ by the application/utility.\\n\u2022 Freeze the tables in a permanent backup\\\ n\u2022 Drop the redundant/unwanted tables."
Maitenance
"Complete List has been shared with the team. We would need to carry out\ \ the following steps :\\n\\n\u2022 Identify the tables which are being used by\ \ the application/utility.\\n\u2022 Isolate these tables and defragment it.\\n\u2022\ \ Consult the application team/product vendor on creating clustered index on tables\ \ where heap is more than 70% fragmented."
Query Optimization
A nonclustered index can be created on userlog table on columns sessionid and sysuserno.
Configuration
WebRequest Object should be created once and will be reused for every request.
Configuration
As TBMS application supports multithreading, Large size files need to be split into smaller files and need tobe  processed in parallel.
Query Optimization
As we do not have the source for this procedure, please involve TBMS team to validate what is the sql text for this procedure and check if this can be further tuned.
Query Optimization
Either remove the trunc function for both the tables, or create a functional indexes on TRUNC(CI_EXTRACT_DATE) on CSTM_INTEREST and TRUNC(CII_EXTRACT_DATE) on CSTM_INTEREST_INTEREST tables.
Query Optimization
Please modify the query to add jl_start_time is the query for the current index to be used or create an index on JL_STATUS.
Query Optimization
The view needs to be recreated to use the indexes involved. It needs to be checked if the order by is really needed.
Query Optimization
Create  indexes on SPH_FROM_TIME and SPH_TO_TIME  columns or modify the query to use current indexes.
Maitenance
Update the data structure every time the rate changes i.e. end of the fswPrimact_Changed and fswJPY_Changed functions
Code review
List of compressed JS ,css, ASPX files shared. Caching when done on these objects will reduce the round trips.
Code review
Can Remote server and FLMS application be co-located on the same server to reduce the network latency?
Code review
Can we have the  Hybrid data configuration i.e InMemory database with the Sql server database on the disk. The frequently accessed data like sessions can be fetched from the InMemory database.(Development team was supposed to the analysis on this point by 3rd july).
Query Optimization
Can the Cut off Mechanism be handled in the application rather than the DB. This SP should be called only when the input parameters have valid values.(Development team was supposed to the analysis on this point by 4th july)
Code review
Avekshaa has shared the recommendations on all the JS files which have been compressed. The development team need to validate the recommendations and implement it.
Code review
The thread sleep should be eliminated
Code review
The operations can be eliminated to increase throughput.
Code review
Thread.sleep should be eliminated
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Configuration
Parameter pga_aggregate_target is currently set to 1024M. It should be increased to 2048M.
Configuration
Configure temporary and data files on separate mount points/disks.
Configuration
Configure undo data files and other data files on separate mount points/disks to improve IO distribution and have better space management.
Configuration
Perform data file  movement to make some space available. Do take a note that these 2 mount points host temporary files too.
Configuration
Remove one which is unused. This has no impact on performance but is a better practice to follow.
Code review
Overall throughput of the batch file polling can be improved if this is converted to a multi-threaded model.
Code review
We propose that RAC based database deployment be configured to avoid database being a SPOF.
Code review
These servlets should be loaded during server boot up rather than during first usage. Add servlets in web.xml  under InitServlet section.
Code review
Currently, salary batch is processed one-file-at-a-time.  This is the primary reason for a delay between salary file arrival time and its process initiation time.\nFile processing should be done in a concurrent manner using ThreadPool or PooledWorker technique.
Query Optimization
Remove the hint which will reduce the execution cost of query by using index unique scan on location_pk.
Code review
Improvement to exisitng logic of processing Reverse File Gen Corp:\nCurrently, when an Excel file triggers an OOM error the status of the file remains unchanged and hence when App server restarts it picks the same file and that too crashes due to OOM error. This loop continues and blocks other good files from being processed. This flow/logic can be chnaged to add one more status to the files. Currently, each reverse MIS file has only 2 statuses, Unprocessed and Porcessing Finished. Adding third status of "Processing Started" should help alleviate above loop problem. At the outset, file status would be "Unprocessed". Flow should first pick up unprocessed files for processing. Very first thing to be done is to change its status as "Processing Started". Once entire processing for the file is finished, update the status to "Processing Finished" (This is current logic. No change is needed.). When there is an error like OOM etc, the file status will remain "Processing Started" and hence this errorneous file will not be picked during subsequent runs. Once all files with status "Unprocessed" are completed, flow can loop through files with status "Processing Started". With this change, erroneous files won't block other good files from being processed thus improving reliability of the application and will also add retry logic for erroneous files.
High CPU
Since infyaccount.jsp has a dependency on data set by crosssell_drop.jsp, initiate infyaccount.jsp in the Ajax call only after the crosssell_drop.jsp processes the request
Code review
Database connection and Statements instance always needs to be created in try block and  closed  in finally block as following
Code review
Define Property class as a singleton. Load properties values on first loading of this class only (put properties loading code in static block) and assign properly value to respective instance value. Also change instance variables from public to private and provide getter method to access these instance values.
Code review
The thread pool settings have also been optimized. The thread count was reduced from 800 to 400. Only about 200 threads are utilized.
Deadlock Errors
'Create Index in Table: DealSlip_CounterParty for columns: CP_KShortName, PK_CP_ID, CP_IsActive'
Found Error `The maximum number of rows in an excel worksheet
Limit the maximum period on Front End for creating the Excel File.
466 ViewstateErrors
Check Application Pool Recycle Settings in IIS. Please ensure that it will recycle only during non working hours. Reference http://msdn.microsoft.com/en-us/library/aa720473(v=vs.71).aspx\n\nViewState Stettings are already implemented in web.config\n\nAnother cause of this error is that, Page Postback occurs before the Page does not Loads completely. To resolve the problem mark the form as disabled and then enable it in script once the page load is complete.\nfunction enableForm() \n{ \n      document.getElementById("form").disabled = false; \n} \nwindow.onLoad = enableForm();
Found Error `Error during serialization or deserialization using the JSON JavaScriptSerializer.
Set the MaxJsonLength property in web.config:\n\n<configuration> \n   <system.web.extensions>\n       <scripting>\n           <webServices>\n               <jsonSerialization maxJsonLength="50000000"/>\n           </webServices>\n       </scripting>\n   </system.web.extensions>\n</configuration>
NoData
Create primary key on PK_Dealid on table DealSlip_IntermediateBlotter which is being referred to in multiple places in the SP so that it can be used as a clustered index in the table.
NoData
Create primary key on PK_Dealid on table DealSlip_IntermediateBlotter which is being referred to in multiple places in the SP so that it can be used as a clustered index in the table.
High Response Time
Index on CP_KCOUNTerpartyid to be created on table dealslip_counterparty
High Response Time
To validate from the data populated in the table if LTRIM,RTRIM and not null checks are required for DD_MiscCounterPartyName,DD_DealerName,DD_ForDealerName,DD_PartyName used in case of data access from dealslip_dealdetails table.
High Response Time
To validate from the data populated in the table if LTRIM,RTRIM and not null checks are required for CP_KCounterPartyName used in case of data access from dealslip_counterparty table and CU_CurrencyCode from DealSlip_Currency table.
High Response Time
Please implement Viewstate Compression in ASPX Pages. Reference http://www.codeproject.com/Articles/14733/ViewState-Compression\nAlso please check the feasibility of disabling viewstate for those controls which do not need that.
Code repeated
Please move the Generic Code to Common Classes. And call them from classes of ASPX Pages by passing required parameters.
NoData
Please remove sessions after their usage. Specially for those sessions which stores DataTable or Class Objects.
Found Type Conversion for DataTable Cell Values
Type Conversion is not required for DataTable Cell Values. By default, Value is of same Type which is defined in the Column of DataTable.
Found `if` condition which is called even when not required.
Replace `if` condition by `else if` condition.
Found common code in both `if else` condition.
Move common code above the `if else` condition.
Throw Exception` for Error
Try-Catch Block is not required. By default, Global.asax will catch the exception.
NoData
Please remove sessions after their usage.
NoData
Please remove sessions after their usage.
NoData
Remove unwanted `if` conditions, which is always satisfied.
Found duplicate assignments
Remove duplicate assignments operations.
Found `if` condition for Null and Empty are different
Combine `if` condition for Null and Empty into single one using `string.IsNullOrEmpty`.
NoData
Type Conversion is not required for DataTable Cell Values. By default, Value is of same Type which is defined in the Column of DataTable.
Found `if` condition for Null and Empty are different.
Combine `if` condition for Null and Empty into single one using `string.IsNullOrWhiteSpace`.
High CPU
Use Type `int16` instead of `int` in `For Loop` and Counters where small numbers are stored.
'`Throw Exception` for Error'
Try-Catch Block is not required. By default Global.asax will catch the exception.
Found Generic Code for checking user rights
Please move this Code to Common Classes. And call them from this class.
Found Generic Code for showing Pager Buttons
Please move this Code to Common Classes. And call them from this class.
HttpException in Event Viewer
Please remove `Response.Redirect...` line from `ClearUserInfo` Method of `Global.asax.cs` File. Since when the session ends, HttpContext or Response Object is not available.
NoData
Please use configuration file to store the database connection string.
Win32 Status 64 for ASPX Pages
Win 32 status 64 from IIS logs suggests that the network packet is being lost. To be taken up with the network team.
Slow response of Deal Details Page
Index on column FK_PK_DD_DealDetailsID to be created on table DirectRates_DealUtilizedDetails
SqlException in Event Viewer
In procedure usp_DirectRates_GetDeals_New, Please move the `where` condition from line 239 to line 240. This change will rectify the syntax error.
NullReferenceException in Event Viewer
Recommendation mentioned in Point 4 will solve this issue too.
Slow response of Deal Report Page
In Procedure usp_DirectRates_GetReportDeals, Please Select only those columns in the query which are required in the business layer.
Application Code Review (frmAuditTrail.aspx.cs)
In frmAuditTrail.aspx.cs, Please replace `txtdealID.Text` by `txtmurexID.Text` in line number 352
Response Time high
Compression of images needs to be carried out. Please refer image_compression sheet for changes in size of images ( Sample images have been shared with team to validate pixcel quality )
Response Time high
Specifying a width and height for all images allows for faster rendering by eliminating the need for unnecessary reflows and repaints.
Response Time high
To ensure CSS files are downloaded in parallel, always include external CSS before external JavaScript.
Response Time high
use one-time expressions, where the first time the expression is evaluated it sets the style property to an explicit value, which replaces the CSS expression. If the style property must be set dynamically throughout the life of the page, using event handlers instead of CSS expressions.
Workflow Delay
N/A
Response Time high
Optimization of stored procedures will be carried out. Please refer SP_Timings sheet for more details
Response Time high
Compression of javascripts, css, jpegs, gifs files.\nPlease refer below sheets for compression details:\n1. CSS_Compression\n2. JS_Compression\n3. Image_Compression
architecture
If table does not have any foreign key constraints instead of delete, truncate statement can be used, which will help to reduce execution time of SP
Response Time high
Non clustered index need to be created on supplier_id column of this table. This table is having duplicate index on billing_id column which needs to be dropped.
Workflow Delay
As per CNK team data before 5 mins of system timestamp needs to be fetched and this condition can be changed, which will avoid scanning of 1 year data during procedure execution
Workflow Delay
htaccess is being used at only one place. Implementing this will not benefit.
Workflow Delay
Team has confirmed these joins are not required and can be removed.
High Response Time.
Check possibility to avoid is null, also it has where clause as "DepDate >= '01/01/2010'" which is hard coded value for table qtDepatureDate table.\nThis is fetching data for four years, this can be changed to fetch only required amount of data .
architecture
These duplicate indices need to be dropped since unnecessary indices are overhead on database insert operations and space management. Also indices with same columns with different column position needs to be validated against application requirement.
Query Optimization
Purging needs to be carried out on the BTBATCHDET table.
Query Optimization
Subqueries needs to be replaced by Inner Joins. Also, index needs to be created on entrydate and paymentmethodid on btaccountentry table.
Configuration
For enabling caching, on the web server, we suggest you to make some modifications in the httpd.conf file in the web server.The caching can be done for the frequency defined by you. For now, we have made it as 1 week. This frequency will depend on the frequency of modifications that is generally made on these static objects.\nPlease test this extensively on one of the UAT server, and if results found okay, can be put in production.\n#Enabling Caching for Static Objects\nLoadModule expires_module modules/mod_expires.so\n#Enabling Caching for Static Objects\n<IfModule mod_expires.c>\nExpiresActive On\nExpiresByType image/gif "access plus 1 week"\nExpiresByType image/jpeg "access plus 1 week"\nExpiresByType image/png "access plus 1 week"\nExpiresByType image/bmp "access plus 1 week"\nExpiresByType application/javascript "access plus 1 week"\nExpiresByType application/x-javascript "access plus 1 week"\nExpiresByType text/css "access plus 1 week"\nExpiresByType text/html "access plus 1 week"\n</IfModule>
Configuration
More intermittent accounts needs to be configured at the C-24 end, and mapping needs to be done at paypro application.
Maitenance
Complete List has been shared with the team. Statistics needs to be updated on the listed indexes.
Query Optimization
A nonclustered index can be created on users table on column usertype by including columns sysuserno,userid,client
Page Not Found
The list is provided for which the referrer page should be modified to comment out the listed referred objects, so that these errors can be avoided.
Configuration
Static code should be moved out from the main function. So that static code executes only once for all the requests.
Maitenance
Large Volume tables needs to analyzed frequently before the month end operation.
Query Optimization
As we do not have the source for this procedure, please involve TBMS team to validate what is the sql text for this procedure and check if this can be further tuned.
Maitenance
Deliberate such cases accordingly and try to limit such maintenance activities to desired level as this creates an overhead on the regular operations.
Query Optimization
The view needs to be rewritten to either not use this table or use a join instead of not exist as it will help eliminate FTS on this big table.
Query Optimization
Create  indexes on CM_OPEN_DATE and CM_CLOSING_DATE columns or modify the query to use current indexes.
Query Optimization
The View needs to be rewritten to use the indexed column UT_LABEL_ID which is indexed.
Query Optimization
The View needs to be rewritten to use the where clause. Currently there are no where clause being used.
Code review
Solution like ping tool (as proposed in  Retail Internet Banking) can be leveraged for this requirement. The ping tool will monitor the performance of different back-end systems by sending dummy messages. If a degradation is observed the Ping Tool will communicate with the iView application. The iView application should have the capability to remove the functionality related to the affected application from its list of services.
Configuration
'The value of the "PROCESSES" parameter must be a minimum of one for each background process plus one for each user process. The number of background processes will vary according the database features that you are using. \nFor example, if you are using Advanced Queuing or the file mapping feature, you will have additional background processes.\nSince the database is write intensive, what has been stated above may be used to calculate the parameter.\nThere is also a relationship between sessions on a database and the number of processes. During hours of intense\nactivity on the database, the number of sessions can rapidly increase. If the "PROCESSES" parameter has not been\nset sufficiently high to control this exigency, we will get an "ORA-00020: maximum number of processes exceeded" error'
Configuration
NoData
Query Optimization
Fix all queries for proper index for selected column
Configuration
'Fix enq: TX - row lock contention by identifying table on which this is happening'
Configuration
Please remove `Response.Redirect...` line from `ClearUserInfo` Method of `Global.asax.cs` File. Since when the session ends, HttpContext or Response Object is not available.
Configuration
Please change the data type of variable `RewardsRisk` from String to StringBuilder.
Configuration
Please throw exceptions in catch block.
Query Optimization
Please use list parameter to fetch and update records of all the clients in a single operation. Recommended Interface is described in the next sheet.
Query Optimization
Please create a table to store mails. This table will be used by different schedulers to store the mails. And a common Mail Scheduler will process this table to send the mails.
Query Optimization
Please use configuration file to store the database connection string.
Configuration
Please use configuration file to store the settings.
404 Error
Source Code should be corrected to remove reference path of the file. List of 172 files is shared in the next sheet.
Network Latency
Win 32 status 64 from IIS logs suggests that the network packet is being lost. To be taken up with the network team.
Code review
Please move the piece of code to common class and call them on all the pages. This will move the functionality to one place and it will be easy to control.
Code review
Please implement error handling in `Application_Error` Event of Global.asax.cs file and record complete exception details in the log file.
Code review
Please dispose the objects in finally block.
Code review
Please implement `Header` Control in Master Page and use this Master Page in all the pages for consistent design.
Code review
Please throw exceptions in catch block.
Code review
Please change the data type of variable `strhtml` from  String to StringBuilder.
Code review
This can be avoided by implementing Image Caching in the Application.
Code review
Please implement .NET's SqlBulkCopy Class for inserting all deals at a time. This will make the deal insertion faster.
Code review
Integration of all schedulers into one common scheduler will help in solving the problem. Recommended Architecture is shared in the next sheet.
Response Time high
Move all servers in single dmz zone so that only a single firewall check is done for requests.
Response Time high
Use outproc session management with either sql server or a separate session state server.
Workflow Delay
Perform shrinking of database log files.
Workflow Delay
Remove User_Id index and ad user_id in the composite index IX_UserLocation_Role_Status_ID
Response Time high
It is recommended to rebuild the indexes so that fragmentation drops below 30% .
Response Time high
Add Max Pool size of 50 in the  connection property of nHibernate
Workflow Delay
Limit the call for helptext.json to once.
Workflow Delay
Put a check depending on user type to avoid calls to both the modules.
Response Time high
Correct the image path or remove the reference of beacon.gif in code.
Workflow Delay
Limit the call for PageButton.json to once.
Response Time high
Remove all ddl data from DDLData.json except for  ddlAllocate and ddlPrimaryLanguage
Workflow Delay
Store location_id and role_id in session variable after login and pass the same as parameter in usp_get_communication_summary stored procedure
Workflow Delay
Limit the call for ViewAwardDetails.html to once.
Response Time high
Limit the call for ViewAwardDetails.html to once.
Response Time high
Check the feasibility of loading these .js files and remove if not needed.
Workflow Delay
Avoid call for Search\Country in Participant\Profile page if not needed.
Workflow Delay
Limit the call for GetUserHistory to once.
Response Time high
Limit the call for GetParticipantProfileLevelData, GetAwardsOfAParticipantByUserLocId and GetCommunicationSummary  to once.
Workflow Delay
Limit calls for GetMenuOnSubmission to once.
Response Time high
Request GetUserLocations only when user clicks on Change link.
Response Time high
Avoid call to GAP/RoomAllocated in GAP/EventOverview page load event if not needed.
Workflow Delay
Avoid call to AccountStatus in Resources/AddResources page load event if not needed.
Response Time high
Store location_id and role_id in session variable after login and pass the same as parameter in usp_SearchUsers stored procedure
Response Time high
Setup a fallback server which could be immediately restored in case of database crash.
Workflow Delay
Store HID in session variable after login and pass the same as parameter in usp_SearchUsers stored procedure
Workflow Delay
Limit the call of GetSelectedParticipantListDuplicate to once.
Response Time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Voluntering.
Response Time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Skill.
Response Time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Expedition.
Workflow Delay
Limit call for GetSubmenuOnPermission to once.
Response Time high
Limit call for GetSubmenuOnPermission to once.
Response Time high
Call GetSubmenuOnPermission only for menus where submenu is present.
Workflow Delay
Limit requests for ViewAwardDetails.html to once
Response Time high
Limit the call for ProcessImages.aspx.jpg to once.
Response Time high
Clear all view engines and add RazorViewEngine in application_start code. Also disable MVC response header
Workflow Delay
Limit the call for GetCommunicationSummary to once.
Workflow Delay
Avoid using Begin Transaction as same is handled in nhibernate
Workflow Delay
Avoid using Begin Transaction for select statements.
Response Time high
Avoid using Begin Transaction for select statements.
Response Time high
Avoid using Begin Transaction for select statements.
Response Time high
Avoid using Begin Transaction for select statements.
Configuration
Update the data structure every time the rate changes i.e. end of the fswPrimact_Changed and fswJPY_Changed functions
Code review
This can lead to memory leakage. Add finally block to close the resources properly
Code review
Index on ForexEDeals_FlowDeskDeatils table for column FDD_ForDealer is created.
Query Optimization
Index on ForexEDeals_FlowDeskDeatils table for column FDD_MurexID is created.
Slow Response Time
ICICI team needs to take this up with the winadmin team.
Query Optimization
The Index creation script which was shared by Avekshaa and also revalidated by Microsoft to be implemented. This will bring down the DB CPU Utilizaton. Moreover, bring down the multiple executions on this SP as this is being called by redundant functions. While loading blotter page for the first time, the same SP was called in JS as well as Ajax call. The call from JS needs to be prevented.
Code review
Infosys to analyze the performance of the Call Menu Option and revert with fix
Code review
The operations can be eliminated to increase throughput.
Code review
The thread sleep should be eliminated
Code review
Multi threading to be enabled for this service so that the application can be scaled for better throughput
Code review
Multi threading to be enabled for this service so that the application can be scaled for better throughput
Query Optimization
95 SQL queries related to RTGS are shared with the iConnect team from Bank. Execution plans has been analyzed and below are the recommendations
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Configuration
Oracle Kernel level parameters interfacing with underlying OS (AIX v5.3) should be configured to make best use of OS level resources:\nInstall gpfs.base filesystem.\nIncrease maxuprocs to 16384 from current 4096.\nIncrease aio_maxreqs to 64k (65536) from current 8192.\nChange page_steal_method  to 1 from current 0.
Object Locking
Due to lack of ADDM and NMON reports for the day, the issue could not be analysed further to be able to come up with recommendations.
Maitenance
Due to lack of ADDM and NMON reports for the day, the issue could not be analysed further to be able to come up with recommendations.
Maitenance
Drop one undo space and get the benefits in terms of space reclamation  & reduced dictionary access.
Configuration
From the scalability standpoint we propose that the amount of processing carried out at Db layer be reduced.\nMoving relevant parts of batch processing flow on JVM will provide flexibility of scaling out. Multiple JVMs can concurrently process batch files. \nTo cater to increasing load, more JVMs can be added to achieve desired throughput. This will be necessary as more clients are added. This model can also enhance the availability.
Code review
Considering that the application user base and transaction load is increasing, it is appropriate to introduce additional nodes and load balancing to take care of SPOF and future load requirements.
Query Optimization
Below tables should be indexed:\n Table CPAY_LIQ_UPLOAD_MST\n    KEY is a FK but not indexed\n    RETURN_REASON_ID is a FK but not indexed \n    \nTable CPAY_PAYMENT_ENTRY_MST\n    AUTH_RULE_APPLIED_ID is a FK but not indexed \n    LAST_AUTH_MTX_ID is a FK but not indexed \n    WORKFLOW_ID is a FK but not indexed \n    SI_ID is a FK but not indexed \n    DOC_SETUP_ID is a FK but not indexed \n    BATCH_ID is a FK but not indexed \n    CUST_PROD_ID is a FK but not indexed \n    CURRENCY_ID is a FK but not indexed \n    GROUPING_ID is a FK but not indexed
Query Optimization
It is recommended that SR be raised with Oracle to get a fix/workaround for this anomaly.
Code review
Secondary for-loop to check "customer already exists" is non-efficient. HashMap should be used with customer code as a key. This will be faster than current for-loop-over-array approach.
Code review
JDBC objects like Connections, ResultSet & PreparedStatement should be closed in a finally block. Not closing these objects will restrict database server from releasing these objects from its memory.  Not closing Connection object can induce connectiod leak and cause a system failure. (This one is critical and should be addressed as soon as possible).
Code review
All StringBuffer variables declared inside a method should be replaced with StringBuilder. This will improve performance slightly.
Query Optimization
In a query to fetch format and process details for a customer, second column (FORMAT_CODE) is not used and hence it should be removed from the query.
Code review
Sysouts should be removed.
Code review
Exisitng java code makes use of long thread sleeps, indefinite thread waits to manage threads. These low-level thread management techniques are extremely hard to get right and are easy source of issues like deadlock, race condition etc.\n\nWe propose that CDCI jobs be implemented using high-level and reliable constructs provided in java.util.concurrent package. Pseudo code with explanatory comments have been shared with Bank on 05/24.
Query Optimization
Should create separate index on WORK_BR_ID field
Code review
'Interim workaround till permanent fix is made (as per item #31 above):\nIncrease memory allocation to Reverse File Gen Corp by 500 MB\nUpgrade POI jar with the latest stable version'
Code review
NoData
Code review
while(true) code in infyaccount.jsp was continuously calling session object for session attribute and was reason of blocking the other threads.
Code review
DataOutput object instance always needs to be created in try block and  closed  in finally block as following\n DataOutput dataOutput = null;\ntry{\n       dataOutput = new \n                DataOutputStream(response.getOutputStream());\n        byte[] bytes = buffer.toByteArray();\n        response.setContentLength(bytes.length);\n        for (int i = 0; i < bytes.length; i++) {\n            dataOutput.writeByte(bytes[i]);\n        } \ndataOutput.close();\n}catch (IOException ext) {       //Print to log\n}finally{\n       try{\n           if(dataOutput != null){             dataOutput.close();           }\n       }catch (Exception ext) {}             //Print to log\n}
Code review
Use Configure Datasource and get connection from Datasource instead of JDBC Driver.
Code review
Use logger to log any message. Change all System.out.prinln with logger. Disable web - log access as size of log grows to 5GB within 2-3 days.
Code review
Need to fix all invalid URL that has been used in code and Fix recommendation for Server log analysis. List of all URL for 500 and 404 has been shared.
Code review
'- Cache the properties file and use this cached file in all connection request. Caching will reduce File I/O and   processing request time. Implement Observer pattern to  re-load the file if modified. \n - Evaluate introduction of Socket connection pool to optimize the resource utilization and improve response time  \n - Evaluate replacement of IO with NIO for better performance and scalability. NIO uses Selector which can examine one or more NIO Channel''s with a Single thread. This leads to optimal utililzation of the available resources (like threads).'
Query Optimization
Application should apply optimal logic to leverage the parallelism of query execution
Configuration
"\u201COptimizer\" initialization parameters influence the Cost-Based Optimizer\ \ (CBO) and SQL processing and these will influence the performance"
Configuration
Fix all queries for full table scan and analyze AWR report for these queries
Query Optimization
Full table scan has been observed in few queries, Need to fix these and analyze AWR for these queries
OS space
Increase the disc size
Configuration
1. Need to investigate database connection and connection pool parameters\n2. Need to analyze network between application server and database
Configuration
Check database connection and connection pool\nCheck application for any memory leak
Configuration
Possibly due to contention in application
Configuration
First need to fix contention in application and need to check this once again. If still this persist then need to analyze IIS performance
Configuration
1. CLR monitoring for 10-15 days and analyzing heap dump and Garbage collection (sign of memory leak)\n2. Need to analyze further heap dump, object creation garbage collection pattern\n3. IIS Performance counters have already been shared and these need to configure on iPartner IIS as well.
Configuration
1.Policy Picked for Sync\n2.Health Payment PF Request/Response\n3.PF Premium Calculation for MISC\n4.Proposal Sync PF Call for 4W\n5.Health Customer PF Request/Response\n6.PF Proposal Sync for 2W\n7.Health Payment Tagging PF Request/Response\n8.Health Payment PF Request/Response\n9.Health Customer PF Request/Response\n10.PF Premium Calculation for PCV
Configuration
web.config file should be corrected to remove reference path of the files from the `customErrors` tag.
Configuration
Please add condition to check `ds.Tables.Count > 0` before the condition `ds.Tables[0].Rows.Count != 0` in `GetPendingApprovals` Method of `PendingApprovals.aspx.cs` Page.
Configuration
Please implement Viewstate Compression in ASPX Pages. Reference http://www.codeproject.com/Articles/14733/ViewState-Compression
Code review
Please move these Methods to common class and call them on all the pages.
Code review
Please dispose the session after use.
Code review
Please use one session instead of two, since they are doing same work.
Code review
Please remove the Session["dtUnderlying"] assignment from the Method `GetDataSource`
Code review
Please replace Tag name from `Client_Identification_No` to `CID` or `CINO` in `RefNo.xml` file. This will reduce size of xml file from 7.36 MB to 3.72 MB
Code review
Please implement Viewstate Compression in ASPX Pages. Reference http://www.codeproject.com/Articles/14733/ViewState-Compression
Code review
Please move `Response.Redirect` outside the `if-else` conditions. Use string for URL creation and use that string in `Response.Redirect`.
Code review
Please move `Response.Redirect` outside the `if-else` conditions. Use string for URL creation and use that string in `Response.Redirect`.
Code review
Please remove the Session["dtNonCIB"] assignment from the Method `GetDataSource`
Code review
Implementation of Token Based Authentication will secure the CIBClient Module from unauthorized access.
High CPU Utilisation and High IO Writes
Logging is removed from iteration of code
High Response Time
It is recommended to use Arraylist over Vector unless used in multithreaded environments.
High Response Time
It is recommended to use BufferedOutputStream instead of OutputStream.
High Response Time
It is recommended to remove synchronization for single threaded piece of code
High Response Time
It is recommended to increase the archive_lag_target value from current 600 to 900.
High Response Time
It is advisable to either use IF ELSE construct over just repetative IF blocks .
High Response Time
It is recommended to combine all these queries and create a stored procedure. Stored procedure can return RCODE which can then be used to generate Alerts and return the response.
High Response Time
This may not cause a performance bottleneck keeping in mind the current workload . \nBut when the concurrency increases multiple database calls to get the Nbin Details need to be clubbed in a Stored procedure.
High Response Time
This boilerplate code can be elimindated by using Hibernate framework . Follwing would a typical workflow for converting the existing logic into hibernate . \n1) Each table will be mapped to an Java Entity (pojo) via annotations/HBM mapping files\n2) For retrieval or updating of entities , simple HQL queries can be written which will return an Entity Object populated with values or can directly update an Entity object in the database . \n3)Hibernate can make use of Multiple caches for improvement in performance \na) Session level cache - This cache is turned on by default and helps with caching in the same session\nb) 2nd level cache in hibernate by default implemented by Ehcache helps in bringing common cache to the table . Any set of entities that needs to be cached at the sessionfactory level can use 2nd level cache . Timeouts,Invalidation policies can be set accordingly . \nc) Query cache can be used locally for certain queries which are called repeatedly and are suppose to deliver consistantly simmilar results.\n4) Further hibernate can be guided to use connection pooling mechanism of Jboss by using the Hibernate config file . In case hibernate connection pooling is required it can used by setting properties for C3p0 connection pooling mechanism of hibernate. \n5) Be extra cautious while mapping relationships in entities. Decide which properties and relationships will load lazily and which will load eagerly
High Response Time
It is recommended to set enabled="false"
High Response Time
It is recommended to move these values to the app.config file
High Response Time
It is recommended to create index on table "mst_Beneficiary" on columns "BenCode", "CustomerID"
High Response Time
'Very high CPU utilization (~100%) observed. Query resulting in Full table scan on GAM identified. \nQuery to be optimized by service provider. \nRefer: Q001 in SQL_QUERIES'
Unwanted Index present
Drop the index if it is not required
NoData
Update GEC and RCL table for corresponding columns
NoData
The package needs to be tuned by Infosys. Any optimization in the package will reduce the time spent on the DB. \nProcedure - MIGADM.SP_ADDRESS_MIG_CHECK \nPACKAGE - MIGADM.PREVALIDATION_CATEGORY.SEARCHCATEGORY#2
NoData
"We suggest that we have a common file for stopping and starting the services\ \ where we have a sleep of 30 secs after the stop sevice is executed. This will\ \ ensure that all services are brought down, and there are no service in the hung\ \ state. \\nTo validate further, we can have a ps \u2013ef |grep lisrvr|grep maria|grep\ \ limo to check if all the services have been brought down before a restart is initiated."
NoData
Infosys to rvert back on what is 99 mapped to in Finacle
NoData
NoData
NoData
Disable logging in the Uniser and CBC configuration files.Also script traces should be disabled.
NoData
Query to be tuned
NoData
Concurrency in accessing the accounts could cause a lock on the account. The debit accounts for the failed transactions should be looked at, and if it is hitting the same account, the number of accounts should be increased.
NoData
Query to be tuned
NoData
1. Reduce the no. of concurrent users from a single zone.\n2. Multiple zone codes, sol id combination for the same.\n3. Alternatively, the product vendor can look at the possibility of having a NOWAIT after update.
NoData
Correct mapping of Schme Code and GL Sub Head Combination needs to be done. Infosys has to fix the issue of FIN_LISTVAL getting killed.
NoData
Napi error - W0205 encountered. The test is executed sucessfully if it is run for a single user, but fails during load(concurrency). Infosys needs to investigate from code, the reason for the exception encountered.
NoData
The transaction should be processed by the same node in entirety, the avg. response time would be much lower than when it is processed by both the ESB nodes.
NoData
1.Index on utr field needs to be created.\n2. Sequence Cache size increased to 20. \n(Alter sequence owner.sequence_name cache 20) -\nSequence Names - \nTrasanctionidsequence \njob_id_seq\nonline_job_id_seq
NoData
1. NOSTRO/USD combination is notmaintained in SRGPM parameters because of which there are NAPI errors.\n2. General exception error are happening because of concurrency of data selection for the query mentioned. Need to have more data sets so that concurrency is avoided(the data accessed is shared with Priyadarshi), or Infosys can provide an alternative solution.
NoData
Index creation needed on utr as well as on routing_ref_num
Caching of sequence numbers were less
The cache size of the sequences were increased from 0 to 40.\n(Alter sequence owner.sequence_name cache 40) -\nSequence Names - \nADT_REF_NUM_SEQ_IB\nFT_TRAN_NUM_SEQ_IB\nFTTRAN_NUM_SEQ_20120601_IB\nRTGS_SEQ_NUM_SEQ_IB\nPORH_SEQ_NUM_SEQ_IB
High Response Time
1. Deployments at 107 and 108 are not in synch.(product exes are not in synch)Prima facie, it needs to be ascertained that all nodes are in synch to rule out any issues due to difference in deployments\n2.  We opine that there could have been a memory clog on the application due to high no. of records processed. When the next run is done, we would want to have the NMON running on the application as well as DB server to ascertain the same.
NoData
"There are queries which are running on CNMA, not utilizing the index. Create\ \ index CRMUSER.IDX_ADDRESS_TEST on CRMUSER.ADDRESS(\u201CBANK_ID\u201D,\u201DORGKEY\u201D\ ,\u201DADDRESSCATEGORY\u201D)\\nAlso analyse the table after creating the index."
Table lock observed
There was a noise because of which these queries were being run. These sessions were killed.
NoData
a.            Increase freelists  of table & its indexes to 5 (no can be increased if event occurs again).  (using multiple free lists may cause some empty blocks to go unused, causing the segment to extend. Multiple free lists can be used to improve concurrent access, possibly at the expense of additional space used.)\n\nb.            Table & corresponding indexes can be moved to larger block size tablespace of 16K. The inserts would become faster.
NoData
Infosys to investigate the issue
NoData
Need to have stats to be gathered on fixed objects using "dbms_stats.GATHER_FIXED_OBJECTS_STATS" package of oracle.
NoData
The SAF Replay needs to be reconfigured to use parallelization even with hash number configuration.
NoData
This query was fired from the customized Interface finacle script /finacle/appln/Finacle/FC10.2.9/app/cust/01/INFENG/scripts/INT8023Post.scr. Infosys to analyze and apply the fix.
NoData
There are lots of comments which are sent in xsl, javasctipt files which are served to the client which add to page weight and time. The comments needs to removed from js, css and xsl files which would reduce the page weight and would improve the performance.
NoData
Same java script files are referenced multiple times in the same jsp files.\nMod_exprires needs to be enabled on I H S servers and a far longer expiry time needs to specified for static files.
NoData
Compression of all static files needs to done for all the static contents serverd
Database Listner Starting manually
This process needs to be automated, to avoid any manual intervention during actual failover
Unnecessary logical block is written
Recommended to remove the unwanted operations from the source file. This will help in faster execution of logical blocks and hence improve the performance. Also the objects created inside this block will get eliminate which result in low memory consumption.
Streams not closed inside finally
It is recommended to add finally block in source file and close all important resources inside it. Finally block will guarantee to close all resources if any exceptions thrown
Resource leak suspected code block(in case of an Exception)
Recommended to write the code snippet in try/catch/finally and close the PrintWriter object in finally.
Use of Println
It is recommended to turn this println off. Logging API can be used instead which can turn of debugging statements.
arrayList.size() used in for loop condition
It is recommended to call arrayList.size() once and store its value in another object and use the same object in the code.
Object.length() is used in for loop
It is recommended to call Object.length() once and store its value in another object and use the same object everywhere in the code.
Used size() == 0 (or size() != 0)
Substitute calls to size() == 0 (or size() != 0) with calls to isEmpty().
Empty catch blocks
Need to log some messages to detailed out the exception.
Empty catch blocks
Avoid empty catch blocks. Capture specific type of exception and redirect user to common page with appropriate custom message, so that the specific event triggered by the user doesn't look unresponsive.
Broken Null Check
'Recommended to replace this type of condition in below pattern.\nCurrent: \nif(result != null || result.length() >0)\nRecommended:\nif(result != null && result.length() >0)'
ICLGNREQ01 Multiple same if conditions
Only one block should be used and all required data manipulation should be done within this block
Consecutive calls to StringBuffer/StringBuilder append method
Consecutively calls to StringBuffer/StringBuilder .append should reuse the target object.
Used += operators for string concatenations
It is recommended to use StringBuilder instead of String class where there are lot of concatenations used . StringBuffer can also be used in multithreaded environments
Unnecessary call to toString() on String object
Avoid calling toString() on String objects; this is Unnecessary.
Handled String comparison in improper way
Use equals() or equalsIgnoreCase() to compare strings instead of ''=='' or ''!=''
Unnecessary Operation On Immutable Objects
Remove all such operations from code
Not Nulling the WebServiceResponseParser object
Add below block inside finally block. \nparser = null; \nparser is reference to WebServiceResponseParser class. Above block will make sure that in any case normal/exceptional parser object reference to null and can be garbage collected.
Redundant Call from Client App to Back-end
Change the if condition to some variable. And use the cached data.
Repeated StringBuilder calls.
Remove one call.
Unused object creation
"It is recommended not to create much of unused objects as it will result\ \ in memory consumption. This should be considered important when it\u2019s a mobile\ \ device code."
Unnecessary operations on response string.
Remove these redundant calls
Workflow Delay
Remove Dynamic compression and allow only static compression.
Response Time high
Add Async tag in the javascript of layout.cshtml page where search functions are defined.
Response Time high
Add Async tag in the javascript of all source .cshtml pages to improve performance of javascripts on internet explorer.
Response Time high
Use Jquery grid to bind the resultset to optimize the loading of quick search results.
Query Optimization
The procedures should be modified to update only those rows created after last successful update. Modified date time column may have to be added to the source tables to identify the updated rows.
Query Optimization
Perform TRIM and TOUPPER function on data before inserting into CCTGLive tables. This implies a change in the components that are inserting data into the source table.
Query Optimization
Remove trim function as it never makes sense to apply trim while checking values for null in where clause
Query Optimization
The procedure PROC_ALL_TEMS2 should be modified to call update of limit values  only when temII updates are available.
Query Optimization
Allocate separate mount point for TEMP table space and create TEMP datafiles on those mount points.
Configuration
Allocate three different mount points and move REDO log group and control files on those mount points.
404 Error
Several source code files should be updated with correct reference path as per the shared list. List is allready shared with ICICI team internally.
Code review
Remove large unwanted comments from AjaxSessionTimer.js. This will reduce the size of file to 1 kb.
Query Optimization
Create indexes on table TEMS_CPTYGRP for columns CPTY_SHORTNAME
Query Optimization
As a temporary fix implement functional indexes for key tables to immediately improve the performance of scheedulers. Later a calls needs to be taken to remove these functions from queries and subsequently replaces these functional indexes with normal indexes.
Query Optimization
Update query Q007 to Q0071  in  stored procedure CRM_PROC_INTERFACE
Query Optimization
Update query Q008 to Q0081  in  stored procedure CRM_PROC_INTERFACE
Query Optimization
If this is same scenario in production then redefine the partition window with correct data range to equally distribute data among  all partitionsi
Query Optimization
Create indexes for column ReportDate in tables  CRM_HIST_KREDITNETDETAILS
Query Optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_TEMPORARY_CPTYLIMITSSUMMARY,TEMS_TEMPORARY_CPTYLIMITS
404 Error
Several source code files should be updated with correct reference path as per the shared list.
404 Error
Several source code files should be updated with correct reference path as per the shared list.
404 Error
Several source code files should be updated with correct reference path as per the shared list.
404 Error
As a temporary fix implement functional indexes for key tables to immediately improve the performance of scheedulers. Later a calls needs to be taken to remove these functions from queries and subsequently replaces these functional indexes with normal indexes.
Query Optimization
Create functional indexes for columns  SDEALER, NTID in table  NP_LEVEL_3_ASAL_EOD
404 Error
Create indexes for columns  PID in tables  NP_CRON_REFRESH
404 Error
Create indexes for columns  SDEALER in table  NP_LEVEL_2_ASAL_PEAK
404 Error
Create indexes for columns  UM_LOGINID in table  NP_USERMASTER
404 Error
Create functional indexes for columns  SDEALER in table  table NP_PPR_LEVEL_1234
Query Optimization
Remove trim function from sql Q007 from CRM_PROC_INTERFACE and update referred table columns with trim function in stored procedure at single time. With this I have received improvement of 60% in ececution time for Proc_ITLM_SCH_PROCESS.
Query Optimization
Remove to_char function from sql Q011 from stored procedure proc_refresh_newpos as both column refreshtime and variable P_rpt_dt are of date type.
Query Optimization
Remove to_char function from sql Q012 from stored procedure proc_cal_level as both column refreshtime and variable rpt_dt are of date type.
Query Optimization
Create functional index for column ntid in table np_tmp_level_1234_peakhi
Query Optimization
Create functional index for column ntid in table np_level_4_peak
Query Optimization
Remove upper and trim functions referred for CPTYGRP_ID column as it is observed they are defined as numeric datatypes in referred tables.\nOnly below 4 out of 330 tables are having varchar2 datatype for CPTYGRP_ID column. Need to check feasibility of changing datatype to Number.\nLIMITS_DAILY_PPTDETAILS_HIST_MG\nTEMS_MANUALENTRY\nTEMS_MANUALENTRY_AUDIT\nTEMS_MANUALENTRY_TEMP
Query Optimization
Create functional index UPPER(TRIM(DealType)) in table RTS_tmpMain
Query Optimization
Create functional index TRIM(CurrencyPairRic) in table RTS_tmpMain
Query Optimization
Create functional index UPPER(TRIM(Tenor)) in table RTS_tmpMain
Query Optimization
Trucate table RTS_tmpMain at the beginning to ensure table is empty this will be useful if stored procedure is called twise in same session.
Query Optimization
Instead of calling several delete commands to delete rows from table RTS_FW_HLRates for different fwhl_riccode call single delete command by passing all fwhl_riccide values at once.
Query Optimization
Create index for BreachedRecordId in table FX_BREACHEDDEALSAPPROVAL
Query Optimization
Create functional index TRIM(APPROVER_STATUS) for table RTS_BREACHDEALS
Printing so many print statements on the console/log
It is recommended to use Log4j.debug for logging debug statements . These can then be turned off during production by keeping the logging levels as Warn/Error .
generic exceptions "Catch (Exception e)" are being caught at most of the places
It is recommended to catch specific exceptions e.g. Catch (FileNotFoundException e), SQLException etc
no continuous integration used
It is recommended to use jenkins or any other open continuous tools for build, unit test and deployment purposes
old versions of jars are used
It is recocmmended to review this process time to time and after reading the release notes of latest version we should include latest jars into our library folder
all request and responces from various servers is done using xml
It is recommended to Use Google Gson framework instead of xmls because json is fast in processing and memory overhead is less and also good for transportation.
no MVC framework is used in CAR Intranet Module Code Recommendations
It is recommended to use MVC Pattern in web application for better categorisation of Code Recommendations and for better maintanability
xml response is stored in two dimensional array of string and compare each item with string constants on right hand side
it is recommeded to take string constants as string final string and check constant.compare(string)
web module does not have micro services architecture
It is recommended to use micro services architecture of each apis so that in UI it can be shown that what all services are working and end user can perform available services requests.
no function header written
It is recommended to use javadoc specifications for function headers so that dynamically help can be built and used for reference purposes
all class variables setters/getters provided
it is recommended to check this carefully and provide only required getters/setters
Code Recommendations is commented in various files, also there are FileInputStream handles opened and closed but not used.
It is recommended that commented Code Recommendations should not go into production. Run find bugs in entire Code Recommendations before every release
no proper Code Recommendations commenting is done in entire Code Recommendationsbase
It is recommended to put proper Code Recommendations comment so that any other developer can understand it
no Junit test cases present in Code Recommendationsbase
it is recommended to write Junit test cases for each class for Unit Testing
Using old apis can cause several runtime issues
It is recommended to use latest provided API of given third party jars
no jsp exception handling done in CAR web module
it is recommended to provide proper exception handling mecanism.
High Memory
A POC needs to be carried out to on XML versus JSON messages to ascertain the overhead of XML over JSON.
Design
It is recommended to use standard Message Queuing system like IBM WebSphere MQ or RabbitMQ for availability of this system with connected interfaces. We also propose to use Extended Architecture where two phase commit happens, messages will be deleted from MQ when those messages are saved in Database so no recovery is required with this approach.\nCheck this link for more info https://en.wikipedia.org/wiki/X/Open_XA and\nhttp://docs.oracle.com/cd/E19509-01/820-5892/ref_xatrans/index.html
no MVC Architecture is used in CAR web module
Currently no MVC Architecture used in CAR Internet Module so it is recommended to use industry certified Spring MVC framework for better maintainability of Code Recommendations.
no Unit Testing test cases written for Unit Testing.
It is recommended to write Junit Test Suit for all the classes each function with all valid/invalid scenarios, it will achieve 100% Code Recommendations coverage.
xslt+xml are used for making reports
It is observed that MIS Reports are combined of all the servers which should be sent separately also for individual servers, also mis report only contains data for others and web which should also showcase from which input interface how many messages received and response time etc
NoData
Create composite index on column \nCML_MSG_TYPE, CML_DATE on table CARTBL_MSG_LOG
NoData
Create separate functional Index on \nDMI_INDIVIDUAL_NAME for table CARTBL_ISC_DMOG_INFO
NoData
Need to create functional index on \ncolumn CFPC_FILE_ID currently  the \nquery it is not hitting the index \nfor table CARTBL_FILE_PRCS_CTRL
Code review
This can be avoided by implementing AJAX in the Application. AJAX allows portions of a web page to be loaded dynamically, separately from other parts of the web page. Please start implement AJAX from top 15 pages, especially for Search Functionality in List and Report Pages.
Code review
This can be avoided by disposing unused Session Objects in the application during page redirects.
Code review
Index on tables tbl_FC_Booking, tbl_Corporate_Dtl, tbl_Corp_Authorization, tbl_Corporate_User, tbl_Document_Client_Dtl needs to be created. Index script is shared in the next sheet.
Code review
Please move the `return` statement after `InsertErrorLog` statement in `try` block of `SendEMail` Method.
Response Time high
Change application pool request queue size to 15000.
Response Time high
Perform below activities.\n-Club multiple .js files called in a same request to single file.\n-Minify .js files to reduce size.\n-Remove comments
Workflow Delay
Update UI at view itself without exposing files at client side. Singleton class could be used for different languages with property of all field to display UI instead of using avascript function in _Layout.cshtml.
NoData
Add Status_ID along with User_Id in index NC_User_Application_User_ID to make it a composite index.
Response Time high
Implement Database level caching using sql server notification by associating SQLDependency class with nHibernate linq queries.
Workflow Delay
Use transaction scope to rollback updates in case of multiple databases.
Workflow Delay
Limit the call for StatusHelp.html to once.
Response Time high
Provide picture or correct path for profile picture
Response Time high
Limit the call for GetCommunicationSummary to once.
Response Time high
Retrieve StatusHelp.html when user clicks on Show or Hide evidence.
Workflow Delay
Limit the call for  GetUserLocations and GetParticipantPlace to once in select participant event.
Response Time high
It is recommended to select only those columns which are required
Workflow Delay
Check the feasibility of loading these .js files and remove if not needed.
Response Time high
Avoid request for jquery.jqgrid.min.js in load event of Participant\AddEvidence page.
Response Time high
Check the feasibility of loading these .js files and remove if not needed.
Response Time high
Check the feasibility of loading these .js files and remove if not needed.
Response Time high
Limit the call for GetcommunicationSummary to once.
Response Time high
It is recommended to enable NoCount for all the stored procedures unless there is a specific requirement for disabling the option
Workflow Delay
Avoid call for Search\Language in Participant\Profile page if not needed.
Response Time high
It is recommended to use varchar(n) where n Is the max size expected for the variable. Fix to be applied at all possible places in stored procedures.
Workflow Delay
Limit calls for GetUserHistory to once.
Response Time high
Call GetCommunicationSummary only when popup is opened.
Response Time high
It is recommended to use just the union clause .
Response Time high
Maintain cache of Communication Summary  based on locationid and roleid.\n1. The controller should store response data for each getcommunicationsummary request into cache.\n2. Before sending request to the database, the controller should check cache if data is present in the cache else fetch it from the database.\n3. For actions that result into changes in Communication Summary  fresh data should be fetched from the database and cache should be updated asynchronousely accordingly.\n4. Records in cache should have expiry period which should be configured in configuration files.
Response Time high
Limit calls for Google api to once
Workflow Delay
Limit calls for GetVenues to once
Workflow Delay
Limit calls for GetRoyalAttendance to once
Workflow Delay
Avoid call to Search/GapRole in GAP/EventOverview page load event if not needed.
Response Time high
Avoid call to Search/GapRole in GAP/EventOverview page load event if not needed.
Response Time high
Avoid call to GAP/GAPAllRegionsforTpTab in GAP/EventOverview page load event if not needed.
Workflow Delay
Avoid call to GetUserLocations in Resources/AddResources page load event if not needed.
Response Time high
Limit call of Search\AccountStatus to once.
Response Time high
Remove UserName and LastName input parameters if not needed.
Response Time high
Remove Begin Transaction, Commit and Rollback statements in USP_SearchUsers stored procedure.
Response Time high
Avoid retrieval of Role_Location.Status.Detail in usp_SearchUser and application code id not needed.
Workflow Delay
Store HID in session variable after login and pass the same as parameter in usp_Get_CommunicationSummary stored procedure. Use the way it is used in usp_SearchUsers using like operator.
Workflow Delay
Limit the call of GetCommunicationSummary to once when communication Summary view is open and don't call if view is colapsed.
Response Time high
Avoid calling AccountStatus LeaderRecorded/AddTimeScales page load event if not needed.
Response Time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Residential.
Workflow Delay
Limit call for GetSubmenuOnPermission to once.
Response Time high
Limit requests for ViewAwardDetails.html to once
Response Time high
Avoid call to AcontStatus in Participant/AwaitingApproval if not needed.
Response Time high
Limit call for GetSubmenuOnPermission to once.
Workflow Delay
Limit the call for ProcessImages.aspx.jpg to once.
Workflow Delay
Limit call for GetSubmenuOnPermission to once.
Response Time high
Avoid call to GetCommunicationSummary if not needed
Response Time high
Avoid using Begin Transaction for select statements.
Query Optimization
Remove all to_char() functions on date columns of where clause. Instaed convert variable to date type in case variable is of different data type
Query Optimization
All the  indexes for CCTGLIVE should be  created on separate table space and with separate mount points allocated.
Configuration
The history tables should be moved to a  separate  table space to improve the performance.
404 Error
Several source code files should be updated with correct reference path as per the shared list. List is allready shared with ICICI team internally.
Query Optimization
Create indexes on table TEMS_CPTYGRP_MAP_INFO for columns CPTY_SHORTNAME
Query Optimization
Create indexes on table TEMS_LIVE _CPTY_LIMIT_SUMMARY for columns CPTY_SHORTNAME and CPTY_GRPNAME
Query Optimization
Create indexes on table ITLM_CRM_COPCPTY_TEMP for columns CPTY_SHORTNAME
Query Optimization
Use truncate command instead of delete whereever whole data is deleted from the tables.
Query Optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_REASONMASTER,TEMS_PENDING_CONF,TEMS_MANUALENTRY,TEMS_FAVOURITE_CPTYGRPID
Query Optimization
Create indexes for column CPTYGRP_ID in tables TEMS_TEMSLSETTLE_UTIL_BUCKET,TEMS_TEMS1_EXPOSURESUMMARY
Query Optimization
Create functional indexes for columns  SDEALER, NTID in tables  NP_LEVEL_2_ASAL_PEAK,NP_LEVEL_2_ASAL_PEAK_DOM,NP_LEVEL_3_ASAL_PEAK,NP_LEVEL_3_ASAL_PEAK_DOM
Query Optimization
Create indexes for columns  SDEALER in tables  NP_LEVEL_2_ASAL_EOD
Query Optimization
Create indexes for columns  CCY in tables  NP_LEVEL_1_ASAL_EOD
Unnecessary replace on PvtDataField125 variable.
The replace is not required. It is recommended to call split on PvtDataField125 directly.
NoData
Recommend to set the Loglevel to Error/Warn as in other web servers
NoData
Please refer attached file for the list of these requests.  Missing files should be added to reduce the number of hits on the server.
NoData
Exceptions to be reviewed by the Product team.
NoData
Check the connectivity and performance of CDCI Component
NoData
These queries are observed consistently in all AWR's and hence we have recommended that the tables be analyzed. Tables used by queries have not been analyzed since Dec 2013. \n\nIndexes were present for columns used in 'where' clause however indexes are not getting utilized.  Recommended to analyze the below tables for queries to utilize the indexes.  \n1. ALERT_DETAILS_TABLE\n2. CORPORATE_USER\n3. CHANNEL_SPECIFIC_IND_PROP
NoData
NoData
NoData
NoData
NoData
'Increase below memory parameter values:\nSGA_TARGET = 64\nDB_CACHE_SIZE = 48G\nSHARED_POOL_SIZE = 8G\nPGA_AGGREGATE_TARGET=8G\n\nNote: ADDM report also recommends to increase the SGA size.'
NoData
IDX_CADT index is composite index on CUSTAUDITTBL table on columns -- ADT_SRL_NO, LOG_SRL_NO and BANK_ID.\nChoose the highest cardinality column out of these columns and create a reverse key index to avoid locks on the index.
NoData
"Create below indexes on ALERT_DETAILS_TABLE tables:\\n1. Index on column\ \ R_CRE_TIME .\\n2. Composite functional index on below columns in order of lower\ \ to high cardinality:\\nALDT.BANK_ID\_\\nUPPER(CORP_ID)\\nUPPER(USER_ID)\\nUPPER(ALERT_NAME)\\\ n3. Create an index on USER_ID Column."
NoData
Reason for full table scan is usage of like operator in the query. Create text search index on the column where like operator is used in queries.
NoData
NoData
Selecting Fincore hangs intermittently.
NoData
Very high number of redo log switches in SSO Database
To increase the number of log groups to 6 from 3 with each redo log file size of 1GB. This will cater to the current load for isolated testing. For further loads the redo log sizing will be monitored and fine tuned accordingly.
Row lock contention in KWIKTD_BBY table
NoData
Full table scan on SECU_DETAIL_RGTR_TABLE table
NoData
High response time of 0.2 sec per execution
Check functionally if the query can be changed to improve performance . Else we recommend to add an index on EVENT_TRAN_ID column on BET table to avoid full table scan.
sequence exceeds MAXVALUE
Increase the max value of sequence or use recycle flag
The PL/SQL block is used for file transfer
This can be replaces by Stored Procedure with bind variables.
SQL statement generating more performance cost
Adding below index hint improves SQL performance cost to 12071.\n/*+ index(FCI IDX_FEX_CLEAN_INST_TABLE) */
Intermittent spikes in response time
NoData
Query taking high cost for execution
Index present on PAYSYS_ID and BANK_IDENTIFIER. But the WHERE clause contains only BANK_IDENTIFIER. PAYSYS_ID is available in the script. This should be added in the WHERE CLAUSE of the query
Query taking high cost for execution
Check whether sol_id is available in BANCS.INPUT or BANCS.STDIN repository and add SOL_ID condition with that variable in the WHERE clause of the query
Fatal errors observed
NA
High response time and failure
NA
Full table scan on table HSCLIVE.
NA
High failures and  response time for KWIKTD submit
NoData
Response time does not meet SLA
NoData
Response time does not meet SLA
NoData
Issues in new menus
NoData
Multiple fetch for wait.gif from server across the actions
NoData
bullet.jpg not fetched from browser cache
NoData
High Page Download size for HACLI transaction
NoData
High Page Download size for HBDTM Add transaction
NoData
High Page Download size for HAAM-Modify transaction
NoData
High Page Download size for HAAM-Verify transaction
NoData
High Page Download size for ICIANWCS-Add transaction
NoData
High Page Download size for KWIKTD-Add transaction
NoData
High Page Download size for KWIKTDV transaction
NoData
Large size of js file
File size of all .js files can be reduced considerably by compressing and minifying them. Page size can further be improved if all .js files are clubbed into maximum one or two js files.  Also comments should be removed.
High Page Download size for HCASHDEP transaction
NoData
High Page Download size for HACM Modify transaction
NoData
High response time for Select CRM
NoData
High SQL cost
create index CRMUSER.IDX$$_18FD30001 on CRMUSER.ACCOUNTS("BANK_ID"). It will reduce cost to 15062 if  index is created
Full table scan for table PERSON_SKILLS
Create Index on PERSONID column
Amount and account tab out on HTM and HCASHDEP menu calls a set of URL's which in turn calls mentioned finacle scripts that takes more than 1 Second to complete. Intermittently this spikes > 3 Second thereby impacting overall response time for these steps
Instead of maintaining the configuration parameters in a flat file and open the file for each iteration for read, its recommended to mainatin these parameters in a database table and query the same .
High Page Download size for CIF Verify transaction
NoData
Core file generated in C APP server
NoData
High Page Download size for HOAACSB-Verify transaction
NoData
High Page Download size for HOAACVLA-Verify transaction
NoData
High Response Time and not able to scale up the TPS
NoData
High Page Download size for HAAM-Verify transaction
NoData
We found multiple session wait event on 'virtual circuit wait' for SQL 41mj9dwdpkb07
NoData
SQL statement is performing full table scans with high CPU cost
Create index for ENTITY_CRE_FLG column on NETWORK_DIRECTORY_TBL table. This will reduce cost to 1
SQL statement is performing full table scans with high CPU cost
Create a composite index for ROUTING_REF_NUM,BANK_ID,UTR columns on SWIFT_MSG_HISTORY_TABLE table. This will reduce cost to 1
Fatal Errors
NoData
Error in View
NoData
GC not happening
NoData
Coredump
NoData
Slow execution of genlimo service
NoData
SQL statement is performing full table scans with high CPU cost
Create a composite index for ACCT_NUM,MICR_CODE columns on C_ICHB table. This will reduce cost to 23
Fatal errors observed
NoData
SQL statement is performing full table scans with high CPU cost
Remove TO_CHAR in join condition (gam.cif_id=to_char(accounts.orgkey), and its helped to reduced the execution time and COST, also full table scan on ACCOUNTS table prevented.\nColumn data type as below \ngam.cif_id VARCHAR2(50 CHAR) accounts.orgkeyNVARCHAR2(50)
NoData
Create Index on CAM_ACTIVE_FLAG & Stats are old \n for table CARTBL_CCIF_UCC_ACNT_MAP
Response Time high
It is recommended that the XML file generation code needs to be re-visited. The Operations should be done in memory and flushed to disk at regular intervals. \nA limit for the memory buffer can be configured and once it reaches the limit the data can be flushed to the file system.
Workflow Delay
Recommendation to use PreparedStatements instead of statements.
Response Time high
Remove all sysouts from the code base. If these messages are required for debugging, please move these messages to a logger with appropriate logging level.
Response Time high
It is recommended to close the opened connection, resultset and statement in finally statement.
Workflow Delay
It is recommended to close the opened resource handle in finally statement.
Workflow Delay
'It is recommended to be replaced  with StringBuilder..\nIf StringBuffer has to be retained in the code. Set the initial capacity of StringBuffer using its constructor this improves performance significantly. \nStringBuffer public StringBuffer(int capacity) Constructs a string buffer with no characters in it and the specified initial capacity.\nParameters: capacity - the initial capacity.\nThrows: NegativeArraySizeException - if the capacity argument is less than 0.\nSubsequent slides have information on the classes where StringBuffer is used with line numbers.'
Response Time high
Assign this calculated value to a variable outside the loop.  This would avoid the performance overhead of calculation for each iteration. It would improve the performance of the loop by 150%
Workflow Delay
Restructuring of the loop is required.  Move the most likely case first. Ensure that by satisfying earlier parts of the expression, we do not cause the later expressions to be evaluated and the code executes as fast as the condition is met.
Workflow Delay
Load the javasctipts on load or after all componetns in the page has been loaded. This will improve the performance of the application from enduser perspective.\nBelow example illustrates how to download external javascript in a non blocking manner\nvar h = document.getElementsByTagName('head')[0];\nvar link = document.createElement('link');\nlink.href = 'mycss.css';\nlink.type = 'text/css';\nlink.rel = 'stylesheet';\nh.appendChild(link);
Response Time high
Check if an instance of MI is already running on the server and exit the duplicate request to run the application. Implement the below code in the startup script of MI.\nMI_COUNT=`ps -ef | grep java | grep -v grep | grep MI.jar`\nif [ $MI_COUNT -gt 1 ]\nthen\n{\necho "Already $MI_COUNT instances of MI is running, aborting this startup request"\nexit\n}\nfi
Response Time high
It is recommended to use database global temporary tables to do these transactions. Since these operations would be faster in database temp tables.
Response Time high
The function UPPER to be removed and the value that needs to be passed should be assigned to a bind variable in the expected alphabet case
Workflow Delay
Use PrepatedStatement rather than Satement. Use bind variables for the PreparedStatements.
Workflow Delay
Access Template XML file only once and cache these in lcoal memory using Hashmap and return cached data subsequently.
Workflow Delay
Replace pure local/method scope Hashtables with Hashmaps. \n\nCases where local variable is escaping scope either by returning the Hashtable or modifying value passed as method argument, it could be necessary to use Hashtable (this will have to be evaluated on per-case basis)
Workflow Delay
Use constant first and then the variable.
Response Time high
Use document fragments (container) to hold DOM elements and add document fragment at one go.\n\nvar list = document.getElementById("list"),\n    frag = document.createDocumentFragment(),\n    items = ["one", "two", "three", "four"],\n    el;\nfor (var i = 0; items[i]; i++) {\n  el = document.createElement("li");\n  el.appendChild( document.createTextNode(items[i]) );\n  frag.appendChild(el); // better!\n}\nlist.appendChild(frag);
Workflow Delay
Change the initrans of table to 20 and its indexes to 40
Hard Parsing Queries
Use bind variables instead of literals
NoData
It is recommended to use Hashmap if not used in  multithreaded environment .In case the map is to be used in multithreaded environement we recommend concurrenthashmap .
NoData
Recommended to use Constants instead for hard coding the values inside the classes.
NoData
duplicate calls for same method needs to be removed.
NoData
redundant call to database needs to be removed
NoData
Recommended to have a separate util class for all kind of date formatting or other convertion of fields and those can be reused in the required classes.
NoData
Recommended to combine all the select statement as 1 select and use in the table update.
NoData
It is recommended to remove the cursor user_id and combine both SELECT statements into one statement.
NoData
We recommend into debugging this as to why the transitioninfo list has same task name in its list of objects .
NoData
We recommend to debug into this behaviour . Loggers for these are seen in the weblogic logs . These show the repeated calls to these methods . We recommend caching the object for subsequent uses in an operation.
NoData
These insert statements need to be commented out in production. If these are required for any error tracking then make changes in the code so that if any error occurs then only run insert command.
NoData
It is recommended to comment out dbms_outout.put_line package call in  the packages xxsbi_ar_premium_collection and xxsbi_ar_invoice_pkg which are part of production database. In UAT it is helpful for debugging.
NoData
It is recommended to combine all the update on the same tables as one update statement.
NoData
'It is recommended to assign next value of sequence using variables as suggested below - \nv_trx_header_id =: xxsbi_policy_header_s.nextval;'
On fly conversion of documents/images to pdf files
Perform pdf conversion activity offline using windows service.
Dynamic Compression at web server
Remove compression for Dynamic contents and keep compression for static contents to reduce to page download size for static contents.
Use of Println
Recommended to turn this off . Instaed of this logging api can be used.
Slow respoonse at lower speeds due to transfer of large xml data over network
Do following steps at both dotnet server and android client side:\n1. Before Sending request.\n   - Convert xml string to bytes   \n   -Compress the bytes  using gzip \n   -Convert Compressed bytes to Base64 string.\n2. After receiving request.\n     - Convert Base64 string to bytes.\n     - Decompress using gzip\n     - Convert bytes to xml string
404 errors
Use below approach:\n1. If broken link is from from android client analyze cause and fix it.\n    - If it refers to static missing file then provide it.\n   - If it refers to dynamic missing file analyze to identify  reason for broken link.\n2. If broken link is not due to android app and is due to some manual access no fix is needed.
Hard coded Image compression quality
Configure image compression quality in the web.config of RLI_API. Android application should retrieve the required compression quality from the server at the start of document upload activity.
Missing header for content expiration
Open response header of MobileApp and set following in Set common header of MobileApp website on web server.\n- Set "Enable http Keep Alive" option to true.\n-set "Expire web content:" to some longer duration(~3  months) .
Multiple calls for demo.xml while calling Endown method in ENDOWN.htm
Ensure that request for demo.xml is sent once.
Multiple calls for demo.xml in the load event of RelianceLifeInsuranceMoneyMultiplierPlan.htm
Ensure that request for demo.xml is sent once.
Repeated request for multiple static files after page load of RelianceLifeInsuranceGuarantedMoneyBackPlan.htm
Ensure that repeated requests are avoided for these static resources.
Unused additional data transferred along with image data while document upload.
Use a new light class with only relevant properties such as REFNUMBER and image bytes instead of using ProposalApplication class which contains entire proposal data.
Multiple requests for source xml data file in RelianceLifeInsuranceClassicPlan_II_Single.htm
Avoid multiple calls to same source xml in same event.
Continuous logging and debugging on dotnet server applications
Set configuration for mode of logging in web.config file of all applications and perform logging based on configured logging mode. Create a separate log files for error and messages for efficient IO operations.
Unnecessary call to toString()
Avoid calling toString() on String objects; this is unnecessary.
String comparision not handled properly
'Use Position literals first in String comparisons for equals/equalsIgnoreCase. \nExample: x.equalsIgnoreCase("2"); // should be "2".equalsIgnoreCase(x)'
Use of Stringbuffer
Use StringBuilder instead of StringBuffer if expensive thread-safe operations are not required. StringBuilders is faster than StringBuffer for strings concatenation.
Repeated request for multiple static files during loading of RelianceImmediateAnnuity.htm
Repeated requests should be avoided for the static contents
Multiple calls for demo.xml in the load event of RelianceLifeInsuranceSuperEndowmentPlan.htm
Ensure that request for demo.xml is sent once.
Multiple requests for demo.xml data file in the load event of RelianceLifeInsuranceSmartPensionPlan_Single.htm
Multiple requests of demo.xml should be avoided in the same event.
Same hardcoded value for static variable IP in commonfunctions class for both in UAT and Production.
Use separate service urls for IP values in UAT and production.
Unnecessary select statements in GroupValidation stored procedure in MobileBI database
'In GroupValidation stored procedure just keep select statement for #MSG temp table and comment out select statements for remaining tables.'
'Unnecessary use of temp table #en_agn_trnuserformula in GroupValidation stored procedure in MobileBI database'
'Remove/Comment code to create and populate temp table #en_agn_trnuserformula in GroupValidation stored procedure'
'Avoidable temp table #en_agn_trnformulaSumm in GroupValidation stored procedure in MobileBI database'
'Modify logic to fetch value for ValueSa directly from temp table #en_agn_trnUserFormula instead of #en_agn_trnformulaSumm.'
Multiple requests for demo.xml data file in the load event of PremiumCalculatorforLifeStyleRetirementSolution.htm
Multiple requests of demo.xml should be avoided in the same event.
Repeated request for multiple static files during loading of PremiumCalculatorforLifeStyleRetirementSolution.htm
Repeated requests should be avoided for the static contents
Unnecessary request for rupee_foradian font file in LifestyleRetirementSolutionCalculator.htm
Avoid request for rupee_foradian font files if not needed
Usage of Vector class
We recommend using ArrayList instead of Vector if expensive thread-safe operations are not required.
Multiple requests for demo.xml data file in the load event of RelianceLifeInsuranceSuperMoneyBackPlan.htm
Multiple requests of demo.xml should be avoided in the same event.
Multiple requests for source xml data file in RelianceLifeInsuranceSmartCashPlusPlan.htm
Avoid multiple calls to same source xml in same event.
Multiple requests for demo.xml data file in the load event of ULIP.htm
Multiple requests of demo.xml should be avoided in the same event.
Usage of Hashtable class
We recommend using hashmap instead of Hashtable . In case there is a requirement for high concurrency we can use ConcurrentHasMmap.
404 Error
Create functional indexe for columns  NTID in tables  NP_LEVEL_1_ASAL_EOD_DOM
Query Optimization
Call  PROC_NOOP_FILLSNAP only in stored procedure PROC_Refresh_newPOSXRect. Even this could be avoided if data is directly read from base tables.
Query Optimization
Create index for column refreshtime in table np_cron_refresh
Query Optimization
Remove all trim and Upper functions and update referred table columns with trim and upper functions at beginning of stored procedure. I have received 30% better result by doing so.
Query Optimization
Create index for column ntid in table np_tmp_cross_snap_peakhi
Query Optimization
Create functional index for column ntid in table np_level_1_asalIBG_peak
Query Optimization
Create functional index for column ntid in table np_level_2_asal_peak
Query Optimization
Create functional index for column ntid in table np_level_3_asal_peak
Query Optimization
Create functional index for column ntid in table np_level_4_peak
Query Optimization
Create index for column maturitydate1 in table RTS_GetMaturityRics
Query Optimization
Either apply trim to all comparisons of CurrencyPairRic or don't apply anywhere. If not using trim then create normal index in point 72.
Query Optimization
Create index for column maturityRic in table RTS_tmpMain
Query Optimization
Assign values to all variables in single statement like below.\nIf v_tempcnt> 0 then\nselect currencypairric into currPairRic, CurrencyPair into CurrencyPair_1, Tenor into Tenor, DealType into Dealtype, MaturityRic into matRic from RTS_tmpMain where CurrencyPairRic = currPairRic;\nend if;
Query Optimization
Create functional index TRIM(CurrencyPair) in table RTS_tmpMain
Query Optimization
Remove trunc function on Addedon field of RTS_MaturityMatrix table in all where clauses and take care during insert itself.
Query Optimization
Create functional index TRIM(PORTFOLIO) in table RTS_DEALS_AUDIT
Query Optimization
Create functional index TRUNC(BREACH_DATE) in table RTS_MARGINBREACHDEALS
Query Optimization
"Remove NVL command from queries whereever used like below.\\nNvl(Variable_Name,'0')\ \  not in (VAL1,VAL2,\u2026)"
Query Optimization
No need to have Trader field in sub query. Simply '_BKP' should be specified in the subquery. Also Upper function should be removed.
Query Optimization
fix referenc error of ImageURL  for excel.gif in FXRateScan_BreachedDeals_RepoprtOracle.aspx. This file is missing in images folder.
Query Optimization
Create index for FK_LM_ID in table rts_user_entitymapping1
Query Optimization
Create index for PK_LM_ID in table rts_locationmaster
Query Optimization
Create index for FK_UM_UserID in table rts_user_entityMapping2
Query Optimization
Create index for FK_GM_ID in table rts_user_GroupMapping
Query Optimization
Create index for PK_GM_ID in table rts_GroupMaster
Query Optimization
Create index for TradeDate in table FXRateScan_BreachedDeals
System Properties are hashtable under the hood and are very slow
It is not recommended to use System.get/set property for storing class variables. Instead one global class with static getters should be used by reading all properties at startup time.
It is observed that Stream objects  are not being closed.
It is recommended to close the Stream objects in finally blocks .
Stringbuffer is used many classes even though it is used in single threaded environment .
Its recommended to use StringBuilder instead of StringBuffer after careful evaluation of multithreadedness of the piece of Code Recommendations.
String literals are used in the application very frequently.
it is recommended to use String constants rather literals.
hashtable data structure is used
it is recommended to use concurrenthashmap class over hashtable class.
jdbc custom class written for db connections
It is recommeneded to use dbcp third party open source db pool for better performance
custom CarQueue and CarContainer classes used
It is highly recommended to use RabbitMQ or any other message queueing framework for better message processing with all connected interfaces.
Code Recommendations is not aligned properly
It is recommended to prepare proper checkstyle for Code Recommendations formatting and use eclipse checkstyle feature for formatting the Code Recommendations
some variable are in upper case and some are in camel case
it is recommended to use lower case in .properties file
no toString() method is implemented
It is recommended to override toString() method for pretty print of object for debugging point of view
no jsp template mecanism used in CAR web module
it is recommended to use jsp template mecanism for better maintainability and proper Code Recommendations structrisation.
Custom logging is used in CAR application
For audit trail, the asynchronous logging needs to be looked at rather than current blocking based logging. Log4j can be used for this purpose.
No Clustering is used
It is observed that no Weblogic clustering used in current architecture so we proposed to use Weblogic Clustering for better performance and availability.
Daemon and Message Handler Code Recommendations are in a single module
We recommend to separate Daemon Code Recommendations base from Message Handler Code Recommendations and create separate jar for commonly used utility classes and use among Daemon, MsgHandler and Intranet Modules.
no profiling tool is used for Code Recommendations profiling
It is recommended to use JProfiler tool for doing the profiling. It will give you report of method performance timing.
Single Point of Failure checkings
"To avoid single point of failure, follow given below basic high level recommendations.\\\ n1.\_\_\_\_\_\_ All production servers should have at least 2 Network Interface\ \ Cards.\\n2.\_\_\_\_\_\_ All Production servers should have same operating system\ \ version and build version.\\n3.\_\_\_\_\_\_ All production servers if virtualized\ \ then should be derived from different base server."
NFR Document Prepration
It is recommended to do load testing of CAR application using HP Load Runner for better performance and high load testing and Non Function Document (NFR) should be prepared for application benchmarking for future performance testing.
Process Management
All Use Cases with concurrent users and average response document should be prepared from application knowledge point of view.
NFS Partition was not connecting
'Monitoring NFS Mount points using APM Tool: The NFS mount point working can be checked via custom scripts and these scripts can be called using APM tools at different time intervals'
256 MB only allocated to CAR JVM processes which is not enough for this critical application
It is recommended to do proper JVM Tuning of CAR Java applications and for now we can set Xms-1024M and Xmx:1024M for better performance
This metric is not captured which needs to be captured for better disk usage analysis
To capture the Avg Disk Queue Length, (% wait in Solaris) in monitoring software. This will help in the analysis or hard-disk utilization.
New Feature
It is recommended to use APM Tool JIM (Java Inclusive Monitoring) for checking the method level response time.
New Feature
It is also recommended to use Forensic feature of APM tool
NoData
Create  index & test  on column CTA_FCRM_SR_NO  for table CARTBL_TEMP_ACCOUNTS
NoData
Use UPPER function in the where clause with the columnn\nCUM_CLIENT_NAME  for table  \nCARTBL_CCIF_UCC_MASTER
NoData
Create composite index on CLA_ACCT_NO,\nCLA_TRANSACTION_TYPE,CLA_CREATED_BY FOR \nTABLE CARTBL_CONTACT_LNKGS_APPROVE
Response Time high
The thread count needs to be parameterized in an external configuration file and can be read during the init of the application and kept in memory. This can be tweaked easily for optimal performance
Response Time high
Since there are a limited number of connections that can exist between the host process and the server at one time, setting a timeout enables the host process to open a new request sooner, rather than waiting on a delayed stream.
Workflow Delay
"The for loop performance can be further improved more by changing the loop\ \ to count backwards. So rewriting a loop to compare against 0 will produce faster\ \ loops. \\nSo for example, the earlier discussed program changed as below following\ \ for better performance\\n\\npublic PerfLoopControl()\\n     {\\n         String\ \ str = \"Avekshaa Technologies Pvt Ltd\";\\n         int len = str.length();\\\ n         for (int j = len-1; j >= 0; j--)           \\n          {\\n// code doesn\xED\ t change the length of the string.\\n           }\\n     }"
Workflow Delay
Recommendation to use PreparedStatements instead of statements.
Response Time high
It is recommended to close the opened connection, resultset and statement in finally statement.
Workflow Delay
Analyse requests which are very frequently fired and could be clubbed as single request.
Response Time high
Datawarehouse scripts should be modified to retrieve only Cutomerinduced transactions for uploads and processing from Finacle. This would reduce the number of transactions to be processed.
Workflow Delay
Recommendation to rewrite the logic to avoid filtering based on null values\n2) to create the below index CREATE INDEX IDX_ACCTRISKMAPPING_ACCTCLOSEDDATE ON TBL_ACCOUNTRISKMAPPING(ACCOUNTCLOSEDDATE,' ');
Workflow Delay
The design of these codes to be changed to pass bind variables in the cursor query output instead forming the query as a string,assigning to a variable and then passing it through as cursor output
Response Time high
The recommendations provided in the sheet for each problematic query to be implemented
Response Time high
In certain cases its found that eventhough the values are proper , the program still uses TRIM function. The value should be trimmed before the sql and the trimmed value should be passed as bind variable
Response Time high
The pipe concatenated variables should be removed and only proper bind variable needs to be passed
Batch job execution
Recommended to split batches across all C-App servers as EOD jobs
Batch job execution
NoData
NoData
Increase the heap size from default 64 MB to 500 MB (on 8 GB machine) and 1 GB (on 16 GB machine) and check if the OutOfMemory error is addressed. Check GC behavior after altering heap settings.  \nAdd parameter to the JVM to dump the Heap in a file if OutOfMemory error occurs.
NoData
High service time observed on storage devices even at low transfer rates. Call to be logged with EMC to understand the reason for high service time on the storage devices. This is a problem across servers with varying severity.
NoData
'Change DB level parameter : DB parameter filesystemio_options=directIO.'
NoData
Action linked with DB-1. SGA resizing needs to be done after action DB-1 is implemented. Recommended sga_max_size=160GB and db_cache_size=120GB and tune further as required
Blocked connections
'1. Primary Approach: Need to change the IPs of the servers, so that all the servers belongs to the same subnet. This will eliminate the firewall overhead in the response time and results in significant improvement in response time. It is best advised that components within the logical flow are kept in the same subnet. Any additional layer in between will lead to delay.\n2. Alternate Approach: Need to create Inbound and Outbound Rules in the firewall to not filter/check traffic from specific IP range.'
Static jpg and png files consuming resources of Nginx Load Balancer and Tomcat App Server
Static Resources needs to be cached on Nginx for better Performance. Nginx can be used as a caching layer and these requests will be served from Nginx itself.
Single instance of Nginx Load Balancer Server is running. This is a Single Point of Failure for the complete Platform
Atleast two instance of Nginx Load Balancer Server needs to be there to avoid Single Point of Failure and High Availability of the Application.
Single instance of MySQL Database Server is running. This is a Single Point of Failure for the complete Platform
Atleast two instance of MySQL Database Server (Master-Slave) needs to be there to avoid Single Point of Failure and High Availability of the Application.
Highiest  disk busy percentage, High read and write I/O consumption
We strongly suggest to have different disk to store the critical database related file as this will divide the  I/o consuption to all the available disks and reduce the contention on one disk. This has to taken care as once the load increases on the database this contention will also increase exponentially.
High resource consumption
The table fragmentation needs be to taken care as the query execution is hampered  .
High Resource consumption
Output of validateSP API needs to be cached on Nginx or Im-Memory-Cache for better Performance. Nginx can be used as a caching layer and these requests will be served from Nginx itself.
High Resource consumption
Output of getActiveProducts API needs to be cached on In-Memory-Cache for better Performance. And these requests will be served from App Server itself.
High Resource consumption
These API calls needs to be served directly through method call instead of RestServiceCaller to improve the turn around time.
High Resource consumption
These API calls needs to be run in parallel to improve the turn around time.
High Resource consumption
maxConnection value needs to be increase and impact needs to be monitored. Recommended value of MaxConnection attribute is 12 * Number of Cores.
High response time
To reduce the total size, GZ Compression needs to be implemented for js and css files. This will reduce the total size by ~80% and improves the page performance.
High response time
To reduce the total size, GZ Compression needs to be implemented for js and css files. This will reduce the total size by ~60% and improves the page performance.
High resource consumption
1)We suggest to schedule alerts with respective warning thresholds.\n2) Also set the SESSION_CACHED_CURSORS parameter to value 60.\n3) Use bind varieables in the queries instead of literals to avoid high parsing .
Availaibility Issues
Hence increase the size of redo_log from 100 to 200 MB. Also should have two members for each redo_log group.
Availaibility Issues
1)These queries with high resource consumption &  execution time need to tuned and corresponding indexing need to be validated .\n2) Also need to consider data purging where it is possible. Partitioning of the table will also be helpful but this may need additional license
High memory consumption
We suggest to increasing the  memory by 30 %   on  server inorder to handel 3x load.
Database slowness
The table fragmentation needs be to taken care as the query execution is hampered  .
High memory consumption
We suggest to increase 30%  memory on the server inorder to handel 3x load.
One sluggish service degrades the other services also
Expose all TeBT portal services as microservices which can be run on  lightweight application server (apache tomcat), and to be deployed on various instances in cluster.
Workflow Delay
1. It has been observed that this batch takes less than  6 mins for execution. We recommend the batch frequency to be changed from 30 mins to 15 mins. This will ensure that policy conversion for respective policies can be reduced by 15 mins.\n\n2. This batch can also be a candidate for converting into a real time service with the same rationale as provided in the recommendation (# no 4).
High Memory Uilization
Cached memory of both server should be uniformally distributed.
High Response Time
The data will be backed up every month and then purging will be done so that ample space can be released back to OS.
Workflow Delay
We had intially suggested the  "optimizer_index_cost_adj" parameter to be set to 100 (default) to use optimal execution plan for sql queries.
High CPU Utilisation and High IO Writes
After analyzing thread dump, it has been observed that 52% of total thread was in blocked state. All these threads were blocked while getting connections from DB. The effect of getconnection() method is that a lot of threads gets blocked during processing of resultset object. Each of these processing  have a connection assigned to it which does not get released until the processing/transformation of resultset object into json gets completed. This incident has been observed on hslpaext1 - 10.60.5.175 for OPS application.\n\nCode review comment:\nIn code, connection is getting released after the result object gets converted into json. For json conversion Blob column is used which is taking time for transformation from/to json. This is done to save memory, but this will take time for processing resultset object. The optimization of code would not save a significate time in releasing DB connection.
High Response Time
'We propose to increase JDBC connection pool across all the SOA layers (Front office, back office, Branch and BPM - WAS clusters). \nThe proposed increase is by 50% where existing connection pool value is less than 110. For values more than 110, there is NO change is required.\nNote: \n1) Please make changes to only those data sources which are related to TeBT application flow, other need not be changed.\n2) Please make one changes to one WAS cluster at a time. Once it''s stabilized then proceed for the next cluster. \n3) Also, do not make more than one change at time to ensure that it can be rolled back\nThis will ensure the system has higher pipeline to accommodate more connections/requests. In the embedded image, proposed plan to implement the connection pool across all the related servers have been highlighted.'
High Response Time
Increased JDBC connection pool size to 125 on Flowdox app servers.
High Response Time
We have observed "BreakNetExeception" from OPS portal to DB.\n\nOur suspicion is that there were network packets losses between external portal and DB Server. This however is observed intermittenly. Please follow the below approach in case of similar observations in future:\n- Take TCP dump between the hslpaext1(external portal server) and DB Server \n\nThis dump will indicate if there are network related issues at external Portal / DB server. \n\nAs a long term strategy , we strongly recommend to monitor the network performance across the servers. It is best advised that HDFC Life leverage the capabilities of Dyntarce Network Monitoring feature. Alternatively you can also install iftop across servers and monitor network utilizations.
Workflow Delay
'It''s recommended to reduce the Minimum heap size (-Xms) for all the Java setups so that GENCON which is a defult algorithm in Java 1.6 works efficiently. Setting it at equal size does not leave Java any room for memory increase. Also, -Xmx (max heap) size affects GC in bad way such as long GC duration etc.\n\nWe recommend  to change all settings for -Xms to 4GB for all the Java Servers (SOA+BPM) where -Xmx (max) is set to 12GB\n\nNote: This will NOT have any negative impact as such since we not restricting the Max memory'
High Response Time
Its recommend to switch GC policy from gencon to balanced
High Response Time
Increase the bandwidth between the two cluster interconnect nodes to 1 Gbps for private network.
Workflow Delay
Our suspicion is that there were network packets losses at load balancer end. As per Dynatrace logs there were timeout errors observed on LB 10.60.5.118. \nThis however is observed intermittenly. Please follow the below approch in case of similar observations in future:\n1. Take TCP dump between the Portal and LB (talking to EMP Portal)\n2. Take TCP dump between the SOA Server and Back office \nThese dumps will indicate if there are network realated issues at SOA / LB / PAN server\n\nAs a long term strategy , we strongly recommend to monitor the network performance across the servers. It is best advised that HDFC Life leverage the capabilities of Dyntarce Network Monitoring feature. Alternatively you can also install iftop across servers and monitor network utilizations.
High Response Time
Recommended settings shared in "limits.conf" and "90-nproc.conf" sheet.\nImplementation plan has been shared with the team.
High Response Time
We propose the below approach :\n1. We propose physical memory to be increased to 23 GB for the below servers and Java Heap Min & Max( Xms & Xmx) to be set 4Gb and 12 Gb respectively.\n\nHOST                   Proposed GB\nhslpabsoa3       23\nhslpabsoa13     23\nhslpabsoa14     23\nhslpabsoa4       23\nhslpabsoa11     23\nhslpabsoa5       23\nhslpabsoa6       23\nhslpabsoa12     23\nhlpabsoa17       23\n\n2. In case on the below servers if physical memory can't be augmented (however we strongly recommend to increase it to 23 GB), the below approch should be followed.\n\nHOST                   Available GB        Xms         Xmx\nhslpabsoa3       15                         4               12\nhslpabsoa13     13                         4               8\nhslpabsoa14     13                         4               8\nhslpabsoa4       15                         4               12\nhslpabsoa11     11                         4               8
Workflow Delay
"We recommended to improve document mapping at POS side so that a set of\ \ images can be categorized into one single type then and there and same will be\ \ reflected in FileNet. This can be done as follows,\\nBy following document mapper/taxonomy\ \ in POS before uploading document into FileNet.\\nAdding front end validation while\ \ uploading document.\\nAdding a tooltip which will provide more detail about the\ \ type of document , no. of images/documents, size of the image, etc.\\nRestricting\ \ number of documents uploaded in \u2018OTHERS\u2019 category."
Workflow Delay
"We recommended to improve document mapping at POS side so that a set of\ \ images can be categorized into one single type then and there and same will be\ \ reflected in FileNet. This can be done as follows,\\nBy following document mapper/taxonomy\ \ in POS before uploading document into FileNet.\\nAdding front end validation while\ \ uploading document.\\nAdding a tooltip which will provide more detail about the\ \ type of document , no. of images/documents, size of the image, etc.\\nRestricting\ \ number of documents uploaded in \u2018OTHERS\u2019 category."
High Response Time
Our suspicion is that there were network packets losses at load balancer end. As per Dynatrace logs there were timeout errors observed on LB 10.60.5.46. \nThis however is observed intermittenly. Please follow the below approch in case of similar observations in future:\n1. Take TCP dump between the SOA Server and LB (talking to PAN Servers)\n2. Take TCP dump between the SOA Server and PAN Server \nThese dumps will indicate if there are network realated issues at SOA / LB / PAN server\n\nAs a long term strategy , we strongly recommend to monitor the network performance across the servers. It is best advised that HDFC Life leverage the capabilities of Dyntarce Network Monitoring feature. Alternatively you can also install iftop across servers and monitor network utilizations.
High Response Time
'Raised ticket with IBM: TS001341188\n\nAs per IBM Support team''s reply, IBM BPM product upgrade is required in order to resolve this issue.'
Workflow Delay
Solution\nN+1 Standby deployment manager in HA\nFailover to the new standby deployment manager is depicted in the following diagram:\n\n\n\n\nIn above diagram, The active and standbys share work spaces. When a deployment manager takeover occurs, work is not lost, because the ODR automatically recognizes the election of the new active deployment manager and reroutes administrative requests to the new active deployment manager.  During the takeover from the active deployment manager to the standby, shared file system detects the loss of the active deployment manager and release the lock.
Workflow Delay
Total 22 issues identified in Premium Calculation, Proposal Form Filling Journey and Submission. Observation and Recommendation details shared in Analysis Report (Online_Journey_Analysis_7Sep2018.pdf and 2nd_Online_Journey_Analysis_17Sep2018.pdf)
Workflow Delay
Please check the MSGLOG table (which has a CLOB column in which entire message is dumped ) and why that kind of requests are failing. At present it's truncated at regular inetrvals but till we fix this error at the souorce , this approch will not be useful.
High letancy in query thoroughput.
1. Create tablespace with 16 K blocksize  and move the DET_TRADES_DELETED table with the tablespace.\n2. Create tablespace with 16 K blocksize  and move the DET_TRADES_DELETED table indexes to it.
Static data downloaded multiple times.
Caching of Static data.
Oracle Connection object used multiple times.
It is recommended to use seprate datautility class file.
No Tests Present.
Write the Unit Test cases
No automated alert mechanism.
There should be an email mechanism which can capture call stack and logged user information and send email to IT.Net Support Team.
No Profiler Reports available.
It is recommended to maintain the Profiler reports before publishing new deployment on production servers.
No Impact Analysis Document available.
It is recoomended to maintain the Impact analysis document for each CR.
No Application logs are available.
It is recommended to maintain Application Logs.
Static Hard Coded values found.
It is recommended to read the static hard coded values from the config files.
Process
It is recommened to remove the un-used commented code.
Process
It is recommended to prepare setup program using Install Shield or NSIS Install System  for IT.Net Application
Maintenance
1. Please review the empty tables and drop the tables which are not required. The tables which are created for any adhoc requirement and not used for application or not used by any query, please review the same and drop the tables.\n2. Attached the list of tables with sizes.
Maintenance
Defrag the high fragmented tables, which will release the space and improve the performance of the database. Tables list attached.
Adhoc queries are running in prod environment.
1. Do not run any ad hoc query in production database.\n2. Use active dataguard database for the Ad hoc queries.\n3. Every query should run with optimal plan, which  should use the proper index.
No Parallelism used.
The INSERT,SELECT and DELETE query can be appended with a PARALLEL hint to enable ORACLE to parallely process the DML's .
Design
Please check the functionality if SQL can re-write by removing SST from FROM clause and WHERE clause. This will reduce the Temp space utilization and SQL cost will reduced to 2900 approx.
No Online Backup
We recommend to carry out a HOT backup (online flash copy) for database .
Multiple requests for demo.xml data file in the load event of RelianceLifeInsuranceDoubleEasy.htm
Multiple requests of demo.xml should be avoided in the same event.
Multiple requests for demo.xml data file in the load event of RelianceGarnteedmoneybackPtS.html
Multiple requests of demo.xml should be avoided in the same event.
Unnecessary query to initialize variable in stored procedure get_Cashflow_NewPlans
Avoid initializing variables @startRange and @EndRange in stored procedures if not needed.
Unnecessary query to initialize variable in stored procedure get_Header_NewPlans
Avoid initializing variables @startRange and @EndRange in stored procedures if not needed.
Unnecessary query to initialize variable @mindate in stored procedure get_Header_NewPlans
Avoid initializing variables @mindate  in stored procedures if not needed.
Unnecessary code  initializing @str variable and print command in stored procedure get_Header_NewPlans
Avoid initializing variable @str and print command in stored procedures if not needed.
Unnecessary inserts in table PERFORMANCETESTING..
Avoid inserting values in PERFORMANCETESTING if not needed.
Thread contention in ECS.DAL.Repository.WebPortal.WebPortalRepository.GetFamilyDetails
NoData
Queries with high response time.
Create non-clustered index on jobtype and status columns of BatchJobs tables.
Large volume of hits for static contents.
Enable browser side caching on application server. This will also result in bandwidth reduction for static contents on application server
Large number of 404 erros due to broken links
Fix 404 errors due to broken links using below steps.\n- Search all instances of url mentioned in excel in application code.\n- Provide correct path for the missing resource"
Thread contention in ECS.DAL.Repository.ODS.ECSPolicyDetailRepository.GetPolicy
Do following steps.\n1. Instead of applying EntityFunctions.TruncateTime function on EndorsementDate column use variable side value without time.\n2. Create Index for EndorsementDate column in ECSPolicyDetails table.
Thread contention in System.Net.UnsafeNclNativeMethods
NoData
Thread contention in constructor DynamicClass.BuildUp_ECS.BL.BL.ClaimCommon.DocumentDetailsBL
The required objects should be passed into functions as parameter instead of initializig them in constructor.
Thread contention in ECS.BL.SavvionReference.RGICL_HCS_WSService.assignOrKeepTask
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
Caching for Master tables
Implement Database level caching using sql server notification by associating SQLDependency class with linq.
~81 broken links in SmartZone application server
Fix the broken links issue for all urls listed in attached list by using correct url for service/resources.
Multiple requests for bundles/jquery and bundles/jqueryUI on page Motor/Motor.
Avoid multiple calls for static resources in same event.
Multiple requests for bundles/jquery?v when user clicks on Travel->Individual link.
Avoid multiple calls for a static resources in same event.
Repeated requests for method GetallStates, GetCountry, GetDistrictWithStateId, GetCityWithDistId and GetAreaWithCityId when user clicks on Travel->Individual link.
Avoid repeated calls to same methods in same event.
Unnecessary initialization of list PricingResponseList with tempdata value in action method MotorQuote
Avoid initializing PricingResponseList if not needed.
Unnecessary query to fetch MasModelRegion from table tblMasModelRegion in method FetchMotorPolicyWithPolNo
Avoid query to set value for MasModelRegion and RTOLocation if not needed
UnUsed variables in SaveMotor method
Avoid initializing unused variable if not needed
Unnecessary calls to method loginmodel.getuserid to initialize variable loginid
Avoid unnecessary call to getuserid function and try to persist user id for entire session to avoid multiple calls to database.
Unnecessary query in function FillPolicy to initialie variable PolicyIPA of type tblPolicies.
Avoid query to initialize the variable PolicyIPA if not needed
Unnecessary retrievals from tblpolicy table to set properties on objPolicy in SaveMotor method.
Set entire objpolicy properties in  FillPolicy method only.
Unnecessary query to retrieve the user id from Users table in savexml function
Avoid query to retrieve user id if not needed.
Unnecessary query when objvehicledetails.ncbeligible value is 3 in savemotor function
Avoid calling query if not needed.
Unnecessary same repeated query to set objPolicyCover when it returns null
Avoid repeat query for objPolicyCover when it returns null.
Multiple requests for Motor/FetchRTOStateandRegion when clicked on calculate premium button
Avoid multiple requests for the motor/FetchRTOStateandRegion in the same event.
For RPAS application call for GetProposalAllDetails in Home action method to fill the entire dataset when only count of records is needed.
Call some other service which should return just count instaed of entire proposal details.
Active session state on application controllers
Set attribute <sessionState mode="off"> on controllers where session is not needed.
Action methods simply returning blank json.
Avoid request for action method which simply returns blank json response if not needed now.
Column concatenation and use of function SqlFunctions.StringConvert on column in method FetchVehicleMakeModelProductBaseDetails
Separate out values for Make_Name, Model_Name ,variance and CC for comparing against clumns in queries
Unnecessary multiple execution of queries on same condition overriding result of last query in method FetchVehicleMakeModelProductBaseDetails
Avoid calling multiple queries on same variable on same conditions.
Unnecessary query to initialize the variable ProductArc in method FetchVehicleMakeModelProductBaseDetails
Avoid query to initialize the variable ProductArc if not needed.
Continuous exception "InsufficientExecutionStackException" in table tblATLog of database AuditTrail.
Try to catch the InsufficientStackException exception in all controller classes and hendle  error gracefully
Unnecessary call for controller method Covers after click on Save/Continue button
Remove call for Covers if not needed
Unnecessary passing of @ViewBag.PolNo to action method GridCoverType_ReadSS
Avoid passing viewbag object if not needed and change action method accordingly to remove unnecessary code.
Unnecessary initialization of variable UserId by calling method GetUserName in the action method GridCoverType_ReadSS
Avoid initializing variable UserId if not needed
Linq queries with very high cost
Check policyid for null or zero outside query and Optimize query to avoid index scan on these tables. Can split query into two.
Linq queries with very high cost
Check policyid for null or zero outside query and Optimize query to avoid index scan on these tables. Can split query into two.
Very large number of requests for static resources in home.aspx and throughout the application .
Use Microsoft ASP.Net optimization framework to bundle .js and .css files into few requests. The bundle groups should be created based on page category.
Multiple requests for initstrings.js during page load of Home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple calls for embed/4hHIuacCdOo during page load of Home.aspx
Avoid multiple calls for same request in the same event.
Multiple requests for strings.js during page load of CarInsurance.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for core.js during page load of CarInsurance.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for analytics.js during page load of CarInsurance.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for jqueryui.min.css file during page load of CarInsurance.aspx.
Avoid multiple requests for the static resources in the same event.
Client side search on every key input on search by make model field.
Avoid search for make model at client side when user is typing. The search should be called only when user stops typing for 1 seconds similar to smartzone application.
Multiple requests for jquery.SPService-2014.01.min.js when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for FAQForCar.js when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for footable.core.css when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for rgi-fav-icon.ico  during page load of Two-Wheeler-Insurance.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for core.js during page load of Two-Wheeler-Insurance.aspx.
Avoid multiple requests for the static resources in the same event.
Empty catch block in the LoadHomeBanner method in QuickQuoteHome.ascx
Log the errors in LoadHomeBanner using Utility.LogDataToFile as done in other methods.
UnUsed variables in function FillPolicyDetails of QuickQuoteFourWheeler.ascx.
Avoid initialiing the unused variables.
Unnecessary initialiation of entire datatable DtPolNo in the load event of QuickQuoteHome.ascx
Avoid initialiing entire DtPolNo datatable in the load event of QuickQuoteHome.ascx. Instead just fetch required policyno.
High Fragmentation on Heap and Indexes of database DBWebsite
For heaps create clustered index on table and for indexes rebuilt to remove fragmentations.
Unncessary code execution after response.redirect in TwoWheeler method of QuickQuoteHome.ascx
Exit function with return statement after response.redirect.
503 error while trying to perform search.
Remove search ICON from the website page to prevent user from performing search.
Multiple requests for core.js during page load of Dashboard.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for strings.js during page load of Car-Insurance-Premium-Calculation.aspx..
Avoid multiple requests for the static resources in the same event.
Unnecessary intitialization of variables dtEntry and tspTotalTime in LogDataToFile method of Utility class.
Avoid computing timespan and avoid to initialize variables dtEntry and tspTotalTime if not needed.
Workflow Delay
Each queries must have a proper exception handling clause with proper exception codes which will be followed across all the procedures
Workflow Delay
Remove synchronization blocks/methods where object is not being used in multi-threaded mode or when method is not accessing any class property. If a method or code blok is accesing only local variables there is no need for synchronization.
Response Time high
Use logging framework like log4j.
Response Time high
Use logging framework like log4j.
Workflow Delay
Use StringBuilder rather than string. This will be faster and will also have smaller memory footprint.
Response Time high
Access expesive resources only once and cache these in lcoal memory using Hashmap and return cached data subsequently.
Workflow Delay
Read and store a value before the loop starts and use this value inside a loop rather than calculating same value each time.
Response Time high
The audit entries should be made in an asynchronous manner so that it does not impact the live business transaction. Also, the call to audit entry be surrounded with try-catch block and all exceptions should be absorbed with a possible log entry. It is also advisble that Audit database is running on separate physical server so that it down not interfere with PROD server.
Response Time high
Read loop size once before the loop start.
Response Time high
Always use Radix when using parseInt in javascript.\nparseInt("020", 10);\nparseInt("237", 8);
Workflow Delay
Check for space on standby location & confirm standby loaction parameters
Workflow Delay
Allocate extra extents to LOB colum, But this is temporary fix,It is recommended to raise a service request with My SQL support & confirm if this has been a bug for which My SQL can recommend some patch.
Response Time high
A shell script has been provided, which will monitor the space in periodic interval and send a alert on mail if mount point is 80% full.
Workflow Delay
Moving redo logs to RAID 1+0 was recommended, during load testing itself
Response Time high
Raise a service call with My SQL support to confirm if there is any patch needs to be applied.
Response Time high
Contacts table need to be analyzed
Workflow Delay
Separate mount points for\n1. Tables Datafiles\n2. Index Datafiles\n3. Redo and comtrol files\n4. Tempfiles\n4. Undo datafiles
Response Time high
Autoextend should be set to OFF with maxsize defined as 4 GB. This will also help in I/O distribution and Less dataloss in case of recovery
Response Time high
DBA role should be revoked from application users and only required privilges should be assigned
Response Time high
Recreate temp files on different mount points with 8gb each
Response Time high
It is recommended to have RAID 1+0 storage for database files
Response Time high
Need to change application logic to execute the query or use order by clause
Workflow Delay
The initial extent needs to be set to 64K as that of current production.\nTable & its indexes have to be moved to new tablespace & recreate the constraints and analyze tabel
Response Time high
The initial extent needs to be set to 64K as that of current production.\nTable & its indexes have to be moved to new tablespace & recreate the constraints and analyze tabel
Response Time high
fn_categorylookup function has to be changed to have join on bank_id field on categories & category_lang tables
Response Time high
sga_max_size - 24G\npga_aggregate_target - 6G\njava_pool_size - 512M\ndb_cache_size - 10G\nshared_pool_size - 2048M\nlarge_pool_size - 256M
Workflow Delay
below parameters are changed.\nparallel_max_servers = 32                         \n_enable_NUMA_optimization = true               \n_undo_autotune    = false\n\n_db_block_numa ,_gby_hash_aggregation_enabled,INBOUND_CONNECT_TIMEOUT  parameters need not be changed, since 11g has given values as default.\n\ndb_cache_advice needs to set to OFF at end of PT.
Response Time high
Sales table needs to be moved to tablespace having maxsize of database files as 8 GB
Response Time high
Categories table needs to be moved to tablespace having maxsize of database files as 8 GB
Workflow Delay
Need to have proper indexes on queries and jvm needs to be run with  DMy SQL.jdbc.defaultNChar=false option to avoid implicit datatype conversion
Out of memory error
Change/Add the value of following parameters in the JVM parameters file \n Parameters are provided in a separate mail
NoData
It is recommended to close the file object post usage . Finally block is recommended as follows \n finally {\n  if (fileObject != null) {\n    try {\n      fileObject.close();\n      catch(Exception e) {\n        log it -- do NOT rethrow\n      }\n    }\n  }
NoData
It is recommended to close all the artifacts related to connection .
NoData
It is recommended to add parameters in a SQL query via preparedstatement.set("") methods for correct datatype .
NoData
It is recommended to close all these artifacts only in a finally block with individual try catch blocks.
NoData
Need to increase the DB_CACHE_SIZE to around 20 GB from 3.5 GB which is minimum size and it is growing up to 12GB as of now on both the database nodes.
NoData
It is recommended to remove or comment out sysout. Recommended to use Logger with log level if necessary.
NoData
It is recommended to close all the connections in finally block only.
NoData
Reorganize the tables and rebuild the indexes on this table.\nPlease refer the list of tables from Fragmentation tab that need to be reorganized.
NoData
duplicate calls for same method needs to be removed.
NoData
Insured object list to be computed only in perform() and should be passed to the respective method
NoData
if/else condition should be used for productId comparison
NoData
the value for productId should be computed only once and set it to some long vlaue. So that productId will not be computed in all the blocks.
NoData
Recommendation to club  smaller operation steps in to one operation step which can reduce the calling of number of classes. Target should be to reduce the number of operation steps. This will also reduce the plumbing at the start of each class.
NoData
Loading of the policyBO should just be computed once. Recommendation to put that in FLowContext or some other existing persistent class or cache.
NoData
duplicate instantiation of policyBO object which is loading the PolicyBO multiple times. Recommended to revisit the code and remove it.
NoData
redundand code needs to be removed from the code base.
NoData
classes should be imported once below package definition of the class instead of defining the class definition each time the class is used.
NoData
Recommendation to create index on Policy_id column of table T_SBI_MEMBER_DTLS.
NoData
It is recommended to comment out dbms_outout package call in the procedures/funcations/packages which are part of production database. In UAT it is helpful for debugging.
Improper use of list.size()>0
Substitute calls to size() == 0 (or size() != 0) with calls to isEmpty(). list.size()>0 slower than list.isEmpty().
Large size of .css and .js files
Perform following.\n1. Remove comments from .js and .css files.\n2. Minify and compress  the .js and .css using minification tool.\nRefer to http://dean.edwards.name/packer/
Unnecessary request for rupee_foradian.ttf file in RelianceLifeInsuranceClassicPlan_II_Single.htm
Avoid request for rupee_foradian.ttf file if not needed
Application using android.util.Log resulting in single large log file
Use custom logging to write the application logs on daywise custom log files so that application log size couldn't grow very large. Maintain separate logs for error and messages. Also implement log archival policy which is not possible to implement currently.  These log files can be accessed by support team for diagnostic purpose without taking the root access of android tab.
Use of String.indexOf(String)
Use String.indexOf(char) when checking for the index of a single character; it executes faster.
Misplaced null check
The correct way is to place the null check in front of the if statement. The second part of the statement will be evaluated only if the requestId variable is not null.
Repeated request for multiple static files during loading of RelianceLifeInsuranceSmartPensionPlan_Single.htm
Repeated requests should be avoided for the static contents
Unnecessary call for "CommonFunctions.deletesession" function in all methods of Service1.svc
Avoid calling method "CommonFunctions.deletesession" in below 36 methods in Service1.svc.\n(PayFive, Endown, Child, Term, FixedSavings, SRS, MoneyMulti, GMB, GMBPTS, GMBReverse, cp109, cp110,  imedateann, cfu113, HTP, HTRPC, Superedwn, sm117, sm2118, p1191, p1192, SMB, ERSSelectCalc1, ERSSelectCalc1, ERSSelectCalc2, Wkid,  income, supermoney, supermoneyReverse, supercashplus, supercashplus, supercashplus, ulip, DERS, r8, r9
Repeated request for multiple static files during loading of RelianceLifeInsuranceSuperMoneyBackPlan.htm
Repeated requests should be avoided for the static contents
Multiple requests for source xml data file in RelianceLifeInsuranceDoubleEasy.htm
Avoid multiple calls to same source xml in same event.
Repeated request for multiple static files during loading of RelianceLifeInsuranceDoubleEasy.htm
Repeated requests should be avoided for the static contents
High cost index seek for Clustered index PK_en_agn_trninputvalues
Avoid using ltrim and rtrim function on the column fieldcode to avoid clustered index scan on  index PK_en_agn_trninputvalues
Very large log file size of MobileBI and PDC database
Shrink the database log file size using DBCC SHRINKFILE command.
Very high limit to grow for MobileBI and PDC database log file
Restrict the MobileBI and PDC database log file size to lower value ~500 MB.
Multiple requests for jquery-ui.min.css file during page load of Two-Wheeler-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for initstrings.js during page load of Two-Wheeler-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for strings.js during page load of Two-Wheeler-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for core.js during page load of Two-Wheeler-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Low autogrowth size for active log file of website_audit.
Set autogrowth for log file between 100MB to 500 MB and keep max size as unlimited
Multiple locations for static contents
Map all static contents such as images , css, js and woff files to directly download  from akmai servers instead of IIS server to reduce the latency of downloading static contents
Unnecessary call to RegisterStartUpScript before redirect in PopulatePaymentObject method of  BuyFourWheeler.ascx.cs class
Avoid calling RegisterStartUpScript if not needed.
Unnecessary code execution after response.redirect in CreateProposalForTravel method of BuyTravel.ascx.cs class
Add return statement after response.redirect. Move InsertTravelLogger statement before the response.redirect.
Query Optimization
This module pertains to transaction creation through MTT routine. HP team to check on the usage of this module during business hours in RPT server and if possible execute it after business hours when all report extraction jobs are completed
Configuration
Cache size to be set for sequences to improve the response time of transactions referencing to sequences. Also the patch details provided for the above issue holds good for this observation too
Configuration
It is recommended to have RAID 1+0 storage at both DC and DR for improved storage performance
Query Optimization
Oracle has suggested a patch for oracle version 10.2.0.5 (Doc ID 1133845.1) to address this error. It is also recommended to upgrade database to oracle version 11gR2, which uses adaptive cursor sharing to addresses issues related to change in execution plan of the query.\n\nAlso the query was running from  rrbx4001 module, which is used for reporting purpose. Hence we recommend to check feasibility to run these reports from MIS server
Slow Response Time
Network team to check the reason for 2 hops on the same IP and eradicate the same
Slow Response Time
It is reccommended to migrate to the latest certified version for better performance
Code Review
The transaction creation process and message creation process can be bifurecated into two seperate steps.
Code Review
We recommend to increase the cache size to appropriate value which will reduce down the cache utilization levels and result in reduced "Cache write Pending" to improve the performance of core banking database IO system.\n\nAs confirmed with Pankaj, Cache size should be set to double of the current value. Also this reccomendation will assist in enabling direct I/O for redo log file system for database ( point 4 in database analysis)
Code Review
Feasibility of using a flashcopy to update the RPT server to be checked by the storage team
Configuration
The necessary change for this is done in the load balancer by enabling  " Insert x-forwarding-for" to pass the client ip in the "x-forwarded-for" HTTP header. This change in the HTTP header needs to be accommodated in the Web servers also by installing ISAPI filters for "x-forwarded-for" HTTP header.
Configuration
Fix the path to the static contents shared.
Slow Response Time
Reduce the file size, by compressing, or create pdf files from optimized microsoft office word documents.
Code Review
Style sheets are in the body of the document rendered. This needs to be moved to head of the document which is flushed from the server. This would accelerate the page rendering.
Code Review
Javascripts blocks the content download while on head or body, currently we have observed that javascripts are in the document head/body, which needs to be moved to the bottom of the body. This would allow the browser to download all contents in the page in a non-blocking manner.
Code Review
"Components which doesn\u2019t change for a long time like css, js, images\ \ can be cached at the client side(Browser). The returning customers will benefit\ \ if this is enabled, since the pages would load faster and no additional requests\ \ would be made by the browser.\\nHeaders to be configured for static resources\ \ in Webserver IIS\\n1. Vary: Accept-Encoding\\n2. Expires on future date to be\ \ configured  for *.ico,*.gif,*.css,*.js\\n3. Configure FileETag as none"
Code Review
Further to investigate why the response was not sent/received by vendors for these transactions, we recommend to do the application debug testing and check at which point it is failing while responding back to vendors. From the Internet Banking team, we came to know that some customization is done by the bank team over the product for this application. We have requested for customization code from Internet Banking team to put debug statement in code.
Query Optimization
Please refer query list sheet for more details
Query Optimization
Please refer query list sheet for more details
Maintenance
Reorganization and rebuilding activities needs to be performed in the indexes shared. Please refer Sheet "DB Fragmentation" for details of the objects which needs to be acted upon
Query Optimization
Please refer query list sheet for more details
Configuration
Sepearate mount points to be allocated for Corporate Index files and Payaway database files.
Query Optimization
Application logic an be changed to loop back to find valid port and IP inside the C code. The config file can be read inside the while loop till a valid IP address and port can be found
Query Optimization
The program logic needs to be deeply analyzed to find out the reason for so much lower number of updates
Query Optimization
Check for the logic and take appropriate action
Query Optimization
Check for the logic and take appropriate action
Code Review
Application logic can modified to use the user hooks once and use the data simultaneously.
'Cursor: Pin S'
Avekshaa to review the AWR's with the new database version on AIX
Query Optimization
need to check application why it is locking
Performance
Bank needs to look at their future volume and discuss with product vendor on a viable solution (either customisation or base product) so that volumes as projected by their business can be handled
Query Optimization
This can be changed with EXISTS clause for better performance as following\nSELECT ACID into :recCnt FROM CTD WHERE exists (SELECT ACID FROM CTD ACID=:acid AND TRAN_DATE=:tran_date  AND INSTRMNT_NUM=LPAD(:inst_num,16) AND TRAN_AMT=:tran_amount);
Query Optimization
Replace first query with second and use exist clause to check data in result set.\nselect count(*) into :icicnt from where EXISTS (select nvl(rej_type,'000') into :icirej from ICI where sol_id=:solId and zone_code=:zoneCode    and zone_date=:tran_date and zone_srl_num=:zone_srl_num and      inst_num=lpad(:inst_num,16))
Query Optimization
Analyzed Sql plan are fine and there no any issue observed
Configuration
This has been shared and discussed with ICICI team. After discussion it has been decided that time.tbg log should not be modified and there should be a separate file name used for this logging. Log file name should be created day wise and log should include following information about batch execution \n1. Start date\n2. End date\n3. Volume of data processed\n4. Indicator name  \n5. Sol id
Configuration
This prototype is designed to parse the log of any batch and shows analysis. This would be tool to view statistical data in readable format for batch performance analysis perspective.
Configuration
Implementation of the parser tool in production for data collection
Configuration
File name should be validated before  upload starts with database  and using AJAX . This has been shared and discussed with ICICI team. Solution Design and prototypes has been shared with ICICI team
Configuration
No issues indentified. However, scope for analyzing code/design is minimal since most of it is product code.
Configuration
This prototype is designed to parse the log of any batch and shows analysis. This would be tool to view statistical data in readable format for batch performance analysis perspective. EOD/BOD Batches process job using parrallel processing and currently log is recorded for starting of these no of job and finish time. This tool need to configure for no of jobs selected in each execution.
Code Review
Convert gifs to PNG files and use tools like pngcrush to optimize png files. Make code changes on all pages and replace .gif with .png.
Configuration
'Increase TCP/IP buffer size to 64K.  This is an IBM recommended value for standard web app traffic. \nNote: On Wondows 2008 server it was not accepting  8388608. Hence set to 64K on UAT server. Same will be done on PROD server too.'
Configuration
It is recommended to set this  value to \n -1 (unlimited) and let OS manage the upper limit.
Configuration
Apply latest fix pack from IBM. This will address few important performance related issues and will take WAS version to the latest one in WAS 7. The new version should be 7.0.0.29.
Configuration
Edit httpd.conf file on all 3 web servers\n\nAdd below section in httpd.conf file immediately after section "mod_mime_magic.c":\n\n<IfModule mod_mime.c>\n    AddType image/ico .ico\n</IfModule>\n\nAdd expiry period for ico files:\n\n<IfModule mod_expires.c>\nExpiresActive On\nExpiresByType image/ico "access plus 6 months"\nExpiresByType image/gif "access plus 1 year"\nExpiresByType image/jpeg "access plus 1 year"\nExpiresByType image/png "access plus 1 year"\nExpiresByType image/bmp "access plus 1 year"\nExpiresByType application/javascript "access plus 1 year"\nExpiresByType application/x-javascript "access plus 1 year"\nExpiresByType text/css "access plus 1 year"\nExpiresByType text/html "access plus 1 year"\n</IfModule> \n\nRestart web server after making above change.
Code Review
Move to V10 from V7.5 and leverage asynchronous invocation of the web trends API
Storage
Storage team to coordinate with IBM for root cause of this behavior.
Performance
Move data sanity checks and data preparation operations which do not need any data access to the java layer.
Performance
The throughput of the Listener can be increased if each messages can be passed onto individual handler instance so as to leverage parallel processing. Need to check if the messages can be passed onto upstream handlers from the decoder.
Slow Response Time
Use StringBuilder instead of StringBuffer if expensive thread-safe operations are not required. StringBuilders is faster than StringBuffer for strings concatenation.
Slow Response Time
'Recommended to replace this type of condition in below pattern.\nCurrent: \nif(result != null || result.length() >0)\nRecommended:\nif(result != null && result.length() >0)'
Slow Response Time
These are not required, removing this will improve performance
Slow Response Time
Change the if condition to some variable flag rather than on pastpaynorep html element
Slow Response Time
Remove one call.
Slow Response Time
Remove these redundant calls
Slow Response Time
'The thread pool setting on the machine.config needs to be reset to as follows :\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs \nThe same needs to be done on both web server as well as app server.'
Slow Response Time
The spriting of images will ensure redundant calls on web server is avoided.
Slow Response Time
Timeout needs to be defined at the web.config with not more than 10 mins, so that the users do not keep the session open for an infinite time.
Unnecessary request for rupee_foradian font file in Assuredreturn2.htm
Avoid request for rupee_foradian font files if not needed
Multiple requests for demo.xml data file in the load event of fixedsavings1.htm
Multiple requests of demo.xml should be avoided in the same event.
Object.length is used in for loop
It is recommanded to call Object.length once and store its value in another object and use the same object everywhere in the code.
Large number of failure during file uploads.
Recommended to increase timeout duration from existing 5 minutes to 30 minutes to avoid connection timeout in case of weak net connectivity.
Large number of string concatenations in logs.cs class functions
Use Strigbuilder class instead of performing direct string concatenation.
Multiple calls to function CommonFunctions.getinputfile
Avoid calling CommonFunctions.getinputfile twice in a method if not needed(The logic in encrypted stored procedure needs to be analyzed)
Unnecessary request for rupee_foradian font file in RelianceLifeInsuranceMoneyMultiplierPlan.htm
Avoid request for rupee_foradian font files if not needed
Repeated request for multiple static files during loading of RelianceGarnteedmoneybackPtS.html
Repeated requests should be avoided for the static contents
Unnecessary call to stored procedure to initialize variable in stored procedure get_Cashflow_NewPlans
Avoid initializing variable @term in stored procedures if not needed.
Unnecessary execution of query to set variables @userid and @password in stored procedure get_InputFile
Avoid initializing variables @userid  and @password in stored procedures if not needed.
Unnecessary initialization of variables @str and @str1 with queries.
Avoid initializing variables @str  and @str1 in stored procedures if not needed.
Unnecessary execution of queries to initialize of variables @f_code and @d_name.
Avoid initializing variables @f_code and @d_name if not needed.
Queries with high response time.
1. Rebuild indices idx_ECS_INsured_details_policyno_hCardNO and IX_ECS_Insured_details to remove fragmentation.\n2. Instead of refreshing tables in ODS instance, move them to HCS prodution instance and refresh, this will reduce intercommunication time inbetween two instances.
Thread contention in ECS.DAL.Repository.Status.StatusServiceRepository.GetCLClaimStatus
Following should be checked for GetCLClaimStatus or GetALClaimStatus.\n1. remove sub query if IVRSCode field is not needed.\n2. If IVRSCode is required then fetch its value using another linq query instaed of fetching this in select section of same query.
Large size of asp.net cache due to large number of objects in  finaliser queue.
1. For dynamic loader classes where reflection is used needs to implement dispose methods to effectively clear them.\n2. For unreleased data tables in memory we can do following in every instance of datacontext class of HCS and ODS databases.\n    - Set dataContext.ObjectTrackingEnabled to false if object tracking is not needed.\n    - call dataContext.ClearCache()
Thread contention in DynamicClass.BuildUp_ECS.BL.Communication.CommunicationBL
The constructor of CommunicationBL expects around 27 class objects and simply assigns them to local variables. The user functions in class hardly need more then one class objects.\nNo need to pass all 27 class instances to constructor as this makes CommunicationBL class heavy instead of this the functions should read class variables as parameter if needed or create them inside functions only when required.
Thread contention in DynamicClass.BuildUp_ECS.BL.Master.MasterBL
The constructor of MasterBL expects around 53 class objects and assigns them to local variables. The user functions in class hardly need more then on class objects.\nNo need to pass all 53 class instances to constructor as this makes MasterBL class heavy instead functions should read class variables as parameter if needed or create them inside functions only when required.
Several un-usable objects initialized in constructor of Business Layer classes under Service folder
The required objects should be passed into functions as parameter instead of initializig them in constructor.
Thread contention in ECS.DAL.Repository.Status.StatusServiceRepository.GetClaimsByPolicyNo
Following should be done to make GetClaimsByPolicyNo function faster.\n1. Remove string concatenation for Output string.\n2. Remove logging if not needed
Performance degradation due to firewall between app servers and DB server.
Keep the all application servers and database server in same zone either DMZ or corporate zone. There shouldn't be any firewall between application server and database server.
Unnecessary call for method  Policy/ManyfacturingMonthAndYearNew in $(document).ready function in MotorQuote.cshtml page
Remove call for method in Policy/ManyfacturingMonthAndYearNew in $(document).ready function if not needed.
Unnecessary writing of objECompensation.BlazeErrorMessages into disk file in ValidateECBlazeAuthorities method.
Avoid writing objECompensation.BlazeErrorMessages into disk file if not needed.
Multiple requests for method Motor/GetDocuments on page Motor/Motor.
Avoid multiple calls for a method in same event.
Multiple requests for bundles/jquery?v when user clicks on Make Payment button.
Avoid multiple calls for a static resources in same event.
Repeated requests for method master/getrelationshipname?relationname=childrelations when user clicks on Travel->Individual link.
Avoid repeated calls to same methods in same event.
Unnecessary query in loop for all previous policy proof documents in savemotor function
Avoid calling query in loop for all previous policy proof document if not needed
Unnecessary request for Motor/PreviousInsuranceDetail when clicked on save button on Motor policy for new business.
Call Motor/PreviousInsuranceDetail only in case of renewals.
Unnecessary query to initialize variable dbPayment in FillPolicyPayment function
Avoid query to initialize variable dbPayment if not needed. Avoid entire if block.
Request for Motor/NCBReservingDetails while saving motor quote even when NCBReservingDetails is hidden
Avoid request for Motor/NCBReservingDetails in all conditions when div "#divNCBReservingDetails" is hidden
Unnecessary initialization of variable BusinessType in FetchIDV
Avoid initializing BusinessType variable if not needed.
UnUsed variables in controller method FetchIDV
Avoid initializing unused variables.
Unnecessary logging of request and response data of blaze service in tbllogxml table
Store single blaze request and response data for each policy in the tbllogxml table at the time of final save.
Unnecessary passing of parameter "un" in Home action method in HomeController.cs
Avoid passing encrypted un (user name) value if not needed.
Call for GetUserTask in Home action method without verifying appName.
Call to GetUserTask method only when required i.e. when appName is IMD.
No update of userid in cookie after retrieval from users table in getUserId function
Update the cookie with userid value after retrieval to avoid database call in next call of getUserId function.
Unnecessary query on table tblMASDEOs to set variable masDEOObj in Healthwise action method of class HealthwiseController
Avoid initializing variable masDEOObj if not needed.
Large number of connections created with database even when few users connected to Smartone
Modify connection parameters to include connection pool with max connection size of 50.
Unnecessary call for controller method NCBReservingDetails after click on Save/Continue button
Remove call for NCBReservingDetails if not needed
Intermittent delay in login page due to either initial 302 or 200 request for home controller.
Consider expiring the IMD and other cookies used in application during load of login page or when user clicks on login button to avoid intermittent delays during login.
Blockings due to scan on large tabllogxml table due to regular select and delete queries.
Perform following.\n1. Move tbllogxml and tbllog tables into audittrail database.\n2. Partition the major audittrail tables such as tbllogxml and tblatlogxml datewise.\n3. Optimize insert operations on audittrail database using simple recovery model .
Multiple requests for conversionasync.js during page load of Home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for strings.js during page load of Home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for core.js during page load of Home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for conversionasync.js during page load of CarInsurance.aspx.
Avoid multiple requests for the static resources in the same event.
Client side search for make and model  even when less then 3 characters entered.
Avoid search  for make model at client side when number of characters entered is less then 3 characters.
Very high response for premium estimate when tried from home.aspx
"Avoid multiple calculation of quotation and send necessary details such\ \ as motor model, years, email\u2026etc to insurance page directly (such as car-insurance.aspx)\ \ instead of performing premium calculation in home page."
Multiple requests for footable.metro.css when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for bootstrap.min.css when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for jquery1.11.0.min.css when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for style.css when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for sharepoint.css when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for jqueryui.min.css file during page load of Two-Wheeler-Insurance.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for strings.js during page load of Two-Wheeler-Insurance.aspx.
Avoid multiple requests for the static resources in the same event.
Unncessary code execution after response.redirect in FillPolicyDetails method of QuickQuoteFourWheeler.ascx
Exit function with return statement after response.redirect.
Unnecessary retrival of multiple rows in datatable DtRtoDetails in TwoWheeler function of QuickQuoteHome.ascx
Change stored procedure usp_GetRTOLocationByTextValue_Website to select top 1 row instead of retrieving many duplicate rows .
Unnecessary retrival of large datatable DtRtoDetails in FourWheeler function of QuickQuoteHome.ascx
Change stored procedure usp_GetRTOLocationByTextValue_Website to select top 1 row instead of retrieving many duplicate rows .
Risky autogrowth option for database file of db_website.
Update dbwebsite configuration to set autogrowth value to a fixed value(100 to 500 MB) instead of percentage.
Multiple requests for initstrings.js during page load of Car-Insurance-Premium-Calculation.aspx..
Avoid multiple requests for the static resources in the same event.
Multiple requests for jquery.creditCardValidator.js when click on Next button of Car-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for jquery-1.3.2.min.js when click on Next button of Home.aspx.
Avoid multiple requests for the static resources in the same event.
Unnecessary multiple times write to disk file in the LogDataToFile method of Utility class.
Instead of using multiple writeline methods construct the entire message in stringbuilder class and write once to disk file using  the write method of TextWriterTraceListener class
Multiple requests for analytics.js during page load of Two-Wheeler-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for method collect from google-analytics.com  during page load of Two-Wheeler-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for same method in the same event.
Multiple requests for conversion_async.js during page load of Two-Wheeler-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Maintenance
For these tables stats to be gathered in regular interval. Database should be monitored that no table goes for stale stats
Design
These queries to be checked with the EOD team whether these pertains to any EOD functionality or can be avoided
Design
"Rearranging the cluster sets with more number of sol\u2019s in each cluster\ \ and reduce the number of cluster"
Design
It is recommended that compressed all .jpg images immeditely after scanning and before uploading to server 1st time. Sample file is shared with the team, where the original as well as the compressed image is shared. The entire process needs to be carried out on both the images to understand the response time improvement.
Design
Indexes needs to e created on column ORN for tables TBL3IN1BANK,TBL3IN1DATA,TBL3IN1DP,TBL3IN1SIGNATURE
Design
Indexes needs to be created on column ORN for table TBLDEMATDATA
Design
Index on ORN needs to be created on tables tblbatchbdfmap ,\ntblDematADDR ,\nTBLDEMATBCKOFF,\ntblDematSignature,\ntblfinacleerrors ,\ntblHoldReason,\ntblLoanapplicationdata ,\ntblSBFinacleData ,\ntblSBInstaCustData ,\ntblCaseStatus ,\ntblDematData,
Adhoc queries are running in prod environment.
Deliberate such cases accordingly and try to limit such maintenance activities to desired level as this creates an overhead on the regular operations.
Design
Either remove the trunc function for both the tables, or create a functional indexes on TRUNC(CI_EXTRACT_DATE) on CSTM_INTEREST and TRUNC(CII_EXTRACT_DATE) on CSTM_INTEREST_INTEREST tables.
Design
Either add index on this table for the column CDR_USER_BAND or modify the query to use any column which is already indexed.
Design
Create  indexes on SPH_FROM_TIME and SPH_TO_TIME  columns or modify the query to use current indexes.
Design
Duplicate indexes on payee_master table are observed one can be removed.( pmt_id , del_flg /del_flg,pmt_id).  defragmentation on pmts and payee_master table is required.
Maintenance
PLOG table needs to be defragmented.
Maintenance
customer_payee table needs to be defragmented.
Maintenance
customer_payee table needs to be defragmented.
Design
'Fetch static data outside the loop, do data modification there itself(if require) and store it in a new object for further processing.\n\nReference : Srl 6.\nInt primAccount;\nif(cm.getString("userAccountIndex") != null)\n{\nprimAccount = cm.getInt("userAccountIndex");\n}// if close\nfor(condition) // loop start\n//some code\nString refValue = Convert.ToString(primAccount); // code marked in red can be move before loop start inside if condition\n//some code\n} //loop end\n\nReferences : Srl 7.\nfor(condition) // loop start\n{\nfield125 = "SCH" + vo.getCIDN() + cache.getString("stdntRegId").PadRight(10) + cache.getString("schlid1").padRight(6) // code marked in red can be move before loop start\n} // loop end'
Design
Such method calls needs to call first before loop starts rather than calling it inside loop.\nfor(int i = 0; i < ba.count; i++)\n{\nGUCTVO guctchallanvo = (GUCTVO)ba[i];\nDebitAcNo = guctchallanvo.getDEBT_ACID().ToString().Substring(0,4);\nBranchID = BranchCodeDescription.getDesc(userInfo.bankId(), solid, cache); // code marked in red can be move before loop start \nGuctchallanvo.setbranch_ID(BranchID);\nbaList.Add(guctchallanvo);\n}\n\nBranchID = BranchCodeDescription.getDesc(userInfo.bankId(), solid, cache);\nfor(int i = 0; i < ba.count; i++)\n{\nGUCTVO guctchallanvo = (GUCTVO)ba[i];\nDebitAcNo = guctchallanvo.getDEBT_ACID().ToString().Substring(0,4);\nGuctchallanvo.setbranch_ID(BranchID);\nbaList.Add(guctchallanvo);\n}
Code
Application needs to be restructuring to more generalized/parameterized structure to avoid lots of code file creation and also to avoid more memory consumption.
Code
Use StringBuilder.Append() method once to generate query. No need to call StringBuilder.Append() method 3 times on 3 different lines to generate query.
Code
Order by clause not required in query to fetch data in ascending order. Default order is ascending.
Code
Place one copy of faq page in Corporate domain and fetch the same from that location.
Code
There should be an intermediary landing page, which should only show the details for the primary account (Saving Account), and there should be a link for the other schemes.\n On clicking this, it should highlight all the other accounts linked.
Code
"a. The js functions are written inline in the aspx page. The js file should\ \ be written outside and should be called through a link in the aspx file. This\ \ will load the page faster.\\nb. Check why there are so many js validations done\ \ for a static page. Eg. For disclaimer page, there are only two buttons \u201C\ I Agree\u201D/\u201DI Disagree\u201D but there are multiple js validations written\ \ on the page.  \\nc. There are multiple js files being called sequentially one\ \ after another. This should be collated into a single file so that the on load\ \ of these js files happens just once. Eg. RetailShoppingMallLogin.aspx has multiple\ \ js files loaded sequentially one after another."
High CPU Utilization
Only selective columns should be included in select query from product, this reduces the data transfer from DB to APP
Process
As a standard practice username and password should not be a part of code. It should be moved to configuration file. Please refer DB_Credentials_Details sheet.
Slow Response time.
Compression of images needs to be carried out. Please refer image_compression sheet for changes in size of images ( Sample images have been shared with team to validate pixcel quality )
Slow Rendering of page
These needs to be moved to the bottom of the body. This would allow the browser to download all contents in the page in a non-blocking manner.
Large size of js file
"To improve the Response time of these pages,  below steps needs to be carried\ \ out\\n1. Compress js files, css files and images - Please refer below sheets for\ \ compression details:\\n1. CSS_Compression\\n2. JS_Compression\\n3. Image_Compression\\\ n\\n2. Enable caching for static elements which doesn\u2019t change for a long time\ \ like css, images.\\n\\n3. Remove unwanted links ( 404 errors ) from pages"
Process
Need to change the log format to "LogFormat "%h %l %u %t \"%r\" %>s %b %T \"%{Referer}i\" \"%{User-Agent}i\"" combined"
High Memory Utilization
Apache version upgrade from 2.2 to 2.4 to use prefork mpm is recommended for multithreading. This needs application testing to be carried out
High out of memory and swapping observed
use of php-fpm manager is recommended to server PHP requests and static contents will be served by apache
Temporary table space identified on DB server
$usage of large hash joins and sorts = YES
Bind variables are not used in the query.
Hard coded input values are always causing the recursive SQL againt the data dictionary. To avoid this and to get the optimal performance use of Bind variables suggested.
Maintenance
To execute with the best cost effective execution plan always suggested to  collect the stats for the stale tables.
High Response Time.
Purgig policy should be defined for the transactional tables according to the requirement.
High Memory Utilization
Check with Avekshaa Memory Leak Tool for any connection leakage. (Cursors are not closed).
Design
Run the long running queries in non business hours.
Design
Optimize the SQL statement that initiated most of the waits. The goal is to minimize the number of physical and logical reads.
Design
"Tune LGWR to get good throughput to\_ disk eg: Do not put redo logs on\_\ \ RAID5"
Design
Increase the number of freelists. Use below command.\nAlter table table_name storage (freelists 10).
Design
"\_Reduce the amount of redo being generated"
Design
Check with netstat to ensure that your TCP/IP does not have bottlenecks.
Design
Increase the size of the redo log.
Design
Increase the size of shmmax parameter to optimum.
Design
Reduce the reloads by increasing the shared pool size as the locks may take a long time if the pool is undersized.
Design
Create password file using below command.\nOrapwd file=filename password=password
Design
Increase pga_aggregate_target
Design
Online the undo tablespace using below command.\nAlter tablespace UNDO online.
Design
No. of threads needs to be reduced.Cache static pages.
Design
Convert all the JPG/GIF images into PNG extension
Design
Change is required at the machine.config file, where the maxconnection under connection management tag needs to be made as 65535.
Design
Combine all the js files into one and reference it at the bottom of the html
Maitenance
Update Table/Index statistics if it is not done so, so that it starts taking the latest execution plan.
Design
Customization team to assess if these queries are necessary to be run during business hours and see if they can review these queries. Implicit functions used in the select is causing the query to take a lot of time.
Maitenance
Check if the datafiles are being defragmented on a regular basis. Please defragment the datafiles of the tables involved in these views.
Design
Comment out the lines in aspx where referencing to those objects are done which are not present
Design
The comments from these two pages needs to be removed as these pages has the maximum hits.
Design
The query once is being executed with status in the where clause and again without it. Please look at the logic of executing this query.
Design
1.Defragment CUSR,IPAY tables\n2.Select on IPAY is having all columns, hence high read. Only use columns in select which is required.\n3. Implicit conversions used for NEFT_Payment_Requests should be avoided.
Design
Disbale all script traces by below two options\n1. Comment out trace on from all the scripts.\n2. Enable Global Trace Off at the commonenv.com
Design
Remove all the unwanted fatal and fatal_info logs. \nYou can run this command on a periodic basis to find and delete all fatal and fatal_info.logs.\nfind . -name *log|xrags rm fatal*log
Design
Max RIST operations should be done before CEOD by handling max volume at ABH. (Approach shared seperately via mail).EAB GST needs to be run before to minimize the CEOD process timelines
Bacup strategy
RMAN backup should be taken so that incremental backup is possible.
Design
Parallelization required for 198 sols.(Approach shared seperately via mail).
Multiple requests for core.js during page load of Two-Wheeler-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Risky autogrowth option for active log file of db_website.
Set autogrowth for log file between 100MB to 500 MB and keep max size as unlimited
No image compression for images served from AkamaiGHost
Implement static compression for images on Akamai server.
Unnecessary code execution after response.redirect in fillpolicy method of BuyFourWheeler.ascx.cs class
Add return statement after response.redirect.
Unnecessary code execution after response.redirect in fillpolicy method of BuyFW.ascx.cs class
Add return statement after response.redirect.
Configuration
It is recommended to enable direct i/o for redo log file systems in DC and DR
Analysis
No issues has been found
High CPU Utilization
Bifurecate the CRON jobs across all app servers so that the load is evenly distributed across all the app servers
Query Optimization
As a best practice COMMIT should always be present at the end of each logical unit of work. Also increase in the number of COMMITS will increase the average wait time of 'log file sync' event in the database.
Maintenance
Please remove the safe copies and unwanted files from the customization directories. This will provide more space to the respective mountpoints
Code Review
On debugging the ENTERED transactions, it was found that for successful transactions the process sometimes take more than 25 secs. Since the process does an in-memory posting, the time taken for posting a single transaction is more. We have captured the timing taken for the user hook call to MTT transaction in the script traces and the record creation and posted time in DTD table. Request you to raise a call with Infosys with these details to probe the high time taken for posting a transaction.
Network Bandwidth
Compression of javascripts, css, jpegs, gifs
Code Review
Put the favicon ico at predefined URI which is relative to the server root
Configuration
Sepearate mount points to be allocated for Corporate Index files and Payaway database files.
Query Optimization
"Application logic can be modified so that batch program loops back for\ \ more records and processes them instead of process getting killed after completion\ \ of data check. In case no records can be processed, it should go to sleep for\ \ a defined period of time and then start the processing again.  This would avoid\ \ excessive processing logic in the application. \\nThis also ensures that existing\ \ DB connections will be reused thus avoiding cost of creating and destroying new\ \ connections. So, 32 connections will be used instead of 2.4L in 30 mins. \\nThis\ \ will also ensure the process is continuous there by reducing the cost of creating\ \ new process and probably it also reduce the cost of ps \u2013fu being fired from\ \ shell scripts."
Query Optimization
Both sol_id and cust_id should be added to tables ICICI_ALERT_INFO and ICICI_ALERT tables.  These can be populated in ICICI_ALERT_INFO as part of insertion of records. \nQueries should be modified to use these values from these table instead of values from GAM.
Query Optimization
During the record selection, corresponding ROWID field should also be selected. This field should then be used during Update statement so that updates are fastest
Query Optimization
Exit handling needs to be provided in the program to hand the extreme conditions like.
Query Optimization
Comment the printf statements to avoid the cost of IO.
Query Optimization
"Usage of \u201CSelect IF Exists (sql query)\u201D will help gain performance\ \ as it is less costlier than count(*)."
Query Optimization
Check for the logic and take appropriate action
Code Review
This can be optimized by creating only one static scr files\nby utilizing UREX/Functions provided in Finacle there by avoiding creating and parsing of .SCR file for every 200 records.
Configuration
This can be avoided by redistributing log files to faster disks..
Query Optimization
This needs to optimized. Need help with development team and DBA.
Performance
Avekshaa to propose a design for instrumentation.
Performance
Strategy has been already shared with ICICI. ICICI to get the changes implemented by Infosys.
Performance
NoData
Configuration
Implementation of the suggested design changes in production environment.
EOD/ BOD
As there is difficulty in recording volume for each job, so Avekshaa has suggested to record volumes for each day. And this number should be divided by no of branches to get volume of job processed for each job per branch. This is not accurate volume but at least this will help in instrumentation strategy. ICICI need to implement changes to record the data.
Code Review
Comment out or remove all lines in jsp/html files, which are referring to missing objects.
Code Review
Minifying/Compacting CSS code can save many bytes of data and speed up downloading and parsing time. Any open source tool like cssMin, YUI Compressor etc can be used to minify CSS files.\nFiles in a source code repository can remian as is (without minification), but before these files are deployed to production server these should be minified and then deployed to production server.
Configuration
"To reduce such occurrences and increase overall response time and throughput\ \ of the system it is recommended that current\_statement\_cache\_value of 50 be\ \ increased to\_100."
Configuration
"Currently, Nursery area is default which is 10% of max heap (200 MB).\_\ Setting Nursery size to 25% of max heap (25% of 2 GB = 500 MB)\_should trigger less\ \ frequent scavenger GCs and will improve overall throughput."
Configuration
"Set initial heap size to 2 GB using             \u201C-Xms2048m\u201D option."
Configuration
"Manually purge this  file  every week. Alternatively, set \u2013Xverbosegclog\ \ JVM option  from WAS Admin console. This will create  a new file for each GC cycle\ \ with following naming convention :\\nverbosegc.%Y%m%d.%H%M%S.%pid.txt"
Configuration
Application should log only error messages to the log files  and debug information should  not be logged.
Code Review
Remove sysouts from the  code. If information needs to be logged it should be logged using a logger like log4j etc.
Configuration
There should be a manual/auto archive and purge policy for the file. Since file is growing apporximatley at the rate of 400 MB per month, it is a good policy to manually / automatically archive and purge this file, once every month.
Configuration
Edit httpd.conf file on all 3 web servers and \n\nadd below line:\nHeader set Cache-Control Public\n\nimmediately after line:\nHeader append Vary User-Agent env=!dont-vary\n\ninside below section:\n<IfModule mod_headers.c>\n\nRestart web server after making above change.
Configuration
Edit httpd.conf file on all 3 web servers\n\nChange expiry period to 6 months from 1 year. \nReplace "1 year" with "6 months" in section <IfModule mod_expires.c>\n\nRestart web server after making above change.
Query Optimization
FILEDETAILSTABLE is doing FTS.Create Index /Rebuild existing index on FILEDETAILSTABLE table.
Code Review
Temporarily move to bottom of the page. Long term solution should be to move to V10 and also move the JS to bottom
Query Optimization
Indexes need to be re-built (>40% fragmentation) and re-organized (10-40% fragmentation)
Code Review
'Fix is provided by IBM for this issue: ( For Websphere version 8 ).  Fix pack to be applied'
Performance
Remove the sleep from the SMSServerIdleHandler after sending the EXT message.
Performance
Duplicate checks to be removed
Slow Response Time
Recommended to remove the unwanted operations from the source file. This will help in faster execution of logical blocks and hence improve the performance. Also the objects created inside this block will get eliminate which result in low memory consumption.
Slow Response Time
It is recommended to add finally block in source file and close all important resources inside it. Finally block will guarantee to close all resources if any exceptions thrown
Slow Response Time
Recommended to write the code snippet in try/catch/finally and close the PrintWriter object in finally.
Slow Response Time
It is recommended to turn this println off. Logging API can be used instead which can turn of debugging statements.
Slow Response Time
It is recommended to call arrayList.size() once and store its value in another object and use the same object in the code.
Slow Response Time
It is recommended to call Object.length() once and store its value in another object and use the same object everywhere in the code.
Slow Response Time
Substitute calls to size() == 0 (or size() != 0) with calls to isEmpty().
Slow Response Time
Need to log some messages to detailed out the exception.
Slow Response Time
Avoid empty catch blocks. Capture specific type of exception and redirect user to common page with appropriate custom message, so that the specific event triggered by the user doesn't look unresponsive.
Slow Response Time
Avoid the use of unused import statements to prevent unwanted dependencies.
Slow Response Time
Avoid printStackTrace(); use a logger call instead. call printStackTrace() on an exception the trace is written to System.err and it's hard to route it elsewhere (or filter it). Instead of doing this use a logger call instead.
Slow Response Time
Avoid using hard coded IP. Externalizing IP addresses is preferable.
Slow Response Time
One choice to avoid these re-renders would be to instead use the visible binding on a container element around our section or on the individual elements.\nIf we prefer to use if binding in this case, then we need to make sure that it is only triggered when the number of items in our array moves between 0 and 1
Slow Response Time
A better pattern is to get a reference to our underlying array, push to it, then call .valueHasMutated(). So that the subscribers will only receive one notification indicating that the array has changed.
Slow Response Time
This will cause the operations to execute on every iteration. So it is recommended to store the calculated value into a variable and then use it within the for loop condition.
Slow Response Time
Only one block should be used and all required data manipulation should be done within this block
Slow Response Time
Consecutively calls to StringBuffer/StringBuilder .append should reuse the target object.
Slow Response Time
It is recommended to use StringBuilder instead of String class where there are lot of concatenations used . StringBuffer can also be used in multithreaded environments
Design
export LDR_CNTRL=MAXDATA=0x40000000 for the local session. After successful testing at UAT, please deploy the variable in production in /etc/environment.
Design
The timeout parameter needs to be increased(The applet does not have any timeout parameters currently). \nAs a work around, you can process smaller batches of files, so that time in processing of records is less than the session timeout time.
Design
The MIS related queries should be ported to MIS queries to provide headroom for the production DB server to be leverage optimal load.
Configuration
The pga_aggregate_target needs to be increased from 1GB to 2GB
Configuration
The DB_CACHE_SIZE should be increased from 1.47GB to 3GB for faster read process
Configuration
Redo Log files can be moved to RAID 1+0 for better log synching.
Design
While writing queries (select or update) always use columns in the where clause which already have an index on them.
Design
Closing each connection (cursor) after it is used
Maitenance
"Hash out all such queries which use tables which don\u2019t exist in the\ \ production database"
Design
Replace sendunix with FTP/SCP process so that batch transfer happens instead of line by line copying.
Hi IO
The PGA_AGGREGATE_TARGET needs to be increased from to 2048MB to 2560MB.
Maitenance
Possible Approaches :\n\n1. To eliminate such cases of having unwanted sessions on the database for a long time, we need to establish a threshold value which needs to be set, so that the session is timed out after the user is not doing anything on the system. \n\nThis needs to be set on resin.conf for the tag <session-config> with parameter as <session-timeout>\nEg :\n<session-config>\n        <session-timeout>10</session-timeout> -- This is set for 10 mins. Please confirm with the application team if this value is okay.\n\n2. The session parameter on the database is not correctly configured. The session value needs to be increased to 1.5 times the processes. Currently the processes value is 1200 and sessions value is 1325.  This will take care of high concurrency coming into the application. Please check on a periodic basis what is the concurrency achieved in GBM during peak load. Post this, the value should be estimated and setup.\n\n3. You can alternatively clean up all invalid sessions, by adding a timeout for the jdbc user by setting up a Idle_time value in the profile. This will ensure all the invalid sessions are terminated after the idle time threshold is reached.\n\nPlease find below the steps to do that :\n\n1. alter system set resource_limit = true;\n2. create profile idletime limit idle_time 30;  --- This should be established after concurrence with the product team.\n3. alter user system profile idletime;
Maitenance
NoData
Design
The query needs to be tuned to include the column which is indexed, or create an index on IS_DELETED.
Design
The query needs to be tuned to include the column which is indexed, or create an index on IS_DELETED.
Design
The query needs to be tuned to include the column which is indexed, or create an index on RCC_CODE.
Design
Absolute value should be given instead of Like. Query processing will improve.
Design
Eiether a procedure needs to be written to replace the logic of 4 nested selects or the query needs to be tuned to use indexed columns in the where clause.
Design
Enable access.log for 2 days. This will also help in understanding if there are broken links/ other issues in the application which needs a fix.
Design
Archive the stdout and stderr logs for a week to validate any issues in the application
Maitenance
Please analyse the tables on daily basis and share the observations.
Design
The query logic should be re-written to use the bind variables, or the CURSOR_SHARING_PARAMETER should be set as FORCE instead of EXACT, which is set currently. The application team can take a call to check on the feasibility of either of the two approach.
Design
The referrer page should be modified to hash out the references to the objects which are not present.
Design
Connection has to be closed at finally, otherwise the sessions will keep increasing on the database.
Design
The DB_CACHE_SIZE needs to be increased from to 4096MB to 5600MB.
Design
The query needs to be tuned to include the column which is indexed.
Design
The query needs to be tuned to include the column which is indexed.
Design
An index on foracid,inst_alpha and inst_num to be added.The TRIM function on the WHERE clause fields needs o be removed.
Design
The result set which is joined between GAM and DHT should be less to reduce the high temp space utilization. Please check with the vendor as to why two WHERE clauses of the same nature (APPLICABLE DATE field) is present in the query.Also please check the feasibility of reducing the data fetched for JOIN by extracting data between two dates instead of extracting data which is less than a given data
Design
Bank to check to check the functional index usage and recreate the index with the respective functional index on sol_id field
Design
An additional sol_id condition by joining the GAM table with SST table for set_id ALL to be added in the WHERE clause
Design
The INSERT,SELECT and DELETE query can be appended with a PARALLEL hint to enable ORACLE to parallely process the DML's .
Design
The TRIM funtion in main WHERE clause needs to be removed, Subsequently the data storage of column TRAN_ID of AXIS_CREDIT_CARD should be left padded as in DTD table by using LPAD function. Currently this data is right padded
Design
Increase parallelism for the job groups in the application. HSCOD parallelization to 60 and BJE jobs parallelization to 70 and common env parameter to 50 from current value of 40
Design
Recreate the index with revise column position as per below.\nTO_NUMBER(SOL_ID),TRAN_DATE,SENT_FLG
Design
Please check the functionality if SQL can re-write by removing SST from FROM clause and WHERE clause. This will reduce the Temp space utilization and SQL cost will reduced to 2900 approx.
Cold backup used.
We recommend to carry out a HOT backup (online flash copy) for database .
CPU intensive queries.
These queries to be checked with the EOD team whether these pertains to any EOD functionality or can be avoided
Design
To make separate cloned jobs which will execute the functionality only for 2567 and 2568 seperately.
Design
Only for job id ZTDAC, parallelization of 10 sols with each sol of 1000 records for ICBX4008 exe is recommended to be added in B2K_PreJibExecCheck.scr
Design
We recommend to implement parallelization for these two exe's only for 002 sol in the script B2K_PreJobExecCheck.scr.
Design
"Rearranging the cluster sets with more number of sol\u2019s in each cluster\ \ and reduce the number of cluster"
Design
Calling URLs needs to be modified to comment out the lines calling non existing pages.
Design
Calling URLs needs to be modified to comment out the lines calling non existing pages.
Design
HP to internally probe why only opcle is CPU intensive while the other monitoring tools are not.
Design
Infosys to make changes in the configuration so that the Lisrvrs are killed after completing the transaction.
Design
As these are static files which can be picked from the client rather than the server when recalled, these files should be cached.
Design
Images stored in PNG formats are the lightest extensions for images. All the images should be converted into PNG files
Design
JS files needs to be placed at the bottom. Common js files called sequentially can be placed in a single js file and called.
Design
Js files should be minified.
Design
Use RAID 1 + 0  for transaction logs & Datafiles
Design
Remove ToString.ToUpper method call for such cases.\nFor eg. (flag != null && flag.ToUpper().Equals("Y".ToString.ToUpper())) can be written as (flag != null && flag.ToUpper().Equals("Y"))
Design
Instead compare can be used which will internally check for case sensitivity. (str1.ToString.ToUpper().Equals(str2.ToString.ToUpper())) can be written as (string.Compare(str1, str2, true) == 0), it will work well and efficiently.
Design
All resources should be closed in finally block only.
Design
Fetch static data from cache outside the loop.
Maitenance
CUSR table needs to be defragmented.
Design
index to be created on user_report_table table on columns act_code,access_channel
Compilation Setting in web.config
Please set this value to debug="false"
IndexOutOfRangeException in Error Logs
Please add condition to check `ds.Tables.Count > 0` before the condition `ds.Tables[0].Rows.Count != 0` in `GetPendingApprovals` Method of `PendingApprovals.aspx.cs` Page.
ThreadAbortException in Error Logs
Please replace `Response.Redirect(strURL)` with `Response.Redirect(strURL, false)` , details are shared in the next sheet.
NoData
Please change the data type of variable `RewardsRisk` from String to StringBuilder.
NoData
Please throw exceptions in catch block.
NoData
Please implement Viewstate Compression in ASPX Pages. Reference http://www.codeproject.com/Articles/14733/ViewState-Compression
NoData
Index on tables Labeling_TermSheet, Labeling_Answers and Labeling_ClientMaster needs to be created. Index script is shared in the next sheet.
Slow Response Time
The logs before the LB should be monitored for delays if any.
Slow Response Time
The code/third party calls needs to be reviewed to check the bottleneck. This will be done in Phase 2 of the engagement.
Query Optimization
Remove TRUNC from the joining condition
Query Optimization
Remove unused objects from report
Query Optimization
Use filter to restrict Historical data or separate historical data to a new report with a link in existing dashboard. \nNeed to check with Business the need for Historical Data.
Query Optimization
Upgrading Microstrategy Version will help dashboards  having multiple datasets  with cubes to execute in Parallel.
Code Review
Build a cube on single dataset formed to reduce multiple database hits and  report runtime
Code Review
Recommended a design change by creating the cube with restricted data to reduces execution time\nView has been provided for the logic implementation\n\nViews have been provided for the same.\nAVE_TEST1\nAVE_TEST2\nAVE_TEST3\nAVE_TEST4_gainer\nAVE_TEST4_loser\nAVE_TEST5\n\nRefer Queries Q5-Q10 in worksheet "Queries" for DDLs.
Code Review
Recommended a design change by creating the cube with restricted data to reduces execution time\nView has been provided for the logic implementation\n\nViews have been provided for the same.\nAVE_TEST1\nAVE_TEST2\nAVE_TEST3\nAVE_TEST4_gainer\nAVE_TEST4_loser\nAVE_TEST5\n\nRefer Queries Q5-Q10 in worksheet "Queries" for DDLs.
Code Review
View provided for cube generations resolves this issue
Code Review
Remove unused objects
Maintenance
Refresh statistics on the tables and the corresponding indexes
High CPU Utilization
Create a passive application node, which will serve as failover instance.
Code Review
Weekly backup of Schema and Dashboards is required to avoid lost changes and reduce recovery time in case of failure
Code Review
Redesign to use only one dataset instead of 3. Redesign dashboard to reduce no. of datasets
Query Optimization
Create below indexes -\n1. Functional index ( trunc ) on value_date and creation_date \n2. Index on REQUEST_UUID column.
Query Optimization
Oracle comes with functionalities of Temporary Tables (GTT), which can be used instead of creating the tables and dropping them for temporary use.
Code Review
It is recommended to remove system.gc() calls from application code and let JVM handle the GC mechanism OR use GC command line option -Xdisableexplicitgc.
NoData
Recommended to gather stats on indusind_test schema.
Query Optimization
Create index on batch_name and value_julian columns on error_limit_log  table. (Need to validate from Calypso team if no. of executions are going to be high in production environment also as data grows execution time for query will be increased.)
Code Review
We recommend following things \n- Just fetch only 10 records to show on the Manual Intervention Page\n- Fix the links of previous and next when one returns from submitting a manual intervention transaction to the manual intervention list page. \n-Fetch only the columns needed to display the records on the screen . Table fpd_payment_in has 46 columns and we are fetching all of them even when we need to show just 10 columns. We recommend to fetch just the number of columns needed to display .
Query Optimization
It was observed application is sending integer datatype to column value, while datatype is varchar in database. Recommended to fix application code to send varchar datatype instead of integer so that index can be used by query.
Query Optimization
Create nonclustered Index  on table TBT_DO_Details on column Deal_No
Query Optimization
Create nonclustered Index  on table TBT_NOC_Outward on column Deal_No
Code Review
As discussed, this procedure is being used at multiple screens for fetching product code. Application logic needs to be investigated to check if there are any locks for holding record set.
NoData
create index non clustered index on request_no column of table TBD_Payments_List_Extract_Etransfer
NoData
Table tbt_deal is having duplicate index on column status_flag. One index can be dropped.
NoData
Create Nonclustered Index On Tbt_deal table on column Session_no and \nInclude (Deal_no,Product)
Code Review
It is recommended to make a single call with an Array of parameters and populate master dataset which can be used to validate each logical block. Changes in procedure need to be done accordingly.
Code Review
Populate a collection/array inside the for loop and then make a single call to the procedure with collection/array as an argument. Change the procedure accordingly.
Code Review
It is recommended to make a single call with an Array of parameters and populate master dataset which can be used to validate each logical block. Changes in procedure need to be done accordingly.
Code Review
All the User specific details should be loaded with a single procedure call during the login or on Load of respective module and should be kept in client application memory.
NoData
Create non-clustered index on TBT_Payments on columns Product,Maker_Location,PV_Date
Query Optimization
Need to validate if data can be fetched from local DB instead of PRODOX database.
Code Review
Data from one procedure  call can be stored and used for conditions rather than multiple database calls.
Query Optimization
Create Nonclustered Index \nOn Tbt_repayment_dt on columns (Deposit_number,Session_no,Serial_number,Pdc_date)
Query Optimization
Recommended to verify if data from 2004 needs to be scanned if not needed date can be changed to scan only required amount of data
Code Review
These multiple calls need to validated against functional requirement and need to minimized wherever possile. Please refer "Sp_Call_Count" sheet for more details
Code Review
Make sure all path returns
Code Review
Instead of break, use return, which will improve the instruction execution cycle
Code Review
Parentps.GetProperty can use to reduce the loop
Code Review
The 'if' condition is not in use. It could have kept for the feature use. Comment it along with if condition, it is  taking the execution instruction cycle unnecessarily. Given here is an example, like wise many if statements are not in use in this function
Code Review
Can try to use name index property to get the object of "Qnts WCIG City Pairs", instead of looping. If 'r' is greater number, it is unnecessarily loops. Likewise other loops also can be reduced.
Code Review
Relooking the pattern of execution cycle further in better way. \nFor example \nr = ExtSystemParent.GetChildCount();\nfor(i=0;i<r;i++)\n if(ExtSystemParent.GetChild(i).GetType()== "Qnts WCIG City Pairs")\n   Child =  ExtSystemParent.GetChild(i);\nOnce we have got the object required, then the comparison can be started\nif( Child != null)\n{\n if(oCabinClass == oEcoClass) { ... }\n if(oCabinClass == oFirstClass) {...}\n}\nThe above for loop also can be avoided by relook of using the name index pattern.\nif(ExtSystemParent.GetProperty('"Qnts WCIG City Pairs") != null)\nChild=ExtSystemParent.GetProperty('"Qnts WCIG City Pairs")\nThis way it help us to  reduce the internal looping.
Code Review
try using the name index pattern to get the object, avoid the for loop
Code Review
when the NoOfPass is null or empty, then the divide option will fire the DiveByZero Exception. Continue of this, code is checking the NoOfPass for empty and null, if so, the NoOfPass is assigned to 1.\nRelook at this, Should n't it be like following?\n  var oDefFlag = "N";\n  if(NoOfPass == "" || NoOfPass == null)\n   NoOfPass = 1;\ngNumberofPass = ToNumber(NoOfPass);\noFFPVal = oFFPVal/gNumberofPass;\nAvoid unnecessarily DiveByZero exception
Code Review
Append is called multiple times, logically invoke method is multiple times called in append function. The multiple invoke invocation can be avoided by passing the string of required object from the WCIG function.\nFor an example :\nAppend function\n\nvar oEcoClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS","Economy");\n var oFirstClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS","First");\n var oBClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS","Business");\n var oPEClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS","Premium Economy");\n\nInstead of the above\nvar oCmpClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS",passingString);\nThe calling function WCIG\nwould have Append("Economy")\nAppend("First")\nThis reduces the multiple invocation firing in the append function. The WCIG called append method 4+4 = 8 times and in append method invocation is fired 4 times for each call. 4*8 = 32 times it is calling the invocation, which can be reduced to 8*1 = 8 times. We can save the execution cycle which helps us to improve the performance.
Code Review
As a best practice, in the finally block, the required global variables needs to be reinitialized.
Code Review
Avoid else
Code Review
Avoid else
Code Review
Avoid else
Code Review
deinitialize in finally block
Code Review
All path needs to return
Code Review
While(c<ct){\nDeleteRecord();\nc++;\n}  better coding for deadlock,  < is better than == checking
Code Review
if(QuoteProduct != "OneWorld")\n {\n   with(oTransactionBC)
Code Review
QuoteProduct = "Partner"; \nif(noClass!="Y")\n  {\n    if(IsOneWorldQuote == "Y")\n    {  \n     if(ToNumber(OneWorldQuoteSum) < ToNumber(PartnerQuoteSum)) //One World Quote   \n     {\n      QuoteProduct = "OneWorld";  \n     } \n  }\n}\n if(QuoteProduct == "OneWorld")\n  {  .......
Code Review
res = OMktPartnerArray[0].split("/");\n//without checking the length of the arrau res, it is dangerous of accessing array index 1\n// it should have checked something\nif(res.length < 2)\n{\n  // Exception should be handled for res[1] array index accessing when it misses it\n}\n    res1= res[0];//partner\n    mktprtnr = res1;\n    res2 = res[1];//distance
Code Review
Multiple place this type of code is used. Use always else if statement for this kind of comparison, which can improve the instruction execution time\nQFPartnerItinerary.SetProperty("Itinerary", QFPItineraryArray[a]);\n     QFPartnerItinerary.SetProperty("Class", QFPCabinClassArray[a]);\n     if(sftind == "E" || sftind == "" || sftind ==null)\n      QFPartnerItinerary.SetProperty("Points Excluding SFT", QFPPointsArray[a]); \n     else if(sftind == "I") \n      QFPartnerItinerary.SetProperty("Points Including SFT", ToNumber(QFPPointsArray[a]) + (sftvalue* ToNumber(NTripArray[i]))); \n     else if(sftind == "B")\n     {\n      QFPartnerItinerary.SetProperty("Points Including SFT", ToNumber(QFPPointsArray[a]) + (sftvalue* ToNumber(NTripArray[i]))); \n      QFPartnerItinerary.SetProperty("Points Excluding SFT", QFPPointsArray[a]); \n     }
Code Review
Logically, it is right way of breaking the for loop using the max count of ( I=gltiCnt-1). But this will allow for loop to check the conditional again then break. When use of break,  it breaks the loop interruptly with out comparing the for loop conditional
Code Review
deinitialize in finally block
Code Review
"use else if for sftind  to compare all it\u2019s value"
Code Review
also make sure  if(lItinerary != "" && lItinerary != null)
Code Review
In for loop , if condition checking for the 'i' count may not required. At the end of the loop, this activities can be performed. Logically, it's right but it takes the extra execution time. This can be avoided by performing at the end of the loop. It is checking for the last index, which can be directly accessed after the loop.
Code Review
deinitialize in finally block
Slow Response Time
Avoid calling toString() on String objects; this is Unnecessary.
Slow Response Time
Use equals() or equalsIgnoreCase() to compare strings instead of ''=='' or ''!=''
Slow Response Time
Remove all such operations from code
Slow Response Time
Remove all such operations from code
Slow Response Time
Only one call is enough as the string is already trimmed.
Slow Response Time
Change the if condition to some variable. And use the cached data.
Slow Response Time
Change the if condition to some variable. And use the cached data.
Slow Response Time
Change the if condition to some variable flag rather than accsum.length
Slow Response Time
Change the if condition to some variable flag rather than cardlessPayeeList().length.
Slow Response Time
This is not required and operationId itself can be used further.
Slow Response Time
Remove these redundant calls
Slow Response Time
"It is recommended not to create much of unused objects as it will result\ \ in memory consumption. This should be considered important when it\u2019s a mobile\ \ device code."
Slow Response Time
Replace select * queries with the required column name.
Slow Response Time
Put a null check on such objects (here goals) before performing any operations on it.
Slow Response Time
Since HttpServeletRequest is immutable. So these attribute changes should be removed.\n\nThis need to be discussed with development team for understanding why this is being done. As no oveeriden method was found to map these immutable entries.
Slow Response Time
Can this js be called at the bottom of the page so that it does not block other objects? If there are elements of the js which necessarily needs to be called at the top, lets bifurcate the js file into multiple files, so that the js file is not as heavy as it is today (149 KB) which takes time on a slower network.
Slow Response Time
We need to add one more web server behind the LB. This will ensure that if we want to deploy a patch into production during business hours, one server can be pulled out, patch is deployed and the results monitored.
Slow Response Time
The connection pool on the web.config needs to be reset to as follows :\nConnection Lifetime 0\nEnlist 'true' \nMax Pool Size 100\nMin Pool Size 0 \nPooling 'true'\nThe same needs to be done on both web server as well as app server.
Code Review
Rewrite the existing Talisma Life cube to include the aggregation.
Query Optimization
Refresh Statistics on the tables
Code Review
Remove unused objects from report
High CPU Utilization
Hardware configuration for Application Server has to be increased  to minimize the CPU utilization and getting rid of server crash or failure in ETL data loading.
Architecture
One standby instance of database server has to be added.
Code Review
Recommendation is to have dataset distributed across two groups:\nMovement Data - Where customer changes the group(e.g. 0-1L to 1L-3L. This data is limited and can be pushed to cube.\nView AVE_TEST11  (Refer query Q11) is created to give the logic for cube formation.\nNon Movement Data - This has high volume of data and will have to be kept as it is, as per the the user's need. These links will continue to hit database to fetch results as pushing millions of records in cube is not recommended.
Code Review
Recommendation is to limit the data shown to the user either thru Pagination or applying filter.
Code Review
All cubes need to be looked into to remove attributes which are  not required for dashboard to save space.
Code Review
Month's data is being feteched from daily table. Business logic and requirements needs to be validated against the code.
Maintenance
Refresh Statistics on the tables
Design
Create index on following columns and test for runtime performance.
Query Optimization
TRUNC needs to be removed from all the view for better performance.
Code Review
This cube needs to be decommissioned
Code Review
Replace all the existing queries with a single cube fetching single record each for each date. Remove existing date data sets from the report.\n\nView AVE_TEST_iw is provided for the same
Code Review
Build an individual cube for the datasets and pull data from it.
Query Optimization
Only selected columns should be included in select query, this helps to reduce data transfer between DB to APP server.
Code Review
It is recommended to use arraylist instead of vectors, since vectors use internal synchronization on every operation and lead to performance degradation. For thread safety in arraylist  "Collections.SynchrinizedList(new ArrayList<type>)" can be used.
Code Review
Use Position literals first in String comparisons for equals/equalsIgnoreCase. If the String is null you won't get a NullPointerException, it'll just return false.
Query Optimization
Check application logic to put where clause. (Need to validate from Calypso team if no. of executions are going to be high in production environment also as data grows execution time for query will be increased.)
Query Optimization
Create composite index on ers_limit_usage table on columns (version,julian_offset) as recommended earlier.
Query Optimization
Check application logic for commit on this update statement.
Query Optimization
Create the indices on the columns  which will reduce the CPU cost.\nTable - FPD_PAYMENT_IN | COLUMNS - INWARD_FILE_NAME,TXN_CODE,Q_STATUS\nTable - FPD_FILE_INOUT |COLUMN - BATCH_FILE_NAME\nTable - FPD_CBS_AC_ENTRIES | COLUMNS- PROCES_DATE,STATUS_CODE
Query Optimization
gather the tables stats with the option method_opt=> 'FOR ALL CLOUMNS SIZE AUTO' at regular interval on the following tables \nFPD_CBS_AC_ENTRIES\nFPD_PAYMENT_IN\nFPD_PAYMENT_OUT\nFPD_FILE_IN_OUT
Query Optimization
Create the new tablespace to hold the indexes on the tables.
Code Review
On Analysis of deadlock issues we observed that following things \n- Connections are not being closed in some classes\n- Connections artifact closing order is also incorrect .  \nA detailed mail is shared already .
Configuration
We have already shared a mail pointing out the differences in both the databases. \nWe recommend to align UAT Database properties with production.
Code Review
We recommend to implement Auto refresh  in the menu section of the application . Currently it has a manual refresh button .
Query Optimization
Create nonclustered Index  on table TBT_PDC_Receipts on columns Deposit_Number
Code Review
Application code needs to fixed to avoid broken links
Query Optimization
Create non-clustered index on deal_no\non Tbt_Pdc_Pullout table
Query Optimization
Create Nonclustered Index On Tbm_customer_account on column (Maker_id])
Code Review
It is recommended to populate collection of Document_Number and Document_Amount inside for loop and pass them to the stored procedure
Code Review
Get required challan_number from DB and perform manupulation of string on client side.
Code Review
deinitialize it in finally block
Code Review
Avoid instruction execution cycle
Code Review
Instead of looping to get the properties, can use direct method like "GetProperty"\nvar sShipper = Inputs.GetProperty("Shipping Company");
Code Review
deinitialize it in finally
Code Review
use return to reduce the instruction execution cycle
Code Review
deinitialize in finally block
Code Review
origin & dest anything is null, it gets same error code. It would be good to have different value for origin and dest. Caller will not know the problem with origin or dest or both.
Code Review
deinitialize in finally block
Code Review
deinitialize in finally block
Code Review
deinitialize in finally block
Code Review
Dangerous with out checking the spl array length accessing the index of 2\nbefore accessing index of spl[2], check the size of the array\nif(spl.length <3)\nsp=sp1[2];
Code Review
deinitialize in finally block
Code Review
reconsider as \nif(vActivityDate!= "" && vActivityDate != null). Null is compared as string than null object or may required to check null as string would be better in following \nif(vActivityDate!= "" && vActivityDate != null && vActivityDate != 'null')
NoData
Please create a table to store mails. This table will be used by different schedulers to store the mails. And a common Mail Scheduler will process this table to send the mails.
404 Error for down.gif
'Source Code should be corrected to remove reference path of down.gif. Following pages contains the reference: frmAuditTrail.aspx, frmDeletedReport.aspx, frmFwdContractDealReport.aspx, frmFwdContractDealsDetails.aspx and frmFwdUtilizedDealDetails.aspx'
HttpException in Event Viewer
Please remove `Response.Cookies.Add...` line from `Session_End` Event of `Global.asax` File. Since when the session ends, HttpContext or Response Object is not available.
Slow response of frmDeals.aspx Page
In Procedure usp_DirectRates_GetDeal, Please Select only those columns in the query which are required in the business layer.
Application Code Review (frmDealDetails.aspx.cs)
Please replace `if` condition by `else if` condition.
Application Code Review (frmFwdUtiliazationDeals.aspx)
'Please enable security on the `Upload` Folder, So that files cannot be accessible without Authentication.  Also please check the feasibility of Encryption for these files.\nReference: http://support.microsoft.com/kb/815152'
Application Code Review (frmFwdUtiliazationDeals.aspx)
Please add unique names to the files, so that files cannot be overwritten. Below is Code Sample for Reference.\nFileName = FileName + "_" + Guid.NewGuid.ToString();
Response Time high
validate if the table can be created once and insert statement can be used to push data into the table. \nPlease refer create_Table_Query sheet.
Response Time high
As a standard practice username and password should not be a part of code. It should be moved to configuration file. Please refer DB_Credentials_Details sheet.
Workflow Delay
These need to be converted to js files. Which can be moved to bottom of body
Response Time high
Check if js and css files can be combined and compressed. For small background images CSS sprite can be used. ( Pt 5 to 11 apply for other webpages of portal application )
Response Time high
Load them asynchronously to reduce blocking of page rendering.
Response Time high
Fix paths or deploy documents to avoid 404 errors
Workflow Delay
It is recommended to have load balancing in place, so that the load is evenly distributed across all vm instances
Workflow Delay
Need to change the log format to "LogFormat "%h %l %u %t \"%r\" %>s %b %T \"%{Referer}i\" \"%{User-Agent}i\"" combined"
Response Time high
As confirmed by CNK team, direct value can be returned to SP and this will reduce the function execution time without affecting the functionality of application.
architecture
Implement security policies for file access (only required permissions should be given to particular user)
architecture
Only selective columns should be included in select query from product, this reduces the data transfer from DB to APP
architecture
Please refer Server_Slowness_Crash_Analysis.docx for RCA and recommendations
Workflow Delay
It was recommended to use memcache to store session data, instead of http process.
Workflow Delay
It was recommended to use memcache to store session data, instead of http process.
Workflow Delay
It is on by default and no need to enable it
High Response Time.
such extra objects in database are not required to be maintained by dictionary. There is no need of view since columns can directly be selected from table.
architecture
ursor needs to be closed after it has finished its work else resources wont be released from server.
High Response Time.
Apache version upgrade from 2.2 to 2.4 to use prefork mpm is recommended for multithreading. This needs application testing to be carried out
Workflow Delay
use of php-fpm manager is recommended to server PHP requests and static contents will be served by apache
architecture
Recommended to move cache build operation to log shipping server, which has 15 mins lag as compared to production and log shipping server should not be sharing the same LUN as that of production.\n- Optimal storage configuration should be given to database instance\n- Optimization of SP is required
architecture
Data needs to shard from avekshaa team
Query Optimization
Purging needs to be carried out on the BTNEFTPROCESSDET table.
High Memory Utilization
Set database connection pool size to same value across all the servers. Change hibernate.c3p0.max_size property in all application server Database.properties file.
Configuration
As a short term fix, This value needs to be altered to have a headroom to accommodate the long running processes. As a long term fix, we suggest you to fix the issue from the root by finding out from different places in the source where the leak is happening. We have observed lot of connections being abruptly killed in the stack trace at stderr.log. Please share the logs with the product team for ready referemce who can validate such cases and close connections appropriately.
Configuration
Change the parameter DEBUG=FALSE in the web.config file in the web server.
Configuration
Use advanced logging techniques such as log4net so that file writing using multiple threads can be optimized.
Configuration
Please fix the conversion errors in the Scheduler's Code.
Maitenance
Such activities should be done only when the tables/indexes are not being used for operations.
Query Optimization
Analyse REP_MATURITY_REPORT table before generating this report.
Query Optimization
'1) The query needs to be modified to tune the view. \nAn index is already present on cbl_disc_date, however it is not being used because the column is being used in a decode function -- DECODE (cbl_tenor_id, ''B'', cbl_bill_date, cbl_disc_date).\n2) Functional index can be created on this function\n\nE.g :     create index temp2 on cfs_bill_log (DECODE (cbl_tenor_id, ''B'', cbl_bill_date, cbl_disc_date))'
Query Optimization
Either add index on this table for the column CDR_USER_BAND or modify the query to use any column which is already indexed.
Query Optimization
As the saving, current and cash credit scheme accounts are independent of each other, these schemes can be processed in parallel.  The smaller batches can be run in parallel while heavy batches could be run in isolation. Even if the smaller batches have to be run sequentially, these can be grouped with the other schemes.
Query Optimization
Create  indexes on CMH_FROM_TIME  and CMH_TO_TIME  columns or modify the query to use current indexes.
Code review
We propose a multi-threaded Form1.cs instance which will be able to handle simultaneous change events.  See Flow 1 Analysis slides in the Analysis report.
Code review
The proposed solution is to CLOSE the Pop-up page when the Dealers sign out of the Main Page. This will eliminate the un-necessary calls to CurrencyFromRIC_Ajax.aspx and further reduce the Logout.aspx invocation. \nThe changes have been implemented and will be deployed in Production in the next CR cycle. The IIS logs should be analyzed after the changes have been implemented.
Code review
Can we store the session date in the main memory rather than in the database.(Development team was supposed to the analysis on this point by 3rd july).
Query Optimization
The CR has already been raised to have a position table created and the said SP has been changed. There is huge scope of improvement in the modified SP, and the indexes were missing in the position table being used. Suitable indexes have been created on two tables used in the SP.
Code review
We should evaluate the possibility of having multiple threads (3-4) picking such sets (of 498) and processing them in parallel. This will add scalability and improve throughput.
Code review
Change start-up script to provision 512 MB heap size (both minimum and maximum).  Suggestion has been implemented.
Code review
No issues were identified
Code review
Thread.sleep should be eliminated
Code review
The operations can be eliminated to increase throughput.
Code review
The operations can be eliminated to increase throughput.
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Query Optimization
Appropriate Indexes needs to be applied
Configuration
Recommended RAID configurations:\nRedo log & control files - RAID 1+0\n16k tablespace datafiles - RAID 1+0 preferred ( else RAID 5)\nother data files / archive logs - RAID 1+0 preferred ( else RAID 5)\nundo and temp files - RAID 1+0
Configuration
Perform data file  movement to make some space available.
Configuration
Change the way data is manipulated or the way it is declared in order that this does not violate the constraint. Since an alert log is polluted with this error there is a good change that some other error might get masked in future due to this.
Code review
In httpd.conf (for both corporate & bank servers) append %T to the current list of options for LogFormat.\n\nThe LogFormat line should look something like:\nLogFormat "%h %l %u %t \"%r\" %>s %b %T" common
Older Version
From a compliance standpoint, it would be good to upgrade current Oracle Application Sever to 10g or better still to upgrade it to the latest version of more popular Oracle Weblogic server.
Code review
Permanent fix for this issue is to reduce memory foot-print of the application. POI HSSF usermodel API is extremely memory hungry. Replacing this API with SXSSF (Streaming XSSF) will reduce memory foor-print by a big order. Change current excel generation logic a bit and make use of SXSSF API rather than HSSF one.
HOPS
'This needs to highlighted to network administrator for resolution as the response time will get affected. Following machines need to be analyzed: \n10.127.253.105 - > 53ms\n10.16.117.134 -  > 76ms\n10.16.117.130 -  > 40ms\n10.16.167.155 -  > 78ms\n10.16.58.151  -  > 64ms\n10.16.0.207   -  > 59ms\n10.16.58.67   -  > 108ms\n10.16.58.151  -  > 64ms\n10.16.167.155 -  > 78ms'
High CPU
CPU was saturating because of a while (true) loop in the Header.jsp file which is in-turn included in many other two JSP's.  As a workaround, we have introduced a small sleep in the loop to reduce the CPU cycles. This is a temporary work-around
Configuration
Change heap size to  2 GB(min) and 2 GB (max).  Also suggested some high performance algorithm settings for garbage collection e.g. -Xconcurrentio, -XX:+UseParallelGC etc.
Code review
'Code was changed to close the Connection, Sockets and IO objects after their use. As a work-around sleep introduced in the while(true) loop that consumed high CPU cycles. \nSee recommendation # 2, 8, 9, 10 and 11 for details.'
Code Review
deinitialize in finally block
Code Review
deinitialize in finally block
Code Review
deinitialize in finally block
Code Review
Not used any where, can be removed or commented
Code Review
Refactor the code
Code Review
Add logging inside catch block
Code Review
Object creation is expensive enough that you should avoid unnecessarily creating temporary or intermediate objects in situations where performance is an issue. Define instances outside the loop will solve this warning.
Code Review
Change statement with log statement
Code Review
Break the classes into multiple clasess
Code Review
break the method into mutiple methods
Code Review
Refactor the code
Code Review
Fix all variable that is not thread safe
Code Review
Reader class provides close() method and it should be invoked in the last.  It's very important to invoke in finally block, so it will be called even if an exception occurs.
Code Review
implement serealizable
Code Review
Use Buffered Input stream class instead of InputStream as following\nBufferedInputStream in = new BufferedInputStream(new FileInputStream(from Filename));\nBufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(to Filename));
Code Review
Log enabled status should be checked before calling the log util method for logging the message. By doing this unnecessary message string construction time can be saved.
Code Review
Add server VM option - The server VM option has been specially tuned to maximize peak operating speed. It is intended for executing long-running server applications, which need the fastest possible operating speed more than a fast start-up time or smaller runtime memory footprint
Code Review
As server side state saving option has been used, so limit the number of active views per session and configure it initially with 10 in web.xml. Monitor this value and increase the value as required\n<param-name>com.sun.faces.numberOfViewsInSession</param-name>\n<param-value>10</param-value>
Code Review
Catch the exception where it require to be handled. Also, handling the flow using Exception bring performance bottleneck.
Code Review
Code Review in progress. Solution- String to numeric value conversion.
Code Review
Remove sysout and use logger with log level where ever required.
Code Review
Consider replacing Vector usages with the newer java.util.ArrayList if expensive thread-safe operations are not required.
Code Review
Statistics need to be gathered on the tables for optimal execution plan of the queries.
Concurrent I/O
"We recommend to implement the concurrent I/O feature for file systems on\ \ AIX  where database datafiles (.dbf) and redo logs resides .\\nTo mount a filesystemin\ \  with CIO Feature we can use below command\\n$ mount \u2013o cio /data"
Index creation on  CUST_CFCM_MAIN
We recommend to either \n1) Create a new index on the table  CUST_CFCM_MAIN for column ENTITY_ID . \n2) Edit the existing composite index to shuffle the column place of ENTITY_ID column to the first place on the left . We recommend this only afer carefull evaluation of the existing index usage.
Batch Job Parallelization
We recommend to increase to parallelization to imrpove the utilization of the available hardware . In the first increment we recommend it to increase it 30 . Post change obseration may lead to further fine tuning of this parameter.
Index creation on  IAP_SMS_TXN
We recommend to create an index on the STATS column of the table to avoid full table scan.
Audit Queries
We recommend to analyze the running of Audit queries during EOD/BOD time frame . These queries if necessary can be moved out of EOD/BOD window .
Scheduled Jobs
We recommend to analyze the running of DBMS schedular during EOD/BOD process. These scheduled jobs  if necessary can be moved out of EOD/BOD window .
Table Fragmentation
We recommend to degragment the tables which are shared in a separate mail .
Full Table scan
We recommend to create new composite index on LA_ACCT_MAST_TABLE table with columns (DMD_SATISFY_MTHD,OP_ACID).
Configuration
Start mongo DB server under numactl as below:\nnumactl --interleave-all /path/to/mongo/db/mongod -f /etc/mondo.conf
Code Review
'Use String.indexOf(char) when checking for the index of a single character; it executes faster then String.indexOf(String).\nReference:  int lastIndex = s.lastIndexOf("/");\nRecommanded: int lastIndex = s.lastIndexOf(''/'');'
Code Review
Many DB calls are made in model classes to fetch the same object from Db. Make one DB call and store result locally in Map.
Code Review
Make Jackson parse call once and store it in local variable. Later use local variable.
Code Review
Replace find and findById methods with Morphia query calls as shown below:\nList<Issue> users = MorphiaDatastoreWrapper.getInstance().ds.createQuery(Issue.class).filter("_id", 32).asList();
Code Review
Check Morphia devloper documentation and API to check feasibility of adding projections in queries.
Code Review
Jio News client developers should evaluate JSON reponse from the server and list down redundant objects in the response tree. Server devs to drop redundant Db calls to fetch these redundant objects.
Code Review
Transparent huge pages to be disabled. The below commands to be executed for disabling transparent huge pages    echo never > /system/kernel/mm/redhat_transparent_hugepages/enabled    echo never > /system/kernel/mm/redhat_transparent_hugepages/defrag.   This needs to be added in rc.local file also
Code Review
Check Morphia developer documentation/API so that max "_id" is fetched from the Favorite collection wihout having to fetch all records.
Code Review
Is it necessary to populate the cache here? Can the cache be not populated during first access? This is again a hot cache update and I think we should avoid it. \n\nIn any case, it is querying Favorite and ordering based on date. You need to add index on date in collection Favorite.
Code Review
Policy configuration changed on the environment.
Code Review
Following changes done on F5 Load Balancer:\n1. TCP Timer set to 30 seconds\n2. SSL Offloading Implemented\n3. Multiplexing Enabled
Code Review
Setting following in sysctl.conf on all the Seco Nodes:\nnet.core.rmem_default = 262144\nnet.core.wmem_default = 262144\nnet.core.optmem_max = 40960\nnet.ipv4.tcp_rmem = 262144 262144 8388608\nnet.ipv4.tcp_wmem = 262144 262144 8388608\nnet.ipv4.tcp_mem = 8388608 8388608 8388608\nnet.ipv4.tcp_fin_timeout = 10
Code Review
sysctl.conf file synched from the Seco Nodes to the Mysql Database.
Code Review
Defragmentation is required for those tables.
Code Review
Add the file /etc/security/limits.d/99-ssg-appliance.conf with the contents below:\n# Layer 7 Limits (SSG-8322)\n# gateway user value based on /proc/sys/kernel/pid_max\n*               hard    maxlogins    10\n*               hard    core    0\n*               soft    nproc   5120\n*               hard    nproc   16384\n*               soft    nofile  4096\n*               hard    nofile  63536\ngateway         soft    nproc   31768\ngateway         hard    nproc   31768\n# End Layer 7 Limits
Code Review
Raising up the thread limits. These settings are configurable through the Policy Manager -> Tasks -> Manage Cluster Wide Properties\nio.httpCoreConcurrency - 500\nio.httpMaxConcurrency - 750\n\nAs the concurrency values are increase we also need to take into consideration the number of concurrent databases connections for auditing and other related tasks. The default value is 260 connections so increasing value should be httpCore + 100 so for 500 we need to set the value to 600. Further to this depending on the number of nodes in the cluster you will need to look at whether the max pool size X Number of nodes will be over 2625 and if so use the procedure below to control the value in the my.cnf file.\n\nModify /opt/SecureSpan/Gateway/node/default/etc/conf/node.properties\n\nadd the line\nc3p0DataSource.maxPoolSize=600
Code Review
Additions to the Cluster Wide Properties\nprincipalSessionCache.maxPrincipalGroups to 1000 principalSessionCache.cache to 1000 ldap.group.searchMaxResults to 1000 ldap.searchMaxResults to 1000
NoData
The ulimit -n parameter needs to be increased to a high value for the server to accept high concurreny. The ulimit -n is set as 1000001.
Code Review
The memcache connect() was changed to pconnect() to use persistent connect to reduce the connect on the memcache.
Code Review
Code change needs to be done to include the else condition, where the requests should do not die if the memcache service is down.
Code Review
Bonding was removed and a dedicated 10Gbps network line was introduced. (Max network throughput currently is 500 Mbps, 10 Gbps line is sufficient).
Code Review
The net.netfilter.nf_conntrack_max was set as 256000 to accommodate these many max connections on the API Server.
Code Review
Replace date(date) by date in the query
Code Review
echo 2048 >/sys/block/sda/queue/nr_requests\necho 1024 >/sys/block/sda/device/queue_depth
Code Review
For table playlist_master , the primary index needs to have userid and playlistid in the columns instead of playlistid alone. A secondary index needs to be created on playlistname. Allow filtering should be removed from the query.
Code Review
For table playlist_master ,the primary index needs to have userid and playlistid in the columns instead of playlistid alone. A secondary index needs to be created on playlistname. For table playlist_details_new the primary index needs to have userid, playlistid and songid in the columns. Remove allow filtering from the query.  Allow filtering should be removed from the query.
Code Review
For table user_likes, secondary index needs to be created to status column, and allow filtering should be removed from the query.
Code Review
This should be limited by pagination.
Code Review
user_likes table needs to be recreated with primary key on userid,srno,songid, with clustering order by (srno desc,songid asc). A secondary index needs to be created on status column.
Code Review
A logical call needs to be taken to have the cassandra connect call in blocks where cassandra queries are being called.
Code Review
Extra hit on the new release should be avoided.
Code Review
Rename playlist needs to be refreshed immediately.
Code Review
Add limit 2 to the query fired on user_likes.
Thread contention in ECS.DAL.Repository.ODS.ECSPolicyDetailRepository.GetPolicy
Do following steps.\n1. Instead of applying EntityFunctions.TruncateTime function on EndorsementDate column use variable side value without time.\n2. Create Index for EndorsementDate column in ECSPolicyDetails table.
Slowness in application due to sudden load from various interfaces
Use following approach to resolve this.\n1. Assign more connections using <system.net> configuration in web.config of HCS services application to ips of interfaces dedicated for various services to avoid slowness in web request processing.\n\nOr\n2. Divide logically services across multiple worker processes to avoid slowness due sudden rise of load from any of the interface.
Thread contention in ECS.DAL.Repository.GlobalSearch.CLSearchRepository.GetCLDetailCount
Following should be checked to make GetCLDetailCount query faster.\n1. Remove EntityFuctions.TruncateTime from table columns.\n2. In select section just one column is enough.\n3. GroupBy clause is unnecessary as just count is needed.
Thread contention in ECS.BL.SavvionReference.RGICL_HCS_WSService.UpdateAndCompleteCLFlowTask
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
Several un-usable objects initialized in constructor of Business Layer classes under Service folder
The required objects should be passed into functions as parameter instead of initializig them in constructor.
Thread contention in ECS.DAL.Repository.GlobalSearch.ALSearchRepository.GetALDetailsCount
Following should be checked to make GetALDetailCount query faster.\n1. Remove EntityFuctions.TruncateTime from table columns.\n2. In select section just one column is enough.\n3. GroupBy clause is unnecessary as just count is needed.\n4. Review Query if same logic can be accomplished with less number of joins
Thread contention in ECS.DAL.Repository.Status.StatusServiceRepository.GetClaimsByPolicyNo
Following should be done to make GetClaimsByPolicyNo function faster.\n1. Remove string concatenation for Output string.\n2. Remove logging if not needed
Thread contention in constructor DynamicClass.BuildUp_ECS.BL.BL.ClaimCommon.DocumentDetailsBL
The required objects should be passed into functions as parameter instead of initializig them in constructor.
Currently Antivirus software is installed on the DB Server.
If any antivirus software is installed on the SQL Server computer then disable real time scanning of SQL Server data and SQL Server transaction files (.mdf, .ldf).
Method code lines are not formated
It is recommended to fromat code lines insied the  Methods.
Not using .Net Profiler
It is recommended to regularly use .Net Profiler.
Database connection pooling
set following keys in connectionstring \nConnection Lifetime 0\nEnlist 'true'\nMax Pool Size 100\nMin Pool Size 0\nPooling 'true'
Remove browser waiting time while waiting for scripts to be received.
Move all the script tags and script references to the end of the page in the files in the Views folder.
The null checking of input parameters with integer in the methods of Controllers is done without setting the integer as nullable.
NoData
Not created New Class for Input Parameters where the methods have more than 5 input parameters
It is recommended to create new class for input parameters where the methods have more than 5 input parameters.
Hard Coded Values Found
Its recommended to fetch hard code values from config files.
Enum Should be used
Its recommended to use Enum and call Enum for hardcoded values. Also hardcoded values should be fetch from config files.
Handling Null values for string variables
It is recommended to assigned the string variables to local variables using Convert.ToString() instead of .ToString()
Validation Missing
It is recommended to do null check for IdataReader object before fetching data from that object.
Hard Coded Values Found
Its recommended to fetch hard code values from config files.
Found unused commented code
Its recommeded to remove unused commented code.
Method Header Comments Missing
Its recommended to give Header Comments above all the Methods.
Validation Missing
It is recommended to do null checking of the variables before assigning their values.
Hard Coded Values Found
Its recommended to fetch hard code values from config files.
Multiple classes found in a single cs file
It is recommended that one class should be present in a single file.
Database Design and Code Review
Need to test and rectify the code and design issue identified in the production database.
'sql_id : 5v2jrmvmjzhk6'
The execution of the pakages (begin ONL_MSGTIMEOUT.AutoReverseException; end;;)
'It is observed that Stream objects (Writers) are not being closed.\nExample: ServerSocketThread.java'
It is recommended to close the Stream objects .
It is observed that Logger (Log4J) is used to log information which is of the info level.
It is recommended to set the log level to debugging since this all information is used during debugging . Log level 'info' is used for highlighting the progress of the application .
'It is observed that critical information is being stored in variables or passed a string.\nExample: RelationshipDetailsManager.java,BankConfirmationVO.java,CustomerDetailsMBean.java and many more places'
It is recommended to not use straight forward variable names like user , password , proxy , ip , port.  It is also recommended to enCode Recommendations these values for security reasons
It is observed that System properties are used for global variables.
It is not recommended to use System.get/set property for storing global variables. Instead one global class with static getters should be used by reading all properties at startup time.
Its is observed that Stringbuffer is used many classes even though it is used in single threaded environment .
Its recommended to use StringBuilder instead of StringBuffer after careful evaluation of multithreadedness of the piece of Code Recommendations.
It is observed that servername, port number and various other types of hard Code Recommendationsd values are used.\nCustomerDetailsMBean.java, ADAuthentication.java etc
It is recommended to put application configuration specific values from applicationconfig.properties file
'Its is observed that String is used many classes with the usage of ''+'' operator. \nExample: BankAccountStatementMBean.java,ChequeLeafMBean.java etc'
It is recommended to use Stringbuilder instead of String class where there are lot of concatenations used . Stringbuffer can also be used in multithreaded environments
It is observed that length/size() methods are used inside loops . This adds to unnecessary processing for each iteration in the loop.\nExample:AccountDetail.java,EODBalance.java etc
It is recommended to compute the length/size value at the start of the loop and assign it to a variable . This variable then can be used in the loops
'It is observed that exceptions are consumed by having empty catch blocks.\nExample: QuickKills.java,CarDetailsMBean.java and many more'
It is recommended to log / process an exception .
It is observed that generic exceptions "Catch (Exception e)" are being caught at most of the places
It is recommended to catch specific exceptions e.g. Catch (FileNotFoundException e), SQLException etc
It is observed that String literals are used in the application very frequently.\nExample:IViewAuthorizationUtility.java
it is recommended to use String constants rather literals.
It is observed that hashtable class is being used
it is recommended to use concurrenthashmap class over hashtable class.
It is obseved that no bean class is derived from serializable class
It is recommended to derive bean class from serializable class
It is observed that xml response is stored in two dimensional array of string and compare each item with string constants on right hand side, it is present in almost all the classes
it is recommeded to take string constants as string final string and check constant.compare(string)
it is observed with various Reqxxxx classes used without any interface even if they all have same methods
It is recommended to use interface and put getXml(), getXmlHeader(),setDate() and getXmlFooter() functions in it and all Reqxxxx classes should implement this interface
It is observed that CustomExceptionHander classes are created but not used in Code Recommendations
It is recommeneded to make custom exception handler with product name and use that wherever needed ex. ICICIIViewException
It is observed that oops concepts are not used in Iview Code Recommendationsbase
it is recommended to use interfaces and abstract base classes for better Code Recommendations maintainability
It is observed that no function header written
It is recommended to use javadoc specifications for function headers so that dynamically help can be built and used for reference purposes
It is observed that all class variables setters/getters provided
it is recommended to check this carefully and provide only required getters/setters
It is observed that so many util packages are used
It is recommended that in Web Application we should follow Model/View/Controller packages and move all data structure in Model and all xhtml into View and all controller classes in controller packages
It is observed that Code Recommendations is not aligned properly
It is recommended to prepare proper checkstyle for Code Recommendations formatting and use eclipse checkstyle feature for formatting the Code Recommendations
It is observed that no proper Code Recommendations commenting is done in entire Code Recommendationsbase
It is recommended to put proper Code Recommendations comment so that any other developer can understand it
It is observed some variable are in upper case and some are in camel case
it is recommended to use lower case in .properties file
It is observed that unwanted import packages are seen in so many files
it is recommended to run organise import command in eclipse
It is observed that no Junit test cases present in Code Recommendationsbase
it is recommended to write Junit test cases for each class for Unit Testing
It is observed that main method is kept in several classes
it is recommended to remove all main methods and make another name method
It is observed that no toString() method is implemented
It is recommended to override toString() method for pretty print of object for debugging point of view
The heavy usage of XML payload to interact with source systems carries additional overhead on the latency and memory footprint of the application. Will have to talk to all source systems and slowly the data should be exchanged via a lighter JSON format.\nIn the interim, EAI can convert the message formats from XML to JSON and vice versa.
A POC needs to be carried out to on XML versus JSON messages to ascertain the overhead of XML over JSON.
General Suggestion
Application static images and JS/ CSS files will be cached at web server.
General Suggestion
The setup/infra for BB and CC channels should be separate and independent.
Custom logging used which needs to be changed with Log4J
For audit trail, the asynchronous logging needs to be looked at rather than current blocking based logging.
SAX based xml parsing is used and manually pojo are created after xml parsing.
JAXB based XML parsing needs to be considered rather than current SAX based parsing approach.
The application is used by the call center and branches where operational efficiency is very important.
"We are proposing to use a recommender system (similar to Social media sites)\ \ help to show screens/ functions as per user behavior. Screens/ functionalities\ \ can be re-arranged based on what end-users use most.\_"
'Incident Dated 02/03/2017 : High CPU utiization observed on 10.50.49.45 App Server causing slowness and fluctuations in i-View admin console.'
Proper JVM tuning is required. One Production servers full day GC log is requried.
Currently Avg Disk Queue Length - parameter is not monitored in APM Tool.
To capture Avg Disk Queue Length (% wait in Solaris) in monitoring software.
Found more response time after analysis of IIS logs
Around 8 Recommendations given to improve the reponse times on various pages of LOP application.
Code Review
reconsider null is compared as string than null object\nif(vBookingDate!= "" && vBookingDate != null)
Code Review
reconsider null is compared as string than null object\nif(vflightDate!= "" && vflightDate != 'null')
Code Review
reconsider null is compared as string than null object\nif(vProcessDate != "" && vProcessDate !='null')
Code Review
reconsider null is compared as string than null object\nif(vTrnsdate != "" && vTrnsdate != 'null')
Code Review
reassigning can be avoided using direct call like\n oJoinDt = new Date( Inputs.GetProperty("QntsDateofJoining"));
Code Review
deinitialize in finally block
Code Review
recheck  sPromopoint is not using anywhere. If not required, this line can be commented
Code Review
Global variables are used. May required some of the important variable to be reinitialize here
Code Review
Not used any where, can be removed or commented
Code Review
Not used any where, can be removed or commented
Code Review
Return directly value where asigning to temporary variable
Code Review
Change statement with log statement
Code Review
Try to minimize the cyclomatic complexity
Code Review
Change with StringBuffer append
Code Review
Refactor the dead code
Code Review
Parameter binding should always be used for better performance.
Code Review
String concatenation should be avoided and use only StringBuilder or StringBuffer instead of String concatenation using (+) operator for better performance.
Code Review
Create this InputStream instance before instantiating the Properties and use the created instance. Also this InputStream should be closed in the finally block.
Code Review
If you didn't create instance of OutputStream, then you don't need to close it yourself. Here OutputStream is getting from response and web container are responsible to close it. But call flush() method to commit the response.
Code Review
InputStream class provides close() method. It should be invoked in the last.  It's very important to invoke in finally block, so it will be called even if an exception occurs.
Code Review
Change to instance variable or best define as local variable.
Code Review
Infinite while loop always avoided as it eats most of the CPU cycles. Code is not getting much advantage of the same and while loop can be removed with little modification of the code.
Code Review
This option enables caching of commonly allocated strings.
Code Review
Also, reduce the Logical Views for server side state saving to 10 initially. Monitor this value and increase the value as required\n<param-name>com.sun.faces.numberOfLogicalViews</param-name>\n<param-value>10</param-value>
Code Review
To understand the hibernate performance, configure this setting. \nhttp://raibledesigns.com/wiki/Wiki.jsp?page=HibernateJMX
Code Review
Recommended to use of hibernate 2nd level caching using EHCache. Second level cache stores entities between sessions and scope is SessionFactory. It tells cache provider how many objects it should store and when/why they should be invalidated.
Code Review
Avoid the use of unused import statements to prevent unwanted dependencies
Code Review
Avoid using printStackTrace(), use a logger call instead
Code Review
Use StringBuilder instead of StringBuffer. StringBuilder is faster than StringBuffer for strings concatenation.
Code Review
Remove/comment all unused local variables
Redo log file members reside on same mount point
We recommend that  Redo log file members should be on different mount points
Row Lock Contentions
We recommend to analyze the application logic causing this issue.
Query Optimization
We recommend to analyze the usage of order by clause . Incase its not necessary it can excluded from the queries.
SGA size optimization.
We recommend to increase SGA value from 14336 Mb to 24576 Mb. But due to limitations on the hardware size we recommend to increase the SGA size to what ever max RBL can . Based on the further observations we will take a calf we we need to further increase the value.
Exe level granular Parallelization.
We will keep recommending settings for global parallelization and exe level parallelization on a regular basis till we get rid of the sinusoidal cpu utililization .
Flawed dispatching Logic for Fibee/Application
Currently the logic of distributing the requests between servers is done by a simple rule to check request ID as even or odd. This logic is flawed and we propose a flag based approach to distribute requests amongst 2 application servers for more even distribution .
Long times for Bigger sols
We recommend to parallelize sols 0121, 0169, 0114,0117 for exe 4012 and  0121 , 0169 fo exe Asor5002 further to reduce time of running for these exe's.
Long Running LateF job
Since jobs with lower prority(ADEMP -850) than Latef (prio 900) are non blocking in nature we can move up the Job to reduce the running time for the job in PSBKD batch job group .
Code Review
It should be started in a PROD mode.
Configuration
Change thread stack size in /etc/system/limits/limits.conf to 1 MB from 10 MB.
Configuration
Change the number of process and number of file descriptors to 64000
Code Review
Make MongoDB call once and store it locally.
Code Review
Make MongoDB call once and store it locally.
Code Review
Invoke logic from batch job rather than from front-end.
Code Review
Consider replacing Vector usages with the newer java.util.ArrayList if expensive thread-safe operations are not required.
Code Review
Remove unused StringBuffer objects from code.
Code Review
Add finally block in source and close all important resources inside it.
Code Review
Remove/Comment all System.out.print calls
Code Review
'Singleton objects are not synchronized. Non-thread safe singletons can result in bad state changes. In highly concurrent load, this will cause NullPointerException.\nReference: public static ComplexPreferences getComplexPreferences(Context context, String namePreferences, int mode)'
Code Review
Readahead value needs to be reduced to 32. Execute the below command to reduce and also add the same in rc.local file                                                                                 sudo blockdev --setra 32 <device>
Code Review
Do not check whether the refID in Favorite class is present in Edition collection. This will reduce one query per user to fetch all Editions from the collections.
Code Review
Use HashMap rather than Vector to search Ids. HashMap gives constant-time fetch.
Code Review
Set buffer size of 1 MB so that download can happen in much less time. Earlier it was taking few minutes to download single PDF. With above buffer size set, file is now getting downloaded in few seconds (35 MB PDF in less than 2 seconds).
Code Review
Move batch queue management to mysql database.
Code Review
Move nginx_cache folder to RAM disk (tmpfs mount point) so that Disk write will be avoided and cache will be picked up from RAM.\n\nAdd below line to nginx.conf:\nfastcgi_cache_path /dev/shm/nginx_cache levels=1:2 keys_zone=microcache:1000m max_size=90000m inactive=60m;\n\nCreate folder nginx_cache in /dev/shm
Code Review
Maintain seprate issue_today table which will contain issue details data for a given day's ingestion batch only. This will get rid of order by clause.
Code Review
Optimized code deployed on the Seco VM Nodes.
NoData
Selinux parameter needs to be changed from enforcing to disabled.
Code Review
All API's are changed to have PDO implemented for it to use prepared connection.
Code Review
The max_connection has been increased to 20000. The max_user_connection is reaching 1300 as of now. In the mixed load testing, with all scripts running together, the max_user_connection will be evaluated, and then the final max_connection parameter will be set.
Code Review
These tables were altered to InnoDB storage engine.
Code Review
Master Slave Tsung configuration was replaced with 2 physical servers firing independent transactions onto the API server with 15 VIP's each.
Code Review
Composite index created on userid and songid
Code Review
composite index created on userid and playlistname
Code review
change socket code as following\n       Socket connection = null;\n       try {\n         connection = ....\n         ---------\n       }catch (IOException e) {}\n       finally {\n         try {\n           if (connection != null) connection.close(  );\n         }catch (IOException e) {}          \n       }\nAlso close BufferedReader in jsp sendrequest on line 19, BufferedWriter in PrimaryCC on line 296
Code review
Java 1.5 provides java.util.concurrent package to provide thread pool. Also a sun recommended design for pool implementation has been shared with team.
Code review
Ajax implemented application should be rigorously tested to deal with the idiosyncrasies of different browsers, platforms and usability issues. jQuery is lightweight  and plug-in based javascript framework and well known tools in building an efficient Ajax based application. As application is already using jQuery in application, so jQuery can be used in implementation of Ajax.
Code review
Fix all these exception from Pramati log file (SERVER_TXTservermsg ). Ideally this file should be free from exception/error
Code review
Keep all Ajax variables name different as following \n\nvar xmlHttpRelation;\nfunction relation(){\n  var input_val = document.getElementById("mainval").value;\n  if (typeof XMLHttpRequest != "undefined") {\n        xmlHttpRelation = new XMLHttpRequest();\n   ...\n\nvar xmlHttpCross;\nfunction cross_time(){\n  var input_val = document.getElementById("mainval").value;\n  if (typeof XMLHttpRequest != "undefined") {\n        xmlHttpCross = new XMLHttpRequest();
Query Optimization
Apply relevant oracle patch and review AWR Report
Query Optimization
Fix all queries for full table scan and analyze AWR report for these queries
Query Optimization
Fix read by other session
Network Latency
The primary database is possibly configured with a standby database. \nARCH wait on SENDREQ monitors the amount of time spent by all archiver processes to write the received redo to disk as well as open and close the remote archived redo logs, so optimization of the network needs to be done here, possibly in association with network administrators, and with network monitoring tools. After the network has been optimized the DBA team can perhaps see the results at the log and tracefile levels, or can modify appropriate parameters in Oracle configuration files, to further enhance the network.
Query Optimization
Full table scan has been observed in few queries, Need to fix these.
Configuration
'The common components of the SGA are: \n(a) Data buffer cache - cache data and index blocks for faster access. \n(b) Shared pool - cache parsed SQL and PL/SQL statements. \n(c) Dictionary Cache - information about data dictionary objects. \n(d) Redo Log Buffer - committed transactions that are not yet written to the redo log files. \n(e) Java pool - caching parsed Java programs. \n(f) Streams pool - cache Oracle Streams objects. \n(g) Large pool - used for backups, UGAs, etc. \n\nWhen automatic shared memory management is enabled, Oracle will adjust the memory parameters dynamically on the fly. \nTo see currently allocated sizes at runtime, one can query the appropriate views.\nIf automatic Shared Memory Management is enabled, the sizes of the different SGA components are flexible and can adapt to the needs of a workload without requiring any additional configuration. The database automatically distributes the available memory among the various components as required, allowing the system to maximize the use of all available SGA memory. Oracle Database remembers the sizes of the automatically tuned components across instance shutdowns if you are using a server parameter file (SPFILE). As a result, the system does need to learn the characteristics of the workload again each time an instance is started. It can begin with information from the past instance and continue evaluating workload where it left off at the last shutdown.\nAgain, the default granule size of the particular version of Oracle one is using, plays an\nimportant role in SGA sizing policies.\nAll SGA components allocate and deallocate space in units of granules. Granule size is determined by total SGA size. \nOn most platforms, if the total SGA size is equal to or less than 1 GB, then granule size is 4 MB. For SGAs larger than 1 GB, granule size is 16 MB. Some platform dependencies may arise. For example, on 32-bit Windows NT, the granule size is 8 MB for SGAs larger than 1 GB. One can consult the operating system specific documentation for more details, or query the V$SGAINFO view to see the granule size that is being used by an instance. The same granule size is used for all components in the SGA.\nIf you specify a size for an SGA component that is not a multiple of granule size, the Oracle database will round the specified size up to the nearest multiple. For example, if the granule size is 4 MB and you specify DB_CACHE_SIZE as 10 MB, the database actually allocates 12 MB.\nIt may be a better practice to leave default values for the less important components of the SGA\nlike java_pool_size,large pool_size or streams_pool_size, unless your applications are using them substantially.\nFor instance, an increased value of java_pool_size will be justified in case of heavy java activity on the database.'
Query Optimization
Apply index based on aggregate function used in query
Configuration
Need to do redo log deployment analysis
Configuration
Please set this value to debug="false"
Configuration
Please replace `Response.Redirect(strURL)` with `Response.Redirect(strURL, false)` , details are shared in the next sheet.
Configuration
Please change the data type of variable `mailtable` from String to StringBuilder.
Configuration
Index on tables Labeling_TermSheet, Labeling_Answers and Labeling_ClientMaster needs to be created. Index script is shared in the next sheet.
Configuration
Integration of all schedulers into one common scheduler will help in solving the problem. Recommended Architecture is described in the next sheet.
Query Optimization
Please use configuration file to store the database schema name.
Code review
Please enable security through configuration on the `UploadFiles` Folder, So that files cannot be accessible without Authentication.
Code review
For case HtmlControls, `Disabled` property should be true.
Code review
Please move `SortGrid` Method to common class and call them on all the pages.
Code review
Please remove the Session["dtNonCIB"] assignment from the Method `GetDataSource`
Code review
Code Refactoring is required to identify repeated code through out the application and move them to common shared methods. Please start this from top 15 pages, especially for Setting Response, Sort Grid, Excel/ CSV Download Functionality.
Code review
Please implement session check in `Page_Load` Event of all the Pages.
Code review
Please remove the delete command from the Procedure at Murex's end. Recommended Interface is shared in the next sheet.
Response Time high
Minify .css files to reduce size.
Response Time high
Please fine tune the query which searches for the first/last name text in the database . \nCurrently the text is searched with "like %text%"  syntax.\nWe recommend to used "like text%" . \nSpecifics have been discussed with the team .
Response Time high
Implement updates to query grids at the server side using libraries like Node.js
Workflow Delay
Change the value of batch size to 50.
Workflow Delay
Limit the call for DisabilityType to once.
Workflow Delay
Limit the call for pageimage.json to once.
Response Time high
Limit the call for ButtonActionMessages.json to once.
Workflow Delay
Limit the call for ButtonActionMessages.json to once.
Workflow Delay
Retrieve ViewExpeditionHelp.html when user clicks on expedition icon.
Response Time high
Call to FindDuplicateUser and GenerateUserName only when values in field are changed.
Response Time high
It is recommended to use just the UNION clause instead of union all with distinct.
Response Time high
Limit the call for ViewAwardDetails.html to once.
Response Time high
It is recommended to add a covering index for user id and password since password is never queried in isolation .
Response Time high
Avoid request for jquery.jqgrid.min.js in load event of Participant\MyDofeLevel page.
Workflow Delay
Avoid request for jquery.jqgrid.min.js in load event of Participant\ExpeditionSection page.
Workflow Delay
Limit the call for ViewAwardDetails.html to once.
Workflow Delay
Avoid request for jquery.jqgrid.min.js in load event of Participant\ViewEvidence page.
Response Time high
Limit the call for GetUserLocations to once.
Response Time high
Limit the call for GetParticipantList to once.
Workflow Delay
Limit the call for GetUserLocations to once.
Response Time high
It is recommended to use varchar instead of Nvarchar . Nvarchar is only needed for internationalization .
Response Time high
It is recommeded to switch to varchar(n)  if interntionalization is not needed and if needed switch to nvarchar(n) .
Response Time high
It is recommended to to use Int instead instead of BigInt if the data is known to not increase to mamoth proportions. Range for INT is 214 crore which we think is enough for most columns .
Response Time high
Limit calls for GetMenuOnSubmission to once.
Response Time high
Avoid call to DDLData.json in ParticipantProfile page if not needed.
Workflow Delay
Limit calls for InvitationStatus to once
Response Time high
Create the index on the required column . Existing index on User Award table can also be edited to include the new column .
Response Time high
Avoid call to GAP/GAPAllRegionsforYpTab in GAP/EventOverview page load event if not needed.
Response Time high
Create the index on the required column .
Response Time high
Limit call of bundles\GenericLocationFilter to once.
Response Time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Physical.
Response Time high
Move google analytics script at the end of layout pages after page rendering.
Workflow Delay
Avoid call to AcontStatus in Participant/QueriedAwards if not needed.
Response Time high
Limit requests for ViewAwardDetails.html to once
Response Time high
Avoid call to AcontStatus in Participant/LeaderApproved if not needed.
Response Time high
Limit call for GetSubmenuOnPermission to once.
Response Time high
Limit the call for GetBasicUserInfo to once.
Response Time high
Limit the call for GetParticipantDetailforViewAward to once.
Disk is heavily in use.
Defragment all disks in the LOP production environment on a regular basis.
Currently CPU and RAM utilization are monitored in SCOM and not the Business Transactions.
It is recommended to use APM Tools for Business Transactions monitoring.
Currently only 1 Network card is available in the Production Servers.
Usage of 2 Network Cards
Currently Hard Disk utilization is not being monitored
To capture Avg Disk Queue Length
Currently method level reponse details are not moinitored.
To monitor LOP Application using APM Tool
Machine.Config
'Thread pool settings in Machine.config\nMaxconnection 12* #CPUs\nMaxioThreads 100\nMaxWorkerThreads 100\nMinFreeThreads 88 * #CPUs\nMinLocalRequestFreeThreads 76 * #CPUs'
Code Optimization
For LOP Website and Bank Bazzar App, it is recommended to use Oracle Connection object in single file only, i.e inside the OracleHelper.cs file only.\nFor SMS App it is recommended to use OracleHelper class, so that the connection object is used only in single class only.
Database Connection Not Closed
It is recommended to close the connection by use of [using  block] or in [finally method of the try, catch block].
In-line queries are used
It is recommended to use store procedures instead of in-line queries.
Return type as Dataset is used for maximum methods
It is recommended to use return type as DataTable instead of return type as DataSet, wherever possible.
CommandType.Text is used instead of CommandType.StoredProcedure
It is recommended to use CommandType.StoreProcdeure where the SP are used for database purposes.
Release web.config configuration
It is recommended to set compilation debug="false" in the web.config of production environment.
When throwing an exception, the throw satement is used with variable name.
It is recommended to use throw statement without specifying the original exception.
Un-used commented code found
It is recommended to remove un-used commented code.
Single Point of Failure
To avoid single point of failure, follow given below basic high level recommendations.\n1. All production servers should have at least 2 Network Interface Cards\n2. All Production servers should have same operating system version and build version.\n3. All production servers if virtualized then should be derived from different base server.
Documentation
All Use Cases with concurrent users and average response document should be prepared from application knowledge point of view.
Undersized Buffer Cache
Increase the size of buffer cache as it is showing undersize in AWR and in Buffer Pool Advisory\nIncrease the buffer cahche(Current 5G) to 10GB and also increase the SGA Max 14G and set SGA target 13G Current SGA is 7,472M
Query\n9f97fs7zt38vn
Use index hint CS_USER.IND_OFFER_MST_ACT_FG, there is index on\ncolumn ACTIVE_FG on table CS_LB_OFFER_MASTER
Query\n02kb5xfs00bmn
Create composite index on column CD_USER_CD and CD_REF_NO on\ntable LOP_CUST_DETAIL to avoid FTS
Bundling of Script Files not done
Grouping of multiple script files in one single bundle.
The image size are not compressed
It is recommeded to reduce the imge size.
The images are not embeded in Style Sheet.
'It is recommended to embed image files in the Style Sheet. Note : Apply only to images less than 30 kb in size'
Cache Expiration header is missing from the static file (images, Script, Style Sheets)
It is recommeded to add Cache expiration header to static files for enabling caching
Database Server Alerts not available
APM Tool should include alerts for Database servers
Bottleneck in Disk cannot be measured
The parameter 'Avg Disk Queue Length' should be monitored on all the servers
RAM Utilization on "Database Server 1 (10.50.90.54)" is maxing out
Upgrade the Server RAM
Query goin for FTS
Create index on \nColumn CBD_BATCH_ID\nAnd cbd_process_flag
Query goin for FTS
Create index on \nColumn cam_ins_date\ncam_inst_code\n&\ncam_agnt_idon \nTable cms_agent_hist\n& stats are old \nThis avoid FTS
Query consiming high CPU.
Number of execution are very high around 11700 and rows \nProcessed are zero with CPU utilization reaching 60%\nNeed to check with Oracle
Query goin for FTS
Create index on \nColumn CAP_INST_CODE,CAP_CUST_CODE,\nCAP_ACTIVE_DATE & CAP_ACCT_NO  on \nTable CMS_APPL_PAN\nThis avoid FTS also stats on table are very old \nSep 27, 2016 4:23:50 AM
Query goin for FTS
Create index on column CBD_BATCH_ID on table \nCMS_BATCHUPLD_DETL .\nOr\nTry using any hint for a composite index \nPCMSPRD.IDX_INST_BATCH.\nTry it in Uat .\nThis will avoid FTS and reduce the Phisical reads
Query goin for FTS
Create index on \nColumn CBD_BATCH_ID or use index\nHint in query to hit the indexes\nThis avoid FTS
Query goin for FTS
Old Stats Jul 10, 2016 6:24:58 AM\nCreate index on \nColumn CXL_RRN\nThis avoid FTS
Query goin for FTS
Create index on column CTL_INST_CODE on table \nCMS_TRAVLPURP_LMT_SUMMRY to avoid FTS on table.\nUse index hint PCMSPRD.IDX_CCM_ID_NUM1 on colum \nCCM_ID_NUMBER1 table CMS_CUST_MAST\n\nCreate composite index on column CTL_TRVLPURPOSE_CODE and \nCTL_INST_CODE to avoid FTS on table CMS_TRAVLPURP_LMT_DTLS
Disabling unwanted operating system services
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
Logging
It is recommended to use Log4j.debug for logging debug statements . These can then be turned off during production by keeping the logging levels as Warn/Error .
Streams not closed
It is recommended to close the Stream objects . It is also recommended to close all stream objects in finally block only
Logger Debug levels set to info
It is recommended to set the log level to debugging since this all information is used during debugging . Log level 'info' is used for highlighting the progress of the application .
Use of SystemProperties
It is not recommended to use System.get/set property for storing global variables. Instead one global class with static getters should be used by reading all properties at startup time.
Use of StringBuffer
Its recommended to use StringBuilder instead of StringBuffer after careful evaluation of multithreadedness of the piece of Code Recommendations.
Use of String and concatenations
It is recommended to use Stringbuilder instead of String class where there are lot of concatenations used . Stringbuffer can also be used in multithreaded environments
Consuming Exceptions
It is recommended to log / process an exception .
Coding Standards
It is recommended to derive bean class from serializable class
Generic Exception Catching
It is recommended to catch specific exceptions e.g. Catch (FileNotFoundException e), SQLException etc
String Literals
it is recommended to use String constants rather literals.
Use of third party jars
It is recocmmended to review this process time to time and after reading the release notes of latest version we should include latest jars into our library folder
Run Code with Findbugs
it is recommended to run findbugs with entire Codebase to address all unit level issues
String comparision with constants
it is recommeded to take string constants as string final string and check constant.compare(string)
Everytime new socket connection is used
It is recommended to use HashMap of Sockets and use them as and when required
Function Headers Missing
It is recommended to use javadoc specifications for function headers so that dynamically help can be built and used for reference purposes
Removal of unwanted setters and getters
it is recommended to check this carefully and provide only required getters/setters
Removal of commented Code Recommendations
It is recommended that commented Code Recommendations should not go into production Code Recommendationsbase.
Usage of checkstyle
It is recommended to prepare proper checkstyle for Code Recommendations formatting and use eclipse checkstyle feature for formatting the Code Recommendations
Code Commenting
It is recommended to put proper Code Recommendations comment so that any other developer can understand it
properties file variable naming conventions
it is recommended to use lower case in .properties file
Organize Imports
it is recommended to run organise import command in eclipse
Missing Junit Test Cases
it is recommended to write Junit test cases for each class for Unit Testing
Removal of main methods
it is recommended to remove all main methods and make another name method
Missing toString() method
It is recommended to override toString() method for pretty print of object for debugging point of view
Migration Code Recommendations to latest java version
It is recommended to use java 1.7 or 1.8 for better performance
Continuous Integration
It is recommended to use jenkins or any other open continuous tools for build, unit test and deployment purposes
Using single application configuration files
It is recommended to combine all properties configurations into one file and use it in entire application via one singleton application config class
Use of deprecated APIs
It is recommended to use latest provided API of given third party jars
Design
A POC needs to be carried out to on XML versus JSON messages to ascertain the overhead of XML over JSON.
Code Review
Redundant index songdetails_id needs to be dropped.
Code Review
Redundant index idx_user_song needs to be dropped.
Code Review
'"if" should be replaced by "else if" for $_GET[''category''] to optimize the code execution path.\nThe same is applicable for $_POST[''playlistid'']'
Code Review
A global file needs to be created which will be called from all php files.
Code Review
Duplicate check should be there in createplaylist.php file.
Code Review
t is recommended to add curl_close, this will close curl object and free up system resources.
Code Review
Use GraphicMagics for transoding server
Code Review
'Changes in the request made from the PHP-FPM server : Listen.backlog = 65535. This should be less than the maxsoconn value set at sysctl.conf file.'
Code Review
Changes in the sysctl.conf to make change in net.core.somaxconn value to 65536
Code Review
Changes in the sysctl.conf to make change in net.core.netdv_max_backlog value to 65536
Code Review
Remove duplicate songid from the where condition in the query
Code Review
Remove "use index (idx_comp_album)" and "use index (idx_comp_song)" from the query
Code Review
Index created on column userid
Code Review
Index created on column songid
Code Review
Index created on column songid
Code Review
Index created on column date
Code Review
Index created on column songid
Code Review
Composite index created on columns username and songid
Code Review
Change the API to GET requests, so that all the most accessed pages are served from the Nginx cache. For any like list demanded by the user, the redirected API can be called which can fetch the liked status from the DB.
Code Review
innodb_buffer_pool_size =20048M;\ninnodb_buffer_pool_instance=2;\ninnodb_log_file_size=256M;\ninnodb_log_buffer_size=16M;\ninnodb_flush_log_at_trx_commit=2;\ninnodb_thread_concurrency=800;\ninnodb_support_xa=0;\ninnodb_concurrency_ticket500;\ninnodb_commit_concurrency=0;\ninnodb_thread_sleep_delay=1;\ninnodb_adaptive_max_sleep_delay=100000
Code Review
40 Gbps network line will be required per server to cater to 1.2 lacs concurrent users.
Code Review
The spinning wheel movement should be reduced from 500 ms to 250 ms as all the pages on the backend are coming in less than 200 ms.
Code Review
Multi Threading replication process is supported in 5.7.3 and has been tested in Test server. Also, the updates happening on songdetails for counters of likes should be moved to cassandra. This will help in lesser incremental updates on Master DB, helping in lesser load at replication
Code Review
The Keep-alive-timeout parameter should be set as 15 for non streaming server and 30 for streaming server.
Code Review
Cluster of php-fpm needs to be created for scaling. 3 pools created. Refernces for the same is mapped in nginx.conf
Code Review
The communication (upstream/downstream) between Nginx and php-fpm should be socket based for higher scaling.
Code Review
This issue was happening because the persistent connections configured at the Client code, was receiving responses which was timing out. Thus, the persistent connection at the client code is done away with.
Code Review
'On Master DB :\nIn my.cnf : Change parameters\nmax_binlog_size =5M\ninnodb_flush_log_at_trx_commit=2\nOn Slave DB :\nsync_binlog =1\ninnodb_buffer_pool_load_at_startup=ON\ninnodb_buffer_pool_dump_at_shutdown=ON'
Code Review
Remove the for loop for userplaylist fetching and fetch image on a call of swipe.
Thread contention in ECS.DAL.Repository.WebPortal.WebPortalRepository.GetFamilyDetails
NoData
Queries with high response time.
Create non-clustered index on jobtype and status columns of BatchJobs tables.
Large volume of hits for static contents.
Enable browser side caching on application server. This will also result in bandwidth reduction for static contents on application server
Large number of 404 erros due to broken links
Fix 404 errors due to broken links using below steps.\n- Search all instances of url mentioned in excel in application code.\n- Provide correct path for the missing resource"
Thread contention in ECS.Common.Integration.Savvion.Service.SavvionWrapper.GetAssignedTaskListForPolicyEndorsementFlow
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
Thread contention in ECS.DAL.Repository.Status.StatusServiceRepository.GetCLClaimStatus
Following should be checked for GetCLClaimStatus or GetALClaimStatus.\n1. remove sub query if IVRSCode field is not needed.\n2. If IVRSCode is required then fetch its value using another linq query instaed of fetching this in select section of same query.
Use of EntityFunctions.TruncateTime function in table columns
Apply  EntityFunctions.TruncateTime function on compare variables instead of table columns.
Thread contention in System.Net.UnsafeNclNativeMethods
NoData
Thread contention in DynamicClass.BuildUp_ECS.BL.Communication.CommunicationBL
The constructor of CommunicationBL expects around 27 class objects and simply assigns them to local variables. The user functions in class hardly need more then one class objects.\nNo need to pass all 27 class instances to constructor as this makes CommunicationBL class heavy instead of this the functions should read class variables as parameter if needed or create them inside functions only when required.
Thread contention in DynamicClass.BuildUp_ECS.BL.Master.MasterBL
The constructor of MasterBL expects around 53 class objects and assigns them to local variables. The user functions in class hardly need more then on class objects.\nNo need to pass all 53 class instances to constructor as this makes MasterBL class heavy instead functions should read class variables as parameter if needed or create them inside functions only when required.
Thread contention in ECS.DAL.Repository.Claims.CLCaseDetailsRepository.GetCLDetails
Consider to modify query using joins instead of using includes.
Default session limit for WSHttp requests on HCF Services.
Increase connection limit from current 20 to 30 in <System.Net> and session limit from current default 10 to 30 using below settings in web.config of HCF services.\n<behaviors> \n  <serviceBehaviors> \n    <behavior name="defaultServiceBehavior"> \n      <serviceThrottling maxConcurrentCalls="30" \n           maxConcurrentInstances="30"  maxConcurrentSessions="30"/> \n    </behavior>\n  </serviceBehaviors>\n</behaviors>\n\nIf this works fine then attempt to gradually increase limit upto 100.
Thread contention in ECS.BL.SavvionReference.RGICL_HCS_WSService.assignOrKeepTask
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
Thread contention in ECS.DAL.Repository.Claims.CLDetailsRepository.GetCLDetailsQueue
NoData
High response time in login page
NoData
Caching for Master tables
Implement Database level caching using sql server notification by associating SQLDependency class with linq.
UnUsed indexes in database
Use below approach.\n1. For small tables Remove UnUsed indexes.\n2. For large tables optimize queries to utilize indexes or drop the indexes.
During the 24 hour analysis of Permon data for the EAI APP Servers (HYDEAIBTS02 and HYDEAIBTS03T1) the counter for Physical Disk (% Idle Time) is continously less than 20 %, which indicates that Physical Disk is heavily in use.
Use fast disk for BizTalk Database System
Disk is heavily in use.
Defragment all disks in the BizTalk Server environment on a regular basis.
It is observed heavy RAM utilization on the EAI App Server HYDEAIMOM01 and EAI DB Server HYDEAIC01.
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
Currently CPU and RAM utilization are monitored in SCOM and not the Business Transactions.
It is recommended to use APM Tools for Business Transactions monitoring.
Best Practices
Daily ensuring successful completion of SQL Agent Job - Purging and Archiving of Tracking Data.
Global configuration for using only Razor View Engine is not done.
It is recommended to add below 2 lines in global.asax.cs in method Application_Start(), as application uses only RazorViewEngine :\nViewEngines.Engines.Clear();\nViewEngines.Engines.Add(new RazorViewEngine());
The hyperlinks for Edit, Details, Delete in the Index pages of all the Views are not working.
NoData
Validation Missing
It is recommended to do null checking.
Method Header Comments Missing
Its recommended to give Header Comments above all the Methods.
Multiple classes found in a single cs file
It is recommended that one class should be present in a single file.
Method Header Comments Missing
Its recommended to give Header Comments above all the Methods.
Deprecated Features
Need to remove these deprecated parameters if they are in use in any module.
'Incident Dt : 20/11/2016 (19:30 to  20:15) : Transactions were getting declined with reason code 251 (Incorrect Authorization Request Cryptogram ) and 99 Authorization Message is expired'
Currently the zipping process are done by cron jobs between 7.30 pm to 8.15 pm.It is recommended to shift the timings for zipping process to late night time so that during peak hours (9 am to 9 pm) the system resources can fully be utilized for iCards Online4 transactions purposes only.
It is observed that in i-Cards Online4 DB Server 21 has around 130 active OS services. Also we have requested the OS services data for App Server 51, 63 .  We feel that 130 OS services count in the i-Cards Online4 Servers are on the higher side.
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
'Found  i-Cards Online4 alerts : Alert Dt : 2017-01-24 - ONLINE_Reports_21 USED_SIZE_PER - ActualValue: 90.0|| ThresholdValue: 80.0'
Regularly remove unwanted data, logs from i-Cards Online4 Production Servers. We recommend to use APM Tool Forensic Feature.
As per i-Cards Online4 Performance Report, the RAM on DB Server 21 is highly utilized.
'Current Hardware Up-gradation :  Purely based on RAM utilization, we need to increase the RAM for better performance. If it is not possible to increase the RAM then it is recommended to add one more DB Server.'
Currently Avg Disk Queue Length - parameter is not monitored in APM Tool.
To capture Avg Disk Queue Length (avgqu -sz in Linux ) , (% wait in Solaris) in monitoring software.
Best Practices
Keep firmware, Logical Domains Manager, Solaris and Linux up to date.
Workflow Delay
Avoid call to AcontStatus in Participant/ApprovedAwards if not needed.
Workflow Delay
Limit call for GetSubmenuOnPermission to once.
Response Time high
Avoid call to GetCommunicationSummary if not needed
Response Time high
Avoid call to GetCommunicationSummary if not needed
Response Time high
Avoid call to GetCommunicationSummary if not needed
Response Time high
Limit the call for GetCommunicationSummary to once.
Workflow Delay
'Avoid calling "Select * from #UserResultTable order by id"  in stored procedure GetEmails_UsersbyName if not needed'
Response Time high
Avoid using Begin Transaction for select statements.
Response Time high
Avoid using Begin Transaction for select statements.
Query Optimization
The constants and hardcoded strings should be explicitly defined in correct case instead of applying upper function on them.
Configuration
Allocate separate mount point for UNDO table space and create UNDO datafiles on those mount points.
Query Optimization
Create indexes on table MD_FX_RATE_REP for columns M_NUMERATOR, M_DENUMERAT
Query Optimization
Update query Q004 to Q0041 in  stored procedures PROC_TEMS1_DATAPROCESSING and PROC_TEMS1_DATAPROCESSING_OLD
Query Optimization
Update query Q005 to Q0051 in  stored procedure PROC_TEMS_FETCH_INTERFACE
Query Optimization
Update query Q006 to Q0061 in  stored procedure PROC_KPLUS_MUERX_EXP_TEMS and PROC_TEMS_MUREX_KPLUS_EXPO
Query Optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_ALL_CPTYLIMITSSUMMARY,TEMS_PROJ24DETAILS,TEMS_CPTYGRP,TEMS_PURPOSEWISE_SUMM,TEMS_REASONMASTER,TEMS_PENDING_CONF,TEMS_MANUALENTRY,TEMS_FAVOURITE_CPTYGRPID
Query Optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_TEMS1SETTL_UTILIZATION,TEMS_TEMS1SETTLE_UTIL_BUCKET,LIMITS_GLOBAL_TEMP_TEMS1
Query Optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_CPTYLIMITDEALWISE_HIST,TEMS_CPTYLIMITCANCHARGES_HIST,TEMS_TEMSTAB_NOTIONAL
Query Optimization
Update query Q009 to Q0091  in  stored procedure CRM_PROC_INTERFACE. Query doesn't use any base table
Query Optimization
Create indexes on table TEMS_PURPOSEWISE_SUMM_HIST  for columns REPORTDATE
Query Optimization
Create indexes for column CPTYGRP_ID in tables LIMITS_DAILY_PPDETAILS,LIMITS_EXPOIMPO_VALIDTY
404 Error
Create indexes for columns  CCY in table  NP_LEVEL_1_ASALIBG_EOD
404 Error
Create functional indexes for columns  NTID in table  NP_LEVEL_2_ASAL_PEAK
404 Error
Create functional indexes for columns  SDEALER and NTID in table  NP_LEVEL_3_ASAL_PEAK
404 Error
Create indexes for columns  SDEALER in table  tableNP_PPR_LEVEL_1234
404 Error
Create functional indexes for columns  SDEALER and NTID in table  table NP_LEVEL_2_ASAL_EOD_DOM
Query Optimization
Call Get_CRM_Country only once and assign values to both variables. I don't see any need of defining two variables here.  With this I am able to save 15 seconds on development server itself. On production saving will be of sevaral minutes.
Query Optimization
Replace delete commands with truncate commands in stored procedure CRM_EXPO_IMPORT_PROC_3. Also put commit after every insert. In development server I was able to about 2 minutes. In production it could be around 18 minutes about 75%.
Query Optimization
Replace delete commands with truncate commands in stored procedure PROC_NOOP_FILLSNAP
Query Optimization
Remove call to stored procedure PROC_NOOP_FILLSNAP from stored procedure proc_refresh_newpos
Query Optimization
Use truncate command instead of delete whereever whole data is deleted from the tables.
Query Optimization
Remove all trim functions and update referred table columns with trim  functions at beginning of stored procedure.
Query Optimization
Create functional index for column ntid in table np_level_1_asal_peak
Query Optimization
Create functional index for column Trim(CurrencyPairRic) in table RTS_GetMaturityRics
Query Optimization
Remove trunc function on Addedon field of RTS_MaturityMatrix table in all where clauses.
Query Optimization
Either use trim function in all comparisons or avoid using trim function and create normal index for fwhl_riccode to improve the performance. While inserting TRIM function is not used in select query and also during delete many places trim function is used for comparing column fwhl_riccode and many places not.
Query Optimization
Create index for FK_UM_UserID in table rts_User_GroupMapping2
Query Optimization
Create index for UM_LoginID in table RTS_UserMaster
Query Optimization
Create index for ApprovalId in table FX_BreachedDealsApproval
Query Optimization
Create index for DEALNO in table RTS_BREACHDEALS
Query Optimization
Create index for DEALNO in table RTS_MARGINBREACHDEALS
Query Optimization
Create index for IsActive in table RTS_BREACHDEALS
Query Optimization
Create functional index TRIM(UPPER(portfolio)) for table RTS_BREACHDEALS
Query Optimization
Avoid settings for temp tables where records gets deleted on any commit. This will allow to use truncate command freely where all records from tables needs to be deleted.
String is used many classes with the usage of '+' operator
It is recommended to use Stringbuilder instead of String class where there are lot of concatenations used . Stringbuffer can also be used in multithreaded environments
It is observed that exceptions are consumed by having empty catch blocks
It is recommended to log / process an exception .
so many warning are shown and unwanted variables functions are available in Code
it is recommended to run findbugs with entire Code Recommendationsbase to address all unit level issues
various properties files are used
It is recommended to combine all properties configurations into one file and use it in entire application via one singleton application config class
blocking socket APIs are used which required separate thread for handling different clients
It is recommended to use Netty framework for Asynchronous client handling
unwanted import packages are seen in so many files
it is recommended to run organise import command in eclipse
java 1.6 is used
It is recommended to use java 1.7 or 1.8 for better performance
all jsp HTML and Java is written.
It is recommended to separate Java Code Recommendations in Java Bean so that it can be used by other jsp also and also for easy Code Recommendations maintainability
High Io
POC to be created for evaluating frameworks with high IO capabilities like Netty. This will be essential if the Performance validation runs on the current architecture. Will need EAI to support NIO.
Design
The entire re-design of the Code Recommendations should be carried out to make Code Recommendations more readable and maintainable. To start with Code Recommendations package and class structures can be re-designed so that duplicate/redundant Code Recommendations can be eliminated.  Following are the top areas to focus:\n1. Packages re-naming.\n2. Proper Code Recommendations commenting at various decision points required in entire Code Recommendations base for maintainability point of view\n3. Usage of checkstyle for Code Recommendations formatting for better understanding\n4. Removal of redundant Code Recommendations\n5. Removal of redundant third party jar files\n6. Usage of latest third party jars \n7.Addition of JavaDoc comments in entire Code Recommendations base so that proper documentation can be created for newcomers in the system and it is required for better understanding and maintainability
no SOA Architecture is used
"The back end services can choke this application if they don\u2019t perform,\ \ to avoid this issue we are proposing to create micro services for the back-end\ \ system to scale on-demand and improve resiliency. \\nSecondly, can CAR can remove\ \ certain functionality in case some backend services are not performing well or\ \ unavailable rather than choking the entire system."
Custom approach is used for sftping the files
Custom file uploading to sftp is written which can be standardized by using JSCH open source framework (http://www.jcraft.com/jsch/)
xslt+xml are used for making reports
We are proposing to use Jasper Framework for generating MIS Reports (https://sourceforge.net/projects/jasperreports/?source=typ_redirect)
no automatic building tool is used
It is recommended to use Maven or Ant build tool for automatic building and running the test cases.
unwanted services are running in production servers
It is observed that unwanted services are running in production servers which should be stopped immediately and proper documentation should be maintained of required services for running the CAR application.\n\nAll Required Services should be checked in UAT Environment and accordingly enabling the these services in Production Environment and proper document should be prepared for this.\n\nAlert should be created in Appnomix for required services so that if anyone enable any unwanted service then support team should get an alert.
documents are not updated as per current infrastructure
We propose to regularly update all documents whenever new hardware or software is added to the application.
Network parameters are not captured of CAR application
'To capture Network Related Parameters :  It will help in the analysis of network utilization.\nWe recommend to use Riverbed tool for Network monitoring which currently available in ICICI.'
35 Server required more RAM for processing 2X Load as per analysing current baselining
It is recommended to increase RAM in 35 Server
NoData
Create index and test on column CC_STATUS need for table CARTBL_CUSTOMERS\nCreate composite  Index on with all three colum CC_NET_USER_ID, \nCC_STATUS and CC_FSID for table CARTBL_ACCESS_DETAILS \nVery old statistics on the tables and indexes
NoData
create index on columnn \nCFL_REG_STAT on table CARTBL_FEDID_LOOKUP
Design
POC to be created for evaluating frameworks with high IO capabilities like Netty. This will be essential if the Performance validation runs on the current architecture. Will need EAI to support NIO.
Design
Application static images and JS/ CSS files will be cached at web server.
Design
Following are the top areas to focus for code re-structuring.\n1. Packages re-naming.\n2. Proper code commenting at various decision points required in entire code base for maintainability point of view\n3. Usage of check-style for code formatting for better understanding\n4. Removal of redundant code\n5. Removal of redundant third party jar files\n6. Usage of latest third party jars \n7.Addition of JavaDoc comments in entire code base so that proper documentation can be created for newcomers in the system and it is required for better understanding and maintainability\n8. JUnit Test cases of each class should be prepared for unit level testing\n9. Profiler reports should be prepared after running each use case in UAT environment for finding slow methods\n10. FindBugs should be used for unit level coding issues findings.
Design
Axis 1.4 is an old framework for web services and now a days a lot of new web services framework are available which are much faster then Axis so we recommend to use Apache CXF or Spring WS Web services framework instead of using Axis because spring framework is already used in existing codebase.
Coding Guidelines
Non Function Document (NFR) should be prepared for application\nbenchmarking for future performance testing. Template shared with pocket team for the same.
Load Testing
It is recommended to do load testing of Pocket application using HP Load Runner for better performance and high load testing and also capturing the benchmarking of application.
Performance Tuning of the system
It is recommended to do a performance tuning exercise for the system.
Hardware CPU Upgradation
It is recommended to upgrade these servers.
Hardware Disk Upgradation
It is recommended to increase the Disk capacity on Production servers.
Currently Network Related Parameters are not being monitored.
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
Currently Hard Disk utilization is not being monitored
To capture Avg Disk Queue Length
It is observed that unwanted operating system services are enabled.
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
Update JVM Heap Memory Settings
It is recommended to keep the same settings for JVM Heap Memory for parameters Xmx and Xms.
Currently unwanted data/logs sizes are not removed automatically.
Usage of APM Tool Forensic Feature
Currently only 1 Network card is available in the Production Servers.
Usage of 2 Network Cards
Currently Base Server is not different for all the Pockets Prooduction Servers.
It is recommended that all Pockets Production servers if virtualized, should use different Base Server to avoid Single Point of Failure.
Currently the application inactive sessions are not monitored in APM Tool.
It is recommended to add alerts in APM tool for monitoring inactive sessions.
High Elapsed time(s)  1.81/FTS
Create composite index on column CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID and funtional index CUSTOMER_TRANDATE \nor second option is remove to_date funtion from column CUSTOMER_TRANDATE and put it on right side of value and create once composite index CUSTOMER_TRANDATE,CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID before implementing on prod test on UAT
High Elapsed time(s)  1.09/FTS
Create index on column SECRET_TOKEN there is composite index on it in order to avoid the   Full table scan  and reduce the cost of the query. Table is ICICI_DIGIBANK_REGISTRATION  There is already an index on the user_id  column and the function in the where clause we should create a functional index on the column in order to avoid the   Full table scan  and reduce the cost of the query.
High Elapsed time(s)  1.64/FTS
Create composite index on CUSTID,REQCODE,RESPCODE and functional index on CAPTUREDATE or Remove to char funtion from column CAPTUREDATE and create one composite index on  CUSTID,REQCODE,RESPCODE ,CAPTUREDATE
High Physical reads due to FTS
Create composite index on column CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID and funtional index CUSTOMER_TRANDATE \nor second option is remove to_date funtion from column CUSTOMER_TRANDATE and put it on right side of value and create once composite index CUSTOMER_TRANDATE,CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID before implementing on prod test on UAT.
High Physical reads sue to FTS
Create composite index on column CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID and funtional index CUSTOMER_TRANDATE \nor second option is remove to_date funtion from column CUSTOMER_TRANDATE and put it on right side of value and create once composite index CUSTOMER_TRANDATE,CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID before implementing on prod test on UAT
High Physical reads sue to FTS
Create composite index on table icici_digibank_sa_towallet_log column custid and reqcode
High Elapsed time(s) due to FTS
create index on column SECRET_TOKEN
High Elapsed time(s) due to FTS
Create composite index on MOBILE_NUM and SECRET_TOKEN on table ICICI_DIGIBANK_REGISTRATION
High Elapsed time(s) due to FTS
Create composite Index on Respcode  and Reqcode .We have already suggested creation of functional index on column CAPTUREDATE for sql_id 166p7jnmtv120
High Elapsed time(s) due to FTS
Plan need to be check was not available on OEM
High Elapsed time(s) due to FTS
Plan need to be check was not available on OEM
High Elapsed CPU and resource consumption
Check if the execution can be reduced from application team .
High Elapsed CPU and resource consumption
Check if the execution can be reduced from application team .
High Elapsed CPU and resource consumption
Check if the execution can be reduced from application team .
Cuurently there are no alerts provided for monitoring the user wise transactions consumption limit.
It is recommended to add alert in APM Tool for notifying expiration dates for user wise transactions consumption limit.
As per Pockets PPT Report in slide no 44, the RCA for incident dated 15/07/2016 was not available as the changes done at vendor end was not documented.
It is resolutions should be properly documented.
As per Pockets PPT Report in slide no 45, for the incident dated 21-10-2016, the JVM parameters were directly updated on Production environment without testing in the UAT environment.
It is recommended to test all JVM parameters in UAT environment and then accordingly make changes in the Production environments.
As per Pockets PPT Report in slide no 47, for the incident dated 22-12-2016 the planned DR activity was not communicated with the respective team involved, so the issue occurred.
It is recommended to inform all the respective teams before performing planned DR activity.
As per Pockets PPT Report in slide no 47, for the incident dated 23-12-2016 the issue occurred as the parameters configuration for NPCI was done beyond the permissible limit.
It is recommended to do properly documentation for all the parameters from NPCI and accordingly test in UAT environment and then in Production environment.
Currently there is no Load Balancer in the UBPS System.
Usage of Load Balancer
Currently Message Queuing System is not in used in UBPS System.
Usage of Message Queuing System - We are proposing IBM WebSphere Message Queuing to avoid port to port manual connections in UBPS. Extended Architecture can also be used where two phase commit is used and MQ and Database is involved. (In Extended Archictecture message is deleted from MQ when it is persist in Database so there is no need of recovery if EA is used, it is widely used in Real Time Systems in large banks). We can either use Load Balancer or MQ but anyone is required to avoid manual interventions and also for high availablility of system.
Currently found that Disk IO Read Activity Tasks is going on in day time during peak hours (10 am to 3 pm) for UBPS App Servers 213, 214,215,216,218, 222 and 223.
Timings for Disk IO Read Activity Tasks in UBPS App Servers -  Found no relation between current UBPS transactions and Disk IO Read Activity Tasks. So it is recommended to shift the Disk IO Read Activity Tasks from day time to night time.
'Found below UBPS App Servers alerts : Alert 1 -  (UBPS 215 used_size_per - Actual Value 81, Threshold value 80). Alert 2 - (UBPS 213 used_size_per - Actual Value 81, Threshold value 80). Alert 3 - (UBPS 216 used_size_per - Actual Value 81, Threshold value 80).'
Regularly remove unwanted data, logs from UBPS App Servers. We recommend to use APM Tool Forensic Feature.
Currently Avg Disk Queue Length - parameter is not monitored in APM Tool.
To capture Avg Disk Queue Length (% wait in Solaris) in monitoring software.
Currently Produciton Servers are not using different Base Servers.
Usage of different Base Server - All UBPS Production Servers if virtualized, it should use different Base Server to avoid Single Point of Failure.
Best Practices
Keep firmware, Logical Domains Manager and Solaris up to date.
Query 4mxkkxfd5cvjb
Gather the fresh stats on the table
High executions of below queries\nDate 9th December 2016\n\nA>3fxatuj5jdhzu \nB>fb4hvrd9g44sa\nC>1bhkm76p82uzd\nD>2gzfkfv52rry0\nE>g9t2tuana15nn
Performnace Improvement
High CPU Utilization
Core dump on LISVR to be analyzed.
Performance
Message broker needs to be tuned for the required load. SoftwareAG to change the configuration as per the load.
Query Optimization
Q005 - This query is going for an FTS even though the Indexes are present on the search condition. Thiscontains an implicit data type conversion on\n  indexed column "USER_ID". This implicit data type conversion prevents the\n  optimizer from selecting indices on table "SSOADM"."SSO_RESOURCE_ACCESS_TBL".
Query Optimization
Drop the index if it is not required
NoData
If the changes in properties files are not expected to change very often then it is not necessary to load the file every time. The same ResourceBundle can be used across requests. It can be controlled through a Singleton
Query Optimization
The package needs to be tuned by Infosys. Any optimization in the package will reduce the time spent on the DB. \nProcedure - MIGADM.SP_ADDRESS_MIG_CHECK \nPACKAGE - MIGADM.PREVALIDATION_CATEGORY.SEARCHCATEGORY#2
Query Optimization
Removal of un-wanted logging. Currently all incomming messages, messages processed at ESB and response messages from Finacle and converted messages are stored in database. Recommended softwareag to remove all these unnecessary loggings and to keep the messages stored only in case there are any failures or timeouts.
Configuration
NoData
Query Optimization
Concurrency in accessing the accounts could cause a lock on the account. The debit accounts for the failed transactions should be looked at, and if it is hitting the same account, the number of accounts should be increased.
Query Optimization
1. Reduce the no. of concurrent users from a single zone.\n2. Multiple zone codes, sol id combination for the same.\n3. Alternatively, the product vendor can look at the possibility of having a NOWAIT after update.
Query Optimization
Correct mapping of Schme Code and GL Sub Head Combination needs to be done. Infosys has to fix the issue of FIN_LISTVAL getting killed.
Configuration
Napi error - W0205 encountered. The test is executed sucessfully if it is run for a single user, but fails during load(concurrency). Infosys needs to investigate from code, the reason for the exception encountered.
Query Optimization
1. Max value for this sequence can be set to higher in order to avoid such issues in future.\n        2. This also could be handled during EOD run (Finacle to confirm on this) in this case the data to be flushed out in the relevant table and reset the next value to 1.
Configuration
1. NOSTRO/USD combination is notmaintained in SRGPM parameters because of which there are NAPI errors.\n2. General exception error are happening because of concurrency of data selection for the query mentioned. Need to have more data sets so that concurrency is avoided(the data accessed is shared with Priyadarshi), or Infosys can provide an alternative solution.
Query Optimization
"There are queries which are running on CNMA, not utilizing the index. Create\ \ index CRMUSER.IDX_ADDRESS_TEST on CRMUSER.ADDRESS(\u201CBANK_ID\u201D,\u201DORGKEY\u201D\ ,\u201DADDRESSCATEGORY\u201D)\\nAlso analyse the table after creating the index."
Query Optimization
Changes in the query to not include predicate in the query, as this will not use the index on addr_id.The procedure needs to be reviewed  to fix all such cases where wrong predicate is used.
Configuration
Need to check with application logic behind running such queries concurrently. Also nowait can be appended to 'select for update' query to reduce row lock contention.
Query Optimization
a.            Increase freelists  of table & its indexes to 5 (no can be increased if event occurs again).  (using multiple free lists may cause some empty blocks to go unused, causing the segment to extend. Multiple free lists can be used to improve concurrent access, possibly at the expense of additional space used.)\n\nb.            Table & corresponding indexes can be moved to larger block size tablespace of 16K. The inserts would become faster.
Configuration
The root cause of the performance issue is that there are lot of transaction on the frozen accounts which are going into entered state. Infosys will internally explore this further. If the transactions are posted for these frozen accounts without the need of proxy posting, there is a huge time and effort saved on this batch program which will lead to reduction of total TAT of the EOD process.
NoData
1)Create index on column CTA_FCRM_SR_NO on table CARTBL_TEMP_ACCOUNTS\n2) Create Index on CFPC_STATUS on table CARTBL_FILE_PRCS_CTRL\n3)Create index on CFCL_FILE_NAME on table CARTBL_FCRM_LINKING_LOG.\n4) Stats on the tables are old
Response Time high
Compress the javascripts and deploy only the compressed copy of javasctipt to the application server. Keep a copy of uncompressed source for any changes or CRs in future in Source control.
Workflow Delay
Change in design, if wait/notify can be used instead.
Workflow Delay
Provide index hint IDX_ACCTMAST_ACCTNUMBER for this query so that the database optimizer would pickup the index mentioned and would reduce the query execution time.\nAdd javascript validation to accept minimum of four to five characters from front end for performing this operation.
Response Time high
The application Design has to be changed to handle the report generation process to use minimal memory resources. \nFew recommendations are \n1. Persist the report on the disk and flush the report in chunks to disk in predefined size and append. Later provide the report to the user as a downloadable option.\n2. Perform the excel report generation in batches and append the report. This would reduce the memory foot print of reportgeneration process.
Response Time high
Remove all the debug insert into table C statements from the code base.
Workflow Delay
Disable the button at front end once the user clicks the button.
Response Time high
The hard coded values to be changed to bind variables
Response Time high
When only one row is expected as output , the orw num condition needs to be removed and any exception cases should be handled through exception handling
Workflow Delay
Insertion to these temporary debug tables to be removed or to be done using bind variables
Workflow Delay
All resources should be closed in finally block only.
Workflow Delay
All sockets should be closed in finally block only.
Workflow Delay
Use below notation:\nvar myArray = [];
Response Time high
Sessions responsible for high temp usage were identified, which were not running from application.
Workflow Delay
Need to pass bind variables in where clause instead of literals
Workflow Delay
Change the initrans of table to 10 and its indexes to 20
Response Time high
Need to pass bind variables in where clause instead of literals
Response Time high
Disable disk I/O pacing for redo log mount points. Currently redo logs are distributed over /FCRM101 & /fcrmdata01 mount points but /fcrmdata01 mount  point also contains datafiles, So we can disable I/O pacing for /FCRM101 mount point only & check the improvements. For better performance we   recommended to have redo logs & controlfiles on seperate mount points with disabled I/O pacing for them.
Workflow Delay
Cache for below sequences has been set to 3000\n1. ACTIVITYID \n2. AUDITID\n3. INTXNID\n4. INCIDENTID\n5. FORMOPTIONSINFOID
Response Time high
Below are the details of index creation \n1. BIZCENTERGROUP - IDX_GIDBIDISA\n2. INCIDENTS - IDX_LIDBIDGID\n3. OBJECT_CONFIG_DETAILS - IDX_OCD_ATTRNAME\n4. STEPMASTER -  IDX_STPMASTER_ID_SNO \n5. TEMPLATEINFO - IDX_TINFO_FUD\n6. INCIDENTS - IX_INCIDENTS_SERVICEREQTYPE\n7. INCIDENTS - IX_STOPPRBNKID
NoData
It is recommended to change the logging levels in production to Error and move all debug statements to logger.debug statements.
NoData
It is recommended to use StringBuilder in case multithreading is not required for the objects.
NoData
getAgeCountMI() needs to be verified and see what  PRC_INS_AGE_COUNT is doing.
NoData
Conditions need to be changed so that it does not need to go through multiple for loops for fetching the same result.
NoData
Data can be fetched once and stored in parameters and the same parameter values can be used in update statements instead of calculation separately each time.\n\nFor updates on similar filter critera, all sqls can be merged to one and all fields can be updated in one pass.\n\nSimilar for other updated statements as well
NoData
Recommended to create composite index on table T_SBI_MEMBER_DTLS_LOG with columns enddo_id and backup_flag. GENERALSYSTEM.T_SBI_MEMBER_DTLS_LOG ("ENDO_ID","BACKUP_FLAG")
NoData
Recommended to create composite index on table T_SBI_TRAVELLER_DTLS_LOG with columns enddo_id and backup_flag. GENERALSYSTEM.T_SBI_TRAVELLER_DTLS_LOG ("ENDO_ID","BACKUP_FLAG")
NoData
It is recommended to add parameters in a SQL query via pstmt.set("") methods for correct datatype and the datatype conversion at runtime will not be happened.
NoData
Recommended to use PreparedStatement.\nPrepared statements are much faster than Statement.
NoData
Recommended to use Batch Insert/ Batch Update of PreparedStatement for better performance.\nRecommended to use executeBatch() instead of executeUpdate().\nPerformance issue if you are try to insert many records, let say 1000 records, because every executeUpdate() will hit database once. For batch update process, it hits database when executeBatch() is called.
NoData
'Recommended not to use HashtableCacheProvider in production. As it does not release objects at all. Not even after a while. \nThis can be considered as a memory leak,\nsource of OutOfMemoryError,\nout of date : caches not aware of changes made to the persistent store by another application. Instead use EHCache.'
NoData
Recommended to use select NVL(MAX(A.PROCESS_ID),0) into V_MAX_PROCESS_ID instead of cursor.
NoData
It is recommended to remove the cursor C1,C2,C3 and use SELECT INTO to hold the vaules. First loop will be able to combine 4 SELECT statements into single SELECT statement and 2nd loop will be able to combine 3 SELECT statements into single SELECT statement for the  UPDATE.
Improper use of String.equals("") method.
Substitute calls to String.equals("") with calls to isEmpty(). String.equalsIgnoreCase("") is actually a bit slower than just an isEmpty() call.
Older android api framework version 2.2- API level 8
We need to upgrade the current api to the minimum supported and acceptable android api version. This is also needed to implement recommendations 7 and 8.
Multiple calls for demo.xml in the load event of RelianceChildPlan.htm
Ensure that request for demo.xml is sent once.
Multiple calls for demo.xml in the load event of RelianceLifeInsuranceGuarantedMoneyBackPlan.htm
Ensure that request for demo.xml is sent once.
Normal asmx web service file upload
Create a separate WCF svc service using wshttp binding and MTOM encoding for document upload and host it on a separate virtual directory running on separate worker process.
Continuous logging and debugging
Set configuration for mode of logging and perform logging based on configured logging mode.
Caching at the android client
Set following seeting on each instance of webview control and test entire application on UAT.\nwebSettings.setAppCacheEnabled(true)\nwebSettings.setAppCacheMaxSize(4*1024*1024)\nwebSettings.setCacheMode(WebSettings.LOAD_CACHE_ELSE_NETWORK) \nwebSettings.setAppCachePath(path to the application cache files)
Very high fragmentation on databases
ReOrganize all indexes where Percent_Fragmentation is high.
Use of String and concatenations
It is recommended to use Stringbuilder instead of String class where there are lot of concatentations used . Stringbuffer can also be used in multithreaded environments
Unnecessary request for rupee_foradian.ttf file in RelianceImmediateAnnuity.htm
Avoid request for rupee_foradian.ttf file if not needed
Repeated request for multiple static files during loading of RelianceLifeInsuranceSuperEndowmentPlan.htm
Repeated requests should be avoided for the static contents
Multiple requests for source xml data file in RelianceLifeInsuranceSmartPensionPlan_Single.htm
Avoid multiple calls to same source xml in same event.
Same hardcoded dynamic file name "c:\txt_fl" across functions in CommonFunction.cs
Use unique file names for the file to avoid conflict such as file name ending with session id or GUID. Create file in some temporary folder within virtual directory so that Network Service has access to it without any special privilege.
Streams not closed inside finally
It is recommended to add finally block in source file and close all important resources inside it. Finally block will guarantee to close all resources if any exceptions thrown
Unnecessary request for rupee_foradian font file in IncomeAdvantageSolution.htm
Avoid request for rupee_foradian font files if not needed
Multiple requests for source xml data file in RelianceLifeInsuranceSuperMoneyBackPlan.htm
Avoid multiple calls to same source xml in same event.
Unnecessary request for rupee_foradian font file in RelianceLifeInsuranceSuperMoneyBackPlan.htm
Avoid request for rupee_foradian font files if not needed
Multiple requests for demo.xml data file in the load event of RelianceLifeInsuranceSmartCashPlusPlan.htm
Multiple requests of demo.xml should be avoided in the same event.
Multiple requests for source xml data file in ULIP.htm
Avoid multiple calls to same source xml in same event.
Unsafe string concatenation for creating sql queries.
Recommend to pass values using sql parameters instead constructing query with string concatenation.
High table scan on table Input _Attributes in MobileBI database
Create non clustered index on table Input _Attributes for columns PlanNo, Sequence, AttributeName and Type.
White Flicker while navigation of screens on android client
Recommended to set the background color of webview control to transparent to avoid any flickering effect during navigation.
Repeated request for multiple static files during loading of fixedsavings1.htm
Repeated requests should be avoided for the static contents
Multiple requests for demo.xml data file in the load event of SecuredRetirementSolution.htm
Multiple requests of demo.xml should be avoided in the same event.
Multiple requests for source xml data file in SecuredRetirementSolution.htm
Avoid multiple calls to same source xml in same event.
Repeated request for multiple static files during loading of SecuredRetirementSolution.htm
Repeated requests should be avoided for the static contents
Unnecessary request for rupee_foradian font file in RelianceLifeInsurancePayFivePlan.htm
Avoid request for rupee_foradian font files if not needed
Wrong coding practices
Fix following throuout the android client code.\n- Avoid empty if statements\n- Avoid empty catch/finally blocks\n- Avoid printStackTrace(); \n- Avoid the use of unnecessary return statements\n- Avoid the use of unused import statements to prevent unwanted dependencies.
Unnecessary code  initializing @str variable and print command in stored procedure get_Cashflow_NewPlans
Avoid initializing variable @str and print command in stored procedures if not needed.
Thread contention in ECS.Common.Integration.Savvion.Service.SavvionWrapper.GetAssignedTaskListForPolicyEndorsementFlow
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
Use of EntityFunctions.TruncateTime function in table columns
Apply  EntityFunctions.TruncateTime function on compare variables instead of table columns.
'sql_id   : fq6xm94bbat78'
The query  is  executed in the production database ,this can be fetched\n from the  fall back if presents
'sql_id: au4gfnrk20p8t'
Need to understand the logic of the packages
'sql_id: 39q34gvpy14w6'
Very old statistics on the tables and indexes
sql_id :ft65jxtafjcaq
Will use of already existing function index index Avoid the FTS
sql_id :acd5pdv7ystam
Need to fix the plans for the query as there are two plan check the appendix
'sql_id : 3abfvwa95p3yb'
Check the execution of the query as there are zero rows processed\n even after 200,000 executions
'sql_id : au4gfnrk20p8t'
The execution of the pakages ( begin exp_fileupd.FileUpdate; end;)
'It is observed that everytime in data fetch calls new socket connection is made.\nExample: XMLSender.java,CustSeg.java,DCMSCardBlock.java and many more'
It is recommended to use HashMap of Sockets and use them as and when required
'It is observed that heavy used of custom buffers used seperated by ''|'' seperator.\nExample: QuickKills.java, AuthenticationMBean.java and many more'
It is recommended instead of custom buffer use xml or json for faster parsing using standard frameworks like jaxb and json library
It is observed that repetitive Code Recommendations is used in entire Code Recommendationsbase, almost in all xxx_main type of functions same type of Code Recommendations is used
It is recommended to put repetitive Code Recommendations into Utility class as static functions
It is observed that old versions of jars are used in various third party tools
It is recocmmended to review this process time to time and after reading the release notes of latest version we should include latest jars into our library folder
It is observed that so many warning are shown and unwanted variables functions are available in Code Recommendations
it is recommended to run findbugs with entire Code Recommendationsbase to address all unit level issues
'It is observed that error Code Recommendationss which are used in Code Recommendations are hard Code Recommendationsd.\nExample: DebitCardAccountMBean.java'
it is recommended to use enumerator of error Code Recommendationss so that it can be addressed via using switch instead of if
It is observed that Utility class is created for closing various types of streams but it is not used in Code Recommendations
it is recommeneded to use these functions in finally block respectively
It is observed that with each request new db connection is created
It is recommeneded to use db pool for better performance
It is observed that no continuous integration used
It is recommended to use jenkins or any other open continuous tools for build, unit test and deployment purposes
It is observed that various properties files are used
It is recommended to combine all properties configurations into one file and use it in entire application via one singleton application config class
It is observed that no MVC framework is used in Code Recommendations
It is recommended to use MVC Pattern in web application for better categorisation of Code Recommendations and for better maintanability
It is observed that depericated API are still in use
It is recommended to use latest provided API of given third party jars
It is observed that so many Code Recommendations is commented
It is recommended that commented Code Recommendations should not go into production Code Recommendationsbase.
It is observed that java 1.6 is used
It is recommended to use java 1.7 or 1.8 for better performance
Since most of the interactions with source systems is happening via EAI and other systems, the EAI/other systems can be reconfigured to provide server sockets as non-blocking IOs (Java NIO or Netty etc)
POC to be created for evaluating frameworks with high IO capabilities like Netty. This will be essential if the Performance validation runs on the current architecture. Will need EAI to support NIO.
Proper hearbeat mechanism should be used either ping or hb
Heart beat mechanism used for Weblogic cluster and Loadbalancer needs to be reviewed to ensure that it meets the performance and availability related NFRs.
It is observed that SOA approach is not used for fetching data from backend.
The back end services can choke this application if they dont perform, to avoid this issue we are proposing to create microservices for the back-end system to scale on-demand and improve resiliency.\n\nSecondly, can IView remove certain functionality in case some backend services are not performing well or unavailable rather than choking the entire system.
'SQL_id:: 0bxpmgmr3w5c6'
There is already an index on the user_id  column and the function in\n the where clause we should create a functional index on the column in order to avoid the  \nFull table scan  and reduce the cost of the query.
It is observed that on App Server 45 - 110 OS services are active, on App Server 46 there are 110 OS services are active and on DB Server 102 there are 25 OS services are active.
Its recommended to enable only required OS services by cross checking in UAT environment. We also recommend to create alert in APM Tool for fixed number of services monitoring.
Currently APM Tool Forensic Feature is not in used.
Usage of APM Tool Forensic Feature
Oracle database connection pooling
set following keys in oracle connectionstring\nConnection Lifetime 0\nEnlist 'true'\nMax Pool Size 100\nMin Pool Size 0\nPooling 'true'
Un-used coding found
It is recommended to remove un-used code.
Parameter index is wrongly assigned
It is recommended to give index 3 in the variable arrParameter.
Found hard coded values in some files
It is recommended that wherever possible to set hard coded values in the config files and then read the data from config files wherever needed.
Unit Tests Projects not present in the solution
It is recommended to add Unit Test Projects which should have unit tests for all important class files and use cases.
string variables are checked for null values only
It is recommended to use string.IsNullOrEmpty(string variable name) rather than (sring varaible != null)
While getting the values from Session and  ViewState variables,  Session["variablename"].ToString()  and  ViewState["variablename"].ToString() is used
It is recommended to use Convert.ToString(Session["variablename"]) instead of .ToString()  and  Convert.ToString(ViewState["variablename"]) instead of .ToString()
Method header comments are missing
It is recommended to use Method header comments.
Un-used class using statements found
It is recommended to remove un-used using statements
The class methods with more than 5 input parameters are not using seperate class file as input parameter
The class methods with more than 5 input parameters should use seperate class file as input parameter
There is no DR and Fallback Servers available in LOP Application
It is recommended to setup separate Disaster Recovery and Fallback Systems for LOP for availability and scalability point of view.
LOP Application is using .Net 4.0 version which is a old version and does not have new features which are available in newer versions of .Net.
It is recommended to migrate LOP Application code to latest .Net Version 4.5 for better performance improvements.
Logging
For audit trail, the asynchronous logging needs to be looked at rather than current blocking based logging. Log4Net can be used for this purpose. By default Log4net is synchronous but by overriding its appender interface asynchronous logging feature can be achieved.
Query Optimization
Infosys to investigate the issue
Configuration
Identify connection leak from livsvr processes , since DB has defined parameter to 2000, which worked fine in earlier tests with 10K users
NoData
The SAF Replay needs to be reconfigured to use parallelization even with hash number configuration.
Design
Same java script files are referenced multiple times in the same jsp files.\nMod_exprires needs to be enabled on I H S servers and a far longer expiry time needs to specified for static files.
It was observed that a very high number of threads were configured for WAS container. General\nguidelines by IBM to set this number to number of CPU * 5 . Using this math the number of WAS\ncontainer threads configured is very high . We also observed from the thread dump / AIX commands\nthat at any given time close to 90% WAS threads are idle
Number of threads configured for WAS container should be reduced . This will help WAS manage\nincoming requests in lesser of threads\nAs a starting point max number of WAS container threads were reduced from 200 to 100 .\nPost this change it was observed that even with lesser threads the response time was unchanged and\nWAS was managing incoming requests in roughly half the number of threads .
Logic uses heavy RegEx processing and is matching based on expression without using Pattern compile. This is inefficient as it will incur compilation cost each time it does parsing.\nExample, HLIFE-WORKSPACE\hlife-mod-otc\src\com\hlife\otc\biz\OTCValidateFileBizprocessor.java method "getRequestObject". \nRegEx is used in many other places in the flow.
Current Code:\nif(cellVal.matches("([a-zA-Z]){3}\\s([a-zA-Z]){3}\\s([0-9]){2}\\s(\\d\\d:\\d\\d:\\d\\d)\\s[a-zA-Z]{3}\\s(\\d){4}")))\n\nRecommended code:\nPatern pattern = Pattern.compile(regexPattern); //Do this once in a static code block so that compilation happens only once.\nMatcher matcher = pattern.matcher(value)\nif(matcher.matches)
Method "private JSONObject formatRequestObj(JSONObject reqObj) throws JSONException". Below sorts are unnecessary as arrays are built using ben id which is generated in a for loop that is already in an ordered state:\nCollections.sort(proddtlsarray);\nCollections.sort(borrowerarray);\nCollections.sort(benarray);
Collections.sort needs to be remove from the places where data is already sort while creation.
Logging concatenated strings are not guarded with isDebugEnabled () checks. This will unnecessarily incur cost of string conatenation and put burden on GC.
Debug logging that involves string concatenation should be guarded with isDebugEnabled() checks. The framework class AppLog needs to have methods like isDebugEnabled\isInfoEnabled etc to be used as a guard before logging string concatenated (or any expensive operation) log messsages.
String.indexOf(String) is used when actual indexing is against a character rather than a string. This is relatively slower operation.
Use String.indexOf(Char). This is relatively faster than indexing against a String.
Calls to collection's size() mehtod  is used to check its emptiness. This is less performant.
Substitute calls to size() == 0 (or size() != 0, size() > 0, size() < 1) with calls to isEmpty() or ! isEmpty().
Multiple update and select queries are going for FTS on SR_AUDIT_TABLE with high cost, causing high execution time. \nDetails mentioned in SQL sheet.
We suggest to create index on table SR_AUDIT_TRIAL with column SR_NO.
Detailed observations:\n1. No logging of "invoke" method of OTCValidateFileBizprocessor class is found after "Calling invoke ....." log on hslotcpar2 - 10.60.6.28.\n2. All the logging of "invoke" method of OTCValidateFileBizprocessor class is found after "Calling invoke ....." log on hslotcpar1 - 10.60.6.27.\n3. Last Trace of "OTCValidateFileBizprocessor.invoke" method in Logs of hslotcpar2 - 10.60.6.28 is found on 06-Sep-2017.\n\nThese observations indicates following:\n1. "invoke" method of OTCValidateFileBizprocessor class is not working on hslotcpar2 - 10.60.6.28. During subsequent attempts file got processed through hslotcpar1 - 10.60.6.27.
Please verify deployment/configuration of JMS MessageListener (BulkFileProcessingBean) on Partner App Server 28. Or at least try to restart the listener service.
Uneven SOA CPU utilization
"Change load balancer scheduling algorithm to \u2018Cyclic\u2019"
Source code for these packages is included in the project source code -  This should be avoided unless any changes are implemented in these libraries.\ncom.sun.mail.handlers com.sun.mail.imap com.sun.mail.imap.protocol com.sun.mail.pop3 com.sun.mail.smtp com.sun.mail.util Classes are decompiled and included in the source list.
NoData
Currently XML is used for transferring data to different components in the system. Data when sent as JSON would have huge impact from performance perspective. JSON is now commonly used and adopted by all technologies. The size of the data sent using JSON is much smaller than that by XML
Replacing JSON instead of XML
Currently the response time of MWI home page is not less than 3 seconds when accessed anywhere from India. This can be reduced by implementing Front End Optimization techniques
Front End Optimization for MWI component continued..
In table "TrnDetails", data type of column "TRnRefNum" is char(25). Due to this additional spaces were coming in the stored data. To avoid this LTRIM and RTRIM were used everywhere in the queries and stored procedures. These operations are resource intensive.
Data type of column "TRnRefNum" of table "TrnDetails" needs to be changed to varchar(25). Additional space characters should be removed one time by an update query.\n\nLTRIM and RTRIM needs to be removed from the queries and stored procedures.
It is observed that the query running on database is having high elapsed time due to inadequate index.
We suggest to create index on trnDetails table with  EnteredDt, Status,Valuedate column with include Amount column.
It is intermittently found that the 'select * into' query having high elapsed time.
We suggest to use 'NOLOCK' in select * into query syntax.
It is observed that the query running on 'ID_SP_FileLevelAuth' procedure is going with FTS on TEMP table.
It is suggested to create index on '#tblTmpTrnDetails' table with TrnRefNum column.
It is observed that entereddt is converted to varchar and used in where condition in the query.  These operations are resource intensive.\n\nCurrent code:\nCONVERT(Varchar(10),entereddt,120) >= '2017-12-01'
Input value should be converted to date before calling the procedure.\n\nCode should be:\nentereddt >= '2017-12-01 00:00:00'
It is observed that the query running on procedure 'BC_SP_ValidateLimit' is having high elapsed time due to inadequate index.
We suggest to create index on Det_FinYearRefNo table with  CustRefNum, CustomerID column. This index is not present in the UAT Database but it is available on Production Database.
It is observed that the query running on procedure 'BC_SP_LimitRecheck' is having high elapsed time due to inadequate index.
We suggest to create index on svc_stg_txn table with  customerid,reserve5,trn_status column.
Attached the unused indexes list from the IndusDirect database.
We suggest you to monitor the usage of the mentioned indexes and drop the unused indexes.
String variable is used inside the loop. Use of string variable inside loop is resource intensive and have performance impact. Complete list of all such instances in code is shared in the "String Optimization" Sheet.
String varaible needs to be replaced by StringBuilder DataType. And should be disposed after use.
Error "Violation of Unique Key" observed in "INSERT" query in procedure BBPS_FetchBillRequest during load on Bill Payment.
It is recommended to insert unique id such as SPID or GUID on column "Req_RefNo" instead of NULL value.
It is observed that the query running  on table TransactionType_Customer_link is going with FTS with procedure SVC_SP_ProcessTxn.
We suggest to create index on column custId with transactiontype_customer_link table.
It is observed that entereddt is converted to varchar and used in where condition in the query.  These operations are resource intensive.\n\nCurrent code:\nCONVERT(Varchar(10),entereddt,120) >= '2018-01-29'
Comparision in date-time fields should be used using operators such as >=, <=, between.\n\nCode should be:\nEnteredDt >= '2018-01-29 00:00:00.000' AND EnteredDt <= '2018-01-29 23:59:59.999'
The head section of the RetailSignOn.jsp has the below snippet
The code was removed from the jsp which removed the delay of downloading the capicom.cab file and octget.dll from different Microsoft mirror sites. SignonScript.js was an external Javascript file which had functionalities for CAPICOM, this javascript was also removed for this fix.
DevicePrint.jsp was not used for any functionalities on \nthe RetailLogin Page but had very resource intensive \ninline Javascript which was blocking the page rendering
This jsp was excluded from the Retail Login Page as this snippet was for supporting RSA and IndusInd E-Banking solution is not using RSA. Hence the blockage of rendering caused by this javascript was completely removed
Bank reported that the Retail login page takes close to or more than 1.5 minutes of \ndelay for the first access in a day
The issue was studied from all layers, All networking components were studied using \ntracert to see if the issue is with any of the components in the network. The \nRoot cause analysis uncovered that the virus scan is causing the delay as \nFinEcEcApplet.jar which is the applet used for retail login forces McAfee OnAccess \nscan to scan even the base class files and archive files in class path which ended up in \n1.5 minutes of delay in Response of Retail Login Page access for first time. Discussion \nwith Infosys product team and architecture team was done and a solution which \nwould exclude the applet was provided which solved the 1.5 minutes of response \ntime issue completely
The header setting in Webserver was not setup properly to handle the static \ncontent caching
Header was enabled in IBMHTTP server to add a far date for expiration for static \ncontent served for internet banking application
Out of Memory Error.
By setting JAVA parameters we can avoid this memory error and application restart will be avoided. Which is the case currently in every 2-3 days
Automation of Rejection Code.
Automation of some rejection code is suggested. By atomizing below rejection codes we can reduce the manual intervention by 30%. Which will also helpful to less manual intervention when transactions increased.\nBelow Error codes can be removed and clearance directly rejected.\nNo such account.\nAccount closed or transferred.\nA/C Inactive.\nKYC documents pending.\nDormant account.\nAccount holder expire.
Connection Pooling not observed
Use pooled connection. A pooled connection instance represents a single physical connection to a database, remaining open during use by a series of logical connection instances. \nThis will improve the time to connect to database and also execution time of queries will improve by 20%
Connection made to Connect 24 not closed inside finally block.
Introduce finally block and close connection inside it. This will guarantee all the resources get released in case if there is any exception occurred and program control not reached the close statement inside try block.
There is a synchronized block inside a finally block on object lBatchFileBean\n\nsynchronized (lBatchFileBean) {\n     long lSuccessRecordCount = lBatchFileBean.addAndGetSucessRecordCount(lSuccessCount);\n     long lErrorRecordCount = lBatchFileBean.addAndGetErrorRecordCount(lErrorCount);\n     long lProcessedRecordCount = lSuccessRecordCount + lErrorRecordCount;\n     if ((lBatchFileBean.getTotalCount().longValue() == lProcessedRecordCount)\n       && !BatchFileBean.STATUS_SUCCESS_LONG.equals(lBatchFileBean.getStatus())) {\n      lBatchFileBean.setSuccessCount(lSuccessRecordCount);\n      lBatchFileBean.setErrorCount(lErrorRecordCount);\n      lBatchFileBean.setStatus(BatchFileBean.STATUS_SUCCESS_LONG);\n      lBatchFileBean.setEndTime(new Timestamp(System.currentTimeMillis()));\n      batchFileDAO.updateUsingPrepared(connection, lBatchFileBean);\n      connection.commit();\n      logger.info("########################################");\n      logger.info("Processed batch number " + lBatchFileBean.getBatchNumber() + " success:"\n        + lBatchFileBean.getSuccessCount() + " Error:" + lBatchFileBean.getErrorCount());\n      logger.info("########################################");\n     }\n    }
Since the IBatchFileBean object has a local scope and is eventually picked up from a queue.poll() call, there is no way more than 1 thread will access this object. Hence the synchronization is not needed in this case. Remove this synchronized block.
We have observed one query running with high execution count where CMPANNo column used twice in where condition. If both of these columns have different values then the query will not give any output.
Please check from your end the requirement of this query. If this query is not required then we can eliminate this query which is consuming the unnecessary resources.\nOr We can remove the duplicate condition.
NoData
Enable this job along with any other strategy of stats gather as it runs on non-peak hours(10pm from mon to fri ; 6pm on sat & sun) and gather stats for only those objects which have stale statistics. Regular gathering of statistics is helpful for overall db performance
NoData
Approximately 50 to 100 record sets are opening and closing while the application is logging in. it needs to be as minimum as possible.
NoData
Use same login connection to complete the login steps
NoData
MaxConcurrentRequestsPerCPU set 0\nHKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\ASP.NET\2.0.50727.0 \n\n%windir%\Microsoft.NET\Framework64\v2.0.50727\aspnet.config\n\nNeed to add the following section under "configuration" section (here I used default values) - don't forget change maxConcurrentRequestsPerCPU to 5000.\n\n< system.web>\n    < applicationPool \n        maxConcurrentRequestsPerCPU="12" \n        maxConcurrentThreadsPerCPU="0" \n        requestQueueLimit="5000" />\n< /system.web>
NoData
NoData
NoData
NoData
NoData
NoData
NoData
"1. \u201CuspMergeClients_maker\u201D procedure needs to be improved to\ \ gain the performance of the application.\\n2. Use  client side validation"
NoData
"1. Implement application caching for lookup data.\\n2. Avoid nested table\ \ tags\\n3. Use more on div\\n4. Avoid Server side validation\\n5. Use JQuery to\ \ validate the client side.\\n6. Improvement required on \u201CAddCall\u201D function.\ \ ~20 parameters are required, can move to stored procedure, this can ease the fetch\ \ calls used for 'AddCall' and improve on insert."
Overall response Time of the entire SI component was very bad.
After monitoring connections made between SI & STUB, identified that only 1 connection is made. Recommended to make config changes to make multiple connections
Hard coded input values are used. It is causing the recursive SQL againt the data dictionary.
No Hard Coded values should be used in the query.
Maximum open cursors exceeded.
There should not be ORA-01000 error in the alert log file.
Query execution time was high as indexe was missing.
NoData
memory leak was identified on application server.
"Bypass Stateless api\u2019s to avoid memory leak."
Connection pooling was not implemented on redis.
Recommended to  implement the connection pooling on redis.
High Availability.
"Horizontally scale the JVM\u2019s i.e. add more number of JVM components\ \ to sustain the load on both application server 1 and application server 2.\\nMove\ \ Money2India database to a different base machine."
High Availability.
Currently XML is used for transferring data to different components in the system. Data when sent as JSON would have huge impact from performance perspective. JSON is now commonly used and adopted by all technologies. The size of the data sent using JSON is much smaller than that by XML
High Availability.
Currently Payment Gateway uses EJB2.1, Upgrading EJB 2.1 to EJB will improve performance
High Availability.
Combine images to image maps or sprites.\nCompress html, css and Javascript used in MWI pages\nCombine all Javascript files to a single file\nEnable cache at webserver for far expiry date for static content like images, javascript and css files.\nConfigure E-tags which would improve performance of the static resource rendering for some of the browsers used by the merchants.
High Availability.
"Currently the JDK version used is 4. JDK has improved over the time with\ \ performance and functional capabilities\\nLots of external api\u2019s and libraries\ \ are used in Payment Gateway currently. Newer versions of JDK has these integrated\ \ and normalized for performance. Using the latest JDK would improve performance"
Limited allocated storage space for Application Servers
It is recommeded to allocate enough space for Application server. Also a log moving/shipping policy/cron to be in place to move logs to a drive where space isnt a constraint . Above this we also recommend to keep alerts for Storage utilization of the application server so that action can be taken before full utilization
Jasper Reports Consuming memory
It is recommended to update Jasper report version from 3.0 to 6.x .
Jasper Reports Consuming memory
We recommend use of Jasper Virtualization feature . Either JRGzipVirtualizer  or JRSwapFileVirtualizer  can be used for Virtualization\nMore information can be found at http://jasperreports.sourceforge.net/sample.reference/virtualizer/
Non Pact Impact
We recommend performance analysis of the other applications that are sharing the environment with PACT since sub-optimal tenant applications can impact performance levels of the over-all system
Uneven Node Hits
We recommend to find out the root cause of this behavior and take correct actions (change of settings / taking up with SAP).
Application Availability when one server is down
We recommend to review the settings for this behavior since this is not an expected behavior. We expect the CI/Web dispatcher to continue working even if one node/server is down . \nWe recommend to to find the root cause of this behavior and take correct actions (change of settings / taking up with SAP)
Slowness in application due to sudden load from various interfaces
Use following approach to resolve this.\n1. Assign more connections using <system.net> configuration in web.config of HCS services application to ips of interfaces dedicated for various services to avoid slowness in web request processing.\n\nOr\n2. Divide logically services across multiple worker processes to avoid slowness due sudden rise of load from any of the interface.
Thread contention in ECS.DAL.Repository.GlobalSearch.CLSearchRepository.GetCLDetailCount
Following should be checked to make GetCLDetailCount query faster.\n1. Remove EntityFuctions.TruncateTime from table columns.\n2. In select section just one column is enough.\n3. GroupBy clause is unnecessary as just count is needed.
Thread contention in ECS.BL.SavvionReference.RGICL_HCS_WSService.UpdateAndCompleteCLFlowTask
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
Thread contention in ECS.DAL.Repository.GlobalSearch.ALSearchRepository.GetALDetailsCount
Following should be checked to make GetALDetailCount query faster.\n1. Remove EntityFuctions.TruncateTime from table columns.\n2. In select section just one column is enough.\n3. GroupBy clause is unnecessary as just count is needed.\n4. Review Query if same logic can be accomplished with less number of joins
Thread contention in ECS.DAL.Repository.Claims.CLCaseDetailsRepository.GetCLDetails
Consider to modify query using joins instead of using includes.
Thread contention in constructor DynamicClass.BuildUp_ECS.BL.BL.Claims.CLInwardDetailsBL
The required objects should be passed into functions as parameter instead of initializig them in constructor.
Default session limit for WSHttp requests on HCF Services.
Increase connection limit from current 20 to 30 in <System.Net> and session limit from current default 10 to 30 using below settings in web.config of HCF services.\n<behaviors> \n  <serviceBehaviors> \n    <behavior name="defaultServiceBehavior"> \n      <serviceThrottling maxConcurrentCalls="30" \n           maxConcurrentInstances="30"  maxConcurrentSessions="30"/> \n    </behavior>\n  </serviceBehaviors>\n</behaviors>\n\nIf this works fine then attempt to gradually increase limit upto 100.
Thread contention in ECS.DAL.Repository.Claims.CLDetailsRepository.GetCLDetailsQueue
NoData
High response time in login page
NoData
UnUsed indexes in database
Use below approach.\n1. For small tables Remove UnUsed indexes.\n2. For large tables optimize queries to utilize indexes or drop the indexes.
Dynamic compression setting configuration on Smartzone app server withouout dynamic server role component installed.
Disable the dynamic content compression in web.config.
Unnecessary retrieval of all agent score card detail in GetScoreCard action method
Change logic to just retrive required rows from DashboardDWHClient in GenericScoreCardDetails function.
Unnecessary out parameter LastUpdated in GetGenericScoreCardDetails
Change procedure to remove parameter LastUpdated if not needed.
Unnecessary code to remove "\\" character from user name in GetUserId in LoginModel.cs
Remove the code to remove "\\" character if not needed.
Late rendering of bundles/motorQuote ,iRPAS.css and other static files in /Motor/PartialQuoteProductTypes
Place all render commands and reference of static files together on the top of the pages to download them quickly.
Compression failure due to content scan at firewall
Add production servers IP to rule on firewall that excludes added servers from content scan.
Repeated requests for several static bundle resources during load event of Motor/PartialQuoteProducTypes
Avoid repeated requests for same static resources in same the same event.
Unnecessary requests for action method Master/GetVehicleMakeModelVarianceCC on each user key input  on motorquote.cshtml.
Avoid sending request on each key input instead use below logic to send request when user stops typing. \n1. On each key input on autocomplete control initialie the timer for 1 seconds. The timer will call the function at the end which is responsible for sending request for Master/GetVehicleMakeModelVarianceCC.\n2. On subsequent inputs if timer is already initialied then reinitialize it.\nRefer to below link.\n http://stackoverflow.com/questions/4220126/run-javascript-function-when-user-finishes-typing-instead-of-on-key-up
High response time during  forms authentication
Avoid forms authentication if not needed and persist the userid instead of retrieving from database each time.
Multiple requests for file Webrupee.V2.0.ttf after saving the proposal on page Motor/Motor.
Avoid multiple calls for a static resources in same event.
Multiple requests for bundles/iRPASScript1 and bundles/iRPASScript2 when user clicks on Travel->Individual link.
Avoid multiple calls for a static resources in same event.
Unnecessary overwriting of same xml file "XmlFiles\AgentRetention V1.4.xml" from same xsd schema file "XmlFiles\AgentRetention V1.4.xsd" in AgentRetentionDetails function.
Keep the pre-generated xml file and load xmldocument directly from xml file without dynamically generating it from xsd file every time.
multiple requests for the getUserId in same the same requests
Avoidmultiple requests for userid by persisting user id at session level or at request level
Multiple requests for Content/iRPASScript1 and Content/iRPASScript2
Avoid multiple requests for static resources in single event.
Unnecessary call to function checkForAddressEquality in savemotor function
Update values of filledaddress instead of fillableaddress or avoid calling method checkForAddressEquality if not needed
Unnecessary query to initialize variable dbCovers in FillCoversForSave function
Avoid query to initialize variable dbCovers if not needed.
Unnecessary call of function getproductid to  set the value of variable productid in function savemotor
Avoid calling GetProductid method to set variable productid if not needed.
Unnecessary query on lstDetails to set variable QuoteRes in FetchIDV function.
Check the missing code to set value for strDetails or remove entire code for setting objPolicy.isMotorQuote.
Unnecessary queries in Home/getProposalInfo method to set several properties of variable obj of type RPASLogin when ProposalDetails proposalstatusid value is 12.
Perform check for the value of valid ProposalStatusId at the beginning of for loop  followed by  checks for ProposalStageStatusId to avoid several unnecessary queries on tables tblpolicy and tblMasProducts before setting properties of RPASLogin object.
Unnecessary call to action method RiskDetails_Read during loading of Healthwise/Healthwise
Avoid request for action method RiskDetails_Read if not needed
Unnecessary query to fetch paidPolicies in method getClientCartDetails
Avoid query to set value for paidPolicies if not needed
Failure of Dynamic compression for json responses.
Install IIS administration pack on app server and follow steps mentioned in below url.\nhttp://stackoverflow.com/questions/17321131/compression-filter-for-web-api/17331627#17331627
Unnecessary queries on users table to fetch userid instead of using getUserId function.
Avoid fetching userid from database instead call getuserid function.
'Low Disk space on D: of'
'Increase disk space on d: to atleast by 20 GB.'
No logout after session expiry
Handle session expiry gracefully on each controller and redirect user to login page.
Unnecessary call to function LoginModel.GetUserName to initialie local valiable
Avoid intialiing variable currentUserName if not needed.
Frequent app pool restart due to more errors in application then set value in failover protection
Change failover protection configuration of iRPAS app pool to avoid frequent restart.
Unnecessary join on table SubAgentName in method getPolicySeaStar of class SeaStarLogic.
Avoid oin on table SubAgentName to optimize the query cost.
Unnecessary join on table tblPolicyMarineExtns in method getPolicySeaStar of class SeaStarLogic.
Avoid oin on table tblPolicyMarineExtns to optimize the query cost.
High cost for query in store procedure usp_GetExShowRoomPrice_Website
Create index with below command.\nCreate nonclustered index IDX_NAME on mom.tblmasmodel(veh_type_id_fk, model_arc) include (model_id_pk,make_id_fk,model_name,variance,CC)
Multiple requests for watch_as3.swf during page load of Home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for initstrings.js during page load of CarInsurance.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for scriptresource.vxd when clicked on "Get Quote Now" button on home.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for conversionasync.js during page load of Two-Wheeler-Insurance.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for initstrings.js during page load of Two-Wheeler-Insurance.aspx.
Avoid multiple requests for the static resources in the same event.
Repeated 401 errors for authenticate.aspx, edit form.aspx and allitems.aspx in iis log.
Remove any reference of these pages from website application and any other application regularly accessing the website resources.
Unnecessary code execution after response.redirect in FillPolicyDetails method of QuickQuoteTwoWheeler.ascx
Exit function with return statement after response.redirect.
Unnecessary code execution after response.redirect in FillPolicyDetails method of QuickQuoteHealth.ascx
Exit function with return statement after response.redirect.
The location of ldf and current mdf partiition file in same drive(d:) for db_website database.
Put ldf file on a separate dedicated drive then the mdf files drive.
Multiple requests for initstrings.js during page load of Dashboard.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for strings.js during page load of Dashboard.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for jquery-ui.min.css file during page load of Dashboard.aspx.
Avoid multiple requests for the static resources in the same event.
Slow content download from content delivery network(cdn)
Review and consider moving all static contents on cdn servers to reliance server for better and consistent performance.
Static compression failing for images
Add static type image/* in the httpcompression module of both web servers to enable compression for images.
Multiple requests for analytics.js during page load of Car-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for conversion_async.js during page load of Car-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for 511169434-Rupee_Foradian.eot during page load of Car-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Multiple requests for core.js during page load of Car-Insurance-Premium-Calculation.aspx.
Avoid multiple requests for the static resources in the same event.
Frequent slowness in downloading https://webengage.com/blank.htm while home page load
Review the need for the file and avoid downloading if not needed.
Unnecessary code execution after response.redirect in FourWheeler method of BuyFourWheeler.ascx.cs class
Add return statement after response.redirect.
Unnecessary call to RegisterStartUpScript before redirect in PopulatePaymentObject method of  BuyFW.ascx.cs class
Avoid calling RegisterStartUpScript if not needed.
Unnecessary code execution after response.redirect in GenerateFopurWheelerXML method of BuyFW.ascx.cs class
Add return statement after response.redirect.
Unnecessary code execution after response.redirect in BindPremiumBreakUpXML method of BuyFW.ascx.cs class
Add return statement after response.redirect.
Unnecessary call to RegisterStartUpScript before redirect in BindPremiumBreakUpXML method of  BuyFW.ascx.cs class
Avoid calling RegisterStartUpScript if not needed.
DB Callback Notification
It is recommended to use ODP.Net framework for database handling in LOP Codebase. This also provides callback notifications which can be consumed by LOP Application and it will be notified whenever any CRUD operations happened so that LOP can take further action based on that.
Capacity Setting
We recommend to review the settings and set the capacity in accordance to the Memory/CPU available to the VM .
SAP VM upgrade
We recommend to upgrade the VM version to 1.6
Logging Framework
We recommend usgae of Apache Log4j
Out of memory error
Change/Add the value of following parameters in the JVM parameters file \n Parameters are provided in a separate mail
Hard Parsing Queries
Use bind variables instead of literals
NoData
No. of threads needs to be reduced. Cache static pages.
NoData
Convert all the JPG/GIF images into PNG extension
NoData
Value of maxconcurrentrequestspercpu needs to be increased to a higher value for the threads to be processed
NoData
Comment out the lines in aspx where referencing to those objects are done which are not present
NoData
Update Table/Index statistics if it is not done so, so that it starts taking the latest execution plan.
NoData
Please defragment the datafiles of the  tables involved in these views.
NoData
ii.Select on IPAY is having all columns, hence high read. Only use columns in select which is required.
NoData
iii.Implicit conversions used for NEFT_Payment_Requests should be avoided.
NoData
Set tcp_tw_recycle=1 and tcp_tw_reuse=1 in sysctl.conf
NoData
Set max_thread=400 in server.xml
NoData
Disable response time logging in server.xml
NoData
Apache Tomcat is replaced by node.js
NoData
Setting following in sysctl.conf:\nkernel.msgmnb= 100000\nkernel.msgmax= 100000
NoData
Set open files to 1000001 in ulimit
NoData
Setting the network configuration to use 10 Gbps network card
NoData
Setting following in sysctl.conf:\nnet.ipv4.ip_local_port_range=4096 65535\nnet.ipv4.tcp_congestion_control=cubic
NoData
Started service irqbalance
NoData
Changing following in the TopologyConf.props:\nBEGIN_SPOUT_CNT=25\nEND_SPOUT_CNT=25\nEVENT_SPOUT_CNT=25\nCRASH_SPOUT_CNT=25\nHDFS_BWRITERS=30\nHDFS_EWRITERS=30\nHDFS_CWRITERS=10\nHDFS_EVTWRITERS=30
NoData
Setting parameters to following in http2Kafka.ini file:\nPorts = 20\nPartitions = Begin-60, End-60, Event-120, Crash30\nBrokers = 2
NoData
Create a separate reporting database server for all reporting data or use of stand alone database server for all reporting purpose
NoData
Orphan records were deleted from queue tables to reduce no of executions.
NoData
Blank Search criteria has to be restricted to avoid high cpu utilization. This is a training that needs to be provided to the users as discussed with Aris Global team.
NoData
Staging tables will be used for moving data from the source system to the new application. Scheduled Batch jobs will be used to transfer the data between the 2 systems
NoData
While there are various workflow and BPM engines available, we recommend that the workflow be custom developed through a MVC framework given that the workflows are not very complex. The Applications in general follows a data view/ modify activities in a Maker-Checker mode and involves 2-3 steps in the workflow at the most. For such complexity levels, a custom workflow mechanism will be both easily maintainable as well as quick to implement (given that other workflows will have a learning curve).  \nHowever, a set of commonly used workflow engines has been provided. These may be useful in the future if there is a need for a comprehensive workflow engine to replace the custom workflow mechanism. All the options are fairly close in their feature list - specific call can be taken once requirements for the Workflow engine/ BPM is defined.
NoData
"User management will be a part of the administration module which will\ \ help in maintaining the system. This module will take care of \u2013 \\n1. User\ \ creation\\n2. Role creation\\n3. Associating privileges with Roles\\n4. Credential\ \ management and recovery\\n\\nWe recommend that a custom module (based on Spring\ \ MVC, Hibernate and JSP) be developed to address this requirement. \\nSpring security\ \ (as mentioned above) can be leveraged for the actual authentication and authorization\ \ requirements."
NoData
We recommend that Spring MVC be used instead of Struts in the application.
NoData
We recommend that Spring be used in the business layer as the framework for developing the application
NoData
"Amortize requests, wherever possible:- Introduce asynchronous processing\ \ at the app server layer (wherever possible)\\n Leads to faster response for end\ \ users\\n Better worker thread availability (as threads are released faster)\\\ n Threads don\u2019t block if end point is not responsive\\n Throttle requests based\ \ on end-point availability/ performance. \\n Add/ Reduce queue Listeners as well\ \ as Queues, as required."
NoData
Data shards:-Database outage can be \ncatastrophic and will bring\ndown the entire system for\nall users till the back up \ntakes over \nLimit impact of downtime\nto a sub-set of users only\nby creating db shards based\non account numbers.
NoData
Using caching servers to reduce load on Session Db:-Use combination of session API provided by Web container and Distributed memory\nCache to build a scalable Http session solution. \n Eliminate heavy db io operations by working on data sets in Memory rather than on disk\n Write session data to multiple cache servers for redundancy in case some cache servers have to be shut down \n Disadvantage is that synchronizing sessions with cache has to be handled by app.
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
Unnecessary code execution after response.redirect in ProposalCreationBundlePA method of BuyFW.ascx.cs class
Add return statement after response.redirect.
Unnecessary call to RegisterStartUpScript before redirect in ProposalCreationBundlePA method of  BuyFW.ascx.cs class
Avoid calling RegisterStartUpScript if not needed.
Unnecessary code execution after response.redirect in CheckUserValidity method of BuyTravel.ascx.cs class
Add return statement after response.redirect.
Unnecessary call to RegisterStartUpScript before redirect in ProposalCreationBundlePA method of  BuyTravel.ascx.cs class
Avoid calling RegisterStartUpScript if not needed.
Unnecessary code execution after response.redirect in CreateStudentUser method of BuyTravel.ascx.cs class
Add return statement after response.redirect.
Configuration
It is recommended to move the redo log storage RAID configuration to RAID 1+0 for both DC and DR instances
Configuration
'After analyzing the issue, we have found out this is bug with oracle version 10.2.0.5. There are two separate patches provided by oracle on this issue                                                                                                                                    - Bug 5749075 - High Requests on dc_rollback_segments. latch / US enqueue  contention (Doc ID 5749075.8) \n - Bug 14226599 - Increase dc_rollback_segs hash buckets to reduce ''latch:  row cache objects'' waits (Doc ID 14226599.8)                                     We recommend to open a service request with oracle to get confirmation on applying the patch.'
Code Review
Some of the below recommnedations can be implemented quickly to Imporve the page performance.\n1. Compressing resources with gzip or deflate can reduce the number of bytes sent over the network.\n2. Minifying landing HTML will reduce its size by 2.3KiB (50% reduction)\n3. Enabling caching will reduce the page rendering time.\n4. No character set specified in HTTP headers. Specifying a character set in HTTP headers to speed up browser rendering.
Slow Response Time
The slow response time only on Saturday's can be attributed to the same observation on the above point. The same reccomendation for the above point holds good for this too.
Memory Analysis
For the present transaction load the memory utilization is fine. However for increased branches, users and transaction additional memory will be required. If the HP team can provide the future plans of increase in the load, then a proper hardware augumentation can be done
Code Review
The RTGS bulk upload process which is run as a background process to be seperated from the 'laps' process script and executed in a seperate script with desired parallel processing
Code Review
Another main reason for transaction going into ENTERED status is locking of records, i.e multiple process using the same records at the same time which results in resource busy error for process which are waiting for the record to be released. This can be overcome by an inbuilt parameter provided in FINACLE called INTV_LOCK_POST (env variable). This has to be configured in micro seconds. The default value if not configured is 500000 micro seconds which is 0.5 secs. If a process finds that the record it requires for processing is locked by another process, then the process will try to acquire the record 60 times(hard coded in the product) with 0.5 secs ( the parameter which is defined) time gap between each iteration. So totally a process will wait for 30 secs (60 x 0.5) to acquire a record and if it doesnt after 30 seconds the process will throw a resource busy error. This value can be configured to a higher value if a single transaction takes a long time in posting and the record is not available for other process. This parameter will affect the entire FINACLE application and hence care and proper testing needs to be done before applying this parameter. Better is to bifurecate RTGS to a seperate server if this parameter is going to be applied. We can check on the usage of this parameter, based on the response from Infosys on the call which will be raised for the above point
Code Review
Convert these GIF files to PNG.
Code Review
Fix the path in application code to these objects.
Code Review
"To minimize the Response time of these pages,  below steps needs to be\ \ carried out\\n1. Compress js files and images \_ \\n2. Enable caching for static\ \ elements\\n3. Remove unwanted links ( 404 errors ) from pages\\n4. css should\ \ be moved out of body tag from pages"
Code Review
"To improve the Response time of these pages,  below steps needs to be carried\ \ out\\n1. Compress js files and images \_ \\n2. Enable caching for static elements\\\ n3. Remove unwanted links ( 404 errors ) from pages\\n4. css should be moved out\ \ of body tag from pages"
Code Review
Below steps were taken by HP team to resolve the issue.\n1. Few new patches provided by Infosys has been deployed in Mobile Banking application.\n2. Timeout period has been reduced from 14 secs to 8 secs in Mobile Banking application and from 14 secs to 6 secs in core.\n3. Seperate uniser service created in core for Mobile Banking application.\n4. Number of office accounts has been increased from 1 to 10 in core.
Configuration
Sepearate mount points to be allocated for Corporate Index files and Payaway database files.
Maintenance
Reorganization and rebuilding activities needs to be performed in the indexes shared. Please refer Sheet "DB Fragmentation" for details of the objects which needs to be acted upon
Maintenance
Reorganization and rebuilding activities needs to be performed in the indexes shared. Please refer Sheet "DB Fragmentation" for details of the objects which needs to be acted upon
Query Optimization
Only one select should be done for one table and all the fields of the table should be cached in local memory for usage during the program.
Query Optimization
Strategy has been already shared with ICICI
Code Review
Recommendations needs to be incorporated
Code Review
Application logic can be modified to avoid opening and closing of files multiple times by putting the data in memory/cache.
'Cursor: Pin S'
DBA to verify and deploy necessary patches
Query Optimization
Avekshaa to review the AWR's with the new database version on AIX
Query Optimization
There were no alarming PL/SQL issues or optimization opportunities
Configuration
NoData
Configuration
Implementation of the parser tool in production after making changes to the code for logging volume data
Query Optimization
After discussion with ICICI team for this query they highlighted that this query will be removed from production from 6th February'12 and, so no need to do anything.
NoData
Analyzed Sql plan are fine and there no  issue observed
Configuration
Scripts mentioned in previous slide should be used to write log for instrumentation with following information. Each information should be 1. separated with | (pipe)\n2. Starting and ending the execution indicator e.g. STARTING AT, ENDING AT etc.\n3. Script execution start time\n4. Script execution end time\n5. Menu option and script name\n6. Sol id\n7. User ID\n8. Volume (No of records) processed\nAny other information about transaction. e.g. Olats51 has been generated\nCreate a new com script to write this log. Call this script in starting and finishing of execution in all scripts mentioned in previous slide\nLog file name should indicate about module/menu option  and user id e.g. user1_hgbmpan.log
Configuration
It was analyzed that  query execution is not taking more than 3-4 secs for large data sets. To analyze further on the application side, logs need to be introduced at various points in the code. As per discussion the development team will put the required logs by Monday (13th Feb).
Configuration
Cache static content JS, CSS, images so that network bandwidth utilization comes down and web server has to take lesser amount of load.
Code Review
Combine all js files on a page into one JS file (wherever it is not too disruptive) and reference it at the bottom of the bodey tag in html/JSP.
Code Review
Minifying/Compacting JavaScript code can save many bytes of data and speed up downloading, parsing, and execution time. Any open source tool like JSMin, YUI Compressor etc can be used to minify JS files.\nFiles in a source code repository can remian as is (without minification), but before these files are deployed to production server these should be minified and then deployed to production server.
Code Review
Statement should be replaced with PreparedStatments. Statements are slower to run than PreparedStatements. Also, statements are vulnerable to SQL Injection attack.
Code Review
Hashtable is synchronised and runs slower than Hashmap due to overhead of synchronizations. Unncessary use of Hashtable will have adverse impact on performance.
Code Review
The possibls issue could be due to Arcot service per se or the connectivity between the end-client and the service. Arcot is a closed source third-party tool and can't be dug deeper. Will have to take this up with Arcot. Also, it is an interaction that heppens betwenn end-client and Aroct service which the CIB app has no control over. The interaction is not happening via CIB server.
Configuration
QK should cache below static content types:\n\n.ico \n.gif\n.jpeg \n.png \n.bmp \n.javascript \n.css \n.html
Query Optimization
Create Non-Clustured cover index OR Create included column Non-Clustered index on CORPORATE_USER and BENEFICIARY_REGISTRATION_REQUEST_* tables
Code Review
"Add \u2018Link\u2019 to the CSS instead of Including in the body so that\ \ the CSS can be cached"
404 Errors
Remove calls to files that are leading to 404 errors. \nCreate favicon.ico image file on the default web folder and cache ico files.
Configuration
We suggest that Transaction logs be moved to RAID 1+0 for better write performance
Query Optimization
Create cluster index on BANK_ID, BAY_USER_ID, CORP_USER of CUSR table.
Query Optimization
Create non-clustered index on bank_id, br_scr_hdr columns of DIRECTTAXPAYMENTS table. Avoid using 'like' condition in where clause of the query.
Query Optimization
Create covering indexes for faster execution of select queries.
Query Optimization
Query is performing full table scan on RqstHistoryTable table of size 8.5 GB.\n(Reference Query Q001 - see next sheet)\nCREATE NONCLUSTERED INDEX index_name ON RqstHistoryTable (Action_By,R_Cre_Time) INCLUDE (Request_Type,Request_Id,Request_Srl_Num,Action_Code,Remarks);
Query Optimization
Query is performing full table scan on FILEDETAILSTABLE table of size 600 MB.(Reference Query Q002 - see next sheet)\nCREATE NONCLUSTERED INDEX index_name ON FILEDETAILSTABLE (corp_id,r_mod_time)  INCLUDE (file_sequence_num);
Performance
Make the function getPipeId 'static' so that multiple threads will not get access to the pipe id concurrently. This will impact performance to some extent since only one thread can get the monitor but is necessary to address the functionality. \nAlternatively add a synchronized block around the pipe id variable and remove synchronized keyword from the function.
Performance
Synchronize the function smsReqResWrite in GlobalFunc class. \nPerformance might be compromised if multiple threads try to get access to the synchronized block and IO operations are initiated for every call. This is a likely case since given that the volume of SMS's will increase with time. \nConsider asynch logging using loggers like Log4J.
Performance
These operations must be executed before retrieving the connection, to optimize the connection hold time within the thread.
Slow Response Time
Recommended to remove the unwanted operations from the source file. This will help in faster execution of logical blocks and hence improve the performance. Also the objects created inside this block will get eliminate which result in low memory consumption.
Slow Response Time
'Use Position literals first in String comparisons for equals/equalsIgnoreCase. \nExample: obj.equalsIgnoreCase("AnyString"); // should be "AnyString".equalsIgnoreCase(obj)'
Slow Response Time
Comment out the unwanted instance of StringBuffer object.
Slow Response Time
Split the String directly with "@" character.
Slow Response Time
The map will be empty after this call returns. - This is not required as map is already empty. Performance overhead.
Slow Response Time
Add below block inside finally block. \nparser = null; \nparser is reference to WebServiceResponseParser class. Above block will make sure that in any case normal/exceptional parser object reference to null and can be garbage collected.
Slow Response Time
This is not required and may cause issues in content-targeting. So proper user-agent value should be passed as the application is targeted to Android and iOS platforms.
Slow Response Time
These are not required, removing this will improve performance
Slow Response Time
Remove the method call.
Slow Response Time
Check the else condition and if not required remove the call made to generateFailureResponse
Slow Response Time
Validate the logic here and remove the if condition as it seems to be Unnecessary
Slow Response Time
The replace is not required. It is recommended to call split on PvtDataField125 directly.
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
Applications running on Debug mode create an overhead on the response time as it resource intensive. The execution speed is compromised. As the load will increase there will be higher impacts.
It is recommended to set  'DEBUG' mode as false in the Production Environment.
Its is a very expensive activity to be opening and closing connections for database operations. Connecting to a database server typically consists of several time-consuming steps. A physical channel such as a socket connection is established, the initial handshake with the DB server  occurs, the connection string information gets parsed, the connection is authenticated by the server & checks are  run for enlisting in the current transaction. This is done every time a coneection is established. This degrades response time and is heavy on resource utilisation.
'It is recommended to use Database Connection Pooling.\nSet following keys in connectionstring: \nConnection Lifetime 0\nEnlist ''true'' \nMax Pool Size 50\nMin Pool Size  25\nPooling ''true'''
Static content will be downloded from server and unwanted hits will go to server which can be avoided by putting static content configuration and setting its age. Currently proposed 365 days as application runs continuously 24x7 and 365 days.
It is recommended to set Static Content Caching as -\n<staticContent>\n      <clientCache cacheControlMode="UseMaxAge" cacheControlMaxAge="365.00:00:00" /> \n    </staticContent>
Writing logs using System.IO.File is synchronous and can create problems in handling more concurrent user requests.
It is recommended to use ascynhronous logging using Log4Net framework.
Writing logs in console is not recommended in Production Environment.
It is recommended to use ascynhronous logging using Log4Net framework.
Unwanted memory will be consumed by all these variables and classes
It is recommended to remove unused references, classes, methods, variables from the Code.
Recompilation of code to be done if any hard coded values are changed which need system downtime in production environment.
It is recommended to read the hard coded values from the Config files.
Difficult to trace end user journey if no logging pattern is followed.
'It is recommended to use given below logging pattern:\n\n<DATE TIME> <LOGLEVEL> <THREAD ID> <CLASS NAME> <REQUEST SENDING TO> <COMPONENT-NAME> <REQUEST DATA WITH MOBILE AND CUSTOMER ID/PASSPORT NO> <TIME TAKEN IN PROCESSING REQUEST> <TIME IN SECONDS>\n\n<DATE TIME> <LOGLEVEL> <THREAD ID> <CLASS NAME> <RESPONSE RECEIVED FROM> <COMPONENT-NAME> <RESPONSE DATA WITH MOBILE AND  CUSTOMER ID/PASSPORT NO > <TIME TAKEN IN PROCESSING RESPONSE> <TIME IN SECONDS>\nNOTE: Exception should be printed completely in all logs, also logs path is hard coded in code files also which should be removed.'
'IO operations will be increased in both the drives simultaneously and also if C: drive gets full then system processing will be impacted.'
'It is recommended to write all the application logs in D: drive only with proper purging and backup policies'
The memory heap size will be increased slowly with every end user calls and leads to system hang after some time.
It is recommended to dispose the WebClient object after use for avoiding memory leaks.
The encryption and decryption are very CPU intensive operations.
It is recommended to avoid un-necessarily  use of encryption - decryption methods in all the codebase.
It is difficult to anlyze the issue if the error logs of issue time is not available.
It is recommended  to do backup the error logs location alternate day.
The parallel execution of the query will be restricted with the defined value.
It is suggested to set the value of max degree of parallelism to 0. With this sql server will detect the best degree of parallesim to use for the query execution.
Equally load will not be distributed among all nodes which is a blocker in application scalability
It is recommended to use distributed cache management system for session management
High count of the query execution will utilize the resources from the server.
It is recommended to check the requirement of the queries and reduce the execution count of the queries.
High cost query cause high CPU utilization and high execution time for the queries.
It is recommended to create below nonclusted index on AllocationForCenter table.\nCREATE NONCLUSTERED INDEX <Index_Name>\nON [dbo].[AllocationForCenter] ([CenterId],[VisaGroupId])\nINCLUDE ([Id],[Date],[MissionId],[TimebandId],[AllocationCategoryId],[TotalSeats],[RemainingSeats],[BlockedSeats],[ConfirmedSeats],[Createdby],[CreatedDate],[Modifiedby],[ModifiedDate])
The memory heap size will be increased slowly with every end user calls and leads to system hang after some time.
It is recommended to dispose the WebClient object after use for avoiding memory leaks.
Unwanted DB Call increases system utilization and decreases the response time of the methods.
It is recommended to remove unwanted DB calls from the Codebase.
High elapsed time for the login page.
We recommend to remove upper function from the query and handle the same from application end.
The users could not be log in for the respected mission and get 403 error.
It is highly recommend to implement  appNeura APM tool across pages to monitor the user experience and to track the errors so that corrective action to be taken.
Unwanted DB Calls increases  system utilization and decreases the response time of the methods.
It is recommended to remove unwanted DB calls from the Codebase.
The parallel execution of the query will be restricted with the defined value.
It is recommended  to set the value of max degree of parallelism to 0. With this sql server will detect the best degree of parallesim to use for the query execution.
It will impact the performance of query and consuming the storage
It is highly recommended to defragment the table and indexes so performance of related query will not impact.
It will be difficult to distribute the balanced load  across different nodes.
It is recommended to use same server configurations across all the nodes to get the optimal performance for the application.
Everytime processing of  DB calls on the pages  increases the system utilization and also increases the response time of methods.
It is recommended to store the output value for GetLocalizedBannerText() inside the Session variable or internal cache.
The consumption of system resources increases.
It is recommnded to remove all unwanted websites from GA production environment.
Difficult to trace network related issues in lack of proper network monitoring tool
It is recommended to use proper network monitoring tool.
Too many indexes are overheads on the database, it will impact the performance of the insert and update statements.
It is recommended to remove the indexes which are not scanned by any queries.
This will lead to utilize more space from the storage end and will took more time and resources while backing up the database.
It is recommended to remove the duplicate / backup tables from the GA database.
This will lead to utilize more space from the storage end and will took more time and resources while backing up the database.
It is recommended to remove the tables with zero counts  from the GA database.
Its is a very expensive activity to be opening and closing connections for database operations. Connecting to a database server typically consists of several time-consuming steps. A physical channel such as a socket connection is established, the initial handshake with the DB server  occurs, the connection string information gets parsed, the connection is authenticated by the server & checks are  run for enlisting in the current transaction. This is done every time a coneection is established. This degrades response time and is heavy on resource utilisation.
'It is recommended to use Database Connection Pooling.\nSet following keys in connectionstring: \nConnection Lifetime 0\nEnlist ''true'' \nMax Pool Size 50\nMin Pool Size  25\nPooling ''true'''
Currently autoconfig option in IIS is used so IIS will take default configurations for handling concurrent request which is very less for handling more more concurrent requests and headroom is available in all the servers as per hardware kpi details so this can be increased as per recommendations for handling more concurrent users.
'It is recommended to disable autoconfig and use custom thread pooling  setting in Machine.config as given below for handling more concurrent requests, below settings needs to be tested in UAT environment in high load before moving into production, it will be further tuned based on performance testing results. \n\nautoconfig : false\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs \nminIoThreads 50\nminWorkerThreads 50'
Static content will be downloded from server and unwanted hits will go to server which can be avoided by putting static content configuration and setting its age. Currently proposed 365 days as application runs continuously 24x7 and 365 days.
It is recommended to set Static Content Caching as -\n<staticContent>\n      <clientCache cacheControlMode="UseMaxAge" cacheControlMaxAge="365.00:00:00" /> \n    </staticContent>
Unused objects will increase the memory consumption of the application.
It is recommended to remove unused objects.
The Encryption - Decryption methods are very CPU intensive tasks.
It is recommended to use Encryption - Decryption only wherever necessary in the application.\nAlso we have confirmed with Gobinath and he agreed that currently Encryption is not required in the method GetTreeData.
Connecting to a database server typically consists of several time - consuming steps. If connection pool is not used then it application can have un-necessary open db connections.
It is recommended to create a static GetConnection() method that returns a new open connection. Use this within a using Statement so it can be closed and returned to the connection pool as soon as possible. Below is example :\nusing (var con = Database.GetConnection())\n{\n //query the data as per requirement\n}
The memory heap size will be increased slowly with every end user calls and leads to system hang after some time.
It is recommended to dispose the WebClient object after use for avoiding memory leaks.
Difficult to trace network related issues in lack of proper network monitoring tool
It is recommended to use proper network monitoring tool, we would recommend to use Riverbed Network Monitoring tool.\n\nhttps://www.riverbed.com/in/products/steelcentral/network-performance-management.html
Unwanted consumption of resources by other wesbsites which are not relevent to LidPro
It is recommnded to move all unwanted websites in other environment
This is imapcting quering performance
Deadlocks are bound to occur if the resources are not processed in a well defined order. To minimize deadlocks, all the concurrent transactions should access objects in a well defined orders.\nThere are update and insert statement on BatchHistory table and update is causing the deadlock issue in the database
This is impacting multiple queries performance and causing high lock wait event
There are indexes on the table BatchHistory where we can see there are columns which are getting frequently updates with update query , it is recommended not to index columns which are keep on updating it will impact the performance of query. Like in BatchHistory table column ConnectionStatus, type columns are indexed
Placing both data and log files on the same device can cuase contention in that disk and resulting poor performance.
It is recommended to use different disks for data and log files.
It is difficult to anlyze the issue if the error logs of issue time is not available.
It is recommended  to do backup the error logs location alternate day.
Writing logs in console is not recommended in Production Environment.
It is recommended to remove Console.WritLine from the application and to use Ascynchronous logging using Log4Net.
Unwanted execution of record.save() method will consume the system resources un-necessarily.
It is recommended to use [ record.save() ] only once in a method.
Unused objects will increase the memory consumption of the application.
It is recommended to remove unused objects.
Unwanted execution of command.ExecuteReader() will consume the system resources un-necessarily.
It is recommened to use command.ExecuteScalar() for methods returning bool objects i.e to check if record exists or not.
Slow Response Time
We should only be calling the objects which are required to paint the page. The GTM calls should be working asynchronously at the bottom of the page. It should not be a part of the header. This should be implemented across all pages.
Slow Response Time
The list of images are provided in the sheet which needs to be optimised.
Code Review
Build a cube by merging 3  date queries to calculate \nOther Leads Date \nMeetings Date \nTalisma Date \nwill reduce execution time to less than minute
Query Optimization
Remove TRUNC from the joining condition
Query Optimization
Merge all 5 datasets by including all the metrics into a single dataset
Code Review
Redesign the panel to reduce rendering time. Recommended to have one panel display and provide option to switch. Need to test the feasibility and business acceptance.
High CPU Utilization
ETL job needs to be optimized as the hardware configuration is already upgraded.
Code Review
Using Parallel Hints in VLDB Settings can fasten the query response time
Code Review
Redesigned the cube to select required data only
Code Review
Code review need to be carried out to fix the high cpu utilization.( Code review of these methods was not carried out due to unavailability of product code base )
NoData
25% of cache is used by custom_postinglog object, Creation of recommended indexes will help to improve the cache hit ratio.
NoData
It can be further optimized by creating composite index on ers_limit_usage table on columns (version,julian_offset)
Code Review
It is recommended to remove the synchronization for better throughput.
Code Review
This pattern is having high occurrences through the code. Use enhanced for loops to iterate or store value in a variable and use it inside condition.
Code Review
Database Connections and Input/Output streams should be closed by introducing  finally block , so that in case of exception it releases the lock on the file/stream and close the respective connection
Code Review
Use StringBuilder instead of StringBuffer if expensive thread-safe operations are not required. StringBuilder is faster than StringBuffer for strings concatenation.
Query Optimization
On Futher analysis of the issue we have found out that the delay configured for camel consumer is on the lower side . We recommend to increase that value \nA detailed mail is shared already
Query Optimization
We recommend the vendor to monitor and debugg the connection pool mechanism .\nA detailed mail explaining the situation with data is already shared .
Query Optimization
Create composite index on pay_bank_code and Q_status columns of fpd_payment_in table.
Code Review
We have recommended a single query which will bring all the data required to be displayed on the pages . Separate mail with all the details has been shared .
Code Review
We recommend multi threading of processing of transactions . We propose use of Executor framework for forming a thread pool and processing transaction in a block .
Design
We recommend to use a different table space (already created but not used) to store indexes
Query Optimization
Create nonclustered Index  on table TBT_Payments on columns Maker_Location,PV_Date
Maintenance
Drop duplicate indexes in database, as these are overhead for insert/update operations. This will also help to reclaim space on disk
Query Optimization
We shall need storage monitoring reports for further analysis
Code Review
Only one call should be made to get the collective data for all the entry codes. And the procedure should return the complete dataset which then can be processed on client side.
Code Review
Insert data directly into master table since there are no where clauses used for select statement. Also use of truncate is recommended instead of delete, since all data is getting deleted from *_inter tables
Query Optimization
Create Nonclustered Index on Tbt_eligible_refinance on column (Deal_no)
Configuration
It is recommended to set max server memory for SQL server to 58 GB and min server memory to 8 GB
Code Review
Avoid non use of variable in cache block
Code Review
Avoid execution cycle
Code Review
deinitialize it in finally block
Code Review
sCurrency is not declared while comparing the sUTN. Check is it logically accepted having the empty value for sCurrency,
Code Review
Instead of looping to get the properties, can use direct method like "GetProperty"\nvar sShipper = Inputs.GetProperty("Shipping Company");
Code Review
deinitialize it in finally block
Code Review
if findchild do nt have record, then ListOfAlternatePhoneps may end of throwing the exception while accessing the GetChildCount. It's always better to check the object instance exists before accessing their property
Code Review
dereference it in finnally
Code Review
deinitialize in finally block
Code Review
if(sftind == "E" || sftind == "" || sftind ==null)\n    {\n      OneWorldResponse.SetProperty("Total Redemption Cost", ToNumber(OneWorldQuoteSum));\n      OneWorldResponse.SetProperty("Promotion Discount", ToNumber(gOWPromoPoints));\n      OneWorldResponse.SetProperty("Promotion Name", PromotionName);\n    }\n    else if(sftind == "B")\n    {\n   //  OneWorldResponse.SetProperty("SFT Cost", (sftvalue* ToNumber(count)));\n     OneWorldResponse.SetProperty("SFT Cost", "SFT NOT VALID FOR THIS ITINERARY");\n   //  OneWorldResponse.SetProperty("Total Redemption Cost Including SFT", ToNumber(OneWorldQuoteSum)+(sftvalue* ToNumber(count)));\n     OneWorldResponse.SetProperty("Total Redemption Cost", ToNumber(OneWorldQuoteSum));\n     OneWorldResponse.SetProperty("Promotion Discount", ToNumber(gOWPromoPoints));\n     OneWorldResponse.SetProperty("Promotion Name", PromotionName);\n    }\nelse if(sftind == "I")\n    { \n     OneWorldResponse.SetProperty("SFT Cost", "SFT NOT VALID FOR THIS ITINERARY");\n     OneWorldResponse.SetProperty("Total Redemption Cost", ToNumber(OneWorldQuoteSum)+(sftvalue* ToNumber(count)));\n     OneWorldResponse.SetProperty("Promotion Discount", ToNumber(gOWPromoPoints));\n     OneWorldResponse.SetProperty("Promotion Name", PromotionName);\n    }
Code Review
deinitialize in finally block
Code Review
deinitialize in finally block
Code Review
reconsider null is compared as string than null object\nif(vEndDate!= "" && vEndDate != 'null')
Code Review
reconsider null is compared as string than null object\nif(vMemberJoinDate !="" && vMemberJoinDate != 'null')
Code Review
Reconsider to improve the execution time like following\n if(oAbvDate > oToday && oExeFlag == "N")\n    {\n     oCurrYear = oCurrYear - '1';\n     oAbvDate = splitMonth + "/" + splitDay + "/"+ oCurrYear;\n     oAbvDate = new Date(oAbvDate);\n    }
Code Review
StatusBonusPoints is declared as block level variable and used out side the block, which is dangerous. Declare it as local variable than block variable
Code Review
sSCRExpiryDate is not been used anywhere. Recheck if it is not using anywhere, why wanted to do this operation. Recheck
Code Review
Global variables are used. May required some of the important variable to be reinitialize here
Code Review
Not used any where, can be removed or commented
Code Review
Not used any where, can be removed or commented
Code Review
Not used any where, can be removed or commented
Code Review
Not used any where, can be removed or commented
Code Review
FileWrite class provides close() method and it should be invoked in finally block, so it will be called even if an exception occurs.
Code Review
This need to be confirmed with team that why these static code has been introduced. If there is no any purpose then these code need to be fixed.
Code Review
This need to be confirmed with team.
Code Review
Default value of fetch size is 10, configure it based on average rows number is returning from queries.
High Availability
Create a passive application node, which will serve as failover instance.
High Availability
Since database is on standard edition, oracle data guard feature can not be leveraged. However manual standby server can be setup by sending archives via ftp or rsync on remote location and recovering database on periodic basic. This will have lag in data sync depending upon frequency of archive transfer.
Design
Recommended to have separate tablespaces for indexes and tables
Design
It is recommended to have multiple files in one tablespace with size of 4g or 8g depending upon size of mount point with autoextensible off. This helps for read and write operations in distributed fashion, instead of scanning one large file of 32 GB.
Design
It is recommended to have separate mount points spread across multiple disks for temp,undo,redo,table tablespace and index tablespace
Code Review
Need to investigate application logic if these many executions are required in an hour. However as confirmed with application team these queries are not related to PAC application.
Code Review
As confirmed with application team these queries are not related to PAC application.
Code Review
Avoid hardcoded values. Use Constants for any kind of hard coded values.
Code Review
The main implication of close() is the release of resources - make sure you always close and never outside of finally block.
Code Review
Use equalsIgnoreCase()instead of using equals("String".toUpperCase()/toLowerCase()) \nequalsIgnoreCase() is faster than using toUpperCase/toLowerCase().equals()
Maintenance
Perform defragmentation of tables and indexes for optimal access of datablocks.
Configuration
Set cache size to 20 for the sequences.
Code Review
The mechanism of fetching data from database for single page should be changed. Development team is looking into it.
Code Review
Implement Paginations when displaying any list of records, that gives you the obvious benefit of faster subsequent page loads
Code Review
This has been discussed with the dev team.
Code Review
Below  parameters are recommended to further improve GC mechanism. \nXX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
SELECT operations on PQT tables
We recommend to carry out purging/truncation on this table on a regular basis. We recommend to  set the  purge policy based on bank 's requirement of the reports to be kept on every individual's tray.
Uneven utilization
We recommend to look into the list of processes running on both the machines and even out the CPU utlization.
Index optimization
We recommend to create a new index onTD_TRAN_TABLE table with columns (TRAN_ID,TRAN_DATE,BANK_ID).Further we recommend to monitor the existing index IDX_TD_TRAN_TABLE,  which can be dropped if it has no other usage.
Long Running ASTCL,SASCL
We recommend to move both the jobs with Priority 935,940 to anywhere between 900-920 for reduced batch timings in BKCOP.
Code Review
Set play core pool size to number of cores +1 (33 in this case).
Code Review
Invoke logic from batch job rather than from front-end.
Code Review
Make getInstance() methods synchronized.
Code Review
Used StringBuilder instead of StringBuffer. StringBuilders is faster than StringBuffer for strings concatenation.
Code Review
Store jsonNode.size() value in a variable and use the same throughout the class instead of invoking jsonNode.size() multiple times.
Code Review
'Avoid calling toString() on objects already known to be string instances; this is unnecessary.\nReference:  String tok = tokens[1].toString();'
Code Review
Make entire Ingestion flow right from download, to merge, to thumbnail generation upto final uplaod multi-threaded. Use Executor Pool service at App.java so that entire Ingestion flow is parallel.
Code Review
atime needs to be disabled by adding the command noattime for the data file partition in fstab file
Code Review
Mysql server upgraded to 16 CPU and 32 GB RAM.
Code Review
Query Cache should be enabled as it was observed that there are 30%  of the queries contributing to READ queries.
Code Review
Modify /opt/SecureSpan/Gateway/node/default/etc/conf/system.properties\n\nadd the lines\n\ncom.l7tech.message.httpParamsMaxFormPost=2147483647\ncom.l7tech.http.maxParameterLength=1000000\norg.apache.tomcat.util.http.ServerCookie.ALLOW_EQUALS_IN_VALUE=true
Code Review
/opt/SecureSpan/Gateway/runtime/etc/profile.d/appliancedefs.sh\n1)Comment out the entire if/fi block.\n2) Change the multiplier value from 2/3 to 1/2
Code Review
The limit in 90-nproc.conf was set to 100001
Code Review
memcache dependent class files missing as memcache.ini and memcache.so were missing in the memcache deployment.
Code Review
The log level was changed to warning, to capture relevant data.
Code Review
Changes in the connection parameters :\n1. pm =static\n2. pm.max_children=50
Code Review
As the volume is increasing and these tables are write intensive , it is suggested to move these tables to NOSQL DB.
Code Review
Changes needs to be done on addtoplaylist_v1.php to update the image URL and songid to playlist master for the first song.
Code Review
The heap size should be changed to 16GB. Make the changes in cassandra-env.sh and run the same so that the change is reflected in cassandra.yaml
Code Review
make changes in the cassandra.yaml to reconfigure the paths to separate disk for better i/o performance.
Code Review
Concurrent Reads=128;Concurrent Writes =32
Code Review
The php needs to be tuned to point to Cassandra DB.
Queries with high response time.
1. Rebuild indices idx_ECS_INsured_details_policyno_hCardNO and IX_ECS_Insured_details to remove fragmentation.\n2. Instead of refreshing tables in ODS instance, move them to HCS prodution instance and refresh, this will reduce intercommunication time inbetween two instances.
Large size of asp.net cache due to large number of objects in  finaliser queue.
1. For dynamic loader classes where reflection is used needs to implement dispose methods to effectively clear them.\n2. For unreleased data tables in memory we can do following in every instance of datacontext class of HCS and ODS databases.\n    - Set dataContext.ObjectTrackingEnabled to false if object tracking is not needed.\n    - call dataContext.ClearCache()
Thread contention in constructor DynamicClass.BuildUp_ECS.BL.BL.Claims.CLInwardDetailsBL
The required objects should be passed into functions as parameter instead of initializig them in constructor.
Currently Network Related Parameters are not being monitored.
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
Validation Missing
Its recommended to do NULL checking and array length checking for string[] backendValues variable before assigning its value to other variables.
Validation Missing
Its recommended to do NULL checking for  string rootNode variable before assigning its value to other variables.
Validation Missing
Its recommended to do NULL checking and array length checking for string[] messageParameters variable before assigning its value to other variables.
Hard Coded Values Found
Its recommended to fetch hard code values from config files.
Regions should be used
Its recommended to use Regions so that all the methods are kept inside the regions.
Duplicate Code Found
Its recommended to remove duplicate code.
Method Header Comments Missing
Its recommended to give Header Comments above all the Methods.
Enum Should be used
Its recommended to use Enum and call Enum for hardcoded values. Also hardcoded values should be fetch from config files.
Found unused commented code
Its recommeded to remove unused commented code.
Unwanted Method Found
It is recommended to remove unwanted Methods.
Unwanted Variables Found inside Method
It is recommended to remove unanted Varibles from Methods.
Unit Tests Projects to be added
It is recommended to add Unit Test Projects so that Unit Tests can be done easily.
New string should be set as string.Empty
It is recommended to set new string as string.Empty
IIS settings
It is recommended to set Managed Pipeline Mode to Integrated and .Net CLR Version to set to latest .Net Version in the IIS in the Production Environment.
Found same variable name declared twice in the single method
It is recommended that varible namely bool authorize should be declared only once and then assigned values to variable authorize as required.\nIt is recommended the values of ViewBag should be written in seprate method and that method should be used as required.
Hard Coded Values Found
Its recommended to fetch hard code values from config files.
Regions not used
Its recommended to use Regions so that all the methods are kept inside the regions.
Found unused commented code
Its recommeded to remove unused commented code.
Unit Tests Projects to be added
It is recommended to add Unit Test Projects so that Unit Tests can be done easily.
Disposible fields should be disposed
It is recommened to disopose or close the fileds which are of Idisposible type in Dispose method.
Found unused commented code
Its recommeded to remove unused commented code.
Un-used variable found
It is recommended to remove un used variable.
Found unused commented code
Its recommeded to remove unused commented code.
High I/o and space wastage
Need to dfragment these tables and also for other big tables need to do a periodic maintenance and purge un-wanted data.
'Incident Dt : 03/06/2016 : Low success rate observed in ONLINE. \nRCA : This issue was not reported to the LINUX team and hence they were not involved for the analysis.'
'We doubt there might be memory leakages in the Application. We have requested following details from the Online4 vendor : 1, Memory Leakage Analysis report for Online4 Application, using open source projects like Valgrind which can be used in Linux, Solaris environments for C, C++ applications for memory analysis.2, Profiler reports for Online4 Application, using open source projects like GPROF which can which can be used in Linux, Solaris environments for C, C++ applications for profiling.'
sql_id :5569bw7dmrbnr
Need the explain plan not available on OEM
The sheet  Table_stats_Details
The list of tables which have stale statistics  which need to be fixed and \nchecked daily in order to have latest statistics on them.
The attached sheets for Candidates_Fragmentation & currently _fragmented
The list of table updated in the Candidates_Fragmentation experience\n heavy DML activities. \nThus qualifying them for stale statistics and Fragmentation .\n Currently Fragmented Database shows fragmented tables
'sql_id : d8ab0m7vz11xn'
Try Index Hint inorder to encourage the use of index access instead of FTS.  .
filesystem_option Database parameter
Set the parameter to setall
'Incident Dt : 02/01/2017 :Primary node server (10.16.58.51) went into hung mode.\nRCA - ITCC Update : As per Redhat & Hardware logs analysis, they didn''t find any relevant errrors during issue occurrence. Hence Linux team is unable to provide RCA of this issue. Same has been informed to application team as well. Team Update : No issue from OS and Hardware side however Redhat suggested some commands output to be taken if it reoccur.'
'We doubt there might be memory leakages in the Application. We have requested following details from the Online4 vendor : 1, Memory Leakage Analysis report for Online4 Application, using open source projects like Valgrind which can be used in Linux, Solaris environments for C, C++ applications for memory analysis.2, Profiler reports for Online4 Application, using open source projects like GPROF which can which can be used in Linux, Solaris environments for C, C++ applications for profiling.'
'Incident Dt : 08/12/2016 : Credit Card transactions were getting declined.   \nRCA : We have received only workaround for the imd.systems which caused process to go on high CPU usage and due to which appliaction services got impacted or we cand stopped funcitoning.'
'We doubt there might be memory leakages in the Application. We have requested following details from the Online4 vendor : 1, Memory Leakage Analysis report for Online4 Application, using open source projects like Valgrind which can be used in Linux, Solaris environments for C, C++ applications for memory analysis.2, Profiler reports for Online4 Application, using open source projects like GPROF which can which can be used in Linux, Solaris environments for C, C++ applications for profiling.'
'Incident Dt : 21/01/2017 : Timeouts were observed on credit card transactions.  \nRCA :  Team faced issue due to MC advices. Team received wrong sub element 48.63 (trace id). Tag value length was not proper. The length of sub element 48.64 was not proper. Therefore it caused auth_eng which reduced from 27 to 4 Only. As per TSYS recommended the parameter to disable the duplicate length check.'
'We doubt there might be memory leakages in the Application. We have requested following details from the Online4 vendor : 1, Memory Leakage Analysis report for Online4 Application, using open source projects like Valgrind which can be used in Linux, Solaris environments for C, C++ applications for memory analysis.2, Profiler reports for Online4 Application, using open source projects like GPROF which can which can be used in Linux, Solaris environments for C, C++ applications for profiling.'
'Incident Dt : 06/02/2017  (09:00  to 09:30) : Timeouts were observed on credit card transactions.  \nRCA :  Due to logging in dump file from node caused I/O waits to search and application got impacted.'
Currently the logging in dump file was done between 9 am to 9.30 am. It is recommended to shift the timings for logging in dump file process to late night time, so that during peak hours (9 am to 9 pm) the system resources can fully be utilized for iCards Online4 transactions purposes only.
It is observed that there are many system.out.println() used for debugging \nExample:AccountDetail.java,QuickKills.java,PtlfDetailsMBean.java,TlfDetailsMBean.java and many more
It is recommended to use Log4j.debug for logging debug statements . These can then be turned off during production by keeping the logging levels as Warn/Error .
It is observed that all request and responces from various servers is done using xml
It is recommended to make xsd of request and responces and use either jaxb for xml to pojo conversion instead of parsing xml manually. Also there is a paid tool xml booster which is world fastest static xml parser tool which converts .java file from xsd and does the xsd validation also and provide pojo object from xml during runtime
Java documentation not properly added in Code Recommendations
Code Recommendations base needs to be accompanied with in-Code Recommendations documentation (javadocs etc) so that the application logic is more readable and maintainable.
'SQL_id: 83vs1160r9dz2'
Need to create index on the userid   column of the table \nIVIEW.IVW_ACTIVE_SESSION in order to reduce the cost .
'SQL_id: cp9q0y1qprt7q'
Need to create index on the userid   column of the table \nIVIEW.IVW_ACTIVE_SESSION  in order to reduce the cost .\nAlso function used in the where clause need to be removed in\n order to take advantage of the above index.
Currently iView DB Server 102 has 1 NIC card, also the NIC card data for APP Servers are requested.
Its recommended that all production servers should have atleast 2 network interface cards to avoid network failure if one cards gives any issues in real time.
Currently APM Tool Feature - Instrumentation / Java inclusive monitoring is not in used.
Usage of APM Tool Feature - Instrumentation / Java inclusive monitoring.
Currently Network Related Parameters are not being monitored.
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
Currently i-View is not being monitored in any APM Tool.
To monitor i-Vew Application using APM Tool
Best Practices
Keep firmware, Logical Domains Manager, Solaris, AIX up to date.
It is observed heavy RAM utilization on the EAI App Server HYDEAIMOM01 and EAI DB Server HYDEAIC01.
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
Currently Network Related Parameters are not being monitored.
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
Currently unwanted data/logs sizes are not removed automatically.
Usage of APM Tool Forensic Feature
Currently method level reponse details are not moinitored.
Usage of Call-Graph Feature on APM Tool
Unnecessary declaration of variables
It is recommended to directly use the input parameter to avoid the unnecessary typecasting.
Dataset object is not dispose
It is recommended to dispose of Dataset object in the finally section
Not using the specfic exception in catch satement
It is recommended to use specific exception in catch statements wherever possible.
New string variable is declared as = "  "
It is recommended to declare new string variable as string.Empty.
Profiling of Application
It is recommended to run Profiling using App dyanmics or PerfView tools at different time intervals and also before releasing any CR into production. It will give you report of method performance timing.
Unit Testing
It is recommended to use xunit framework for generating the Unit Tests.\nhttps://xunit.github.io/
Database Handling
"It is recommended to make single API for doing the select operations in\ \ all 7 databases, this way direct DB connections won\u2019t be required and other\ \ interfaces also could use this API, it will also be good for maintainability point\ \ of view and also it will reduce a lot of code in application."
Rendering Engine
It is recommended to use Razer rendering engine with .Net MVC Framework for better maintainability of code and also Razer rendering engine is faster then aspx rendering engine.
Code Commenting
Code base needs to be accompanied with in-code documentation so that the application logic is more readable and maintainable. It can be add using doxygen code commenting guidelines which can further be used for generating html and pdf help of applications for better understanding of code.
MIS Reports
It is recommended  to use Jasper Framework for generating MIS Reports (https://sourceforge.net/projects/jasperreports/?source=typ_redirect)\nOr\nCrystel Reports can also be used for generating MIS Reports
Build Automation
It is recommended to use NAnt or MSBuild tool for automatic building and running the test cases.
NFR Document
Non Function Document (NFR) should be prepared for application benchmarking for future performance testing.
Documentation
It is recommended to prepare all High Level Design/Detailed Level Design/Use Cases documents and time to time these should be updated based on new CRs.
Dev-Ops
Dev-Ops tools should be used like Bamboo (https://www.atlassian.com)  should be used for continuous integration, deployment and release management purposes.
Fast Rendering
We can use asp.net 4.5 framework bundle feature for minification of css and js files. Also suggested generic recommendation for this item.
Undersized PGA
Increase the size of PGA(Curremt 2000M) to 6G as it is showing undersize in AWR and in PGA Advisory
High executions of query with almost zero row proceed\nbg10qfjspbkvc\n1nzxvmg2vxvau\n4ky0zu2358pjj
Need to check these queries and validations of these queries
Query\n9tq94m78yy14c
Kindly check the system load I.e(CPU and Memory) before executing this query because it can lead to unnecessary resource\nconsumption during peak business hour.
Query\ndwy43ajdzj381
Kindly check the system load I.e(CPU and Memory) before executing this query because it can lead to unnecessary resource\nconsumption during peak business hour.
Query\ng7217t4mnkph6
Procedure\nCreate composite index on column hitdate,offercode,channel and userid on\ntable lop_page_hits\nAnd functional index on column pagename as there is no indexes on\nthis column or remove upper function from\npagename column and aligned this column with above\nComposite index(hitdate,offercode,channel and userid)\nas there is already function on right side on column in where condition\nWhere as no of rows in this table is almost 2.5lakhs
Query\nfww7rw6htdruz
Create composite index on column hitdate,offercode,channel and userid\nOn table lop_page_hits\nAnd functional index on column pagename as there is no indexes on\nthis column or remove upper function from\npagename column and aligned this column with above\ncomposite index(hitdate,offercode,channel and userid)\nas there is already function on right side on column in where\nCondition as there is no indexes on this column to avoid FTS
Query\n8c8urqnk5gv1b
Create index on column dest_code on both table cs_no_offer_dtl and table cs_final_offer\nCreate index functional index on cpcs_flag on table cs_final_offer\nCreate index on SUPPRESS_FLAG on table cs_final_offer
Minification of Script Files not done
'Reduction in Javascript file size through: \nRemoval of blank spaces and lines\nUse of smaller variables'
The script and script references are not at the end of page.
It is recommended to move scripts and script references to end of page.
Minificaiton and bundling of CSS style sheets
It is recommended to do the minification and bundling for CSS style sheets.
Web Server Utilization Metrics not available
APM Tool should include Web servers for monitoring
Bottleneck in Network cannot be measured
Ping statistics to be captured for all servers
Response Time' of about 12 transactions (ICICI_Avekshaa_PCMS_PerformanceReport_v1.0) in PCMS are degrading
Performance Tuning of these transactions are required
Query goin for FTS
Create index on \nColumn CSL_TRANS_TYPE,\nTXN_FEE_FLAG,&\nCSL_PAN_NO_ENCR on \nTable cms_statements_log\nThis avoid FTS
Query goin for FTS
Create index on \nColumn CCM_INST_CODE and another functional index on\nColumn CCM_ID_TYPE1,\nCCM_ID_NUMBER1,\nCCM_ID_TYPE2 &\nCCM_ID_NUMBER2\nTable CMS_CUST_MAST\nThis avoid FTS
Query goin for FTS
Create index on column CBD_PROCESS_FLAG,\nCBD_TOPU_STAT& CBD_LUPD_DATE  of table\nCMS_BATCHUPLD_DETL. \n\nAnd \n\nCreate index on column CBS_BATCH_TYPE,\nCBS_CORP_ID for table CMS_BATCHUPLD_SUMMARY
As per Pockets PPT Report in slide no 47, for the incident dated 23-12-2016 the issue occurred as the deployment done in RIB server had impacted some funtionality problems in the Pocket System.
It is recommended that respective teams should be clearly communicated for any new deployments in any of the layers in Pockets System.
Query\n1.1wv66yu716r0u  Fixed objects V$SYSSTAT\n2.c9umxngkc3byq  Fixed objects v$sql_monitor, v$sys_report_stats\n3.3ds81aj0fzq85  Fixed objects v$sql_monitor
Need to gather fixed objects stats
High executions of below queries\nDate 28th Nov 2016\n\nA>3fxatuj5jdhzu \nB>fb4hvrd9g44sa\nC>1bhkm76p82uzd\nD>2gzfkfv52rry0\nE>g9t2tuana15nn
Performnace Improvement
High CPU Utilization
'Very high CPU utilization (~100%) observed. Query resulting in Full table scan on GAM identified. \nQuery to be optimized by service provider. \nRefer: Q001 in SQL_QUERIES'
Configuration
Change the MQ Channel manager count to 1000 (CFSMGRCHL Manager)
Configuration
We have analyzed that WebMethods Admin threads are blocked by an operation which is converting ISO messages to XMLs.\nThe stack trace is -\nIndusInd_ISO8583/utils.convertISOToXML(utils.java:89)\nSource code to be analyzed
Query Optimization
Avekshaa has shared the details of the queries along with the recommendations with the bank.\nQ003 - This query is going for an FTS (on "WASADM"."SESSIONS") even though the Indexes are present on the search condition. \nQuery fired from WAS.
Configuration
Option 1 - It is proposed to use IP aliases to resolve the IP stickness configured on the Load Balancer.\nOption 2 - IP stickiness between WAS and Finacle App server.\nOption 2 was implemented.
Query Optimization
Update GEC and RCL table for corresponding columns
Memory Analysis
We had earlier recommended Singleton usage for  Resource Bundles loading. This issue has to be fixed before SVS tests can be resumed.
Configuration
The CPU utilization on ESB has come down to acceptable limits. To assess where is the time being spent, Avekshaa's has suggested softwareAG to log the time spent on ESB.
Configuration
Infosys to rvert back on what is 99 mapped to in Finacle
Configuration
Disable logging in the Uniser and CBC configuration files.Also script traces should be disabled.
Configuration
Evaluate useage of lpad,rpad. Pasting the query below for your ready reference.
Query Optimization
Query to be tuned
Configuration
The credit account was not mapped as the settlement account because of which the script was throwing an error.
Query Optimization
Query to be tuned
Configuration
The transaction should be processed by the same node in entirety, the avg. response time would be much lower than when it is processed by both the ESB nodes.
Configuration
Inode which is shared across all app servers got full, which is why there were fatal logs generated. The inode was increased from 3lacs to 6lacs. Traces needs to be off which is eating up the disk space.
Query Optimization
Stats gathering needs to be done judiously. (Stats gathering should not be done during peak hours)
Configuration
Confirm from Infosys team and remove DBA roles and assign only required privileges to users. This will help in better security measures for the database. (User List is shared with Suman)
Query Optimization
Row lock contention on  fiusb_message_table. Probably a case of Duprec happening. Infosys to explore if the commit interval can be reduced.
Design
There are lots of comments which are sent in xsl, javasctipt files which are served to the client which add to page weight and time. The comments needs to removed from js, css and xsl files which would reduce the page weight and would improve the performance.
High Response Time
Thread Pool configuration was increased from 10 to 50. Validated the CPU available which allows the thread pool to be increased to 50
High CPU Utilisation and High IO Writes
Logging is removed from iteration of code
LOS Database AWR reports were analyzed . No show stoppers were identified in the analysis.\nTotal of 2 full table scan queries were identified and listed in Appendix B
Hints for using the index were provided which would optimally use the index.
"We found the data uploaded by the Partner portal on 6-Sep-2017\ \ took 5 hours to validate and process 330 records which is too high. Details are\ \ mentioned in sheet \"Upload Statistics\"\\n \\nDetailed observations:\\n1. On\ \ analyzing the AWR reports w.r.t to the date and time of the issue, we found there\ \ was \u201Crow lock contention\u201D issue with the segment \u201CSAVED_ENGINE_MESSAGE_B_T\u201D\ .\\n2. This wait event was consuming 95 percent of the total DB time, this segment\ \ is having \u201CFOR UPDATE\u201D statement.\\n3. Query: SELECT PKID, PIID, CREATION_TIME,\ \ REASON,ENGINE_MESSAGE_S,ENGINE_MESSAGE_L,VERSION_ID FROM PSBPCDS.SAVED_ENGINE_MESSAGE_B_T\ \ WHERE (PKID=HEXTORAW(:1)) FOR UPDATE.\\n4. We found \u201CFOR UPDATE\u201D statement\ \ was running from 10:15 AM to 18:15 on 6-Sep-2017. We could not found the similar\ \ statement was running on any other day.\\n5. ROW LOCK CONTENTION: This wait occurs\ \ when a transaction tries to update or delete rows that are currently locked by\ \ another transaction."
Detailed approach to solve the problem:\n1. Use of "FOR UPDATE" should be avoided in the code.  \n2. If it is required then test with adding 'WAIT 10'  for the 'FOR UPDATE'  statement, this will wait for 10 seconds for the lock on row to be released.\n This will eliminate to  wait indefinitely for a lock to be released.\n3. The new statement will be as below.\nSELECT PKID, PIID, CREATION_TIME, REASON,ENGINE_MESSAGE_S,ENGINE_MESSAGE_L,VERSION_ID FROM PSBPCDS.SAVED_ENGINE_MESSAGE_B_T WHERE (PKID=HEXTORAW(:1)) FOR UPDATE WAIT 10;
Same static resources (like images, css, js etc) have been found multiple times in access logs shared. This indicates web server level caching is not used for static resources. This will incur exta cost of fetching these static resources from server to  clients and will put burden on network that is avoidable. At high concurrency this could potentially stress network if it is already at a threshold level. We do not have netwrok logs to ascertain whether this is currently the case.
As part of the web best practices, the static resources should be set with appropriate expiry times so that clients can cache these resources at their end. Since we are still awaiting web server cofig file, we are unable to provide with exact caching/expiry constructs. Shall do so once we get web server config files.
We found one of update query is having high execution count during upload process is going for the FTS on table OTC_ACCOUNT_HIERARCHY_INFO which is causing high cost of the query for OTC database.
We suggest to create index on table OTC_ACCOUNT_HIERARCHY_INFO with column ACCOUNT_NO.
We found one of update query is having high execution count during upload process is going for the FTS on table SR_AUDIT_TRIAL which is causing high cost of the query for OTC database.
We suggest to create index on table SR_AUDIT_TRIAL with column CRM_REFERENCE_CD.
File records are inserted in OTC database. For each 100-record batch, it makes call to SOA  Member Addition service and passes file_rk among other things. Since the contents of the file being uploaded are not sent to the SOA service, it is inefficient to make SOA webservice calls after each 100 records. This will incur unnecessary cost of establishing and discarding http connections for each SOA call. For example, For a file with 20k records it will establish and discard HTTP connections 200 times each.
Since only file_rk is sent to the SOA, there is no reason for batching to be implemented. Get rid of batching logic and insert all rows in the file into OTC database and make only one call to SOA Member Addition service. This will reduce number of HTTP connections to be established with SOA server.
All rows inside file are validated, processed and inserted to the OTC database in a single JVM thread. There is not need to keep this processing single-threaded. This will restrict throughput of the file processing engine and will not scale well.  Since CPU utiliation seen from the NMON logs shared so far, seems to be below 25%, there is a good scope to improve upon this design.
'Process rows inside a file in a multi-threaded manner. It is recommended to use Java''s Executor service to multi-thread file processing logic. Since most, if not all , of validation engine and data insertion logic is independent of rows within the file, this entire logic can, and should, be multi-threaded. Validate and insert all rows in  a file, using Java''s Executor service.\n\nBased on NMON logs shared with us, we do not see CPU pressure on any of the servers, and hence multi-threading OTC validation and data insertion flow should improve throughput of the end-to-end flow. (This is assuming SOA layer and GA already process data in a multi-threaded manner, which is most likely the case). \n\nTo start with, the Executor service''s max thread pool size can be set to 5. Based on CPU headroom analysis on all serevrs, this number can be increased further.\n\n(As pointed out in receommendation #15 above, since batching logic is unnecessary and inefficient in this flow, if that is gotten rid of first, the multi-threading of the file proecessing will be that much less cumbersome).'
Multiple update and select  queries are going for FTS on CSPS_EXCEPTIONS_RETRY with high cost, causing high execution time. \nDetails mentioned in SQL sheet.
We suggest to create composite index on table CSPS_EXCEPTIONS_RETRY with column FAILED_SR_NO and RECORD_CREATED_DT.
Uneven Portal Web server hits
"Change load balancer scheduling algorithm to \u2018Cyclic\u2019"
"Need for introducing a contemporary database access framework\ \ \u2013 \u2018DbConnectionBroker\u2019 library is used for database access and\ \ connection pooling. \\nThis is an Open-source library and has not been updated\ \ since the past 10 years. Although this library was an appropriate fit for the\ \ platform 10 years back, the advancements in application servers (for connection\ \ pooling) and availability of extremely stable/scalable data access frameworks\ \ like Hibernate/JPA/ etc prompt for a re-think of the choice."
Review introduction of a contemporary database access framework. Ideally de-couple the View and the Model before introduction of a new framework.
"Old libraries used in the application \u2013 \\nClasses12 -\ \ JDBC driver\_ - 2001 Commons logging - 2002 DOM XML Parser - 2001 Mail - 2001\ \ Servlets - 2004 SMTP - 2000 JCE (crypto) - 2001  Activation \u2013 1999\\nImprovements\ \ in further releases of both the libraries and the JDK versions is not leveraged."
Replace libraries with latest versions.
"Large Java scripts are embedded in the JSP\u2019s (observed\ \ some with 700 LOC!)- \\nJava script in JSP is rendered as inline HTML. Such scripts\ \ cannot be cached/ compressed to reduce response time."
Extract and add Java Script code in a separate Script file so that it can be compressed and cached on client side.
Currently Payment Gateway uses EJB2.1, Upgrading EJB 2.1 to EJB will improve performance
Upgrade from EJB2.1 to EJB3
Combine images to image maps or sprites.\nCompress html, css and Javascript used in MWI pages\nCombine all Javascript files to a single file\nEnable cache at webserver for far expiry date for static content like images, javascript and css files.\nConfigure E-tags which would improve performance of the static resource rendering for some of the browsers used by the merchants.
Front End Optimization for MWI component
"Currently the JDK version used is 4. JDK has improved over the\ \ time with performance and functional capabilities\\nLots of external api\u2019\ s and libraries are used in Payment Gateway currently. Newer versions of JDK has\ \ these integrated and normalized for performance. Using the latest JDK would improve\ \ performance."
Upgrade JDK 4 to JDK 5/6
Table "TrnDetails" is used majorly during all transaction. And multiple select and update queries run on the table during File Upload and Process Transactions.
Create partition on 'EnteredDt"  column on monthly basis with creating file groups on multiple disks and to create the clustered index on EnteredDt and CustomerId column. (As this is discussed together with DBA team.)
It is observed the procedure 'BC_SP_ValidateLimit' running during the transaction process going with FTS on table.
It is suggested to create index on 'Svc_Stg_Txn' table with RESERVE4,RESERVE5,Txnmode columns with include Amount,BENE_ACNO,BENE_IFSC_CODE,Trn_Status
'File: Reports\THAccountStatement\nMethod: ExportAccountSumamry\nString variable is used inside the loop. Use of string variable inside loop is resource intensive and have performance impact.\nReference: Dim tr As String = ""'
String varaible needs to be replaced by StringBuilder DataType. And should be disposed after use.
'Following error observed in application logs: "Object reference not set to an instance of an object."\n\nSession check for nothing is missing before performing operations on the session object, due to this application throws the above exception. PFB files and method list.\n\nBeneficiary\BeneficiaryMaintenance.GetBeneficiaryDetails()\nFTPay\TrnConfirm.displaydetails()\nTransactions\FTOtherBank\NewTrnBenRtgs.Page_Load()\nTransactions\AuthTrn.fillproducttype()'
Session check for nothing needs to be implemented before performing operations on the session object.
'It is observed that "delete from #temp" statement is used for deleting the data from temp table in procedure "ID_SP_FileLevelAuth" which is expensive operation.'
It is suggested to use truncate statement for record deletion.
It is observed that the query running with table trndetails is with high cost.
We suggest to create index on TrnDetails table with column CustomerID,Status,ValueDate with include Amount. (Before partition it was present on production database.)
'"Request Time out" error while Authorizing the File containing 1,00,000 Records.'
'Request Execution Time should be increased from 120 seconds to 200 seconds in web.config file.\nReference: executionTimeout="200" in httpRuntime Tag'
Showing SQL*Net more data from client in top wait event from AWR reports.
We have tested on local database and found by setting the array size with sample size 1000 , we could see an improvement of 50% reduction in response time on local database. Hence advised to change the array size with 1000 in the UAT environment .
It itrates over bidDetails arraylist to fetch BidDetailsBean using pBidReferenceNumber. This is not a optimal design espeically if it ahs to iterate over long list.
Store BiDDetailsBean in a Hashmap rather than Arraylist. Use BidReferenceNumber as key and ASBAApplicationBidDetailsBean as a value.
It validates file extension using String indexOf. Also, it will accept wrong file extensions too (for example, file with extension cs or sv will be accepted).\nAlso, ALLOWED_FILE_TYPES.toUpperCase() is not neede as String is initialized with all upper case already.
1. Use HashMap with file extension as keys. \n2. Remove unnecessary calls to toUpperCase().
The hand-coded logic of splitting a given string using a given delimiter with a 2-pass phase is not needed.
Use Java String's split method to split a given string using a given delimiter.
From a access logs shared for a day (8th Dec), there are 2.67K HTTP requests that come back with HTTP code of 404.
Either place missing resources on Web serevr at appropriate location or remove calls to these resoucres:\nfavicon.ico\n/eipo/bidux/fonts/HelveticaNeueLTStd\n/apple-touch-icon-120x120-precomposed.png\napple-touch-icon-precomposed.png\n/eipo/bidux/images/loading.gif\n/wp-login.php\n/eipoadmin/bids/css/images/orange_top.jpg \n/issueforms/html/images/blockbg.jpg
During our analysis on Production Server monitoring during live IPO , we have observared that there is a memory leak on Database Server and memory utilization is going beyond 80%
'We need to upgrade Windows Server OS & MS-SQL Server to the latest version for following reasons:\n1) To fix the memory leak issue on DB server\n2) Windows 2008 R2 OS support from microsoft got over in 4/9/13\n3) SQL Server 2008 R2 mainstream support ended on 7/8/14\nNote: Application functionality to be tested on UAT Server before Production Migration'
NoData
'Increase APP Server CPU from 4 to 8  Expected Improvement: Response Time will come down by half'
NoData
'Increase APP Server Memory from 4 GB to 8 GB.\nExpected Improvement: Response Time will come down by half'
NoData
'Increase initial heap size to 2000 MB\nExpected Improvement: Response Time will come down'
NoData
'Increase Max heap size to 2000 MB\nExpected Improvement: Response Time will come down'
NoData
Repeating the login steps needs to be avoided.
NoData
Login statement looping should be avoided.
NoData
Enable client caching for jpg, gif,  other images
NoData
Enable client caching for css (*.css)
NoData
In a day 48K requests are not been server by web application because of 404. If this links are not in use, please remove from the application.
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
Other ASPX Pages,/faworkstation/allrecords.aspx, /faworkstation/CallHistory.aspx, & /faworkstation/CallSearch.aspx pages general observation
"1. Implementation caching for recurrence of accessed data.\\n2. \u201C\ Select isnull(birthdayalert,7O) birthdayalerdays from tblfp_parameters\u201D such\ \ a statement should be avoided in all the pages. This SQL statement is note executed\ \ by a procedure call. This is hard coded in the pages. If it is not a valid default\ \ values is applying which can be taken care by application itself rather executing\ \ the SQL function. Again this can be avoided by the caching\\n3. Avoid the nested\ \ table html design\\n4. Use always client side validation\\n5. Use JQuery more\ \ on client side.\\n6. Inline javascript always perform below the page."
NoData
1. Implement caching for the lookup values which is used by pages\n2. Implement SQL dependent caching for SQL lookup tables \n3.  Avoid Server side validation and provide wherever possible client side validation\n4.  tblfp_parameters is the general for application which is frequently used more. Such a rarely unchanged data to be cached by application server.\n5. Use Ajax wherever is possible.\n6. Try use JQuery\n7. Avoid inline query and move to js  file\n8. Use minimize technique for JS files\n9. Use minimize technique for CSS files
NoData
We suggested defragmenting these indexes by rebuilding each index used for this table. This will improve both selects as well as inserts onto the tables, improving the offline report generation as well as improving the online transactions, leading to reduction in timeout instances.
NoData
Either remove CONVERT function or put the conversion logic in application layer rather than database layer.     2.We have gathered execution plans without using CONVERT function for heavy load generating reports like Show transaction , Analyze transaction and Search Cases.
Number of records from CACHE is different from records received from STUB
Some keys maintained for each Supplier were not valid
Total breakdown of multiple request hits , till we encountered the desired number of records from CACHE.
After correction, it was observed that on 5th,6th request we received desired number of records- hence identified that performance issue with Coherence implementation.
Total breakdown of multiple request hits , till we encountered the desired number of records from CACHE.
Loggers were introduced in the deployment on our suggestion & identified - The operation of Putting records in CACHE is SYNCHRONOUS process, suggested to be concurrent
Total breakdown of multiple request hits , till we encountered the desired number of records from CACHE.
The records received were not product specific, but supplier specific, hence suggested to introduce Product as a key too
Total breakdown of multiple request hits , till we encountered the desired number of records from CACHE.
Error handling for long time running leads to Thread blocked, suggested to handle it by introducing TRY - CATCH block
Total breakdown of multiple request hits , till we encountered the desired number of records from CACHE.
Huge time was taken for getting records from CACHE, introduced milliseconds delay in the test runs, identified JSON conversion issue - taking more time
Query execution time is high due to large size of the table.
Table size should be adequate.
Queries started taking more time for execution.
Need to check new parameters and its recommended values before upgrade.
Blocked Threads has been observed for the Logger.info() method.
Set logging level to error
Observed 7 to 8 minutes delay in stage processing of orders
Recommneded to increase the threads from 1 to 5.
No version control tools used.
"Better patch deployment management \u2013 Use Version control tools like\ \ TortoiseSVN."
High Availability.
Deploy the reporting webserver component on web server 1 and webserver 2 as well. Start these additional instances only if there is a failure on the reporting server.\nHave additional JVM instances running on the application server 1 or 2 which can be started when the primary application server is unavailable.
High Availability.
Currently the response time of MWI home page is not less than 3 seconds when accessed anywhere from India. This can be reduced by implementing Front End Optimization techniques
Heap memory values not changed
Values were changed after being brought to notice
Addition of Nodes on Server 4/3/2
We recommend adding 1 extra node for server 2/4 . Additionally 1 extra node can be added to server 3 since its memory has been increased .
Code Review
We recommend to implement all the code review points.
Uneven Server Hits
We recommend to find out the root cause of this behavior and take correct actions (change of settings / taking up with SAP).
NoData
Customization team to assess if these queries are necessary to be run during business hours . Implicit functions used in the select is causing the query to take a lot of time.
NoData
i.Defragment CUSR,IPAY tables
NoData
Set tcp_fin_timeout to 10 secs in sysctl.conf
NoData
Creating multiple instances (5) of Apache Tomcat
NoData
Disable response time logging in server.xml
NoData
C Library changed to LibUV in HttptoKafka
NoData
Changing Partitions of all the Topics from 30 to 60 in Kafka
NoData
"Configuration of DSR will help to \u2013 \\nAvoid manual intervention to\ \ start the VM instance        in case of failover.\\nAutomated Resource Balancing"
NoData
Removal of one log file member from each group had reduced log file sync wait event database time by 35-40 %.
NoData
During load test undo retention was set to 25000 which was on the higher side. DB team has changed it to 1800.
NoData
Hard parsing queries in application needs to be fixed, which will help to reduce CPU utilization on database server.
NoData
Using DB link avoided for same database.
NoData
A combination of front end (browser level) and back end (server side) validations is proposed. Java open source community offers a good set of options for data validation frameworks. \n1. We recommend that either Hibernate Validator OR Spring Validator be used for Data validation on the server side. \n2. Posabsolute can be used as a validation framework for the front end (browser) forms.
NoData
We recommend using Jasper as the reporting framework for the application
NoData
We suggest that the available logging framework be customized for persisting critical events in the application. Log4J (recommended logging framework) provides an option of persisting the log details in a database. Custom logger classes can be created and used at points in the application where auditing information is to be captured. \nCustom UI screens can be developed to extract the auditing information from the relevant database tables for compliance checks/ auditing needs
NoData
"Monitor service end-point performance:- Define SLA\u2019s at the end points.\ \ \\n Monitor end-point performance vis-\xE0-vis SLA\u2019s\\n If thresholds are\ \ consistently breached \u2013 \\n Raise alerts\\n Mark down end-points \\n Selectively\ \ disable features that require these end-points\\n Control request amortization\ \ levels (See next slide)"
NoData
Optimize Connections:- Avoid creating a fresh TCP connection for every request and alleviate connection \nmanagement overhead.  \n Build connection pools for different systems and re-use the connections amongst \nmultiple requests
NoData
"Web server machine failure can add severe load on the other operational\ \ server:- Consider adding a web server to reduce load on the operational server\ \ in case of \\nmachine outage. \\n Web servers are currently functioning as reverse\ \ proxy\u2019s without any heavy \\nprocessing. Instead of adding high end servers\ \ that can run multiple server nodes \\nevaluate the possibility of introducing\ \ multiple low cost rack servers that can run\\none or two nodes. \\n This will\ \ increase redundancy and reduce impact of outage of any server"
NoData
DevicePrint.jsp\nIssue\nDevicePrint.jsp was not used for any functionalities on \nthe RetailLogin Page but had very resource intensive \ninline Javascript which was blocking the page rendering
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData
NoData

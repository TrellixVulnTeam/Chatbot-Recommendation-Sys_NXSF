recommended keep firmware logical domain manager aix date
Performance enhancements are continually added to AIX OS, it is recommended to keep updating for latest operating system versions.
observed ubps app server 215 around 138 active o service app server active service feel 138 o service count ubps app server higher side
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
currently network related parameter monitored
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
currently memory utilization benchmark available ubps vendor
To gather memory utilizaiton benchmarks from UBPS software vendor
high execution queriesndate 8th december 2016nna 3fxatuj5jdhzu nb fb4hvrd9g44sanc 1bhkm76p82uzdnd 2gzfkfv52rry0ne g9t2tuana15nn
Performnace Improvement
high wait event
'Recommended to append the NOWAIT or WAIT(X) parameters to these queries to avoid the contention\nRefer: Q002 in SQL_QUERIES'
performance
Test to be re-run to re-produce the observations for further analysis
query optimization
This query is going for an FTS even though the Indexes are present on the search condition. This contains an implicit data type conversion on indexed  column "USER_ID". This implicit data type conversion prevents the optimizer  from selecting indices on table "SSOADM"."SSO_MODULE_ACCESS_TBL".\nCreate a functional index for optimizer to pick up the correct execution plan
query optimization
Option 1 - Evaluate possibility of reducing the commit interval at application layer \nOption 2 - Increase the INI_TRANS from 1 to atleast 64
configuration
Need to increase the pga_aggregate_target to a suitable value. You can set it up to 2 GB and have a test run.
memory analysis
"We suggest that we have a common file for stopping and starting the services\ \ where we have a sleep of 30 secs after the stop sevice is executed. This will\ \ ensure that all services are brought down, and there are no service in the hung\ \ state. \\nTo validate further, we can have a ps \u2013ef |grep lisrvr|grep maria|grep\ \ limo to check if all the services have been brought down before a restart is initiated."
query optimization
Recommended in memory parsing of XML messages instead of current mechanism of doing a filesystem operation
configuration
Recommended a lower thread connection setting (reduce from current setting of 500 to 50-75 threads per ESB node).
query optimization
1.Index on utr field needs to be created.\n2. Sequence Cache size increased to 20. \n(Alter sequence owner.sequence_name cache 20) -\nSequence Names - \nTrasanctionidsequence \njob_id_seq\nonline_job_id_seq
query optimization
Index creation needed on utr as well as on routing_ref_num
query optimization
The cache size of the sequences were increased from 0 to 40.\n(Alter sequence owner.sequence_name cache 40) -\nSequence Names - \nADT_REF_NUM_SEQ_IB\nFT_TRAN_NUM_SEQ_IB\nFTTRAN_NUM_SEQ_20120601_IB\nRTGS_SEQ_NUM_SEQ_IB\nPORH_SEQ_NUM_SEQ_IB
query optimization
1.Temporary Tablespace got full and as the Resumable_Parameter was set to 1800, it was waiting for the tablespace to be increased, and not giving any error to the end user. This led to slowness of the upload program. After adding the temp file, this issue was addressed.\n2. Stats Gathering is happening in middle of the upload program. This needs to be disabled.\n3. 3. We have observed that there is a query which is being run on the database which is taking more than 2 secs per execution. The total no. of executions are over 30,000 records.\n4. /finundo mount point is 100% utilized. Though there is sufficient free space available on the undo tablespace, we propose to create new undo tablespace and drop the older one which will free up the space on the mount point.
query optimization
1. Deployments at 107 and 108 are not in synch.(product exes are not in synch)Prima facie, it needs to be ascertained that all nodes are in synch to rule out any issues due to difference in deployments\n2.  We opine that there could have been a memory clog on the application due to high no. of records processed. When the next run is done, we would want to have the NMON running on the application as well as DB server to ascertain the same.
configuration
Avekshaa has tuned these queries and the redundant data has been removed. Also queries have been written in a more optimized manner.
query optimization
There is a query on DTD which is going for a full table scan with the below query. Create index on dtd.ref_num or check for the functionality of this query, to understand why this query is being used. If this query has to be used, the index on ref_num is required.
query optimization
CSIS, ESB and MQ should be isolated from the current architecture setup and should be hosted on separate dedicated hardware for better fail-over handling
configuration
Infosys should recommend appropriate value for process parameter based on the expected workload .
nodata
There was a noise because of which these queries were being run. These sessions were killed.
configuration
The server has only 4GB ram with so many components. These components needs to be configured in separate servers.Recommended to increase the server's physical memory which is currently only 4GB
configuration
CBC,Uniser logs are enabled. Also script traces are enabled leading to higher response on Finacle side. Needs to be disabled.
configuration
Mount points to be created on separate disks to improve IO performance
configuration
Recommended to have maxsize defined as 4gb for  datafiles and add more datafiles to tablespaces to avoid space outage. This will help in IO distribution of the system as data size increases
query optimization
FTS on TAM table.Instead of sol_id, bank_id is being used in the query. As Bank_id has only one value, the table will have a FTS. Wrong configuration done for TD-Receipt printing.
configuration
Need to have stats to be gathered on fixed objects using "dbms_stats.GATHER_FIXED_OBJECTS_STATS" package of oracle.
query optimization
This query was fired from the customized Interface finacle script /finacle/appln/Finacle/FC10.2.9/app/cust/01/INFENG/scripts/INT8023Post.scr. Infosys to analyze and apply the fix.
design
Compression of all static files needs to done for all the static contents serverd
design
All javascript which are currently placed in <HEAD> Tag of the html page needs to be moved to bottom of <BODY> html element if these javascripts are not used for rendering objects on the page. Java scripts are blocking the page to render the page.
design
All Jar files which are related to Finacle Product needs to be added to white list in Macafee scan policy.
design
PMR to be raised with IBM and apply the patch for AIX which would fix the issue
design
This process needs to be automated, to avoid any manual intervention during actual failover
high cpu utilisation high io writes
Logging is reduced
observed thread consuming maximum cpu looping hashmap object used commoncodecache class
It is recommended to use ConcurrentHashmap in multithreaded environments instead of Hashmap/Hashtable
jvm parameter analyzed found certain parameter optimal
Default garbage collection policy was changed to Gencon and Maximum heap size was reduced to 2gb .
'method private void soafinalcall map string string mphdtls block processing logic invoke soa service block dead code removedncurrent code n filedeatilsset variable always empty hence dead code nif   filedeatilssetisempty    '
Dead code needs to be remove for easy maintenance of the application.
huge 3400 line long class file without comment code
Comments should be written in the code as per the code functionality for easy maintenance of the application.
string used concatenation le performant put exta burden gc
Use StringBuffer or StringBuilder whichever is appropriate for string concatenation.
us linkedhashmap keyvalue pair incur cost maintaining insertion order also consume memory
Use Hashmap rather than LinkedHashMap, where insertion order is not relevant.
initial heap set 4 gb max heap set 8 gb extra proccessing cost incurred dynamically growing heap allocation 8 gb initial 4 gb gc happening time
Set both initial and max heap size to 8 GB. Use -Xms 8192M -Xmx 8192M
field row file inserted otc database clobs field formatted concatenated form clob object incurs extra cpu cost concatenating string field also put extra stress jvm gc
Insert all fileds as separate columns in OTC database. This will save on heavy string concatenation which is currnetly being done to form a CLOB. If currently, the CLOB is built in a format that is exactly as required by GA, then it is OK to stick with current design. If SOA needs to do transformation of this COLB to a format required by GA, then current design should be abandoned and each field should be saved as a separate column in the database rather than as a single CLOB.
file record updated otc database row dump table row make call otc database update form data inefficient make database call every record file 20k record update database 20k time
Batching logic needs to be implement while performing the database operations. Database update needs to be performed in a batch of 100 or 1000 or so.
method processxlsxfile always returing 1 hence logic file handling needed
Check the logic of method and remove unnecessary code if needed.
observed gc cr block lost wait event awr analysis top wait event high db time soa databasenndetailed observation n1 many lost global cache block transfer hamper application performance block need resent lead wait second transfer completen2 analysis observed latency approx 4 m network ping interconnect ip 1692545928 private ip 1921681035 n3 network latency causing gc cr block lost wait event
We recommend to raise the issue to network team.
observed sized memorytarget parameter impacting performance database soa database
We suggest to set memory_target  and memory_max_target parameter to 67GB from current value of 47 GB
observed otc database approx 3300 table 44 schema soa database approx 7000 table 82 schema soa database
We suggest to drop the unwanted schemas and tables from the live database.
observed table highly fragmented soa database
Defrag the high fragmented tables, which will release the space and improve the performance of the database. Tables list mentioned in "FRAGMENTED_TABLE_LIST_SOA" sheet.
'based dynatrace data cpu utilization soa server minimal 10 resource like network io also look utilized '
SOA Server Thread Pool that interacts with GA and SOA DB should be increased by atleast 5X. If current max size is provided to us, we can suggest the optimal size for this thread pool.
jms messagelistener used read jms queue jmsotcbulkrequestq processing bulk upload file parner app server 28 due issue listener configurationdeployment processing happenning since 6th september
Rather than using MDB, it is recommended to start a new thread to process Bulk Upload File. There is no need to have any JMS Queue for this processing.
file system error observed o kernel log crmdb1 database server around 60k error instance observed log 12th 13th october 2017nnerror detail next4fs error device dm8 ext4lookup1044 inode 1183475 comm java deleted inode referenced 1183519next4fs error device dm8 ext4lookup1044 inode 1183475 comm ologgerd deleted inode referenced 1183519next4fs error device dm8 ext4lookup1044 inode 395360 comm updatedb deleted inode referenced 525266next4fs error device dm8 ext4lookup1044 inode 395360 comm java deleted inode referenced 525266next4fs dm0 initial error 1470201788 ext4mbgeneratebuddy736next4fs dm0 last error 1504937203 ext4mbgeneratebuddy736next4fs dm11 initial error 1463625680 ext4mbgeneratebuddy736next4fs dm11 last error 1463625680 ext4mbgeneratebuddy736next4fs dm6 initial error 1463591423 ext4mbgeneratebuddy736next4fs dm6 last error 1504889102 ext4mbgeneratebuddy736next4fs dm8   initial error 1463591420  ext4mbgeneratebuddy736next4fs  dm8   last error 1507830355  ext4lookup1044  inode 1183475next4fs  dm8   last error 1507917055  ext4lookup1044  inode 1183475
Please raise the issue to Linux Server Team.\nPlease check, whether the issue still persist on OS Kernel Logs. If yes, then check/repair the file system using fsck command.
large number static hit portal server static page make 85 hit 72 bandwidth
Static content can be cached to reduce bandwidth utilization, reduce server hits and improve end user experience.
failed request constitute 10 hit crm server
Eliminate the 404 errors. This will reduce about 10% hits on the server once the static content is cached.
vm restarts
Oracle patch is recommended but cant be tested out due to year end freeze
strong coupling view model nmvc1 architecture implemented strong coupling view model observed lead maintainability issue error prone change db result change view layer undesirable
An additional layer for handling database related logic must be added to disassociate the View from Model. The database layer can invoke Hibernate/ JPA/ etc at the back-end.
"batch uploads processed serial manner \u2013 nbatch upload process\ \ currently block worker thread per upload synchronously processed making user wait\ \ current design scale beyond point number uploads volume record batch increase\ \ hw may getting optimally utilized need confirm analyzing utilization level "
Design a batch scale-out framework by leveraging open-source batch frameworks like Spring Batch, Quartz. \nIdentify batches that contain transactions which can be atomically processed as candidates for the batch scale out framework .
scope data caching application layer nstatic relationship like productproduct type groupcountries need loaded database every request data cached avoiding io database improving response time page
Identify data elements that change in-frequently .  Introduce caching framework (like EHCache, Memcache) or implement a simple caching structure like Hashtable to cache the data. Data refreshing mechanisms must be put in place.
web page optimized specifically help branch low bandwidth nusers branch connected 64 kbps link consitently complaining performanance issue crucial reduce network chatinness well size data
Techniques like Image compression, Image/ JS /CSS Caching, CSS Image sprites to be  implemented to reduce network IO and load on the web server to  complete http page loading request. \nFor Weblogic, introduce web server (like apache) for compression.
vector heavily used application nvectors ideal multithreaded access synchronized call execution required collection vector otherwise add overhead access required
Replace Vectors with ArrayList
implementing new io sfa gateway componentnthe new io nio apis introduced v 14 provide new feature improved performance area buffer management scalable network file io
Implementing New I/O at SFA and Gateway Component
'procedure svcspenqtrxn isnull used column txnrefnum customerrefnum operation resource intensivenncurrent code n txnrefnum refnum isnull refnum    trcustomerrefnum   refnum isnull   refnum       '
Check for @RefNum should be handled before calling the procedure. And OR and ISNULL should be removed from the query.\n\nCode should be:\n(TxnRefNum = @RefNum OR TR.CustomerRefNum = @RefNum)
observed procedure bcspvalidatelimit running transaction process going ft table
It is suggested to create index on 'Svc_Stg_Txn' table with RESERVE5,Txnmode columns with include amount,rem_mobileno,Trn_status
high cpu utilisation high io writes
Logging is reduced
high cpu utilisation high io writes
String objects removed for unwanted logging
high response time
Executor Thread Pool is used
high response time
Its recommended to use StringBuilder instead of StringBuffer after careful evaluation of multithreadedness of the piece of code.
high response time
It is recommended to use Stringbuilder instead of String class where there are lot of concatentations used . Stringbuffer can also be used in multithreaded environments
high response time
It is recommended to compute the length/size value at the start of the loop and assign it to a variable . This variable then can be used in the loops
high response time
It is recommended to log / process an exception .
high response time
It is widely recommended to separate multiplex redo and control files on different disks(raid 1).
high response time
It is recommended to use String.isEmpty() for checking for an empty string.
high response time
It is recommended to catch specific exceptions eg Catch (FileNotFoundException e) first.
high response time
It is recommended to set debug="false"
high response time
It is recommended to create index on table "User_AccountLink" on columns "UserId", "CustomerId"
high response time
It is recommended to create index on table "TrnDetails" on columns "CustomerID", "CustomerRefNum", "EnteredDt"
high response time
'Recommended to append the NOWAIT or WAIT(X) parameters to these queries to avoid the contention\nRefer: Q002 in SQL_QUERIES'
high cpu utilisation
Core dump on LISVR to be analyzed.
high response time
Change the MQ Channel manager count to 1000 (CFSMGRCHL Manager)
high response time
We have analyzed that WebMethods Admin threads are blocked by an operation which is converting ISO messages to XMLs.\nThe stack trace is -\nIndusInd_ISO8583/utils.convertISOToXML(utils.java:89)\nSource code to be analyzed
nodata
NoData
high response time
Message broker needs to be tuned for the required load. SoftwareAG to change the configuration as per the load.
high response time
Avekshaa has shared the details of the queries along with the recommendations with the bank.\nQ003 - This query is going for an FTS (on "WASADM"."SESSIONS") even though the Indexes are present on the search condition. \nQuery fired from WAS.
high response time
This query is going for an FTS even though the Indexes are present on the search condition. This contains an implicit data type conversion on indexed  column "USER_ID". This implicit data type conversion prevents the optimizer  from selecting indices on table "SSOADM"."SSO_MODULE_ACCESS_TBL".\nCreate a functional index for optimizer to pick up the correct execution plan
high response time
Q005 - This query is going for an FTS even though the Indexes are present on the search condition. Thiscontains an implicit data type conversion on\n  indexed column "USER_ID". This implicit data type conversion prevents the\n  optimizer from selecting indices on table "SSOADM"."SSO_RESOURCE_ACCESS_TBL".
load distribution
Option 1 - It is proposed to use IP aliases to resolve the IP stickness configured on the Load Balancer.\nOption 2 - IP stickiness between WAS and Finacle App server.\nOption 2 was implemented.
multiple insert signle table
Option 1 - Evaluate possibility of reducing the commit interval at application layer \nOption 2 - Increase the INI_TRANS from 1 to atleast 64
multiple time property file read
If the changes in properties files are not expected to change very often then it is not necessary to load the file every time. The same ResourceBundle can be used across requests. It can be controlled through a Singleton
nodata
Need to increase the pga_aggregate_target to a suitable value. You can set it up to 2 GB and have a test run.
nodata
We had earlier recommended Singleton usage for  Resource Bundles loading. This issue has to be fixed before SVS tests can be resumed.
nodata
Recommended in memory parsing of XML messages instead of current mechanism of doing a filesystem operation
nodata
Removal of un-wanted logging. Currently all incomming messages, messages processed at ESB and response messages from Finacle and converted messages are stored in database. Recommended softwareag to remove all these unnecessary loggings and to keep the messages stored only in case there are any failures or timeouts.
nodata
Recommended a lower thread connection setting (reduce from current setting of 500 to 50-75 threads per ESB node).
nodata
The CPU utilization on ESB has come down to acceptable limits. To assess where is the time being spent, Avekshaa's has suggested softwareAG to log the time spent on ESB.
nodata
Evaluate useage of lpad,rpad. Pasting the query below for your ready reference.
nodata
The credit account was not mapped as the settlement account because of which the script was throwing an error.
sequence exceeds maxvalue
1. Max value for this sequence can be set to higher in order to avoid such issues in future.\n        2. This also could be handled during EOD run (Finacle to confirm on this) in this case the data to be flushed out in the relevant table and reset the next value to 1.
tablespace full
1.Temporary Tablespace got full and as the Resumable_Parameter was set to 1800, it was waiting for the tablespace to be increased, and not giving any error to the end user. This led to slowness of the upload program. After adding the temp file, this issue was addressed.\n2. Stats Gathering is happening in middle of the upload program. This needs to be disabled.\n3. 3. We have observed that there is a query which is being run on the database which is taking more than 2 secs per execution. The total no. of executions are over 30,000 records.\n4. /finundo mount point is 100% utilized. Though there is sufficient free space available on the undo tablespace, we propose to create new undo tablespace and drop the older one which will free up the space on the mount point.
slowness script
Avekshaa has tuned these queries and the redundant data has been removed. Also queries have been written in a more optimized manner.
nodata
There is a query on DTD which is going for a full table scan with the below query. Create index on dtd.ref_num or check for the functionality of this query, to understand why this query is being used. If this query has to be used, the index on ref_num is required.
3 different application installed sampe physical box
CSIS, ESB and MQ should be isolated from the current architecture setup and should be hosted on separate dedicated hardware for better fail-over handling
o limit set 100 db node
Infosys should recommend appropriate value for process parameter based on the expected workload .
unwanted logging observed
Inode which is shared across all app servers got full, which is why there were fatal logs generated. The inode was increased from 3lacs to 6lacs. Traces needs to be off which is eating up the disk space.
swap due low memory
The server has only 4GB ram with so many components. These components needs to be configured in separate servers.Recommended to increase the server's physical memory which is currently only 4GB
unwanted trace enabled
CBC,Uniser logs are enabled. Also script traces are enabled leading to higher response on Finacle side. Needs to be disabled.
db stas gathered
Stats gathering needs to be done judiously. (Stats gathering should not be done during peak hours)
mountpoints tablespace disk
Mount points to be created on separate disks to improve IO performance
dba role available database
Confirm from Infosys team and remove DBA roles and assign only required privileges to users. This will help in better security measures for the database. (User List is shared with Suman)
database datafiles autoextend size high
Recommended to have maxsize defined as 4gb for  datafiles and add more datafiles to tablespaces to avoid space outage. This will help in IO distribution of the system as data size increases
table lock observed
Row lock contention on  fiusb_message_table. Probably a case of Duprec happening. Infosys to explore if the commit interval can be reduced.
stored procedure optimised
Changes in the query to not include predicate in the query, as this will not use the index on addr_id.The procedure needs to be reviewed  to fix all such cases where wrong predicate is used.
nodata
Need to check with application logic behind running such queries concurrently. Also nowait can be appended to 'select for update' query to reduce row lock contention.
nodata
The root cause of the performance issue is that there are lot of transaction on the frozen accounts which are going into entered state. Infosys will internally explore this further. If the transactions are posted for these frozen accounts without the need of proxy posting, there is a huge time and effort saved on this batch program which will lead to reduction of total TAT of the EOD process.
nodata
FTS on TAM table.Instead of sol_id, bank_id is being used in the query. As Bank_id has only one value, the table will have a FTS. Wrong configuration done for TD-Receipt printing.
o limit le
Identify connection leak from livsvr processes , since DB has defined parameter to 2000, which worked fine in earlier tests with 10K users
nodata
All javascript which are currently placed in <HEAD> Tag of the html page needs to be moved to bottom of <BODY> html element if these javascripts are not used for rendering objects on the page. Java scripts are blocking the page to render the page.
nodata
All Jar files which are related to Finacle Product needs to be added to white list in Macafee scan policy.
nodata
PMR to be raised with IBM and apply the patch for AIX which would fix the issue
unnecessary logical block written
Recommended to remove the unwanted operations from the source file. This will help in faster execution of logical blocks and hence improve the performance. Also the objects created inside this block will get eliminate which result in low memory consumption.
multiple unused package import
Avoid the use of unused import statements to prevent unwanted dependencies.
use stringbuffer
Use StringBuilder instead of StringBuffer if expensive thread-safe operations are not required. StringBuilders is faster than StringBuffer for strings concatenation.
string comparison handled properly
'Use Position literals first in String comparisons for equals/equalsIgnoreCase. \nExample: obj.equalsIgnoreCase("AnyString"); // should be "AnyString".equalsIgnoreCase(obj)'
printstacktrace  written catch block
Avoid printStackTrace(); use a logger call instead. call printStackTrace() on an exception the trace is written to System.err and it's hard to route it elsewhere (or filter it). Instead of doing this use a logger call instead.
unnecessary object created
Comment out the unwanted instance of StringBuffer object.
observed hard coded ip address
Avoid using hard coded IP. Externalizing IP addresses is preferable.
knockoutjs binding causing frequent rerenders
One choice to avoid these re-renders would be to instead use the visible binding on a container element around our section or on the individual elements.\nIf we prefer to use if binding in this case, then we need to make sure that it is only triggered when the number of items in our array moves between 0 and 1
knockoutjs pushing item observablearray loop
A better pattern is to get a reference to our underlying array, push to it, then call .valueHasMutated(). So that the subscribers will only receive one notification indicating that the array has changed.
'file reportsthaccountstatementnmethod exporttoxlwithlogonfollowing error observed application log process access file c windowstempalignpicture1xlsx used another process nnsame file used generate report user multiple user try generate report time error occur report generation failed '
Please use the same method for excel file creation that is used in other places.\nOr needs to append UserId in the file name to make unique file for every user.
index table file group
We suggest to create separate file group for the indexes which will split the IO on different mount points. We can start with important tables like TrnDetails and det_TrnAuthDetails
observed query running uploadtracking going ft procedure idspdsclockfile
We suggest to create index on column IsLocked with include LockedBy on UploadTracking table.
error process access log file observed writelog method file appcodebbpsapploggervb load bill payment
It is recommended to remove "Throw ex" from "Catch" block.\nSuggestion for better logging during high load:\n1. Log File name based on date and userid\n2. High Performance Logging Technique such as log4net
'loopinglogic suboptimal nnfor int lptr lrecordstart lptr ltotalreccount lptr n string lrecord lrecords lptr trim n lrecordlength 0 n continue n listransactionupload n string lcontents commonutilitiessplitstring lrecord lfieldseperator n boolean lfoundblank false n int lcount 0 lcount lcontentslength lcount n commonutilitieshasvalue lcontents 0 lcount 0 first element blank thenn scan elementsn n commonutilitieshasvalue lcontents lcount n lfoundblank true   found blank scan next elementsn continue  n  else  n lfoundblank  false   found non blank breakn break  n  n  n  n  lfoundblank  n continue  n '
1. Each loop iteration is reading first array entry only. This can be extracted only once outside the loop.\n2. When first element is non-empty,  it will loop through foe all elements and will check for first entry again and again. \n3. Also, looks like  else block can be added to below if block and break the loop. This will avoid uncessary looping through all elements within records.\n\nif (!CommonUtilities.hasValue(lContents[0]) && lCount > 0) // if first element is blank then scan other elements\n      {\n\n4. The entire logic looks unnecssary as it is not achieving any meaningful result.
caching resource expiry duration enabled web server
All static web resources like (images, CSS, JS etc)  should be set expiry dates so that clients can cache these resoucres till the expiry time rather than picking from the web server each time. This avoids unnecessary trip to the server.
bulk file upload related thread seen app1 server s thread dump app2 server nalso total http request web1 access log 9658 web2 access log 2404
Check the load balancer configuration and its routing alogorithm. If routing algorithm is round robin the load on both app servers should be balanced.  Once load is properly balanced, both app servers utilization levels will match up.
'default gc policy set jvm may ideal application usage scenario especially throughput based scenario like bulk file upload '
'Since the production Java version is greater than 1.7.0_u4 (1.7.0_u76) the adaptive GC policy of G1 is recommended. Since core funtionality of the application caters to Bulk File Upload, which is primarily throughput driven rather than response time, the GC policy of G1 is best suited in this case.\n\nAdd G1 setting to JVM parameters as shown below:\nset JAVA_OPTS=-Xmx4G -Xms1G -XX:+UseG1GC -DSource=. -DAPP=EIPO1\n\nNote : Add above parameter on UAT first and then move it to both PROD App servers, App1 & App2.'
query fired fetch lmemberentitybean nevr used query unnecessary
Remove call to lAppEntityDAO.findById().
obsered query running high batchfilerecords table high cost
Create index on table BatchFileRecords with BFRBFId column.
obsered query running high asbaapplicationtransactions table high cost
Create index on table BatchFileRecords with AATUsId  column.
observed one query running broadcastmessages table running high execution count approx 9 per second ie approx 32000 per hour
Please check for reducing the frequency of this query.
high execution count
'Recommendation: Create index on table TBL_APPLICATION_TEMP with column ACCOUNT_NUMBER'
nodata
'Set thread pool size as follows (min = 100, Max = 100)\nExpected Improvement: Throttling will improve'
nodata
'Set JDBC Thread Pool size as follows (100).\nExpected Improvement: Throttling will improve'
nodata
To be implemented. Query times will come down by at-least a half
nodata
Response Time of some transactions (posting) were brought down to half
nodata
Overall system performance was observed when Heap Size was increased to 2GB
nodata
Needs to avoid opening & closing connection for each login steps
nodata
Is compression enabled/disable?  If enabled, then disable the compression and measure the performance.  If disable, then enable the compression and measure the performance.
nodata
Enable client caching for javascript ( *.js)
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
"CallSummaryReport.aspx:-1. Perform only client side validation.\\n2. Restrict\ \ the date range From to To. The application now allows free date rage, which will\ \ end of selecting huge records. It would rather allow at a given time or a click\ \ can only take 30 days data\u2019s or range is restrict by commonly accepted.\\\ n3. Avoid displaying more records, provide the proper paging algorithm to avoid\ \ the response time and SQL"
overall response time entire si component bad
Suggested to make some optimization in the transformations performed on records received from STUB
nakshatra lookup took huge time
Suggested some optimization techniques & XML marshelling technique for Nakshatra calling
supplier operation lookup take place layer
We could just point out method names that are consuming time.However a ticket is raised with Oracle for the same
also proactively suggested lb config
Currently , we are analyzing trial & errors for various confuguration changes to Suppoert & LB team & then testing to look for the behavious of the issue.\nAnalysis of this still underway.
single user test case higher payload
Suggested Wrapper implementation, that would split the high payloads to multiple request of smaller payloads
brms migration 64 71
Highlighted this alongwith jersey marshelling warning encountered in logs.\nRedhat suggested some config changes & got better performance
multiple interdependant call
Suggested to remove the unconditional calls to user module
multiple interdependant call
Recommended to put user module to cluster mode for better scalability
multiple interdependant call
LB team were unable to understand the issue, required some config changes.
multiple interdependant call
Proved same methods are called repeatatively, suggested to remove
multiple interdependant call
Query been fired at MDM layer were of too large payloads, suggested to get only required data.
multiple interdependant call
Too large queries been fired on DB. Suggested to optimize queries fired & pass on common data if required to reduce number of joins on the query
huge time single request
Suggested to optimise the threads involved for Kafka + Breakdown of time taken at each layer proved optimisation required at SI , MDM & Commercial Cache components
temporary table space identified db server
If you know total block size, bytes/block then you can find out,you're limited to individual data/ temp files of upto\n[total blocks * no. of bytes/ block / 1024^3)] Gb.
found stale stats perticular table
No stale stats should be observed for the transaction tables.
ora01555 snapshot old cause rollback record needed reader consistent read overwritten writer
We can minimize the error using optimal parameter values.
high row cache lock wait event
Check the cache size value for the sequences.
enq index contention observed top wait event awr report
NoData
high enq sqcontention observed top wait event awr report
Check the cache size value for the sequences.
wait event log file switch observed awr
NoData
query full table scan due started taking time execution
NoData
multiple thread waiting get connection connection pool web server
The connection pool size needs to be increased
static content served portal server taking time
Recommended to serve static contents from Web (OHS) servers.
version control tool used
"Automated patch deBetter patch deployment management \u2013 Use Version\ \ control tools like TortoiseSVN.\\nployment instead of manual patch deployment\ \ \u2013 Can use Maven/Hudson."
manual patch deployment
"Automated patch deployment instead of manual patch deployment \u2013 Can\ \ use Maven/Hudson."
debuging enabled
"Create a debug patch with more loggings onto the Application Server to\ \ check the exact cause of issue \u2013 Debug patch can be deployed in case of any\ \ issue."
tail utility installed server
Install the tail utility for windows on all servers to debug bigger logs.
maintenance
Create roll overs every hours rather than everyday, for easier referencing to the log.
manual start stop service
Automated Scripts to start and stop services on all components.
maintenance
Do a soft boot everyday, hard boot (preferably Sunday)once a week.
maintenance
Run, Avekshaa Memory identifications scripts whenever high memory consumption is observed.
maintenance
Continue to run Avekshaa Monitoring Perfmon Counters through Task Scheduler.
maintenance
Run Avekshaa Monitoring netstat and tracecert scripts in case component failure is observed.
nodata
Netty based asynch communication
one thread per connection thread pool
16 Netty worker thread pool to cater to current load.
1 socket opened nac host
16 concurrent sockets are opened between NAC and Host.
singlethreaded nac client listener bottleneck
Multi-threaded NAC Client listeners to improve throughput.
1 mq session created per iso message creating mq session costly operation creating 1 per message bottleneck
MQ session pool is created at the server startup. This improves throughput of the system.
loop count calculation condition
This will cause the operations to execute on every iteration. So it is recommended to store the calculated value into a variable and then use it within the for loop condition.
unnecessary operation immutable object
Remove all such operations from code
string replace method call split new character
Split the String directly with "@" character.
unnecessary clear function call empty map
The map will be empty after this call returns. - This is not required as map is already empty. Performance overhead.
unnecessary call constructor
These are not required, removing this will improve performance
multiple trim call string object
Only one call is enough as the string is already trimmed.
redundant call client app backend
Change the if condition to some variable flag rather than on pastpaynorep html element
redundant call client app backend
Change the if condition to some variable. And use the cached data.
redundant call client app backend
Change the if condition to some variable flag rather than accsum.length
redundant call client app backend
Change the if condition to some variable flag rather than cardlessPayeeList().length.
hard coded useragent value
This is not required and may cause issues in content-targeting. So proper user-agent value should be passed as the application is targeted to Android and iOS platforms.
unnecessary string concatenation
This is not required and operationId itself can be used further.
unnecessary string value check
These are not required, removing this will improve performance
unnecessary getsafevalue method call
Remove the method call.
unnecessary call generatefailureresponse  method
Check the else condition and if not required remove the call made to generateFailureResponse
unnecessary call stringutils method
Remove these redundant calls
unnecessary condition
Validate the logic here and remove the if condition as it seems to be Unnecessary
sql query column name
Replace select * queries with the required column name.
missing null check object holding data received external system
Put a null check on such objects (here goals) before performing any operations on it.
setting attribute logic end
Since HttpServeletRequest is immutable. So these attribute changes should be removed.\n\nThis need to be discussed with development team for understanding why this is being done. As no oveeriden method was found to map these immutable entries.
nodata
Check the connectivity and performance of CDCI Component
nodata
NoData
nodata
Need to review the indexes on the tables in detail.
nodata
1.Distribute the datafiles on different diskgroups. \n2. Redistribute the objects based on utilization frequency. Move highly utilized objects(Tables/Indexes/Partitions) to seperate tablesopaces.\n2. Define a keep pool and pin the highly accessed indexes and small tables in the keep pool.
nodata
NoData
nodata
Follow below steps to get chained rows details.\n1. execute the UTLCHAIN.SQL to create the table to store chained row's rowid's.\n2. ANALYZE TABLE table_name LIST CHAINED ROWS INTO CHAINED_ROWS;\n3. Then query the CHAINED_ROWS table to find out the details.\n\nRectify these chained rows by moving the tables to another location using uncompress clause.
htm credit amount tab hang intermittently
NoData
application able scale 4000 concurrent user
NoData
index reached maxextent
The MAX_EXTENT should be increased by bank.
currently data compression enabled oh
Page size data is currently being tracked through loadrunner web page diagnostic feature. Enable compression at OHS.
high response time frontend load balancer
Optimize the configuration of frontend load balancer to handle failures and high response time in transactions.
high error percentage
NoData
high error percentage
Finlistval services instances to be reduced from the previous count of 200 to 100
na
Set the current cahce value present in production database. We will fine tune based on further testing results
user unable login
Extend the tablespace size by 32GB. However we are parallely checking on a policy to truncate this table on regular intervals for better maintenance
latch free event found bby database
1) To check the functionality of the query to retrive only one tran id since all the fetched tran id are not allocated to a variable through cursor             2) To use acid instead of foracid and avoid a subquery on GAM table
query taking high cost execution
In the where clause of the query a wrong condition to pick up the index on sol_id is specified.(sol_id >= '!'). This is to be corrected according to the funcationality requirement
could read response server
None
high response timein transaction tested load balancer
NoData
sql statement consuming cpu
The SQL can be re-write for less CPU consumption.
large number timewait connection
NoData
high response time due latch free event
NoData
fatal error hddmiadd transaction
NoData
high response time rampup stage
NoData
high failure high response time selectfincore transaction 3rd node
NoData
issue new menu
NoData
high response time
NoData
full table scan swiftmsghistorytable table
Check with infy about functionality if (tran_id, tran_date) columns can be added in WHERE clause. It will reduce cost to 1.\nElse create inde on BANK_ID, utr columns.
response time meet sla
NoData
response time meet sla
NoData
response time meet sla
NoData
response time meet sla
NoData
response time meet sla
NoData
response time meet sla
NoData
response time meet sla
NoData
wlservletsessions table wasadm schema getting populated
NoData
response time meet sla
NoData
response time meet sla
NoData
high page download size login page
NoData
high page download size select fincore
NoData
high page download size htm action
NoData
calendergif fetched browser cache
NoData
high page download size hcashwd transaction
NoData
application hang tabout enter amount
NoData
mq broker creation throwing ioexception causing le number broker created bottleneck
Exception removed so that all MQ brokers are created and throughput is improved.
singlethreaded mq reply message listener bottleneck
Multi-threaded (16 threads) MQ reply message listeners configured to improve throughput.
300 mq request message listener configured process incoming message consuming resource without throughput gain
Optimal value of 120 request message queue listeners is set to reduce resource utilization.
caching
Caching is introduced. Queries which are seeking the same data multiple times are being cached now.
column many table using large data type consumes lot memory ad overhead index use column
Each column was evaluated and correct data type was identified. This helps with faster index lookup. Lesser space taken by indexes.
stored procedure using nocount hint lead additional return row information never used stored procedure
Enabled the hint NoCount to reduce additional overhead.
"stored procedure using exec execute tsql \u2019 efficient"
"Changed to using \u2018sp_executesql\u2019. This is Microsoft certified\ \ way of running Transactional Sqls."
read query stored procedure running without lock hint leading unnecessary lock table
Read queries now run with NoLock hint to reduce locks on database and make the query execution faster.
unnecessary use drop table command end stored procedure add little overhead since temporary table anyways deleted sqlserver end session
Removed drop temp table commands. This avoids overheads.
design
"1 \u2013 Horizontally scale the JVM\u2019s i.e. add more number of JVM\ \ components to sustain the load. This will\\nhave to be done along with hardware\ \ augmentation (mainly memory). \\n2 \u2013 Add another web server to handle the\ \ load. Failure of one server will not over-load other server."
design
"\u2013 Deploy the AHS component on the other web servers as well. Start\ \ the component if there is a failure\\non the reporting server."
design
"\u2013 Augment the memory component on the Web server 2 to at least 8 GB"
design
"\u2013 Add separate JVM instances for MPI for handling Online e-com transactions\ \ that are NOT initiated from \\nIVR"
design
"1 \u2013 Horizontally scale the JVM\u2019s i.e. add more number of JVM\ \ components to sustain the load. This will\\nhave to be done along with hardware\ \ augmentation (mainly memory). \\n2 \u2013 Add another app server to handle the\ \ load. Failure of one server will not over-load other server."
design
Implement Oracle RAC
design
Vertically scale the Reporting App server by adding another server instance if the availability is critical
design
This area needs a review of the entire batch design and a solution cannot be proposed in isolation. The current solution is not scalable.
nodata
Asynchronous and Parallel processing must be leveraged to handle the process of email creation and delivery.
nodata
Connection pooling to be implemented as a part of the overall email solution.
nodata
Add indexes and change logic so that the indexes can be utilized
nodata
Range partitions proposed on the CP_PAYMENT_DETAIL table.
high availability
Add more JVM instances on both the web server 1 and webserver 2. \nStart the additional instances only if one of the webserver fails.
nodata
Combine all the js files into one and reference it at the bottom of the html
nodata
The comments from these two pages needs to be removed as these pages has the maximum hits.
nodata
The query once is being executed with status in the where clause and again without it. Please look at the logic of executing this query.
nodata
Set Minimum Heap Size to 1 Gb and Maximum Heap Size tp 2 Gb\nJAVA_OPTS="-Xms1024m -Xmx2048m"
nodata
Running multiple instances (20) of HttptoKafka
nodata
Setting following in sysctl.conf:\nnet.core.somaxconn = 65536\nnet.core.netdev_max_backlog = 65536\nnet.netfilter.nf_conntrack_max=1024000\nnet.netfilter.nf_conntrack_generic_timeout=120
nodata
Creating more Partitions (10) in Kafka
nodata
Code of HttptoKafka needs to be fixed accordingly
nodata
Code of HttptoKafka needs to be modified to allow to configure Partitions per Topic
nodata
'Introduction of Apache/ Nginx as a Reverse proxy in addition to the Hardware Load balancer to take care of Caching/ compression of data was recommended in week #1. However, Citrix team has confirmed that Caching/ Compression can be enabled at Netscalar as well. We recommend that these features be enabled on Netscalar to reduce hits on Application server.'
nodata
agEncoder instance is running only on one application server. This is a single point of failure.
nodata
CCM instance is running only on one application server. This is a single point of failure.
nodata
Changes are recommended for distributing files across disks for optimal IO activity
nodata
Setting optimal value of SDU parameter will help to reduce the wait events..  To set the optimal SDU value ,  further more PT test and analysis need to be conducted in the NFR environment
nodata
Application logic needs to be changed to fetch required no. of records.
nodata
All the end users of the system will be authenticated and Access Control List will be configured through the use of Spring Security.
nodata
We recommend Log4J be used as the logging framework in the application.
nodata
Given that there are quite a few batches that move data between source systems like Finacle/ CAR/ CDOC and CMART/CCM we recommend that a comprehensive framework like Quartz be implemented.
nodata
We recommend that Hibernate be used as a ORM tool for the persistence layer
nodata
"Markdown services in  case of unavailability:- End point monitor \u2013\ \ analyzes logs to identify consistent failures (eg. ConnectException)\\n Monitor\ \ marks-down services if end point is not available. Alerts admins.\\n Application\ \ \u2013 must have capabilities to enable/disable features based on end point \\\ navailability\\n Should have capability to mark-up services and re-instate features\ \ as they become \\navailable"
nodata
"Reduced IO by pre-fetching data during high load duration :-Pre-fetch data\ \ that is static/ almost static before the high load duration (start of month)\\\ nfrom the end points (example, User relations \u2013 cards/ loans from CAR)\\n Data\ \ can be maintained in memory at each JVM OR as a distributed memory cache\\n Will\ \ help in reducing the IO operations during high loads and reduce load on other\ \ \\nSystems\\n Synchronize cache based on load on the system"
nodata
Reduce Db reads by caching master data:-The Db server is currently handling both Read/ Write operations for Transactional\nas well as Master data\n It is handling load from all the app server nodes. In the absence of scalability option\n(RAC) it is critical to reduce the load on the db so that it does not become a \n bottleneck device. \n Depending on the frequency at which Master data changes, can the master data \nbe maintained in Cache (either distributed memory cache like Memcached/Jboss \nCache or per JVM cache)?
nodata
Reduce IO ops at  the web server:-Compressing static content,Reduce IO ops at  the web server:-Cache expiry must be optimally set, as per this report from Page Speed (Google tool), Reduce IO ops at  the web server:-Introduce caching at Load Balancer or Web server level to reduce the number of \nhits to the application server. Will lead to better bandwidth utilization.  \n Enable web browser caching by adding expiry headers for static content (Java script, \nCSS, images)\n Introduce compression for static content like JS, CSS, HTML
nodata
The code should be removed from the jsp which removed the delay of downloading the capicom.cab file and octget.dll from different Microsoft mirror sites. SignonScript.js was an external Javascript file which had functionalities for CAPICOM, this javascript was also removed for this fix.
nodata
The issue was studied from all layers, All networking components were studied using \ntracert to see if the issue is with any of the components in the network. The \nRoot cause analysis uncovered that the virus scan is causing the delay as \nFinEcEcApplet.jar which is the applet used for retail login forces McAfee OnAccess \nscan to scan even the base class files and archive files in class path which ended up in \n1.5 minutes of delay in Response of Retail Login Page access for first time. Discussion \nwith Infosys product team and architecture team was done and a solution which \nwould exclude the applet was provided which solved the 1.5 minutes of response \ntime issue completely
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
crm configured node
NoData
high page download size hpordmadd transaction
NoData
able achieve targetted tps
NoData
connection persistent multiple request tabout account number field
Check http connection persistance at NLB.
high page download size hddmiadd transaction
NoData
high page download size hddmipost transaction
NoData
shortage swap memory issue
Increase the swap size from 500 MB to 51 GB
large size css file
File size of all .css files can be reduced considerably by compressing  them. Page size can further be improved if all .css files are clubbed into maximum one or two css files. This will help in reducing number of round trips and will help improve response time . Also comments should be removed.
high page download size hacm verify transaction
NoData
high page download size cif address modify transaction
NoData
high page download size hfti transaction
NoData
use literal rather bind variable
Explore the feasibility of using bind  variables.
rule based scan oracle 11g
Perform gather stats on user schema CRMUSER.
connection leak
Analyse the code to validate whether all connection and related objects are being closed properly in both success and exception conditions.\nQueries need to be tuned (already reported).\nConnection pool settings need to be revisited for harvesting the idel/unused connections so that they are returned to the pool quickly
query taking high cost execution
Index present on PAYSYS_ID and BANK_IDENTIFIER. But the WHERE clause contains only BANK_IDENTIFIER. PAYSYS_ID is available in the script. This should be added in the WHERE CLAUSE of the query
high page download size cif phoneemail modify transaction
NoData
high page download size hbdtm modify transaction
NoData
fatal error hacm verify
NoData
high page download size icianwcsverify transaction
NoData
high page download size hoaacsbadd transaction
NoData
high page download size hoaaclaadd transaction
NoData
response time meet sla
NoData
response time meet sla
NoData
high response time able scale tps
NoData
full table scan accountsmod table
Recommend to analyzed below tables ASAP.\nACCOUNTS_MOD\nPARTNER_REP\nPERSON\nPHONEEMAIL_MOD
deadlock detected
NoData
batch job execution
NoData
batch job execution
NoData
batch job execution
NoData
nodata
Explore possibility of adding new machines to reduce the load on 8 GB RAM machines. Check page fault behavior after hardware augmentation.
nodata
"Reduce the amount of exceptions getting triggered and logged in the log\ \ files. \\nRoll-over the file at the end of every day/ every 100 MB\u2019s."
nodata
Evaluate if scripts in top 10 pages or so can be externalized and then minified, compressed and cached for optimizing the download time and network bandwidth utilization
nodata
Evaluate if java scripts used in top 10 pages or so can be combined into 3-4 scripts based on the functionality. Infosys involvement required for the analysis
nodata
"Reduce size of applet \u2013 \\n- Remove the class file - TBAProcessor.class_30JUNE2008.class\ \ - from the jar. This is an invalid class file and cannot be used. This will reduce\ \ the size by about\_ 13% since the size of the file is about 37 KB.\\n- Compile\ \ the source with -g:none option to remove the debugging information. This reduces\ \ the size between 5-15%.\_\\n- Use tools like PMD to identify and remove unused\ \ classes and methods from the jar file."
nodata
Evaluate the option of storing the static content on a couple of web server accessed through a load balancer. Static content will thus be downloaded only once from a web server.
nodata
There is an opportunity to reduce the response time at the Load Balancer end. Currently, the Load Balancer reads through FAB_Master.txt file for every request and creates a multi-dimensional array (holding items like url, port, max-users etc against the FAB Id).\n\nBased on single user test on my machine I am observing that this process consumes almost 90% of the total time taken by the Load Balancer. I am proposing that since the file does not change often, we should not read and build the array for every request. The array should be re-built only if the file changes. Based on tests on my machine, I think this will cut the over-all response time by more than 80%.\nCan we have this approach reviewed by the development team?
nodata
CPU's are getting stressed significantly when the EOD/ BOD batches are executed. Very high queue length is observed. Need to check if the batch load can be re-distributed before the server saturation starts affecting batch windows.
nodata
Number of interrupts on CPU 512 was very high compared to other processors. Its in the range of 8-10K while others are less than 1000. This can slow down the processes attached to this CPU. \nNeed to log a call with SUN Admin to analyze further. This has been discussed with the production team (Nitin Gupta)
nodata
Machine with 32 GB RAM machine is showing signs of low memory.  High paging activity was noticed. Server needs to be augmented with memory. \nAlternatively, the load on the server can be reduced so that the number of processes are reduced
nodata
OS level:\nIn Veritas enable VxFS  options (e.g. "mincache=direct" and "convosync=direct") for Direct I/O or Quick I/O feature ONLY for ALL Oracle filesystem files.\nDisable Veritas filesystem cache.\nOR\nEnable VxFS Direct I/O or Quick I/O feature on a per-file basis to bypass the above problem.
nodata
"\u201Clog file sync\u201D is as high as 15% DB time\\n- Redo logs in faster\ \ sub system required (RAID 0) \\n-LGWR and ARCH should be reading separate disks\ \ \u2013 needs to be reconfigured"
nodata
"1) \"cursor: pin S\". This is a Oracle Bug\\nBug with Oracle \u2013 touch\ \ base with Oracle support to get fix \\n2) \"latch: session allocation\". Highest\ \ users # 18,454\\nDB is hitting sessions limit and will cross the limit soon. Review\ \ following parameters\\nshared_server_sessions is set as 17500.\\nlicense_max_sessions\ \  is set as 21000\\nlicense_max_users is set as 13500\\nlicense_sessions_warning\ \ is set as 1900"
worker handle 1024 simultaneous connection
It is strongly recommended that to deploy Nginx on Linux OS for better Performance and High Scalability.
slow query affect database performance overall application performance
The slow query log feature needs to be enabled in MySQL Database. This feature in MySQL enables logging of queries that exceed a predefined time limit. This greatly simplifies the task of finding inefficient or time-consuming queries. The long query time should be set to 1 second. Periodic monitoring of slow logs needs to be required for fine tuning of the application.
opening closing database connection every request add overhead mysql database impact response time apis
Database connection should be persistent and same connection should be used for multiple requests communicating to the MySQL Database.
ifoundry application hosted genie application server 162  sharing environment genie application application
It is strongly recommendaded that to move other applications to a diiferent server.
application hosted mysql database 81
It is strongly recommendaded that to move other applications to a diiferent server.
upstream connection nginx app server persistent
Upstream Connnection should be persistent and same connection should be used for multiple requests communicating to the App Server. Connection KeepAlive needs to be configured on Nginx Configuration.
multiple database server low memory available
1) We suggest to increase 50%  memory on the server inorder to handel 3x load.\n2) Also need to move any other application database present  on the server to a different server inorder to reduce the resource crunch
control file mutiplexed
The control file should ideally be stored on different location (multiplexed ) as to protect the database in case of any media coruption on the disk .
risk losing datafiles redo log
1) We recommend to separate Datafiles from On-line Redo Log Files as this reduces LGWR and DBWn contention.\n2) It also reduces the risk of losing both Datafiles and Redo Log Files if a disk crash occurs.
average execution time 299 520 sec
The Query is executed on the AUD$ table hourly, which can be executed only when needed.
high resource consumption
The reporting queries are heavy and need to be executed post business hours or on the DR site to avoid resource consumption and to create more headroom for the production queries.
average execution time range 250 370 sec
This query is executed from the OEM (Oracle Enterprise Manager),Ideally this queries the audit table and if the table has high number of records then the audit table needs to reduced periodically .
high resource consumption
Output of getUserDetails API needs to be cached on Nginx or Im-Memory-Cache for better Performance. Nginx can be used as a caching layer and these requests will be served from Nginx itself.
high resource consumption
Output of getProduct API needs to be cached on In-Memory-Cache for better Performance. And these requests will be served from App Server itself.
duplicate call
Implementation needs to check and Redundant calls needs to be removed to improve the performance.
duplicate call
Implementation needs to check and Redundant calls needs to be removed to improve the performance.
high resource consumption
For high performance applications, Debug Mode should be disabled. Please set this value to debug="false" on production web.config file.
high resource consumption
For high performance applications, Debug Mode should be disabled. Please set this value to debug="false" on production web.config file.
high resource consumption
For high performance applications, Debug Mode should be disabled. Please set this value to debug="false" on production web.config file.
high memory consumption
1) We suggest to increasing the SGA  memory by 6 GB on  server for  handeling  the current load.\n2)Also once the SGA memory for the database is increased, then available memory on server will be limited so inorder to support the expected 3X load the memory needs to be increased by 30 %.
availaibility issue
1)We recommend to separate Datafiles from On-line Redo Log Files as this reduces LGWR and DBWn contention.\n2)  It also reduces the risk of losing both Datafiles and Redo Log Files if a disk crash occurs.
availaibility issue
1)These queries with high resource consumption &  execution time need to tuned and corresponding indexing need to be validated .\n2) Also need to consider data purging where it is possible. Partitioning of the table will also be helpful but this may need additional license
high resource consumption
Important to have statistics updated as it helps to improve the   query executions . So we suggest to check statistics bi -weekly and schedule the stats gather activity in non working hours.
risk losing datafiles redo log file disk crash occurs
1)We recommend to separate Datafiles from On-line Redo Log Files as this reduces LGWR and DBWn contention.\n2)  It also reduces the risk of losing both Datafiles and Redo Log Files if a disk crash occurs.
database slowness
The table fragmentation needs be to taken care as the query execution is hampered  .
database slowness
1)These queries with high resource consumption &  execution time need to tuned and corresponding indexing need to be validated .\n2) Also need to consider data purging where it is possible.\n Partitioning of the table will also be helpful but this may need additional license
database slowness
Important to have statistics updated as it helps to improve the   query executions . So we suggest to check statistics bi -weekly and schedule the stats gather activity in non working hours.
availaibility issue
1)We recommend to separate Datafiles from On-line Redo Log Files as this reduces LGWR and DBWn contention.\n2)  It also reduces the risk of losing both Datafiles and Redo Log Files if a disk crash occurs.
workflow delay
Open Source alternatives are available which can replace Filenet system. We propose adoption of OpenKM or Apache Jack Rabbit which fits the requirement of TeBT. The application can be hosted on AWS and AWS-S3 can be used as storage to store the physical documents. However, both these alternatives do not support OCR. In our assessment, OCR feature is not used in Filenet (in the current TeBT platform).
workflow delay
Need to convert this batch process as web service integrating with TeBT application so that it can be called dynamically. And it should appear as bucket list on TeBT OPS portal for each scrutiny user for the scrutiny process, so that he/she can act immediately on assigned applications.
workflow delay
1. There are a lot of adhoc requests which are not getting tracked. We strongly recommend that for any adhoc request on running these batches, it should documented and published so that there is an accountability on execution of each batch job and its impact on the system as a whole.\n\n2. It is also recommended that for batches which takes higher time for processing, there is a clear case for converting them into real time service. In case of jobs running in a batch, it is observed that the job will wait in the process queue, until the batch is triggered. This means that the job will be waiting idle until it qualifies to be executed in the particular batch. This in result will lead to jobs getting delayed in the entire workflow. If these batches are converted into real time service, the job will be executed then and there and will be made available to the next process queue. This will benefit in total turn around time of the jobs.
workflow delay
It is recommended that the batch execution frequency is reduced from 30 mins to 10 mins. Next workflow task for scrutiny will be available 20 mins faster than the current scenario.
high cpu utilisation high io writes
This is a known bug and we have  raised a PMR (service request) with IBM on the same.  PMR number is TS001340458\n\n1. We need a patch for the current BPM version - 8.0.0.5 (This patch has been provided for 8.0.1. Pls see if this can be retrofitted for 8.0.0.5).\n\n2. We propose an upgradation of the current BPM version to the latest stable version (8.5 or greater). This will also ensure we have support from IBM as the current version is desupported. \n\nThe patch will ensure the email notifications are not locking the table, in result impacting slowness in BPM and TeBT platform as a whole.
workflow delay
We propose an upgradation of the current BPM version to the latest stable version (8.5 or greater). This will also ensure we have support from IBM as the current version is desupported. \n\nThe application currently writes around 300 records per second. This is impacting the input/output streams. This will be optimised and the BPM application response time is expected to improve further.
workflow delay
It is a product bug and the fix will be available in next release.
high response time
The OEM license and setup is already available with HDFC Life. It is highly recommened that we start utilising the OEM capabilities to monitor the heath of all Oracle Databases.\n\nThis will benefits us in the following :\n1. To do database administartion activities for RAC database and clusterware.\n2. To identify the performance issues quickly.\n3. To tune the bad performing SQL's using Oracle's SQL Auto Tune feature.\n\nHowever, pls note that the performance tuning pack in OEM is a paid feature in OEM and need a spperate licence for that. We suggest to also procure license for the performance tuning pack as well.
high response time
'We propose to increase JDBC connection pool across all the SOA layers (Front office, back office, Branch and BPM - WAS clusters). \nThe proposed increase is by 50% where existing connection pool value is less than 110. For values more than 110, there is NO change is required.\nNote: \n1) Please make changes to only those data sources which are related to TeBT application flow, other need not be changed.\n2) Please make one changes to one WAS cluster at a time. Once it''s stabilized then proceed for the next cluster. \n3) Also, do not make more than one change at time to ensure that it can be rolled back\nThis will ensure the system has higher pipeline to accommodate more connections/requests. In the embedded image, proposed plan to implement the connection pool across all the related servers have been highlighted.'
system lag statbility tracebility
Use APM tool to monitor the systems, alerts.
old framework used net
It is recommended to use .Net 4.5 framework
process document available
In SDLC Process we must prepare HLD, DLD, Sequence Diagrams of each workflow and User Manual documents.
nodata
Maintain NFR document.
maintenance
Please enable the index monitoring on the tables like DET_TRADE,DET_TRADE_DELETED. Please drop the indexes if not used by any queries. It will release the space and improve the performance of the related queries significantly.
maintenance
1. Please gather the statistics for important tables on reguler intervals..\n2. For highly transactional tables, reduce the frequency(Interval) of the gather stats.\n3. Instead of collecting the stats for entire table, we can collect the stats on partition only which is stale stats(In case of Partition tables).
maintenance
Defrag the high fragmented tables, which will release the space and improve the performance of the database. Tables list attached.
server configuration
'It is recommended to set Thread pool settings in Machine.config as given below:\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs'
large size file
It is recommended to use pdf file formats for better compression. It is also recommended to use Black and White Form and in that also there should not be any background filled block and Century Gothic font should be used.
high cost query
We suggest to create composite  index on DET_TRADES table with column  TRXN_TYPE and TRXN_STATUS.
high cost query
The index suggested in previous recommendations will reduce the cost significantly.\n1. The index on DET_TRADES with TRXN_TYPE and TRXN_STATUS.\n2. The index on DET_TRADES_DELETED with REDEEMED_FLAG.
design
1. It is recommended to create new databases for BLOB images and move all the scanned images BLOB data in it. (We can keep 2 DB Server having BLOB data into it)\n2.It is also recommended to create the tablespace  with 16 K block size for new BLOB database for image data for faster retrival.\n3. It is recommended to keep one month data (Depending upon requirement) on OLTP  database and purge the BLOB data from OLTP database to BLOB database on Monthly / Weekly basis using custom scripts.
design
It is recommended to take RMAN full backup and RMAN increamental backup.
design
once split the IMAGE database and OLTP database with dfferent databases then create new databases w.r.t each schema for OLTP.\nIn single server we can have 6 databases. The server configuration will remain same.
design
It is recommended  that every database should have unique database names while going with spliting of the database.
design
It is recommended to  check the possibity/other alternatives for eliminiting the use of FOR UPDATE statement according to your business logic.
high count execution
1. It is recommended to create index on SCHEME_CODE on table POSTING_DATES.\n2. The cost of the query will be reduced 1/3 of the existing cost which will result in faster execution of the query.
high cost query
1. It is recommended to create the index on INVESTOR_MASTER table with UPDATE_SERIAL column for the MFAMFI  schema.
proper naming convention
'it is recommended to give proper names to each table for easy identification and maintenance.\nExample: ITNET_MODULE_WORKFLOW_TABLE\nITNET_ADMIN_USER_MASTER\nITNET_SIP_DAILY_TRANSACTIONS'
high cost query
It is recommended to create index on DET_TRADES table with TRXN_TYPE andTRXN_STATUS column.
high cost query
Check the logic of the queries and reduce the cost of the queries listed.
high availability
It is recommended to implement RAC Database for handling the future load and for better scalability.
design
It is recommended to to convert IT.Net in  3 Tier Architecture for better scalability and maintainability.
design
It is recommended to check all required OS Services in UAT environment and enable only those required services in Production Servers.
design
An index on foracid,inst_alpha and inst_num to be added.The TRIM function on the WHERE clause fields needs o be removed.
design
The result set which is joined between GAM and DHT should be less to reduce the high temp space utilization. Please check with the vendor as to why two WHERE clauses of the same nature (APPLICABLE DATE field) is present in the query.Also please check the feasibility of reducing the data fetched for JOIN by extracting data between two dates instead of extracting data which is less than a given data
design
The data type of EMPLOYEE_NUMBER to be changed to varchar of the same size of USER_ID field of LGT table
design
Bank to check to check the functional index usage and recreate the index with the respective functional index on sol_id field
design
An additional sol_id condition by joining the GAM table with SST table for set_id ALL to be added in the WHERE clause
design
The TRIM funtion in main WHERE clause needs to be removed, Subsequently the data storage of column TRAN_ID of AXIS_CREDIT_CARD should be left padded as in DTD table by using LPAD function. Currently this data is right padded
design
Increase parallelism for the job groups in the application. HSCOD parallelization to 60 and BJE jobs parallelization to 70 and common env parameter to 50 from current value of 40
design
Recreate the index with revise column position as per below.\nTO_NUMBER(SOL_ID),TRAN_DATE,SENT_FLG
design
Perform De-Fragmentation operation e.g. CTAS, Table movement, export-import, DBMS_REDEFINITION
design
It is recommanded to use compressed image to load and view in Formware application. We have tested the same image after using compression and observed that the total time taken to load and view image has come down to 11 secs from 14 secs for a 1.4 MB file. (Apprach document has also been shared).
design
Indexes needs to be created on column ORN for table TBLDEMATNSDLDATA
design
Indexes needs to be created on column ORN for table TBLDEMATNSDLDATA
design
Index on ORN,NSDL_Batch needs to be created on table tblDematData
design
Index needs to be created on tblCaseStatus on ORN column and on tblHoldReason table for PassNo and SrNo.
design
Index needs to be created on TBLFWIMPORTDTLS on FORMTYPE column.
design
The business logic should be checked to see if any where clause can be added along with the joins. Table TBL_STEP should be defragmented.
maintenance
These tables needs to be defragmented.
parallelism used
As TBMS application supports multithreading, Large size files need to be split into smaller files and need tobe  processed in parallel.
maintenance
Large Volume tables needs to analyzed frequently before the month end operation.
maintenance
Analyse REP_MATURITY_REPORT table before generating this report.
design
'1) The query needs to be modified to tune the view. \nAn index is already present on cbl_disc_date, however it is not being used because the column is being used in a decode function -- DECODE (cbl_tenor_id, ''B'', cbl_bill_date, cbl_disc_date).\n2) Functional index can be created on this function\n\nE.g :     create index temp2 on cfs_bill_log (DECODE (cbl_tenor_id, ''B'', cbl_bill_date, cbl_disc_date))'
design
Please modify the query to add jl_start_time is the query for the current index to be used or create an index on JL_STATUS.
design
The view needs to be rewritten to either not use this table or use a join instead of not exist as it will help eliminate FTS on this big table.
design
The view needs to be recreated to use the indexes involved. It needs to be checked if the order by is really needed.
design
Create  indexes on CM_OPEN_DATE and CM_CLOSING_DATE columns or modify the query to use current indexes.
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
currently autoconfig option ii used ii take default configuration handling concurrent request le handling concurrent request headroom available server per hardware kpi detail increased per recommendation handling concurrent user
'It is recommended to disable autoconfig and use custom thread pooling  setting in Machine.config as given below for handling more concurrent requests, below settings needs to be tested in UAT environment in high load before moving into production. \n\nautoconfig : false\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs \nminIoThreads 50\nminWorkerThreads 50'
'predictability system performance compromised constant monitoring carried besides time taken providing rca delayed team able larger view system tight integration development operation team apm tool could ammunition available development operation team higher preditability application system whole '
It is recommended to use APM tool which can monitor all the application metrics and hardware KPIs in production environments.
static content taking time caching unavailability hit system time static content downloading
It is recommended to keep these images, js, css and font files to AMS server and serve from there keeping static caching as given in Sr. No. 6
unproper timeouts cause thread blocking specified period time turn create problem handling concurrent user request
It is recommended to keep the timeout values  as follows and test these settings in UAT environment :\ncloseTimeout="00:01:00" receiveTimeout="00:10:00" sendTimeout="00:01:00"
unwanted consumption resource wesbsites relevent am
It is recommnded to move all unwanted websites in other environment
lead system hand system slowness proper capacity planning failover testing done
It is recommended to perform fail over testing and do better capacity planning based on given NFRs.
lead high cpu consumption code compilation lead system slowness
"It is recommended to remove visual studio from all production environment\ \ and don\u2019t do any copilation operations in production environment."
high number insert utilizing resource database server
It is recommended  to reduce the inserts on the ActivityLog table which is really required.
high cost query impacting performance database
it is recommended to check from which services this query is calling and stop if not required as this is already created in stored procedure.
lead utilize space storage end took time resource am database backup
It is reccommneded to remove the duplicate / backup tables from the AMS database.
lead utilize space storage end took time resource amd database backup
It is recommended to remove the the tables with zero count if not required.
statistic table stale query optimizer create plan using misinformation result choosing optimal query plan
It is recommended to update the statistics daily or on alternate days(Depend on the usage of tables) for important tables where more than 20 percent rows changed of the table.
static content downloded server unwanted hit go server avoided putting static content configuration setting age currently proposed 365 day application run continuously 24x7 365 day
It is recommended to set Static Content Caching as -\n<staticContent>\n      <clientCache cacheControlMode="UseMaxAge" cacheControlMaxAge="365.00:00:00" /> \n    </staticContent>
unwanted cs j increase rendering time html page
It is recommended to remove unused CSS from the Applicaton.\nAlso for finding unused JS, please comment one by one JS in the UAT environment and check accordingly.
calling j top page increase rendering time html page
It is recommended to declare the JS in bottom of the page.
currently autoconfig option ii used ii take default configuration handling concurrent request le handling concurrent request headroom available server per hardware kpi detail increased per recommendation handling concurrent user
'It is recommended to disable autoconfig and use custom thread pooling  setting in Machine.config as given below for handling more concurrent requests, below settings needs to be tested in UAT environment in high load before moving into production, it will be further tuned based on performance testing results. \n\nautoconfig : false\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs \nminIoThreads 50\nminWorkerThreads 50'
unwanted memory consumed variable class
It is recommended to remove unused references, classes, methods, variables from the Code.
processing db call request increase response time
It is recommended to use internal cache or hash table to store temporary data from db, in the methods which are used multiple times for reteriving data from database.
slowness timeout error observed end user ga application r1 mission
It is recommended modify the logic from the code end so that multiple number of same Scheduler should not run on the single server at same time.
page rendering time increase static content caching present
It is strongly recommended that after making any changes cross validate that the static content policy should not be overwritten so that caching should work fine.
unwanted db call increase system utilization decrease response time method
It is recommended to remove unwanted DB calls from the Codebase.
encryption decryption method cpu intensive task
It is recommended to first store the data for mission.Encrypt(), country.Encrypt() and center.Encrypt() in the string variable and used that string variable wherever required.
response time login page increase logins db call used getting configuration data check whether captcha enabled
It is recommened to store the configuration values for Google Captcha in the configuration file.
unwanted db call increase system utilization decrease response time method
It is recommended to remove unwanted DB calls from the Codebase.
imapcting quering performance
Deadlocks are bound to occur if the resources are not processed in a well defined order. To minimize deadlocks, all the concurrent transactions should access objects in a well defined orders.\nThere are update  statement on Applicant  table and update is causing the deadlock issue in the database\nQuery=update [dbo].[Applicant] set [FirstName] = @0, [LastName] = @1, [ContactNumber] = @2, [PassportNumber] = @3, [DateOfBirth] = @4, [Gender] = @5, [PassportExpiryDate] = @6, [SubmissionDate] = @7, [IPAddress] = @8 where ([Id] = @9)</
placing data log file backup device cuase contention disk resulting poor performance
It is recommended to use different disks for data and log files.
application error caused increase system utilization also increase response time method
It is highly recommended to weekly check application log files and resolve any errors found in the log files.
page rendering time high since cs j image optimized
It is recommended to optimize css, js and images as mentioned in the frontend optimization document.
everytime processing db call page increase system utilization also increase response time method
It is recommended to store the output value for GetDownTimeDetails() inside the Session variable or internal cache.
lead utilization system resource
Below are list of some unwanted windows services which needs to be disabled after confirmation from concerned team:\n(Application Information,Application Management,Background Intelligent Transfer Service,Carbon Black Sensor,CNG Key Isolation,Computer Browser,\nDebug Diagnostic Service,Distributed Transaction Coordinator (b0a5e3e1-4843-4dd5-bf68-2cc4ad62d8cb),InMage Scout FX Agent,\nInMage Scout VX Agent - Sentinel/Outpost,Microsoft Software Shadow Copy Provider,NetBackup Deduplication Multi-Threaded Agent,\nPA Collector,Print Spooler,Smart Card Device Enumeration Service,Symantec CCS Agent, Volume Shadow Copy,Windows Connection Manager,\nWinHTTP Web Proxy Auto-Discovery Service,Windows Modules Installer,Windows Update,WMI Performance Adapter).
'predictability system performance compromised constant monitoring carried besides difficult provide root cause case issue team able larger view system tight integration development operation team apm tool could ammunition available development operation team higher preditability application system whole '
It is recommended to use APM tool which can monitor all the application metrics and hardware KPIs in production environments.
two different type similar code need maintained single web application
It is recommended to keep only single GA App codebase running in production environment after confirmation with concerned team.
high elapsed time cpu utilization
"It is recommended to create index on  Applicant table as mentioned below.\\\ nCREATE NONCLUSTERED INDEX [Index_Name] ON [dbo].[Applicant]\\n(\\n\t[MissionId]\ \ ASC,\\n\t[CountryId] ASC\\n)\\nINCLUDE ( \t[Id],\\n\t[ApplicantGroupId],\\n\t\ [CenterId],\\n\t[FirstName],\\n\t[LastName],\\n\t[PassportNumber],\\n\t[DateOfBirth],\\\ n\t[EmailId],\\n\t[PassportIssueDate],\\n\t[GWFNumber])"
synchrounous logging increase response time concurrent user request
It is recommended to implement ascynhronous logging using log4net.
unwanted memory consumed variable class
It is recommended to remove unused references, classes, methods, variables from the Code.
recompilation code done hard coded value changed need system downtime production environment
It is recommended to read the hard coded values from the Config files.
difficult trace end user journey logging pattern followed
'It is recommended to use given below logging pattern:\n\n<DATE TIME> <LOGLEVEL> <THREAD ID> <CLASS NAME> <REQUEST SENDING TO> <COMPONENT-NAME> <REQUEST DATA WITH MOBILE AND CUSTOMER ID/PASSPORT NO> <TIME TAKEN IN PROCESSING REQUEST> <TIME IN SECONDS>\n\n<DATE TIME> <LOGLEVEL> <THREAD ID> <CLASS NAME> <RESPONSE RECEIVED FROM> <COMPONENT-NAME> <RESPONSE DATA WITH MOBILE AND  CUSTOMER ID/PASSPORT NO > <TIME TAKEN IN PROCESSING RESPONSE> <TIME IN SECONDS>\n\nNOTE: Exception should be printed completely in different log file.'
'predictability system performance compromised constant monitoring carried besides time taken providing rca delayed team able larger view system tight integration development operation team apm tool could ammunition available development operation team higher preditability application system whole '
It is recommended to use APM tool which can monitor all the application metrics and hardware KPIs in production environments.
parallel execution query restricted defined value
It is recommended  to set the value of max degree of parallelism to 0. With this sql server will detect the best degree of parallesim to use for the query execution.
unwanted database consuming resource like cpu memory
It is recommended  to check all the database and remove unwanted database instance from DB server
uwanted processing queue 0 length io increased function also unwanted iteration done
It is recommended to optimise this function with proper logic with proper Unit Test
unwanted execution timer consume system resource unnecessarily
It is recommended to remove unwanted Timer from the application.
design
Create  indexes on SPH_FROM_TIME and SPH_TO_TIME  columns or modify the query to use current indexes.
design
Create  indexes on CMH_FROM_TIME  and CMH_TO_TIME  columns or modify the query to use current indexes.
design
The View needs to be rewritten to use the indexed column UT_LABEL_ID which is indexed.
design
The View needs to be rewritten to use the where clause. Currently there are no where clause being used.
design
Calling URLs needs to be modified to comment out the lines calling non existing pages.
design
As these are static files which can be picked from the client rather than the server when recalled, these files should be cached.
design
Images stored in PNG formats are the lightest extensions for images. All the images should be converted into PNG files
design
JS files needs to be placed at the bottom. Common js files called sequentially can be placed in a single js file and called.
design
Js files should be minified.
improper raid level
Use RAID 1 + 0  for transaction logs & Datafiles
design
Remove ToString.ToUpper method call for such cases.\nFor eg. (flag != null && flag.ToUpper().Equals("Y".ToString.ToUpper())) can be written as (flag != null && flag.ToUpper().Equals("Y"))
design
Instead compare can be used which will internally check for case sensitivity. (str1.ToString.ToUpper().Equals(str2.ToString.ToUpper())) can be written as (string.Compare(str1, str2, true) == 0), it will work well and efficiently.
design
All resources should be closed in finally block only.
design
Check for null before accessing cache items.  This will help in avoiding any exceptions which are caused by null objects.
design
Fetch static data from cache outside the loop.
design
1. index to be created on  central_brd_drct_tax table on pmt_status on column.\n2. index to be created on  pmts table on pmt_stat on column.
maintenance
CUSR table needs to be defragmented.
maintenance
acct_master table needs to be defragmented.
design
index to be created on user_report_table table on columns act_code,access_channel
design
create index on payment_vat table on pid column
slow rendering page
These need to be converted to js files. Which can be moved to bottom of body
slow rendering page
Specifying a width and height for all images allows for faster rendering by eliminating the need for unnecessary reflows and repaints.
slow rendering page
Check if js and css files can be combined and compressed. For small background images CSS sprite can be used. ( Pt 5 to 11 apply for other webpages of portal application )
process
To ensure CSS files are downloaded in parallel, always include external CSS before external JavaScript.
process
Configure CDN to deliver static contents ( css,images,js )
404 error
Fix paths or deploy documents to avoid 404 errors
404 error
The referrer pages need to have the block commented which is calling these not found pages. Alternatively, the objects needs to be placed in the path where it is being referred to so that 404 hits are eliminated.
load balancer used
It is recommended to have load balancing in place, so that the load is evenly distributed across all vm instances
compression used
Compression of javascripts, css, jpegs, gifs files.\nPlease refer below sheets for compression details:\n1. CSS_Compression\n2. JS_Compression\n3. Image_Compression
404 error
Remove links from application responsible for 404 errors or fix the path to the static contents shared. \nPlease refer 404_Bandwidth sheet for more details.
unncessary link code
For enabling caching, on the web server, we suggest you to make some modifications in the httpd.conf file in the web server.The caching can be done for the frequency defined by you. For now, we have made it as 1 week. This frequency will depend on the frequency of modifications that is generally made on these static objects.\nPlease test this extensively on one of the UAT server, and if results found okay, can be put in production.\n#Enabling Caching for Static Objects\nLoadModule expires_module modules/mod_expires.so\n#Enabling Caching for Static Objects\n<IfModule mod_expires.c>\nExpiresActive On\nExpiresByType image/gif "access plus 1 week"\nExpiresByType image/jpg "access plus 1 week"\nExpiresByType image/jpeg "access plus 1 week"\nExpiresByType image/png "access plus 1 week"\nExpiresByType text/css "access plus 1 week"\nExpiresByType text/html "access plus 1 week"\n</IfModule>
backup policy
Need to configure backup policy since servers are in production environment
memory leak
We have identified pattern for connection leaks. As per our discussion, development team will provide us files for review in which connection leaks are fixed, team have commenced work on the same already. Also connection pooling implementation needs to considered
design
'Approach to handle this : The Transaction is created at GBM but not at Finacle, so whenever the user tries to create another transaction at GBM, the system should indicate that a transaction is already created for a the same account and same amount, and finacle transaction pending for the GBM tran id. The user should be given an option to go ahead and create a new tran or delete the pending tran at GBM.'
design
Connection has to be closed, otherwise the sessions will keep increasing on the database.
design
The data type of EMPLOYEE_NUMBER to be changed to varchar of the same size of USER_ID field of LGT table
maitenance
Perform De-Fragmentation operation e.g. CTAS, Table movement, export-import, DBMS_REDEFINITION
design
For these tables stats to be gathered in regular interval. Database should be monitored that no table goes for stale stats
design
Check for null before accessing cache items.  This will help in avoiding any exceptions which are caused by null objects.
design
1. index to be created on  central_brd_drct_tax table on pmt_status on column.\n2. index to be created on  pmts table on pmt_stat on column.
maitenance
acct_master table needs to be defragmented.
maintenance
Duplicate indexes on payee_master table are observed one can be removed.( pmt_id , del_flg /del_flg,pmt_id).  defragmentation on pmts and payee_master table is required.
design
create index on payment_vat table on pid column
maintenance
PLOG table needs to be defragmented.
maintenance
customer_payee table needs to be defragmented.
maintenance
customer_payee table needs to be defragmented.
design
The business logic lies with Infosys. Need to understand for such volumes why so much time is spent for batch execution.
design
Need to understand the reson for executing update over the insert on same columns
design
'Fetch static data outside the loop, do data modification there itself(if require) and store it in a new object for further processing.\n\nReference : Srl 6.\nInt primAccount;\nif(cm.getString("userAccountIndex") != null)\n{\nprimAccount = cm.getInt("userAccountIndex");\n}// if close\nfor(condition) // loop start\n//some code\nString refValue = Convert.ToString(primAccount); // code marked in red can be move before loop start inside if condition\n//some code\n} //loop end\n\nReferences : Srl 7.\nfor(condition) // loop start\n{\nfield125 = "SCH" + vo.getCIDN() + cache.getString("stdntRegId").PadRight(10) + cache.getString("schlid1").padRight(6) // code marked in red can be move before loop start\n} // loop end'
design
Such method calls needs to call first before loop starts rather than calling it inside loop.\nfor(int i = 0; i < ba.count; i++)\n{\nGUCTVO guctchallanvo = (GUCTVO)ba[i];\nDebitAcNo = guctchallanvo.getDEBT_ACID().ToString().Substring(0,4);\nBranchID = BranchCodeDescription.getDesc(userInfo.bankId(), solid, cache); // code marked in red can be move before loop start \nGuctchallanvo.setbranch_ID(BranchID);\nbaList.Add(guctchallanvo);\n}\n\nBranchID = BranchCodeDescription.getDesc(userInfo.bankId(), solid, cache);\nfor(int i = 0; i < ba.count; i++)\n{\nGUCTVO guctchallanvo = (GUCTVO)ba[i];\nDebitAcNo = guctchallanvo.getDEBT_ACID().ToString().Substring(0,4);\nGuctchallanvo.setbranch_ID(BranchID);\nbaList.Add(guctchallanvo);\n}
design
Application needs to be restructuring to more generalized/parameterized structure to avoid lots of code file creation and also to avoid more memory consumption.
design
Use StringBuilder.Append() method once to generate query. No need to call StringBuilder.Append() method 3 times on 3 different lines to generate query.
design
Order by clause not required in query to fetch data in ascending order. Default order is ascending.
design
Place one copy of faq page in Corporate domain and fetch the same from that location.
design
There should be an intermediary landing page, which should only show the details for the primary account (Saving Account), and there should be a link for the other schemes.\n On clicking this, it should highlight all the other accounts linked.
design
Bill Desk Vendor needs to tune this.
design
"a. The js functions are written inline in the aspx page. The js file should\ \ be written outside and should be called through a link in the aspx file. This\ \ will load the page faster.\\nb. Check why there are so many js validations done\ \ for a static page. Eg. For disclaimer page, there are only two buttons \u201C\ I Agree\u201D/\u201DI Disagree\u201D but there are multiple js validations written\ \ on the page.  \\nc. There are multiple js files being called sequentially one\ \ after another. This should be collated into a single file so that the on load\ \ of these js files happens just once. Eg. RetailShoppingMallLogin.aspx has multiple\ \ js files loaded sequentially one after another."
design
Need to understand from Infosys, why does it take such high time for first time loading.
high 404 status error
Source Code at DirectRates Application should be corrected to remove reference path of scwblank.html
le secure
Enable security on Dealer.xml, Margin.xml and Currency.xml Files, So that files are not accessible without Authentication. Also please check the feasibility of Encryption for these files. Reference http://support.microsoft.com/kb/815152
high bandwidth usage
Please compress XML Files on creation and decompress it at the time of consumption. Also please check the feasibility of replacing XML Files by Ajax Call for filling Dropdown Controls.
high io
Please set this value to debug="false"
pocket loss
Win 32 status 64 from IIS logs suggests that the network packet is being lost. To be taken up with the network team.
deadlock error
Use Hint With NoLock in Select Statements for Table DealSlip_IntermediateBlotter and DealSlip_CounterParty
404 error ii log
web.config file should be corrected to remove reference path of the files from the `customErrors` tag.
nodata
Please change the data type of variable `mailtable` from String to StringBuilder.
nodata
Integration of all schedulers into one common scheduler will help in solving the problem. Recommended Architecture is described in the next sheet.
nodata
Please use list parameter to fetch and update records of all the clients in a single operation. Recommended Interface is described in the next sheet.
nodata
Please use configuration file to store the database schema name.
compilation setting webconfig
Please set this value to debug="false"
invalidcastexception event viewer
In `frmFwdUtiliazationDeals.aspx.cs` File, Please check the following condition before Line numbers 1367, 1368, 1372 and 1373:\nif (!(dr["ColumnName"] == DBNull.Value))
application code review
'Please remove the commented javascript code from following pages: frmDealDetails.aspx, frmDealReport.aspx, frmDeals.aspx, frmFwdContractDeals.aspx, Logout.aspx, frmFwdContractDealsDetails.aspx, frmFwdUtiliazationDeals.aspx, frmFwdContractDealReport.aspx, frmDealReportKplus.aspx and jsDeal.js'
response time high
Only selective columns should be included in select query from product, this reduces the data transfer from DB to APP
response time high
These needs to be moved to the bottom of the body. This would allow the browser to download all contents in the page in a non-blocking manner.
response time high
Configure CDN to deliver static contents ( css,images,js )
workflow delay
Analysis of storage performance logs need to carried out, Data from storage team is awaited
workflow delay
The referrer pages need to have the block commented which is calling these not found pages. Alternatively, the objects needs to be placed in the path where it is being referred to so that 404 hits are eliminated.
response time high
Remove links from application responsible for 404 errors or fix the path to the static contents shared. \nPlease refer 404_Bandwidth sheet for more details.
workflow delay
For enabling caching, on the web server, we suggest you to make some modifications in the httpd.conf file in the web server.The caching can be done for the frequency defined by you. For now, we have made it as 1 week. This frequency will depend on the frequency of modifications that is generally made on these static objects.\nPlease test this extensively on one of the UAT server, and if results found okay, can be put in production.\n#Enabling Caching for Static Objects\nLoadModule expires_module modules/mod_expires.so\n#Enabling Caching for Static Objects\n<IfModule mod_expires.c>\nExpiresActive On\nExpiresByType image/gif "access plus 1 week"\nExpiresByType image/jpg "access plus 1 week"\nExpiresByType image/jpeg "access plus 1 week"\nExpiresByType image/png "access plus 1 week"\nExpiresByType text/css "access plus 1 week"\nExpiresByType text/html "access plus 1 week"\n</IfModule>
workflow delay
"To improve the Response time of these pages,  below steps needs to be carried\ \ out\\n1. Compress js files, css files and images - Please refer below sheets for\ \ compression details:\\n1. CSS_Compression\\n2. JS_Compression\\n3. Image_Compression\\\ n\\n2. Enable caching for static elements which doesn\u2019t change for a long time\ \ like css, images.\\n\\n3. Remove unwanted links ( 404 errors ) from pages"
workflow delay
Need to configure backup policy since servers are in production environment
response time high
'-  There are no bind variables being used for the query, it is recommended to use bind variables so that query can reuse the cached plan. The query is coming from "PHP freetds" application.\n   -  The view View_enquiry_bookinghistory used in query refers to another view view_liaisonbookingqt which is having booking id column of bkbookingmaster table. This column is primary key and view definition checks for "not null " constraint on this column, which is not required and can be removed from view definition.\n   -  There are like operators in where clause and as confirmed by team, these can be removed. Since like operators are expensive to use in where clause.\n   -  Team has confirmed we can use table joins to get data out of this query instead of using the view.'
architecture
After discussion on 24-Dec-14,  details from database table to validate inserts and accessed pages will be provided by team for further analysis. Also need understanding on ckcontent inserts pattern change.
workflow delay
We have identified pattern for connection leaks. As per our discussion, development team will provide us files for review in which connection leaks are fixed, Gurpreet and team have commenced work on the same already. Also connection pooling implementation needs to considered
architecture
CNK team has confirmed as part of procedure optimization, this condition has already been removed and instead of temp tables, temp variables are being used now
response time high
Need to involve network team to have discussion on this.
architecture
Create index on bkservicesbooking table on booking_id column
configuration
1. The long running processes - (Heavy queries highlighted below in the tracker) needs to be tuned so that the active no. of processes is limited. \n2. There are queries which are in inactive state which is basically leading to process hog. There is one query on the DB which has been observed to be contributing to 70% of the inactive session count. Refer Inactive Statistics every 15 min and Inactive-Query Reference tracker for the details.\n3.If the workload is increasing, the processes and session parameters on the DB should be increased. The values from v$session and V$process needs to monitored at high loads to arrive at the exact figure. The session value should be 1.5 times the process value.\n4. Look at all possible cases where connections has been left open, and put a connection close at the finally block. Start with the queries which are in inactive state throughout the day.
query optimization
The SP should be modified to add exceptions. With the absence of exceptions, transaction failures are not getting captured. The exceptions can be added to process such cases seperately.
maitenance
the referrer pages need to have the block commented which is calling these not found pages. Alternatively, the objects needs to be placed in the path where it is being referred to so that 404 hits are eliminated.
configuration
To avoid slowness in Paypro Application, make sure c3p0.debugUnreturnedConnectionStackTraces value is set to false on all application server. debugUnreturnedConnectionStackTraces is intended to be used only for debugging, as capturing a stack trace can slow down Connection check-out.
maitenance
"Complete List has been shared with the team. We would need to carry out\ \ the following steps :\\n\\n\u2022 Identify the tables which are not being used\ \ by the application/utility.\\n\u2022 Freeze the tables in a permanent backup\\\ n\u2022 Drop the redundant/unwanted tables."
maitenance
"Complete List has been shared with the team. We would need to carry out\ \ the following steps :\\n\\n\u2022 Identify the tables which are being used by\ \ the application/utility.\\n\u2022 Isolate these tables and defragment it.\\n\u2022\ \ Consult the application team/product vendor on creating clustered index on tables\ \ where heap is more than 70% fragmented."
query optimization
A nonclustered index can be created on userlog table on columns sessionid and sysuserno.
configuration
WebRequest Object should be created once and will be reused for every request.
configuration
As TBMS application supports multithreading, Large size files need to be split into smaller files and need tobe  processed in parallel.
query optimization
As we do not have the source for this procedure, please involve TBMS team to validate what is the sql text for this procedure and check if this can be further tuned.
query optimization
Either remove the trunc function for both the tables, or create a functional indexes on TRUNC(CI_EXTRACT_DATE) on CSTM_INTEREST and TRUNC(CII_EXTRACT_DATE) on CSTM_INTEREST_INTEREST tables.
query optimization
Please modify the query to add jl_start_time is the query for the current index to be used or create an index on JL_STATUS.
query optimization
The view needs to be recreated to use the indexes involved. It needs to be checked if the order by is really needed.
query optimization
Create  indexes on SPH_FROM_TIME and SPH_TO_TIME  columns or modify the query to use current indexes.
maitenance
Update the data structure every time the rate changes i.e. end of the fswPrimact_Changed and fswJPY_Changed functions
code review
List of compressed JS ,css, ASPX files shared. Caching when done on these objects will reduce the round trips.
code review
Can Remote server and FLMS application be co-located on the same server to reduce the network latency?
code review
Can we have the  Hybrid data configuration i.e InMemory database with the Sql server database on the disk. The frequently accessed data like sessions can be fetched from the InMemory database.(Development team was supposed to the analysis on this point by 3rd july).
query optimization
Can the Cut off Mechanism be handled in the application rather than the DB. This SP should be called only when the input parameters have valid values.(Development team was supposed to the analysis on this point by 4th july)
code review
Avekshaa has shared the recommendations on all the JS files which have been compressed. The development team need to validate the recommendations and implement it.
code review
The thread sleep should be eliminated
code review
The operations can be eliminated to increase throughput.
code review
Thread.sleep should be eliminated
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
configuration
Parameter pga_aggregate_target is currently set to 1024M. It should be increased to 2048M.
configuration
Configure temporary and data files on separate mount points/disks.
configuration
Configure undo data files and other data files on separate mount points/disks to improve IO distribution and have better space management.
configuration
Perform data file  movement to make some space available. Do take a note that these 2 mount points host temporary files too.
configuration
Remove one which is unused. This has no impact on performance but is a better practice to follow.
code review
Overall throughput of the batch file polling can be improved if this is converted to a multi-threaded model.
code review
We propose that RAC based database deployment be configured to avoid database being a SPOF.
code review
These servlets should be loaded during server boot up rather than during first usage. Add servlets in web.xml  under InitServlet section.
code review
Currently, salary batch is processed one-file-at-a-time.  This is the primary reason for a delay between salary file arrival time and its process initiation time.\nFile processing should be done in a concurrent manner using ThreadPool or PooledWorker technique.
query optimization
Remove the hint which will reduce the execution cost of query by using index unique scan on location_pk.
code review
Improvement to exisitng logic of processing Reverse File Gen Corp:\nCurrently, when an Excel file triggers an OOM error the status of the file remains unchanged and hence when App server restarts it picks the same file and that too crashes due to OOM error. This loop continues and blocks other good files from being processed. This flow/logic can be chnaged to add one more status to the files. Currently, each reverse MIS file has only 2 statuses, Unprocessed and Porcessing Finished. Adding third status of "Processing Started" should help alleviate above loop problem. At the outset, file status would be "Unprocessed". Flow should first pick up unprocessed files for processing. Very first thing to be done is to change its status as "Processing Started". Once entire processing for the file is finished, update the status to "Processing Finished" (This is current logic. No change is needed.). When there is an error like OOM etc, the file status will remain "Processing Started" and hence this errorneous file will not be picked during subsequent runs. Once all files with status "Unprocessed" are completed, flow can loop through files with status "Processing Started". With this change, erroneous files won't block other good files from being processed thus improving reliability of the application and will also add retry logic for erroneous files.
high cpu
Since infyaccount.jsp has a dependency on data set by crosssell_drop.jsp, initiate infyaccount.jsp in the Ajax call only after the crosssell_drop.jsp processes the request
code review
Database connection and Statements instance always needs to be created in try block and  closed  in finally block as following
code review
Define Property class as a singleton. Load properties values on first loading of this class only (put properties loading code in static block) and assign properly value to respective instance value. Also change instance variables from public to private and provide getter method to access these instance values.
code review
The thread pool settings have also been optimized. The thread count was reduced from 800 to 400. Only about 200 threads are utilized.
deadlock error
'Create Index in Table: DealSlip_CounterParty for columns: CP_KShortName, PK_CP_ID, CP_IsActive'
found error maximum number row excel worksheet
Limit the maximum period on Front End for creating the Excel File.
466 viewstateerrors
Check Application Pool Recycle Settings in IIS. Please ensure that it will recycle only during non working hours. Reference http://msdn.microsoft.com/en-us/library/aa720473(v=vs.71).aspx\n\nViewState Stettings are already implemented in web.config\n\nAnother cause of this error is that, Page Postback occurs before the Page does not Loads completely. To resolve the problem mark the form as disabled and then enable it in script once the page load is complete.\nfunction enableForm() \n{ \n      document.getElementById("form").disabled = false; \n} \nwindow.onLoad = enableForm();
found error error serialization deserialization using json javascriptserializer
Set the MaxJsonLength property in web.config:\n\n<configuration> \n   <system.web.extensions>\n       <scripting>\n           <webServices>\n               <jsonSerialization maxJsonLength="50000000"/>\n           </webServices>\n       </scripting>\n   </system.web.extensions>\n</configuration>
nodata
Create primary key on PK_Dealid on table DealSlip_IntermediateBlotter which is being referred to in multiple places in the SP so that it can be used as a clustered index in the table.
nodata
Create primary key on PK_Dealid on table DealSlip_IntermediateBlotter which is being referred to in multiple places in the SP so that it can be used as a clustered index in the table.
high response time
Index on CP_KCOUNTerpartyid to be created on table dealslip_counterparty
high response time
To validate from the data populated in the table if LTRIM,RTRIM and not null checks are required for DD_MiscCounterPartyName,DD_DealerName,DD_ForDealerName,DD_PartyName used in case of data access from dealslip_dealdetails table.
high response time
To validate from the data populated in the table if LTRIM,RTRIM and not null checks are required for CP_KCounterPartyName used in case of data access from dealslip_counterparty table and CU_CurrencyCode from DealSlip_Currency table.
high response time
Please implement Viewstate Compression in ASPX Pages. Reference http://www.codeproject.com/Articles/14733/ViewState-Compression\nAlso please check the feasibility of disabling viewstate for those controls which do not need that.
code repeated
Please move the Generic Code to Common Classes. And call them from classes of ASPX Pages by passing required parameters.
nodata
Please remove sessions after their usage. Specially for those sessions which stores DataTable or Class Objects.
found type conversion datatable cell value
Type Conversion is not required for DataTable Cell Values. By default, Value is of same Type which is defined in the Column of DataTable.
'found condition called even required '
Replace `if` condition by `else if` condition.
found common code else condition
Move common code above the `if else` condition.
throw exception error
Try-Catch Block is not required. By default, Global.asax will catch the exception.
nodata
Please remove sessions after their usage.
nodata
Please remove sessions after their usage.
nodata
Remove unwanted `if` conditions, which is always satisfied.
found duplicate assignment
Remove duplicate assignments operations.
found  condition null empty different
Combine `if` condition for Null and Empty into single one using `string.IsNullOrEmpty`.
nodata
Type Conversion is not required for DataTable Cell Values. By default, Value is of same Type which is defined in the Column of DataTable.
'found condition null empty different '
Combine `if` condition for Null and Empty into single one using `string.IsNullOrWhiteSpace`.
high cpu
Use Type `int16` instead of `int` in `For Loop` and Counters where small numbers are stored.
throw exception error
Try-Catch Block is not required. By default Global.asax will catch the exception.
found generic code checking user right
Please move this Code to Common Classes. And call them from this class.
found generic code showing pager button
Please move this Code to Common Classes. And call them from this class.
httpexception event viewer
Please remove `Response.Redirect...` line from `ClearUserInfo` Method of `Global.asax.cs` File. Since when the session ends, HttpContext or Response Object is not available.
nodata
Please use configuration file to store the database connection string.
win32 status 64 aspx page
Win 32 status 64 from IIS logs suggests that the network packet is being lost. To be taken up with the network team.
slow response deal detail page
Index on column FK_PK_DD_DealDetailsID to be created on table DirectRates_DealUtilizedDetails
sqlexception event viewer
In procedure usp_DirectRates_GetDeals_New, Please move the `where` condition from line 239 to line 240. This change will rectify the syntax error.
nullreferenceexception event viewer
Recommendation mentioned in Point 4 will solve this issue too.
slow response deal report page
In Procedure usp_DirectRates_GetReportDeals, Please Select only those columns in the query which are required in the business layer.
application code review frmaudittrailaspxcs
In frmAuditTrail.aspx.cs, Please replace `txtdealID.Text` by `txtmurexID.Text` in line number 352
response time high
Compression of images needs to be carried out. Please refer image_compression sheet for changes in size of images ( Sample images have been shared with team to validate pixcel quality )
response time high
Specifying a width and height for all images allows for faster rendering by eliminating the need for unnecessary reflows and repaints.
response time high
To ensure CSS files are downloaded in parallel, always include external CSS before external JavaScript.
response time high
use one-time expressions, where the first time the expression is evaluated it sets the style property to an explicit value, which replaces the CSS expression. If the style property must be set dynamically throughout the life of the page, using event handlers instead of CSS expressions.
workflow delay
N/A
response time high
Optimization of stored procedures will be carried out. Please refer SP_Timings sheet for more details
response time high
Compression of javascripts, css, jpegs, gifs files.\nPlease refer below sheets for compression details:\n1. CSS_Compression\n2. JS_Compression\n3. Image_Compression
architecture
If table does not have any foreign key constraints instead of delete, truncate statement can be used, which will help to reduce execution time of SP
response time high
Non clustered index need to be created on supplier_id column of this table. This table is having duplicate index on billing_id column which needs to be dropped.
workflow delay
As per CNK team data before 5 mins of system timestamp needs to be fetched and this condition can be changed, which will avoid scanning of 1 year data during procedure execution
workflow delay
htaccess is being used at only one place. Implementing this will not benefit.
workflow delay
Team has confirmed these joins are not required and can be removed.
high response time
Check possibility to avoid is null, also it has where clause as "DepDate >= '01/01/2010'" which is hard coded value for table qtDepatureDate table.\nThis is fetching data for four years, this can be changed to fetch only required amount of data .
architecture
These duplicate indices need to be dropped since unnecessary indices are overhead on database insert operations and space management. Also indices with same columns with different column position needs to be validated against application requirement.
query optimization
Purging needs to be carried out on the BTBATCHDET table.
query optimization
Subqueries needs to be replaced by Inner Joins. Also, index needs to be created on entrydate and paymentmethodid on btaccountentry table.
configuration
For enabling caching, on the web server, we suggest you to make some modifications in the httpd.conf file in the web server.The caching can be done for the frequency defined by you. For now, we have made it as 1 week. This frequency will depend on the frequency of modifications that is generally made on these static objects.\nPlease test this extensively on one of the UAT server, and if results found okay, can be put in production.\n#Enabling Caching for Static Objects\nLoadModule expires_module modules/mod_expires.so\n#Enabling Caching for Static Objects\n<IfModule mod_expires.c>\nExpiresActive On\nExpiresByType image/gif "access plus 1 week"\nExpiresByType image/jpeg "access plus 1 week"\nExpiresByType image/png "access plus 1 week"\nExpiresByType image/bmp "access plus 1 week"\nExpiresByType application/javascript "access plus 1 week"\nExpiresByType application/x-javascript "access plus 1 week"\nExpiresByType text/css "access plus 1 week"\nExpiresByType text/html "access plus 1 week"\n</IfModule>
configuration
More intermittent accounts needs to be configured at the C-24 end, and mapping needs to be done at paypro application.
maitenance
Complete List has been shared with the team. Statistics needs to be updated on the listed indexes.
query optimization
A nonclustered index can be created on users table on column usertype by including columns sysuserno,userid,client
page found
The list is provided for which the referrer page should be modified to comment out the listed referred objects, so that these errors can be avoided.
configuration
Static code should be moved out from the main function. So that static code executes only once for all the requests.
maitenance
Large Volume tables needs to analyzed frequently before the month end operation.
query optimization
As we do not have the source for this procedure, please involve TBMS team to validate what is the sql text for this procedure and check if this can be further tuned.
maitenance
Deliberate such cases accordingly and try to limit such maintenance activities to desired level as this creates an overhead on the regular operations.
query optimization
The view needs to be rewritten to either not use this table or use a join instead of not exist as it will help eliminate FTS on this big table.
query optimization
Create  indexes on CM_OPEN_DATE and CM_CLOSING_DATE columns or modify the query to use current indexes.
query optimization
The View needs to be rewritten to use the indexed column UT_LABEL_ID which is indexed.
query optimization
The View needs to be rewritten to use the where clause. Currently there are no where clause being used.
code review
Solution like ping tool (as proposed in  Retail Internet Banking) can be leveraged for this requirement. The ping tool will monitor the performance of different back-end systems by sending dummy messages. If a degradation is observed the Ping Tool will communicate with the iView application. The iView application should have the capability to remove the functionality related to the affected application from its list of services.
configuration
'The value of the "PROCESSES" parameter must be a minimum of one for each background process plus one for each user process. The number of background processes will vary according the database features that you are using. \nFor example, if you are using Advanced Queuing or the file mapping feature, you will have additional background processes.\nSince the database is write intensive, what has been stated above may be used to calculate the parameter.\nThere is also a relationship between sessions on a database and the number of processes. During hours of intense\nactivity on the database, the number of sessions can rapidly increase. If the "PROCESSES" parameter has not been\nset sufficiently high to control this exigency, we will get an "ORA-00020: maximum number of processes exceeded" error'
configuration
NoData
query optimization
Fix all queries for proper index for selected column
configuration
'Fix enq: TX - row lock contention by identifying table on which this is happening'
configuration
Please remove `Response.Redirect...` line from `ClearUserInfo` Method of `Global.asax.cs` File. Since when the session ends, HttpContext or Response Object is not available.
configuration
Please change the data type of variable `RewardsRisk` from String to StringBuilder.
configuration
Please throw exceptions in catch block.
query optimization
Please use list parameter to fetch and update records of all the clients in a single operation. Recommended Interface is described in the next sheet.
query optimization
Please create a table to store mails. This table will be used by different schedulers to store the mails. And a common Mail Scheduler will process this table to send the mails.
query optimization
Please use configuration file to store the database connection string.
configuration
Please use configuration file to store the settings.
404 error
Source Code should be corrected to remove reference path of the file. List of 172 files is shared in the next sheet.
network latency
Win 32 status 64 from IIS logs suggests that the network packet is being lost. To be taken up with the network team.
code review
Please move the piece of code to common class and call them on all the pages. This will move the functionality to one place and it will be easy to control.
code review
Please implement error handling in `Application_Error` Event of Global.asax.cs file and record complete exception details in the log file.
code review
Please dispose the objects in finally block.
code review
Please implement `Header` Control in Master Page and use this Master Page in all the pages for consistent design.
code review
Please throw exceptions in catch block.
code review
Please change the data type of variable `strhtml` from  String to StringBuilder.
code review
This can be avoided by implementing Image Caching in the Application.
code review
Please implement .NET's SqlBulkCopy Class for inserting all deals at a time. This will make the deal insertion faster.
code review
Integration of all schedulers into one common scheduler will help in solving the problem. Recommended Architecture is shared in the next sheet.
response time high
Move all servers in single dmz zone so that only a single firewall check is done for requests.
response time high
Use outproc session management with either sql server or a separate session state server.
workflow delay
Perform shrinking of database log files.
workflow delay
Remove User_Id index and ad user_id in the composite index IX_UserLocation_Role_Status_ID
response time high
It is recommended to rebuild the indexes so that fragmentation drops below 30% .
response time high
Add Max Pool size of 50 in the  connection property of nHibernate
workflow delay
Limit the call for helptext.json to once.
workflow delay
Put a check depending on user type to avoid calls to both the modules.
response time high
Correct the image path or remove the reference of beacon.gif in code.
workflow delay
Limit the call for PageButton.json to once.
response time high
Remove all ddl data from DDLData.json except for  ddlAllocate and ddlPrimaryLanguage
workflow delay
Store location_id and role_id in session variable after login and pass the same as parameter in usp_get_communication_summary stored procedure
workflow delay
Limit the call for ViewAwardDetails.html to once.
response time high
Limit the call for ViewAwardDetails.html to once.
response time high
Check the feasibility of loading these .js files and remove if not needed.
workflow delay
Avoid call for Search\Country in Participant\Profile page if not needed.
workflow delay
Limit the call for GetUserHistory to once.
response time high
Limit the call for GetParticipantProfileLevelData, GetAwardsOfAParticipantByUserLocId and GetCommunicationSummary  to once.
workflow delay
Limit calls for GetMenuOnSubmission to once.
response time high
Request GetUserLocations only when user clicks on Change link.
response time high
Avoid call to GAP/RoomAllocated in GAP/EventOverview page load event if not needed.
workflow delay
Avoid call to AccountStatus in Resources/AddResources page load event if not needed.
response time high
Store location_id and role_id in session variable after login and pass the same as parameter in usp_SearchUsers stored procedure
response time high
Setup a fallback server which could be immediately restored in case of database crash.
workflow delay
Store HID in session variable after login and pass the same as parameter in usp_SearchUsers stored procedure
workflow delay
Limit the call of GetSelectedParticipantListDuplicate to once.
response time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Voluntering.
response time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Skill.
response time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Expedition.
workflow delay
Limit call for GetSubmenuOnPermission to once.
response time high
Limit call for GetSubmenuOnPermission to once.
response time high
Call GetSubmenuOnPermission only for menus where submenu is present.
workflow delay
Limit requests for ViewAwardDetails.html to once
response time high
Limit the call for ProcessImages.aspx.jpg to once.
response time high
Clear all view engines and add RazorViewEngine in application_start code. Also disable MVC response header
workflow delay
Limit the call for GetCommunicationSummary to once.
workflow delay
Avoid using Begin Transaction as same is handled in nhibernate
workflow delay
Avoid using Begin Transaction for select statements.
response time high
Avoid using Begin Transaction for select statements.
response time high
Avoid using Begin Transaction for select statements.
response time high
Avoid using Begin Transaction for select statements.
configuration
Update the data structure every time the rate changes i.e. end of the fswPrimact_Changed and fswJPY_Changed functions
code review
This can lead to memory leakage. Add finally block to close the resources properly
code review
Index on ForexEDeals_FlowDeskDeatils table for column FDD_ForDealer is created.
query optimization
Index on ForexEDeals_FlowDeskDeatils table for column FDD_MurexID is created.
slow response time
ICICI team needs to take this up with the winadmin team.
query optimization
The Index creation script which was shared by Avekshaa and also revalidated by Microsoft to be implemented. This will bring down the DB CPU Utilizaton. Moreover, bring down the multiple executions on this SP as this is being called by redundant functions. While loading blotter page for the first time, the same SP was called in JS as well as Ajax call. The call from JS needs to be prevented.
code review
Infosys to analyze the performance of the Call Menu Option and revert with fix
code review
The operations can be eliminated to increase throughput.
code review
The thread sleep should be eliminated
code review
Multi threading to be enabled for this service so that the application can be scaled for better throughput
code review
Multi threading to be enabled for this service so that the application can be scaled for better throughput
query optimization
95 SQL queries related to RTGS are shared with the iConnect team from Bank. Execution plans has been analyzed and below are the recommendations
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
configuration
Oracle Kernel level parameters interfacing with underlying OS (AIX v5.3) should be configured to make best use of OS level resources:\nInstall gpfs.base filesystem.\nIncrease maxuprocs to 16384 from current 4096.\nIncrease aio_maxreqs to 64k (65536) from current 8192.\nChange page_steal_method  to 1 from current 0.
object locking
Due to lack of ADDM and NMON reports for the day, the issue could not be analysed further to be able to come up with recommendations.
maitenance
Due to lack of ADDM and NMON reports for the day, the issue could not be analysed further to be able to come up with recommendations.
maitenance
Drop one undo space and get the benefits in terms of space reclamation  & reduced dictionary access.
configuration
From the scalability standpoint we propose that the amount of processing carried out at Db layer be reduced.\nMoving relevant parts of batch processing flow on JVM will provide flexibility of scaling out. Multiple JVMs can concurrently process batch files. \nTo cater to increasing load, more JVMs can be added to achieve desired throughput. This will be necessary as more clients are added. This model can also enhance the availability.
code review
Considering that the application user base and transaction load is increasing, it is appropriate to introduce additional nodes and load balancing to take care of SPOF and future load requirements.
query optimization
Below tables should be indexed:\n Table CPAY_LIQ_UPLOAD_MST\n    KEY is a FK but not indexed\n    RETURN_REASON_ID is a FK but not indexed \n    \nTable CPAY_PAYMENT_ENTRY_MST\n    AUTH_RULE_APPLIED_ID is a FK but not indexed \n    LAST_AUTH_MTX_ID is a FK but not indexed \n    WORKFLOW_ID is a FK but not indexed \n    SI_ID is a FK but not indexed \n    DOC_SETUP_ID is a FK but not indexed \n    BATCH_ID is a FK but not indexed \n    CUST_PROD_ID is a FK but not indexed \n    CURRENCY_ID is a FK but not indexed \n    GROUPING_ID is a FK but not indexed
query optimization
It is recommended that SR be raised with Oracle to get a fix/workaround for this anomaly.
code review
Secondary for-loop to check "customer already exists" is non-efficient. HashMap should be used with customer code as a key. This will be faster than current for-loop-over-array approach.
code review
JDBC objects like Connections, ResultSet & PreparedStatement should be closed in a finally block. Not closing these objects will restrict database server from releasing these objects from its memory.  Not closing Connection object can induce connectiod leak and cause a system failure. (This one is critical and should be addressed as soon as possible).
code review
All StringBuffer variables declared inside a method should be replaced with StringBuilder. This will improve performance slightly.
query optimization
In a query to fetch format and process details for a customer, second column (FORMAT_CODE) is not used and hence it should be removed from the query.
code review
Sysouts should be removed.
code review
Exisitng java code makes use of long thread sleeps, indefinite thread waits to manage threads. These low-level thread management techniques are extremely hard to get right and are easy source of issues like deadlock, race condition etc.\n\nWe propose that CDCI jobs be implemented using high-level and reliable constructs provided in java.util.concurrent package. Pseudo code with explanatory comments have been shared with Bank on 05/24.
query optimization
Should create separate index on WORK_BR_ID field
code review
'Interim workaround till permanent fix is made (as per item #31 above):\nIncrease memory allocation to Reverse File Gen Corp by 500 MB\nUpgrade POI jar with the latest stable version'
code review
NoData
code review
while(true) code in infyaccount.jsp was continuously calling session object for session attribute and was reason of blocking the other threads.
code review
DataOutput object instance always needs to be created in try block and  closed  in finally block as following\n DataOutput dataOutput = null;\ntry{\n       dataOutput = new \n                DataOutputStream(response.getOutputStream());\n        byte[] bytes = buffer.toByteArray();\n        response.setContentLength(bytes.length);\n        for (int i = 0; i < bytes.length; i++) {\n            dataOutput.writeByte(bytes[i]);\n        } \ndataOutput.close();\n}catch (IOException ext) {       //Print to log\n}finally{\n       try{\n           if(dataOutput != null){             dataOutput.close();           }\n       }catch (Exception ext) {}             //Print to log\n}
code review
Use Configure Datasource and get connection from Datasource instead of JDBC Driver.
code review
Use logger to log any message. Change all System.out.prinln with logger. Disable web - log access as size of log grows to 5GB within 2-3 days.
code review
Need to fix all invalid URL that has been used in code and Fix recommendation for Server log analysis. List of all URL for 500 and 404 has been shared.
code review
'- Cache the properties file and use this cached file in all connection request. Caching will reduce File I/O and   processing request time. Implement Observer pattern to  re-load the file if modified. \n - Evaluate introduction of Socket connection pool to optimize the resource utilization and improve response time  \n - Evaluate replacement of IO with NIO for better performance and scalability. NIO uses Selector which can examine one or more NIO Channel''s with a Single thread. This leads to optimal utililzation of the available resources (like threads).'
query optimization
Application should apply optimal logic to leverage the parallelism of query execution
configuration
"\u201COptimizer\" initialization parameters influence the Cost-Based Optimizer\ \ (CBO) and SQL processing and these will influence the performance"
configuration
Fix all queries for full table scan and analyze AWR report for these queries
query optimization
Full table scan has been observed in few queries, Need to fix these and analyze AWR for these queries
o space
Increase the disc size
configuration
1. Need to investigate database connection and connection pool parameters\n2. Need to analyze network between application server and database
configuration
Check database connection and connection pool\nCheck application for any memory leak
configuration
Possibly due to contention in application
configuration
First need to fix contention in application and need to check this once again. If still this persist then need to analyze IIS performance
configuration
1. CLR monitoring for 10-15 days and analyzing heap dump and Garbage collection (sign of memory leak)\n2. Need to analyze further heap dump, object creation garbage collection pattern\n3. IIS Performance counters have already been shared and these need to configure on iPartner IIS as well.
configuration
1.Policy Picked for Sync\n2.Health Payment PF Request/Response\n3.PF Premium Calculation for MISC\n4.Proposal Sync PF Call for 4W\n5.Health Customer PF Request/Response\n6.PF Proposal Sync for 2W\n7.Health Payment Tagging PF Request/Response\n8.Health Payment PF Request/Response\n9.Health Customer PF Request/Response\n10.PF Premium Calculation for PCV
configuration
web.config file should be corrected to remove reference path of the files from the `customErrors` tag.
configuration
Please add condition to check `ds.Tables.Count > 0` before the condition `ds.Tables[0].Rows.Count != 0` in `GetPendingApprovals` Method of `PendingApprovals.aspx.cs` Page.
configuration
Please implement Viewstate Compression in ASPX Pages. Reference http://www.codeproject.com/Articles/14733/ViewState-Compression
code review
Please move these Methods to common class and call them on all the pages.
code review
Please dispose the session after use.
code review
Please use one session instead of two, since they are doing same work.
code review
Please remove the Session["dtUnderlying"] assignment from the Method `GetDataSource`
code review
Please replace Tag name from `Client_Identification_No` to `CID` or `CINO` in `RefNo.xml` file. This will reduce size of xml file from 7.36 MB to 3.72 MB
code review
Please implement Viewstate Compression in ASPX Pages. Reference http://www.codeproject.com/Articles/14733/ViewState-Compression
code review
Please move `Response.Redirect` outside the `if-else` conditions. Use string for URL creation and use that string in `Response.Redirect`.
code review
Please move `Response.Redirect` outside the `if-else` conditions. Use string for URL creation and use that string in `Response.Redirect`.
code review
Please remove the Session["dtNonCIB"] assignment from the Method `GetDataSource`
code review
Implementation of Token Based Authentication will secure the CIBClient Module from unauthorized access.
high cpu utilisation high io writes
Logging is removed from iteration of code
high response time
It is recommended to use Arraylist over Vector unless used in multithreaded environments.
high response time
It is recommended to use BufferedOutputStream instead of OutputStream.
high response time
It is recommended to remove synchronization for single threaded piece of code
high response time
It is recommended to increase the archive_lag_target value from current 600 to 900.
high response time
It is advisable to either use IF ELSE construct over just repetative IF blocks .
high response time
It is recommended to combine all these queries and create a stored procedure. Stored procedure can return RCODE which can then be used to generate Alerts and return the response.
high response time
This may not cause a performance bottleneck keeping in mind the current workload . \nBut when the concurrency increases multiple database calls to get the Nbin Details need to be clubbed in a Stored procedure.
high response time
This boilerplate code can be elimindated by using Hibernate framework . Follwing would a typical workflow for converting the existing logic into hibernate . \n1) Each table will be mapped to an Java Entity (pojo) via annotations/HBM mapping files\n2) For retrieval or updating of entities , simple HQL queries can be written which will return an Entity Object populated with values or can directly update an Entity object in the database . \n3)Hibernate can make use of Multiple caches for improvement in performance \na) Session level cache - This cache is turned on by default and helps with caching in the same session\nb) 2nd level cache in hibernate by default implemented by Ehcache helps in bringing common cache to the table . Any set of entities that needs to be cached at the sessionfactory level can use 2nd level cache . Timeouts,Invalidation policies can be set accordingly . \nc) Query cache can be used locally for certain queries which are called repeatedly and are suppose to deliver consistantly simmilar results.\n4) Further hibernate can be guided to use connection pooling mechanism of Jboss by using the Hibernate config file . In case hibernate connection pooling is required it can used by setting properties for C3p0 connection pooling mechanism of hibernate. \n5) Be extra cautious while mapping relationships in entities. Decide which properties and relationships will load lazily and which will load eagerly
high response time
It is recommended to set enabled="false"
high response time
It is recommended to move these values to the app.config file
high response time
It is recommended to create index on table "mst_Beneficiary" on columns "BenCode", "CustomerID"
high response time
'Very high CPU utilization (~100%) observed. Query resulting in Full table scan on GAM identified. \nQuery to be optimized by service provider. \nRefer: Q001 in SQL_QUERIES'
unwanted index present
Drop the index if it is not required
nodata
Update GEC and RCL table for corresponding columns
nodata
The package needs to be tuned by Infosys. Any optimization in the package will reduce the time spent on the DB. \nProcedure - MIGADM.SP_ADDRESS_MIG_CHECK \nPACKAGE - MIGADM.PREVALIDATION_CATEGORY.SEARCHCATEGORY#2
nodata
"We suggest that we have a common file for stopping and starting the services\ \ where we have a sleep of 30 secs after the stop sevice is executed. This will\ \ ensure that all services are brought down, and there are no service in the hung\ \ state. \\nTo validate further, we can have a ps \u2013ef |grep lisrvr|grep maria|grep\ \ limo to check if all the services have been brought down before a restart is initiated."
nodata
Infosys to rvert back on what is 99 mapped to in Finacle
nodata
NoData
nodata
Disable logging in the Uniser and CBC configuration files.Also script traces should be disabled.
nodata
Query to be tuned
nodata
Concurrency in accessing the accounts could cause a lock on the account. The debit accounts for the failed transactions should be looked at, and if it is hitting the same account, the number of accounts should be increased.
nodata
Query to be tuned
nodata
1. Reduce the no. of concurrent users from a single zone.\n2. Multiple zone codes, sol id combination for the same.\n3. Alternatively, the product vendor can look at the possibility of having a NOWAIT after update.
nodata
Correct mapping of Schme Code and GL Sub Head Combination needs to be done. Infosys has to fix the issue of FIN_LISTVAL getting killed.
nodata
Napi error - W0205 encountered. The test is executed sucessfully if it is run for a single user, but fails during load(concurrency). Infosys needs to investigate from code, the reason for the exception encountered.
nodata
The transaction should be processed by the same node in entirety, the avg. response time would be much lower than when it is processed by both the ESB nodes.
nodata
1.Index on utr field needs to be created.\n2. Sequence Cache size increased to 20. \n(Alter sequence owner.sequence_name cache 20) -\nSequence Names - \nTrasanctionidsequence \njob_id_seq\nonline_job_id_seq
nodata
1. NOSTRO/USD combination is notmaintained in SRGPM parameters because of which there are NAPI errors.\n2. General exception error are happening because of concurrency of data selection for the query mentioned. Need to have more data sets so that concurrency is avoided(the data accessed is shared with Priyadarshi), or Infosys can provide an alternative solution.
nodata
Index creation needed on utr as well as on routing_ref_num
caching sequence number le
The cache size of the sequences were increased from 0 to 40.\n(Alter sequence owner.sequence_name cache 40) -\nSequence Names - \nADT_REF_NUM_SEQ_IB\nFT_TRAN_NUM_SEQ_IB\nFTTRAN_NUM_SEQ_20120601_IB\nRTGS_SEQ_NUM_SEQ_IB\nPORH_SEQ_NUM_SEQ_IB
high response time
1. Deployments at 107 and 108 are not in synch.(product exes are not in synch)Prima facie, it needs to be ascertained that all nodes are in synch to rule out any issues due to difference in deployments\n2.  We opine that there could have been a memory clog on the application due to high no. of records processed. When the next run is done, we would want to have the NMON running on the application as well as DB server to ascertain the same.
nodata
"There are queries which are running on CNMA, not utilizing the index. Create\ \ index CRMUSER.IDX_ADDRESS_TEST on CRMUSER.ADDRESS(\u201CBANK_ID\u201D,\u201DORGKEY\u201D\ ,\u201DADDRESSCATEGORY\u201D)\\nAlso analyse the table after creating the index."
table lock observed
There was a noise because of which these queries were being run. These sessions were killed.
nodata
a.            Increase freelists  of table & its indexes to 5 (no can be increased if event occurs again).  (using multiple free lists may cause some empty blocks to go unused, causing the segment to extend. Multiple free lists can be used to improve concurrent access, possibly at the expense of additional space used.)\n\nb.            Table & corresponding indexes can be moved to larger block size tablespace of 16K. The inserts would become faster.
nodata
Infosys to investigate the issue
nodata
Need to have stats to be gathered on fixed objects using "dbms_stats.GATHER_FIXED_OBJECTS_STATS" package of oracle.
nodata
The SAF Replay needs to be reconfigured to use parallelization even with hash number configuration.
nodata
This query was fired from the customized Interface finacle script /finacle/appln/Finacle/FC10.2.9/app/cust/01/INFENG/scripts/INT8023Post.scr. Infosys to analyze and apply the fix.
nodata
There are lots of comments which are sent in xsl, javasctipt files which are served to the client which add to page weight and time. The comments needs to removed from js, css and xsl files which would reduce the page weight and would improve the performance.
nodata
Same java script files are referenced multiple times in the same jsp files.\nMod_exprires needs to be enabled on I H S servers and a far longer expiry time needs to specified for static files.
nodata
Compression of all static files needs to done for all the static contents serverd
database listner starting manually
This process needs to be automated, to avoid any manual intervention during actual failover
unnecessary logical block written
Recommended to remove the unwanted operations from the source file. This will help in faster execution of logical blocks and hence improve the performance. Also the objects created inside this block will get eliminate which result in low memory consumption.
stream closed inside finally
It is recommended to add finally block in source file and close all important resources inside it. Finally block will guarantee to close all resources if any exceptions thrown
resource leak suspected code block case exception
Recommended to write the code snippet in try/catch/finally and close the PrintWriter object in finally.
use println
It is recommended to turn this println off. Logging API can be used instead which can turn of debugging statements.
arraylistsize  used loop condition
It is recommended to call arrayList.size() once and store its value in another object and use the same object in the code.
objectlength  used loop
It is recommended to call Object.length() once and store its value in another object and use the same object everywhere in the code.
'used size 0 size   0 '
Substitute calls to size() == 0 (or size() != 0) with calls to isEmpty().
empty catch block
Need to log some messages to detailed out the exception.
empty catch block
Avoid empty catch blocks. Capture specific type of exception and redirect user to common page with appropriate custom message, so that the specific event triggered by the user doesn't look unresponsive.
broken null check
'Recommended to replace this type of condition in below pattern.\nCurrent: \nif(result != null || result.length() >0)\nRecommended:\nif(result != null && result.length() >0)'
iclgnreq01 multiple condition
Only one block should be used and all required data manipulation should be done within this block
consecutive call stringbufferstringbuilder append method
Consecutively calls to StringBuffer/StringBuilder .append should reuse the target object.
used operator string concatenation
It is recommended to use StringBuilder instead of String class where there are lot of concatenations used . StringBuffer can also be used in multithreaded environments
unnecessary call tostring  string object
Avoid calling toString() on String objects; this is Unnecessary.
handled string comparison improper way
Use equals() or equalsIgnoreCase() to compare strings instead of ''=='' or ''!=''
unnecessary operation immutable object
Remove all such operations from code
nulling webserviceresponseparser object
Add below block inside finally block. \nparser = null; \nparser is reference to WebServiceResponseParser class. Above block will make sure that in any case normal/exceptional parser object reference to null and can be garbage collected.
redundant call client app backend
Change the if condition to some variable. And use the cached data.
repeated stringbuilder call
Remove one call.
unused object creation
"It is recommended not to create much of unused objects as it will result\ \ in memory consumption. This should be considered important when it\u2019s a mobile\ \ device code."
unnecessary operation response string
Remove these redundant calls
workflow delay
Remove Dynamic compression and allow only static compression.
response time high
Add Async tag in the javascript of layout.cshtml page where search functions are defined.
response time high
Add Async tag in the javascript of all source .cshtml pages to improve performance of javascripts on internet explorer.
response time high
Use Jquery grid to bind the resultset to optimize the loading of quick search results.
query optimization
The procedures should be modified to update only those rows created after last successful update. Modified date time column may have to be added to the source tables to identify the updated rows.
query optimization
Perform TRIM and TOUPPER function on data before inserting into CCTGLive tables. This implies a change in the components that are inserting data into the source table.
query optimization
Remove trim function as it never makes sense to apply trim while checking values for null in where clause
query optimization
The procedure PROC_ALL_TEMS2 should be modified to call update of limit values  only when temII updates are available.
query optimization
Allocate separate mount point for TEMP table space and create TEMP datafiles on those mount points.
configuration
Allocate three different mount points and move REDO log group and control files on those mount points.
404 error
Several source code files should be updated with correct reference path as per the shared list. List is allready shared with ICICI team internally.
code review
Remove large unwanted comments from AjaxSessionTimer.js. This will reduce the size of file to 1 kb.
query optimization
Create indexes on table TEMS_CPTYGRP for columns CPTY_SHORTNAME
query optimization
As a temporary fix implement functional indexes for key tables to immediately improve the performance of scheedulers. Later a calls needs to be taken to remove these functions from queries and subsequently replaces these functional indexes with normal indexes.
query optimization
Update query Q007 to Q0071  in  stored procedure CRM_PROC_INTERFACE
query optimization
Update query Q008 to Q0081  in  stored procedure CRM_PROC_INTERFACE
query optimization
If this is same scenario in production then redefine the partition window with correct data range to equally distribute data among  all partitionsi
query optimization
Create indexes for column ReportDate in tables  CRM_HIST_KREDITNETDETAILS
query optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_TEMPORARY_CPTYLIMITSSUMMARY,TEMS_TEMPORARY_CPTYLIMITS
404 error
Several source code files should be updated with correct reference path as per the shared list.
404 error
Several source code files should be updated with correct reference path as per the shared list.
404 error
Several source code files should be updated with correct reference path as per the shared list.
404 error
As a temporary fix implement functional indexes for key tables to immediately improve the performance of scheedulers. Later a calls needs to be taken to remove these functions from queries and subsequently replaces these functional indexes with normal indexes.
query optimization
Create functional indexes for columns  SDEALER, NTID in table  NP_LEVEL_3_ASAL_EOD
404 error
Create indexes for columns  PID in tables  NP_CRON_REFRESH
404 error
Create indexes for columns  SDEALER in table  NP_LEVEL_2_ASAL_PEAK
404 error
Create indexes for columns  UM_LOGINID in table  NP_USERMASTER
404 error
Create functional indexes for columns  SDEALER in table  table NP_PPR_LEVEL_1234
query optimization
Remove trim function from sql Q007 from CRM_PROC_INTERFACE and update referred table columns with trim function in stored procedure at single time. With this I have received improvement of 60% in ececution time for Proc_ITLM_SCH_PROCESS.
query optimization
Remove to_char function from sql Q011 from stored procedure proc_refresh_newpos as both column refreshtime and variable P_rpt_dt are of date type.
query optimization
Remove to_char function from sql Q012 from stored procedure proc_cal_level as both column refreshtime and variable rpt_dt are of date type.
query optimization
Create functional index for column ntid in table np_tmp_level_1234_peakhi
query optimization
Create functional index for column ntid in table np_level_4_peak
query optimization
Remove upper and trim functions referred for CPTYGRP_ID column as it is observed they are defined as numeric datatypes in referred tables.\nOnly below 4 out of 330 tables are having varchar2 datatype for CPTYGRP_ID column. Need to check feasibility of changing datatype to Number.\nLIMITS_DAILY_PPTDETAILS_HIST_MG\nTEMS_MANUALENTRY\nTEMS_MANUALENTRY_AUDIT\nTEMS_MANUALENTRY_TEMP
query optimization
Create functional index UPPER(TRIM(DealType)) in table RTS_tmpMain
query optimization
Create functional index TRIM(CurrencyPairRic) in table RTS_tmpMain
query optimization
Create functional index UPPER(TRIM(Tenor)) in table RTS_tmpMain
query optimization
Trucate table RTS_tmpMain at the beginning to ensure table is empty this will be useful if stored procedure is called twise in same session.
query optimization
Instead of calling several delete commands to delete rows from table RTS_FW_HLRates for different fwhl_riccode call single delete command by passing all fwhl_riccide values at once.
query optimization
Create index for BreachedRecordId in table FX_BREACHEDDEALSAPPROVAL
query optimization
Create functional index TRIM(APPROVER_STATUS) for table RTS_BREACHDEALS
printing many print statement consolelog
It is recommended to use Log4j.debug for logging debug statements . These can then be turned off during production by keeping the logging levels as Warn/Error .
generic exception catch exception e  caught place
It is recommended to catch specific exceptions e.g. Catch (FileNotFoundException e), SQLException etc
continuous integration used
It is recommended to use jenkins or any other open continuous tools for build, unit test and deployment purposes
old version jar used
It is recocmmended to review this process time to time and after reading the release notes of latest version we should include latest jars into our library folder
request responces various server done using xml
It is recommended to Use Google Gson framework instead of xmls because json is fast in processing and memory overhead is less and also good for transportation.
mvc framework used car intranet module code recommendation
It is recommended to use MVC Pattern in web application for better categorisation of Code Recommendations and for better maintanability
xml response stored two dimensional array string compare item string constant right hand side
it is recommeded to take string constants as string final string and check constant.compare(string)
web module micro service architecture
It is recommended to use micro services architecture of each apis so that in UI it can be shown that what all services are working and end user can perform available services requests.
function header written
It is recommended to use javadoc specifications for function headers so that dynamically help can be built and used for reference purposes
class variable settersgetters provided
it is recommended to check this carefully and provide only required getters/setters
code recommendation commented various file also fileinputstream handle opened closed used
It is recommended that commented Code Recommendations should not go into production. Run find bugs in entire Code Recommendations before every release
proper code recommendation commenting done entire code recommendationsbase
It is recommended to put proper Code Recommendations comment so that any other developer can understand it
junit test case present code recommendationsbase
it is recommended to write Junit test cases for each class for Unit Testing
using old apis cause several runtime issue
It is recommended to use latest provided API of given third party jars
jsp exception handling done car web module
it is recommended to provide proper exception handling mecanism.
high memory
A POC needs to be carried out to on XML versus JSON messages to ascertain the overhead of XML over JSON.
design
It is recommended to use standard Message Queuing system like IBM WebSphere MQ or RabbitMQ for availability of this system with connected interfaces. We also propose to use Extended Architecture where two phase commit happens, messages will be deleted from MQ when those messages are saved in Database so no recovery is required with this approach.\nCheck this link for more info https://en.wikipedia.org/wiki/X/Open_XA and\nhttp://docs.oracle.com/cd/E19509-01/820-5892/ref_xatrans/index.html
mvc architecture used car web module
Currently no MVC Architecture used in CAR Internet Module so it is recommended to use industry certified Spring MVC framework for better maintainability of Code Recommendations.
unit testing test case written unit testing
It is recommended to write Junit Test Suit for all the classes each function with all valid/invalid scenarios, it will achieve 100% Code Recommendations coverage.
xsltxml used making report
It is observed that MIS Reports are combined of all the servers which should be sent separately also for individual servers, also mis report only contains data for others and web which should also showcase from which input interface how many messages received and response time etc
nodata
Create composite index on column \nCML_MSG_TYPE, CML_DATE on table CARTBL_MSG_LOG
nodata
Create separate functional Index on \nDMI_INDIVIDUAL_NAME for table CARTBL_ISC_DMOG_INFO
nodata
Need to create functional index on \ncolumn CFPC_FILE_ID currently  the \nquery it is not hitting the index \nfor table CARTBL_FILE_PRCS_CTRL
code review
This can be avoided by implementing AJAX in the Application. AJAX allows portions of a web page to be loaded dynamically, separately from other parts of the web page. Please start implement AJAX from top 15 pages, especially for Search Functionality in List and Report Pages.
code review
This can be avoided by disposing unused Session Objects in the application during page redirects.
code review
Index on tables tbl_FC_Booking, tbl_Corporate_Dtl, tbl_Corp_Authorization, tbl_Corporate_User, tbl_Document_Client_Dtl needs to be created. Index script is shared in the next sheet.
code review
Please move the `return` statement after `InsertErrorLog` statement in `try` block of `SendEMail` Method.
response time high
Change application pool request queue size to 15000.
response time high
Perform below activities.\n-Club multiple .js files called in a same request to single file.\n-Minify .js files to reduce size.\n-Remove comments
workflow delay
Update UI at view itself without exposing files at client side. Singleton class could be used for different languages with property of all field to display UI instead of using avascript function in _Layout.cshtml.
nodata
Add Status_ID along with User_Id in index NC_User_Application_User_ID to make it a composite index.
response time high
Implement Database level caching using sql server notification by associating SQLDependency class with nHibernate linq queries.
workflow delay
Use transaction scope to rollback updates in case of multiple databases.
workflow delay
Limit the call for StatusHelp.html to once.
response time high
Provide picture or correct path for profile picture
response time high
Limit the call for GetCommunicationSummary to once.
response time high
Retrieve StatusHelp.html when user clicks on Show or Hide evidence.
workflow delay
Limit the call for  GetUserLocations and GetParticipantPlace to once in select participant event.
response time high
It is recommended to select only those columns which are required
workflow delay
Check the feasibility of loading these .js files and remove if not needed.
response time high
Avoid request for jquery.jqgrid.min.js in load event of Participant\AddEvidence page.
response time high
Check the feasibility of loading these .js files and remove if not needed.
response time high
Check the feasibility of loading these .js files and remove if not needed.
response time high
Limit the call for GetcommunicationSummary to once.
response time high
It is recommended to enable NoCount for all the stored procedures unless there is a specific requirement for disabling the option
workflow delay
Avoid call for Search\Language in Participant\Profile page if not needed.
response time high
It is recommended to use varchar(n) where n Is the max size expected for the variable. Fix to be applied at all possible places in stored procedures.
workflow delay
Limit calls for GetUserHistory to once.
response time high
Call GetCommunicationSummary only when popup is opened.
response time high
It is recommended to use just the union clause .
response time high
Maintain cache of Communication Summary  based on locationid and roleid.\n1. The controller should store response data for each getcommunicationsummary request into cache.\n2. Before sending request to the database, the controller should check cache if data is present in the cache else fetch it from the database.\n3. For actions that result into changes in Communication Summary  fresh data should be fetched from the database and cache should be updated asynchronousely accordingly.\n4. Records in cache should have expiry period which should be configured in configuration files.
response time high
Limit calls for Google api to once
workflow delay
Limit calls for GetVenues to once
workflow delay
Limit calls for GetRoyalAttendance to once
workflow delay
Avoid call to Search/GapRole in GAP/EventOverview page load event if not needed.
response time high
Avoid call to Search/GapRole in GAP/EventOverview page load event if not needed.
response time high
Avoid call to GAP/GAPAllRegionsforTpTab in GAP/EventOverview page load event if not needed.
workflow delay
Avoid call to GetUserLocations in Resources/AddResources page load event if not needed.
response time high
Limit call of Search\AccountStatus to once.
response time high
Remove UserName and LastName input parameters if not needed.
response time high
Remove Begin Transaction, Commit and Rollback statements in USP_SearchUsers stored procedure.
response time high
Avoid retrieval of Role_Location.Status.Detail in usp_SearchUser and application code id not needed.
workflow delay
Store HID in session variable after login and pass the same as parameter in usp_Get_CommunicationSummary stored procedure. Use the way it is used in usp_SearchUsers using like operator.
workflow delay
Limit the call of GetCommunicationSummary to once when communication Summary view is open and don't call if view is colapsed.
response time high
Avoid calling AccountStatus LeaderRecorded/AddTimeScales page load event if not needed.
response time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Residential.
workflow delay
Limit call for GetSubmenuOnPermission to once.
response time high
Limit requests for ViewAwardDetails.html to once
response time high
Avoid call to AcontStatus in Participant/AwaitingApproval if not needed.
response time high
Limit call for GetSubmenuOnPermission to once.
workflow delay
Limit the call for ProcessImages.aspx.jpg to once.
workflow delay
Limit call for GetSubmenuOnPermission to once.
response time high
Avoid call to GetCommunicationSummary if not needed
response time high
Avoid using Begin Transaction for select statements.
query optimization
Remove all to_char() functions on date columns of where clause. Instaed convert variable to date type in case variable is of different data type
query optimization
All the  indexes for CCTGLIVE should be  created on separate table space and with separate mount points allocated.
configuration
The history tables should be moved to a  separate  table space to improve the performance.
404 error
Several source code files should be updated with correct reference path as per the shared list. List is allready shared with ICICI team internally.
query optimization
Create indexes on table TEMS_CPTYGRP_MAP_INFO for columns CPTY_SHORTNAME
query optimization
Create indexes on table TEMS_LIVE _CPTY_LIMIT_SUMMARY for columns CPTY_SHORTNAME and CPTY_GRPNAME
query optimization
Create indexes on table ITLM_CRM_COPCPTY_TEMP for columns CPTY_SHORTNAME
query optimization
Use truncate command instead of delete whereever whole data is deleted from the tables.
query optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_REASONMASTER,TEMS_PENDING_CONF,TEMS_MANUALENTRY,TEMS_FAVOURITE_CPTYGRPID
query optimization
Create indexes for column CPTYGRP_ID in tables TEMS_TEMSLSETTLE_UTIL_BUCKET,TEMS_TEMS1_EXPOSURESUMMARY
query optimization
Create functional indexes for columns  SDEALER, NTID in tables  NP_LEVEL_2_ASAL_PEAK,NP_LEVEL_2_ASAL_PEAK_DOM,NP_LEVEL_3_ASAL_PEAK,NP_LEVEL_3_ASAL_PEAK_DOM
query optimization
Create indexes for columns  SDEALER in tables  NP_LEVEL_2_ASAL_EOD
query optimization
Create indexes for columns  CCY in tables  NP_LEVEL_1_ASAL_EOD
unnecessary replace pvtdatafield125 variable
The replace is not required. It is recommended to call split on PvtDataField125 directly.
nodata
Recommend to set the Loglevel to Error/Warn as in other web servers
nodata
Please refer attached file for the list of these requests.  Missing files should be added to reduce the number of hits on the server.
nodata
Exceptions to be reviewed by the Product team.
nodata
Check the connectivity and performance of CDCI Component
nodata
These queries are observed consistently in all AWR's and hence we have recommended that the tables be analyzed. Tables used by queries have not been analyzed since Dec 2013. \n\nIndexes were present for columns used in 'where' clause however indexes are not getting utilized.  Recommended to analyze the below tables for queries to utilize the indexes.  \n1. ALERT_DETAILS_TABLE\n2. CORPORATE_USER\n3. CHANNEL_SPECIFIC_IND_PROP
nodata
NoData
nodata
NoData
nodata
'Increase below memory parameter values:\nSGA_TARGET = 64\nDB_CACHE_SIZE = 48G\nSHARED_POOL_SIZE = 8G\nPGA_AGGREGATE_TARGET=8G\n\nNote: ADDM report also recommends to increase the SGA size.'
nodata
IDX_CADT index is composite index on CUSTAUDITTBL table on columns -- ADT_SRL_NO, LOG_SRL_NO and BANK_ID.\nChoose the highest cardinality column out of these columns and create a reverse key index to avoid locks on the index.
nodata
"Create below indexes on ALERT_DETAILS_TABLE tables:\\n1. Index on column\ \ R_CRE_TIME .\\n2. Composite functional index on below columns in order of lower\ \ to high cardinality:\\nALDT.BANK_ID\_\\nUPPER(CORP_ID)\\nUPPER(USER_ID)\\nUPPER(ALERT_NAME)\\\ n3. Create an index on USER_ID Column."
nodata
Reason for full table scan is usage of like operator in the query. Create text search index on the column where like operator is used in queries.
nodata
NoData
selecting fincore hang intermittently
NoData
high number redo log switch sso database
To increase the number of log groups to 6 from 3 with each redo log file size of 1GB. This will cater to the current load for isolated testing. For further loads the redo log sizing will be monitored and fine tuned accordingly.
row lock contention kwiktdbby table
NoData
full table scan secudetailrgtrtable table
NoData
high response time 02 sec per execution
Check functionally if the query can be changed to improve performance . Else we recommend to add an index on EVENT_TRAN_ID column on BET table to avoid full table scan.
sequence exceeds maxvalue
Increase the max value of sequence or use recycle flag
plsql block used file transfer
This can be replaces by Stored Procedure with bind variables.
sql statement generating performance cost
Adding below index hint improves SQL performance cost to 12071.\n/*+ index(FCI IDX_FEX_CLEAN_INST_TABLE) */
intermittent spike response time
NoData
query taking high cost execution
Index present on PAYSYS_ID and BANK_IDENTIFIER. But the WHERE clause contains only BANK_IDENTIFIER. PAYSYS_ID is available in the script. This should be added in the WHERE CLAUSE of the query
query taking high cost execution
Check whether sol_id is available in BANCS.INPUT or BANCS.STDIN repository and add SOL_ID condition with that variable in the WHERE clause of the query
fatal error observed
NA
high response time failure
NA
full table scan table hsclive
NA
high failure response time kwiktd submit
NoData
response time meet sla
NoData
response time meet sla
NoData
issue new menu
NoData
multiple fetch waitgif server across action
NoData
bulletjpg fetched browser cache
NoData
high page download size hacli transaction
NoData
high page download size hbdtm add transaction
NoData
high page download size haammodify transaction
NoData
high page download size haamverify transaction
NoData
high page download size icianwcsadd transaction
NoData
high page download size kwiktdadd transaction
NoData
high page download size kwiktdv transaction
NoData
large size j file
File size of all .js files can be reduced considerably by compressing and minifying them. Page size can further be improved if all .js files are clubbed into maximum one or two js files.  Also comments should be removed.
high page download size hcashdep transaction
NoData
high page download size hacm modify transaction
NoData
high response time select crm
NoData
high sql cost
create index CRMUSER.IDX$$_18FD30001 on CRMUSER.ACCOUNTS("BANK_ID"). It will reduce cost to 15062 if  index is created
full table scan table personskills
Create Index on PERSONID column
amount account tab htm hcashdep menu call set url s turn call mentioned finacle script take 1 second complete intermittently spike 3 second thereby impacting overall response time step
Instead of maintaining the configuration parameters in a flat file and open the file for each iteration for read, its recommended to mainatin these parameters in a database table and query the same .
high page download size cif verify transaction
NoData
core file generated c app server
NoData
high page download size hoaacsbverify transaction
NoData
high page download size hoaacvlaverify transaction
NoData
high response time able scale tps
NoData
high page download size haamverify transaction
NoData
found multiple session wait event virtual circuit wait sql 41mj9dwdpkb07
NoData
sql statement performing full table scan high cpu cost
Create index for ENTITY_CRE_FLG column on NETWORK_DIRECTORY_TBL table. This will reduce cost to 1
sql statement performing full table scan high cpu cost
Create a composite index for ROUTING_REF_NUM,BANK_ID,UTR columns on SWIFT_MSG_HISTORY_TABLE table. This will reduce cost to 1
fatal error
NoData
error view
NoData
gc happening
NoData
coredump
NoData
slow execution genlimo service
NoData
sql statement performing full table scan high cpu cost
Create a composite index for ACCT_NUM,MICR_CODE columns on C_ICHB table. This will reduce cost to 23
fatal error observed
NoData
sql statement performing full table scan high cpu cost
Remove TO_CHAR in join condition (gam.cif_id=to_char(accounts.orgkey), and its helped to reduced the execution time and COST, also full table scan on ACCOUNTS table prevented.\nColumn data type as below \ngam.cif_id VARCHAR2(50 CHAR) accounts.orgkeyNVARCHAR2(50)
nodata
Create Index on CAM_ACTIVE_FLAG & Stats are old \n for table CARTBL_CCIF_UCC_ACNT_MAP
response time high
It is recommended that the XML file generation code needs to be re-visited. The Operations should be done in memory and flushed to disk at regular intervals. \nA limit for the memory buffer can be configured and once it reaches the limit the data can be flushed to the file system.
workflow delay
Recommendation to use PreparedStatements instead of statements.
response time high
Remove all sysouts from the code base. If these messages are required for debugging, please move these messages to a logger with appropriate logging level.
response time high
It is recommended to close the opened connection, resultset and statement in finally statement.
workflow delay
It is recommended to close the opened resource handle in finally statement.
workflow delay
'It is recommended to be replaced  with StringBuilder..\nIf StringBuffer has to be retained in the code. Set the initial capacity of StringBuffer using its constructor this improves performance significantly. \nStringBuffer public StringBuffer(int capacity) Constructs a string buffer with no characters in it and the specified initial capacity.\nParameters: capacity - the initial capacity.\nThrows: NegativeArraySizeException - if the capacity argument is less than 0.\nSubsequent slides have information on the classes where StringBuffer is used with line numbers.'
response time high
Assign this calculated value to a variable outside the loop.  This would avoid the performance overhead of calculation for each iteration. It would improve the performance of the loop by 150%
workflow delay
Restructuring of the loop is required.  Move the most likely case first. Ensure that by satisfying earlier parts of the expression, we do not cause the later expressions to be evaluated and the code executes as fast as the condition is met.
workflow delay
Load the javasctipts on load or after all componetns in the page has been loaded. This will improve the performance of the application from enduser perspective.\nBelow example illustrates how to download external javascript in a non blocking manner\nvar h = document.getElementsByTagName('head')[0];\nvar link = document.createElement('link');\nlink.href = 'mycss.css';\nlink.type = 'text/css';\nlink.rel = 'stylesheet';\nh.appendChild(link);
response time high
Check if an instance of MI is already running on the server and exit the duplicate request to run the application. Implement the below code in the startup script of MI.\nMI_COUNT=`ps -ef | grep java | grep -v grep | grep MI.jar`\nif [ $MI_COUNT -gt 1 ]\nthen\n{\necho "Already $MI_COUNT instances of MI is running, aborting this startup request"\nexit\n}\nfi
response time high
It is recommended to use database global temporary tables to do these transactions. Since these operations would be faster in database temp tables.
response time high
The function UPPER to be removed and the value that needs to be passed should be assigned to a bind variable in the expected alphabet case
workflow delay
Use PrepatedStatement rather than Satement. Use bind variables for the PreparedStatements.
workflow delay
Access Template XML file only once and cache these in lcoal memory using Hashmap and return cached data subsequently.
workflow delay
Replace pure local/method scope Hashtables with Hashmaps. \n\nCases where local variable is escaping scope either by returning the Hashtable or modifying value passed as method argument, it could be necessary to use Hashtable (this will have to be evaluated on per-case basis)
workflow delay
Use constant first and then the variable.
response time high
Use document fragments (container) to hold DOM elements and add document fragment at one go.\n\nvar list = document.getElementById("list"),\n    frag = document.createDocumentFragment(),\n    items = ["one", "two", "three", "four"],\n    el;\nfor (var i = 0; items[i]; i++) {\n  el = document.createElement("li");\n  el.appendChild( document.createTextNode(items[i]) );\n  frag.appendChild(el); // better!\n}\nlist.appendChild(frag);
workflow delay
Change the initrans of table to 20 and its indexes to 40
hard parsing query
Use bind variables instead of literals
nodata
It is recommended to use Hashmap if not used in  multithreaded environment .In case the map is to be used in multithreaded environement we recommend concurrenthashmap .
nodata
Recommended to use Constants instead for hard coding the values inside the classes.
nodata
duplicate calls for same method needs to be removed.
nodata
redundant call to database needs to be removed
nodata
Recommended to have a separate util class for all kind of date formatting or other convertion of fields and those can be reused in the required classes.
nodata
Recommended to combine all the select statement as 1 select and use in the table update.
nodata
It is recommended to remove the cursor user_id and combine both SELECT statements into one statement.
nodata
We recommend into debugging this as to why the transitioninfo list has same task name in its list of objects .
nodata
We recommend to debug into this behaviour . Loggers for these are seen in the weblogic logs . These show the repeated calls to these methods . We recommend caching the object for subsequent uses in an operation.
nodata
These insert statements need to be commented out in production. If these are required for any error tracking then make changes in the code so that if any error occurs then only run insert command.
nodata
It is recommended to comment out dbms_outout.put_line package call in  the packages xxsbi_ar_premium_collection and xxsbi_ar_invoice_pkg which are part of production database. In UAT it is helpful for debugging.
nodata
It is recommended to combine all the update on the same tables as one update statement.
nodata
'It is recommended to assign next value of sequence using variables as suggested below - \nv_trx_header_id =: xxsbi_policy_header_s.nextval;'
fly conversion documentsimages pdf file
Perform pdf conversion activity offline using windows service.
dynamic compression web server
Remove compression for Dynamic contents and keep compression for static contents to reduce to page download size for static contents.
use println
Recommended to turn this off . Instaed of this logging api can be used.
slow respoonse lower speed due transfer large xml data network
Do following steps at both dotnet server and android client side:\n1. Before Sending request.\n   - Convert xml string to bytes   \n   -Compress the bytes  using gzip \n   -Convert Compressed bytes to Base64 string.\n2. After receiving request.\n     - Convert Base64 string to bytes.\n     - Decompress using gzip\n     - Convert bytes to xml string
404 error
Use below approach:\n1. If broken link is from from android client analyze cause and fix it.\n    - If it refers to static missing file then provide it.\n   - If it refers to dynamic missing file analyze to identify  reason for broken link.\n2. If broken link is not due to android app and is due to some manual access no fix is needed.
hard coded image compression quality
Configure image compression quality in the web.config of RLI_API. Android application should retrieve the required compression quality from the server at the start of document upload activity.
missing header content expiration
Open response header of MobileApp and set following in Set common header of MobileApp website on web server.\n- Set "Enable http Keep Alive" option to true.\n-set "Expire web content:" to some longer duration(~3  months) .
multiple call demoxml calling endown method endownhtm
Ensure that request for demo.xml is sent once.
multiple call demoxml load event reliancelifeinsurancemoneymultiplierplanhtm
Ensure that request for demo.xml is sent once.
repeated request multiple static file page load reliancelifeinsuranceguarantedmoneybackplanhtm
Ensure that repeated requests are avoided for these static resources.
unused additional data transferred along image data document upload
Use a new light class with only relevant properties such as REFNUMBER and image bytes instead of using ProposalApplication class which contains entire proposal data.
multiple request source xml data file reliancelifeinsuranceclassicplaniisinglehtm
Avoid multiple calls to same source xml in same event.
continuous logging debugging dotnet server application
Set configuration for mode of logging in web.config file of all applications and perform logging based on configured logging mode. Create a separate log files for error and messages for efficient IO operations.
'unnecessary call tostring '
Avoid calling toString() on String objects; this is unnecessary.
string comparision handled properly
'Use Position literals first in String comparisons for equals/equalsIgnoreCase. \nExample: x.equalsIgnoreCase("2"); // should be "2".equalsIgnoreCase(x)'
use stringbuffer
Use StringBuilder instead of StringBuffer if expensive thread-safe operations are not required. StringBuilders is faster than StringBuffer for strings concatenation.
repeated request multiple static file loading relianceimmediateannuityhtm
Repeated requests should be avoided for the static contents
multiple call demoxml load event reliancelifeinsurancesuperendowmentplanhtm
Ensure that request for demo.xml is sent once.
multiple request demoxml data file load event reliancelifeinsurancesmartpensionplansinglehtm
Multiple requests of demo.xml should be avoided in the same event.
hardcoded value static variable ip commonfunctions class uat production
Use separate service urls for IP values in UAT and production.
unnecessary select statement groupvalidation stored procedure mobilebi database
'In GroupValidation stored procedure just keep select statement for #MSG temp table and comment out select statements for remaining tables.'
unnecessary use temp table enagntrnuserformula groupvalidation stored procedure mobilebi database
'Remove/Comment code to create and populate temp table #en_agn_trnuserformula in GroupValidation stored procedure'
avoidable temp table enagntrnformulasumm groupvalidation stored procedure mobilebi database
'Modify logic to fetch value for ValueSa directly from temp table #en_agn_trnUserFormula instead of #en_agn_trnformulaSumm.'
multiple request demoxml data file load event premiumcalculatorforlifestyleretirementsolutionhtm
Multiple requests of demo.xml should be avoided in the same event.
repeated request multiple static file loading premiumcalculatorforlifestyleretirementsolutionhtm
Repeated requests should be avoided for the static contents
unnecessary request rupeeforadian font file lifestyleretirementsolutioncalculatorhtm
Avoid request for rupee_foradian font files if not needed
usage vector class
We recommend using ArrayList instead of Vector if expensive thread-safe operations are not required.
multiple request demoxml data file load event reliancelifeinsurancesupermoneybackplanhtm
Multiple requests of demo.xml should be avoided in the same event.
multiple request source xml data file reliancelifeinsurancesmartcashplusplanhtm
Avoid multiple calls to same source xml in same event.
multiple request demoxml data file load event uliphtm
Multiple requests of demo.xml should be avoided in the same event.
usage hashtable class
We recommend using hashmap instead of Hashtable . In case there is a requirement for high concurrency we can use ConcurrentHasMmap.
404 error
Create functional indexe for columns  NTID in tables  NP_LEVEL_1_ASAL_EOD_DOM
query optimization
Call  PROC_NOOP_FILLSNAP only in stored procedure PROC_Refresh_newPOSXRect. Even this could be avoided if data is directly read from base tables.
query optimization
Create index for column refreshtime in table np_cron_refresh
query optimization
Remove all trim and Upper functions and update referred table columns with trim and upper functions at beginning of stored procedure. I have received 30% better result by doing so.
query optimization
Create index for column ntid in table np_tmp_cross_snap_peakhi
query optimization
Create functional index for column ntid in table np_level_1_asalIBG_peak
query optimization
Create functional index for column ntid in table np_level_2_asal_peak
query optimization
Create functional index for column ntid in table np_level_3_asal_peak
query optimization
Create functional index for column ntid in table np_level_4_peak
query optimization
Create index for column maturitydate1 in table RTS_GetMaturityRics
query optimization
Either apply trim to all comparisons of CurrencyPairRic or don't apply anywhere. If not using trim then create normal index in point 72.
query optimization
Create index for column maturityRic in table RTS_tmpMain
query optimization
Assign values to all variables in single statement like below.\nIf v_tempcnt> 0 then\nselect currencypairric into currPairRic, CurrencyPair into CurrencyPair_1, Tenor into Tenor, DealType into Dealtype, MaturityRic into matRic from RTS_tmpMain where CurrencyPairRic = currPairRic;\nend if;
query optimization
Create functional index TRIM(CurrencyPair) in table RTS_tmpMain
query optimization
Remove trunc function on Addedon field of RTS_MaturityMatrix table in all where clauses and take care during insert itself.
query optimization
Create functional index TRIM(PORTFOLIO) in table RTS_DEALS_AUDIT
query optimization
Create functional index TRUNC(BREACH_DATE) in table RTS_MARGINBREACHDEALS
query optimization
"Remove NVL command from queries whereever used like below.\\nNvl(Variable_Name,'0')\ \  not in (VAL1,VAL2,\u2026)"
query optimization
No need to have Trader field in sub query. Simply '_BKP' should be specified in the subquery. Also Upper function should be removed.
query optimization
fix referenc error of ImageURL  for excel.gif in FXRateScan_BreachedDeals_RepoprtOracle.aspx. This file is missing in images folder.
query optimization
Create index for FK_LM_ID in table rts_user_entitymapping1
query optimization
Create index for PK_LM_ID in table rts_locationmaster
query optimization
Create index for FK_UM_UserID in table rts_user_entityMapping2
query optimization
Create index for FK_GM_ID in table rts_user_GroupMapping
query optimization
Create index for PK_GM_ID in table rts_GroupMaster
query optimization
Create index for TradeDate in table FXRateScan_BreachedDeals
system property hashtable hood slow
It is not recommended to use System.get/set property for storing class variables. Instead one global class with static getters should be used by reading all properties at startup time.
observed stream object closed
It is recommended to close the Stream objects in finally blocks .
stringbuffer used many class even though used single threaded environment
Its recommended to use StringBuilder instead of StringBuffer after careful evaluation of multithreadedness of the piece of Code Recommendations.
string literal used application frequently
it is recommended to use String constants rather literals.
hashtable data structure used
it is recommended to use concurrenthashmap class over hashtable class.
jdbc custom class written db connection
It is recommeneded to use dbcp third party open source db pool for better performance
custom carqueue carcontainer class used
It is highly recommended to use RabbitMQ or any other message queueing framework for better message processing with all connected interfaces.
code recommendation aligned properly
It is recommended to prepare proper checkstyle for Code Recommendations formatting and use eclipse checkstyle feature for formatting the Code Recommendations
variable upper case camel case
it is recommended to use lower case in .properties file
tostring  method implemented
It is recommended to override toString() method for pretty print of object for debugging point of view
jsp template mecanism used car web module
it is recommended to use jsp template mecanism for better maintainability and proper Code Recommendations structrisation.
custom logging used car application
For audit trail, the asynchronous logging needs to be looked at rather than current blocking based logging. Log4j can be used for this purpose.
clustering used
It is observed that no Weblogic clustering used in current architecture so we proposed to use Weblogic Clustering for better performance and availability.
daemon message handler code recommendation single module
We recommend to separate Daemon Code Recommendations base from Message Handler Code Recommendations and create separate jar for commonly used utility classes and use among Daemon, MsgHandler and Intranet Modules.
profiling tool used code recommendation profiling
It is recommended to use JProfiler tool for doing the profiling. It will give you report of method performance timing.
single point failure checkings
"To avoid single point of failure, follow given below basic high level recommendations.\\\ n1.\_\_\_\_\_\_ All production servers should have at least 2 Network Interface\ \ Cards.\\n2.\_\_\_\_\_\_ All Production servers should have same operating system\ \ version and build version.\\n3.\_\_\_\_\_\_ All production servers if virtualized\ \ then should be derived from different base server."
nfr document prepration
It is recommended to do load testing of CAR application using HP Load Runner for better performance and high load testing and Non Function Document (NFR) should be prepared for application benchmarking for future performance testing.
process management
All Use Cases with concurrent users and average response document should be prepared from application knowledge point of view.
nfs partition connecting
'Monitoring NFS Mount points using APM Tool: The NFS mount point working can be checked via custom scripts and these scripts can be called using APM tools at different time intervals'
256 mb allocated car jvm process enough critical application
It is recommended to do proper JVM Tuning of CAR Java applications and for now we can set Xms-1024M and Xmx:1024M for better performance
metric captured need captured better disk usage analysis
To capture the Avg Disk Queue Length, (% wait in Solaris) in monitoring software. This will help in the analysis or hard-disk utilization.
new feature
It is recommended to use APM Tool JIM (Java Inclusive Monitoring) for checking the method level response time.
new feature
It is also recommended to use Forensic feature of APM tool
nodata
Create  index & test  on column CTA_FCRM_SR_NO  for table CARTBL_TEMP_ACCOUNTS
nodata
Use UPPER function in the where clause with the columnn\nCUM_CLIENT_NAME  for table  \nCARTBL_CCIF_UCC_MASTER
nodata
Create composite index on CLA_ACCT_NO,\nCLA_TRANSACTION_TYPE,CLA_CREATED_BY FOR \nTABLE CARTBL_CONTACT_LNKGS_APPROVE
response time high
The thread count needs to be parameterized in an external configuration file and can be read during the init of the application and kept in memory. This can be tweaked easily for optimal performance
response time high
Since there are a limited number of connections that can exist between the host process and the server at one time, setting a timeout enables the host process to open a new request sooner, rather than waiting on a delayed stream.
workflow delay
"The for loop performance can be further improved more by changing the loop\ \ to count backwards. So rewriting a loop to compare against 0 will produce faster\ \ loops. \\nSo for example, the earlier discussed program changed as below following\ \ for better performance\\n\\npublic PerfLoopControl()\\n     {\\n         String\ \ str = \"Avekshaa Technologies Pvt Ltd\";\\n         int len = str.length();\\\ n         for (int j = len-1; j >= 0; j--)           \\n          {\\n// code doesn\xED\ t change the length of the string.\\n           }\\n     }"
workflow delay
Recommendation to use PreparedStatements instead of statements.
response time high
It is recommended to close the opened connection, resultset and statement in finally statement.
workflow delay
Analyse requests which are very frequently fired and could be clubbed as single request.
response time high
Datawarehouse scripts should be modified to retrieve only Cutomerinduced transactions for uploads and processing from Finacle. This would reduce the number of transactions to be processed.
workflow delay
Recommendation to rewrite the logic to avoid filtering based on null values\n2) to create the below index CREATE INDEX IDX_ACCTRISKMAPPING_ACCTCLOSEDDATE ON TBL_ACCOUNTRISKMAPPING(ACCOUNTCLOSEDDATE,' ');
workflow delay
The design of these codes to be changed to pass bind variables in the cursor query output instead forming the query as a string,assigning to a variable and then passing it through as cursor output
response time high
The recommendations provided in the sheet for each problematic query to be implemented
response time high
In certain cases its found that eventhough the values are proper , the program still uses TRIM function. The value should be trimmed before the sql and the trimmed value should be passed as bind variable
response time high
The pipe concatenated variables should be removed and only proper bind variable needs to be passed
batch job execution
Recommended to split batches across all C-App servers as EOD jobs
batch job execution
NoData
nodata
Increase the heap size from default 64 MB to 500 MB (on 8 GB machine) and 1 GB (on 16 GB machine) and check if the OutOfMemory error is addressed. Check GC behavior after altering heap settings.  \nAdd parameter to the JVM to dump the Heap in a file if OutOfMemory error occurs.
nodata
High service time observed on storage devices even at low transfer rates. Call to be logged with EMC to understand the reason for high service time on the storage devices. This is a problem across servers with varying severity.
nodata
'Change DB level parameter : DB parameter filesystemio_options=directIO.'
nodata
Action linked with DB-1. SGA resizing needs to be done after action DB-1 is implemented. Recommended sga_max_size=160GB and db_cache_size=120GB and tune further as required
blocked connection
'1. Primary Approach: Need to change the IPs of the servers, so that all the servers belongs to the same subnet. This will eliminate the firewall overhead in the response time and results in significant improvement in response time. It is best advised that components within the logical flow are kept in the same subnet. Any additional layer in between will lead to delay.\n2. Alternate Approach: Need to create Inbound and Outbound Rules in the firewall to not filter/check traffic from specific IP range.'
static jpg png file consuming resource nginx load balancer tomcat app server
Static Resources needs to be cached on Nginx for better Performance. Nginx can be used as a caching layer and these requests will be served from Nginx itself.
single instance nginx load balancer server running single point failure complete platform
Atleast two instance of Nginx Load Balancer Server needs to be there to avoid Single Point of Failure and High Availability of the Application.
single instance mysql database server running single point failure complete platform
Atleast two instance of MySQL Database Server (Master-Slave) needs to be there to avoid Single Point of Failure and High Availability of the Application.
highiest disk busy percentage high read write io consumption
We strongly suggest to have different disk to store the critical database related file as this will divide the  I/o consuption to all the available disks and reduce the contention on one disk. This has to taken care as once the load increases on the database this contention will also increase exponentially.
high resource consumption
The table fragmentation needs be to taken care as the query execution is hampered  .
high resource consumption
Output of validateSP API needs to be cached on Nginx or Im-Memory-Cache for better Performance. Nginx can be used as a caching layer and these requests will be served from Nginx itself.
high resource consumption
Output of getActiveProducts API needs to be cached on In-Memory-Cache for better Performance. And these requests will be served from App Server itself.
high resource consumption
These API calls needs to be served directly through method call instead of RestServiceCaller to improve the turn around time.
high resource consumption
These API calls needs to be run in parallel to improve the turn around time.
high resource consumption
maxConnection value needs to be increase and impact needs to be monitored. Recommended value of MaxConnection attribute is 12 * Number of Cores.
high response time
To reduce the total size, GZ Compression needs to be implemented for js and css files. This will reduce the total size by ~80% and improves the page performance.
high response time
To reduce the total size, GZ Compression needs to be implemented for js and css files. This will reduce the total size by ~60% and improves the page performance.
high resource consumption
1)We suggest to schedule alerts with respective warning thresholds.\n2) Also set the SESSION_CACHED_CURSORS parameter to value 60.\n3) Use bind varieables in the queries instead of literals to avoid high parsing .
availaibility issue
Hence increase the size of redo_log from 100 to 200 MB. Also should have two members for each redo_log group.
availaibility issue
1)These queries with high resource consumption &  execution time need to tuned and corresponding indexing need to be validated .\n2) Also need to consider data purging where it is possible. Partitioning of the table will also be helpful but this may need additional license
high memory consumption
We suggest to increasing the  memory by 30 %   on  server inorder to handel 3x load.
database slowness
The table fragmentation needs be to taken care as the query execution is hampered  .
high memory consumption
We suggest to increase 30%  memory on the server inorder to handel 3x load.
one sluggish service degrades service also
Expose all TeBT portal services as microservices which can be run on  lightweight application server (apache tomcat), and to be deployed on various instances in cluster.
workflow delay
1. It has been observed that this batch takes less than  6 mins for execution. We recommend the batch frequency to be changed from 30 mins to 15 mins. This will ensure that policy conversion for respective policies can be reduced by 15 mins.\n\n2. This batch can also be a candidate for converting into a real time service with the same rationale as provided in the recommendation (# no 4).
high memory uilization
Cached memory of both server should be uniformally distributed.
high response time
The data will be backed up every month and then purging will be done so that ample space can be released back to OS.
workflow delay
We had intially suggested the  "optimizer_index_cost_adj" parameter to be set to 100 (default) to use optimal execution plan for sql queries.
high cpu utilisation high io writes
After analyzing thread dump, it has been observed that 52% of total thread was in blocked state. All these threads were blocked while getting connections from DB. The effect of getconnection() method is that a lot of threads gets blocked during processing of resultset object. Each of these processing  have a connection assigned to it which does not get released until the processing/transformation of resultset object into json gets completed. This incident has been observed on hslpaext1 - 10.60.5.175 for OPS application.\n\nCode review comment:\nIn code, connection is getting released after the result object gets converted into json. For json conversion Blob column is used which is taking time for transformation from/to json. This is done to save memory, but this will take time for processing resultset object. The optimization of code would not save a significate time in releasing DB connection.
high response time
'We propose to increase JDBC connection pool across all the SOA layers (Front office, back office, Branch and BPM - WAS clusters). \nThe proposed increase is by 50% where existing connection pool value is less than 110. For values more than 110, there is NO change is required.\nNote: \n1) Please make changes to only those data sources which are related to TeBT application flow, other need not be changed.\n2) Please make one changes to one WAS cluster at a time. Once it''s stabilized then proceed for the next cluster. \n3) Also, do not make more than one change at time to ensure that it can be rolled back\nThis will ensure the system has higher pipeline to accommodate more connections/requests. In the embedded image, proposed plan to implement the connection pool across all the related servers have been highlighted.'
high response time
Increased JDBC connection pool size to 125 on Flowdox app servers.
high response time
We have observed "BreakNetExeception" from OPS portal to DB.\n\nOur suspicion is that there were network packets losses between external portal and DB Server. This however is observed intermittenly. Please follow the below approach in case of similar observations in future:\n- Take TCP dump between the hslpaext1(external portal server) and DB Server \n\nThis dump will indicate if there are network related issues at external Portal / DB server. \n\nAs a long term strategy , we strongly recommend to monitor the network performance across the servers. It is best advised that HDFC Life leverage the capabilities of Dyntarce Network Monitoring feature. Alternatively you can also install iftop across servers and monitor network utilizations.
workflow delay
'It''s recommended to reduce the Minimum heap size (-Xms) for all the Java setups so that GENCON which is a defult algorithm in Java 1.6 works efficiently. Setting it at equal size does not leave Java any room for memory increase. Also, -Xmx (max heap) size affects GC in bad way such as long GC duration etc.\n\nWe recommend  to change all settings for -Xms to 4GB for all the Java Servers (SOA+BPM) where -Xmx (max) is set to 12GB\n\nNote: This will NOT have any negative impact as such since we not restricting the Max memory'
high response time
Its recommend to switch GC policy from gencon to balanced
high response time
Increase the bandwidth between the two cluster interconnect nodes to 1 Gbps for private network.
workflow delay
Our suspicion is that there were network packets losses at load balancer end. As per Dynatrace logs there were timeout errors observed on LB 10.60.5.118. \nThis however is observed intermittenly. Please follow the below approch in case of similar observations in future:\n1. Take TCP dump between the Portal and LB (talking to EMP Portal)\n2. Take TCP dump between the SOA Server and Back office \nThese dumps will indicate if there are network realated issues at SOA / LB / PAN server\n\nAs a long term strategy , we strongly recommend to monitor the network performance across the servers. It is best advised that HDFC Life leverage the capabilities of Dyntarce Network Monitoring feature. Alternatively you can also install iftop across servers and monitor network utilizations.
high response time
Recommended settings shared in "limits.conf" and "90-nproc.conf" sheet.\nImplementation plan has been shared with the team.
high response time
We propose the below approach :\n1. We propose physical memory to be increased to 23 GB for the below servers and Java Heap Min & Max( Xms & Xmx) to be set 4Gb and 12 Gb respectively.\n\nHOST                   Proposed GB\nhslpabsoa3       23\nhslpabsoa13     23\nhslpabsoa14     23\nhslpabsoa4       23\nhslpabsoa11     23\nhslpabsoa5       23\nhslpabsoa6       23\nhslpabsoa12     23\nhlpabsoa17       23\n\n2. In case on the below servers if physical memory can't be augmented (however we strongly recommend to increase it to 23 GB), the below approch should be followed.\n\nHOST                   Available GB        Xms         Xmx\nhslpabsoa3       15                         4               12\nhslpabsoa13     13                         4               8\nhslpabsoa14     13                         4               8\nhslpabsoa4       15                         4               12\nhslpabsoa11     11                         4               8
workflow delay
"We recommended to improve document mapping at POS side so that a set of\ \ images can be categorized into one single type then and there and same will be\ \ reflected in FileNet. This can be done as follows,\\nBy following document mapper/taxonomy\ \ in POS before uploading document into FileNet.\\nAdding front end validation while\ \ uploading document.\\nAdding a tooltip which will provide more detail about the\ \ type of document , no. of images/documents, size of the image, etc.\\nRestricting\ \ number of documents uploaded in \u2018OTHERS\u2019 category."
workflow delay
"We recommended to improve document mapping at POS side so that a set of\ \ images can be categorized into one single type then and there and same will be\ \ reflected in FileNet. This can be done as follows,\\nBy following document mapper/taxonomy\ \ in POS before uploading document into FileNet.\\nAdding front end validation while\ \ uploading document.\\nAdding a tooltip which will provide more detail about the\ \ type of document , no. of images/documents, size of the image, etc.\\nRestricting\ \ number of documents uploaded in \u2018OTHERS\u2019 category."
high response time
Our suspicion is that there were network packets losses at load balancer end. As per Dynatrace logs there were timeout errors observed on LB 10.60.5.46. \nThis however is observed intermittenly. Please follow the below approch in case of similar observations in future:\n1. Take TCP dump between the SOA Server and LB (talking to PAN Servers)\n2. Take TCP dump between the SOA Server and PAN Server \nThese dumps will indicate if there are network realated issues at SOA / LB / PAN server\n\nAs a long term strategy , we strongly recommend to monitor the network performance across the servers. It is best advised that HDFC Life leverage the capabilities of Dyntarce Network Monitoring feature. Alternatively you can also install iftop across servers and monitor network utilizations.
high response time
'Raised ticket with IBM: TS001341188\n\nAs per IBM Support team''s reply, IBM BPM product upgrade is required in order to resolve this issue.'
workflow delay
Solution\nN+1 Standby deployment manager in HA\nFailover to the new standby deployment manager is depicted in the following diagram:\n\n\n\n\nIn above diagram, The active and standbys share work spaces. When a deployment manager takeover occurs, work is not lost, because the ODR automatically recognizes the election of the new active deployment manager and reroutes administrative requests to the new active deployment manager.  During the takeover from the active deployment manager to the standby, shared file system detects the loss of the active deployment manager and release the lock.
workflow delay
Total 22 issues identified in Premium Calculation, Proposal Form Filling Journey and Submission. Observation and Recommendation details shared in Analysis Report (Online_Journey_Analysis_7Sep2018.pdf and 2nd_Online_Journey_Analysis_17Sep2018.pdf)
workflow delay
Please check the MSGLOG table (which has a CLOB column in which entire message is dumped ) and why that kind of requests are failing. At present it's truncated at regular inetrvals but till we fix this error at the souorce , this approch will not be useful.
high letancy query thoroughput
1. Create tablespace with 16 K blocksize  and move the DET_TRADES_DELETED table with the tablespace.\n2. Create tablespace with 16 K blocksize  and move the DET_TRADES_DELETED table indexes to it.
static data downloaded multiple time
Caching of Static data.
oracle connection object used multiple time
It is recommended to use seprate datautility class file.
test present
Write the Unit Test cases
automated alert mechanism
There should be an email mechanism which can capture call stack and logged user information and send email to IT.Net Support Team.
profiler report available
It is recommended to maintain the Profiler reports before publishing new deployment on production servers.
impact analysis document available
It is recoomended to maintain the Impact analysis document for each CR.
application log available
It is recommended to maintain Application Logs.
static hard coded value found
It is recommended to read the static hard coded values from the config files.
process
It is recommened to remove the un-used commented code.
process
It is recommended to prepare setup program using Install Shield or NSIS Install System  for IT.Net Application
maintenance
1. Please review the empty tables and drop the tables which are not required. The tables which are created for any adhoc requirement and not used for application or not used by any query, please review the same and drop the tables.\n2. Attached the list of tables with sizes.
maintenance
Defrag the high fragmented tables, which will release the space and improve the performance of the database. Tables list attached.
adhoc query running prod environment
1. Do not run any ad hoc query in production database.\n2. Use active dataguard database for the Ad hoc queries.\n3. Every query should run with optimal plan, which  should use the proper index.
parallelism used
The INSERT,SELECT and DELETE query can be appended with a PARALLEL hint to enable ORACLE to parallely process the DML's .
design
Please check the functionality if SQL can re-write by removing SST from FROM clause and WHERE clause. This will reduce the Temp space utilization and SQL cost will reduced to 2900 approx.
online backup
We recommend to carry out a HOT backup (online flash copy) for database .
multiple request demoxml data file load event reliancelifeinsurancedoubleeasyhtm
Multiple requests of demo.xml should be avoided in the same event.
multiple request demoxml data file load event reliancegarnteedmoneybackptshtml
Multiple requests of demo.xml should be avoided in the same event.
unnecessary query initialize variable stored procedure getcashflownewplans
Avoid initializing variables @startRange and @EndRange in stored procedures if not needed.
unnecessary query initialize variable stored procedure getheadernewplans
Avoid initializing variables @startRange and @EndRange in stored procedures if not needed.
unnecessary query initialize variable mindate stored procedure getheadernewplans
Avoid initializing variables @mindate  in stored procedures if not needed.
unnecessary code initializing str variable print command stored procedure getheadernewplans
Avoid initializing variable @str and print command in stored procedures if not needed.
unnecessary insert table performancetesting
Avoid inserting values in PERFORMANCETESTING if not needed.
thread contention ecsdalrepositorywebportalwebportalrepositorygetfamilydetails
NoData
query high response time
Create non-clustered index on jobtype and status columns of BatchJobs tables.
large volume hit static content
Enable browser side caching on application server. This will also result in bandwidth reduction for static contents on application server
large number 404 erros due broken link
Fix 404 errors due to broken links using below steps.\n- Search all instances of url mentioned in excel in application code.\n- Provide correct path for the missing resource"
thread contention ecsdalrepositoryodsecspolicydetailrepositorygetpolicy
Do following steps.\n1. Instead of applying EntityFunctions.TruncateTime function on EndorsementDate column use variable side value without time.\n2. Create Index for EndorsementDate column in ECSPolicyDetails table.
thread contention systemnetunsafenclnativemethods
NoData
thread contention constructor dynamicclassbuildupecsblblclaimcommondocumentdetailsbl
The required objects should be passed into functions as parameter instead of initializig them in constructor.
thread contention ecsblsavvionreferencergiclhcswsserviceassignorkeeptask
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
caching master table
Implement Database level caching using sql server notification by associating SQLDependency class with linq.
81 broken link smartzone application server
Fix the broken links issue for all urls listed in attached list by using correct url for service/resources.
multiple request bundlesjquery bundlesjqueryui page motormotor
Avoid multiple calls for static resources in same event.
multiple request bundlesjquery v user click travel individual link
Avoid multiple calls for a static resources in same event.
repeated request method getallstates getcountry getdistrictwithstateid getcitywithdistid getareawithcityid user click travel individual link
Avoid repeated calls to same methods in same event.
unnecessary initialization list pricingresponselist tempdata value action method motorquote
Avoid initializing PricingResponseList if not needed.
unnecessary query fetch masmodelregion table tblmasmodelregion method fetchmotorpolicywithpolno
Avoid query to set value for MasModelRegion and RTOLocation if not needed
unused variable savemotor method
Avoid initializing unused variable if not needed
unnecessary call method loginmodelgetuserid initialize variable loginid
Avoid unnecessary call to getuserid function and try to persist user id for entire session to avoid multiple calls to database.
unnecessary query function fillpolicy initialie variable policyipa type tblpolicies
Avoid query to initialize the variable PolicyIPA if not needed
unnecessary retrieval tblpolicy table set property objpolicy savemotor method
Set entire objpolicy properties in  FillPolicy method only.
unnecessary query retrieve user id user table savexml function
Avoid query to retrieve user id if not needed.
unnecessary query objvehicledetailsncbeligible value 3 savemotor function
Avoid calling query if not needed.
unnecessary repeated query set objpolicycover return null
Avoid repeat query for objPolicyCover when it returns null.
multiple request motorfetchrtostateandregion clicked calculate premium button
Avoid multiple requests for the motor/FetchRTOStateandRegion in the same event.
rpas application call getproposalalldetails home action method fill entire dataset count record needed
Call some other service which should return just count instaed of entire proposal details.
active session state application controller
Set attribute <sessionState mode="off"> on controllers where session is not needed.
action method simply returning blank json
Avoid request for action method which simply returns blank json response if not needed now.
column concatenation use function sqlfunctionsstringconvert column method fetchvehiclemakemodelproductbasedetails
Separate out values for Make_Name, Model_Name ,variance and CC for comparing against clumns in queries
unnecessary multiple execution query condition overriding result last query method fetchvehiclemakemodelproductbasedetails
Avoid calling multiple queries on same variable on same conditions.
unnecessary query initialize variable productarc method fetchvehiclemakemodelproductbasedetails
Avoid query to initialize the variable ProductArc if not needed.
continuous exception insufficientexecutionstackexception table tblatlog database audittrail
Try to catch the InsufficientStackException exception in all controller classes and hendle  error gracefully
unnecessary call controller method cover click savecontinue button
Remove call for Covers if not needed
unnecessary passing viewbagpolno action method gridcovertypereadss
Avoid passing viewbag object if not needed and change action method accordingly to remove unnecessary code.
unnecessary initialization variable userid calling method getusername action method gridcovertypereadss
Avoid initializing variable UserId if not needed
linq query high cost
Check policyid for null or zero outside query and Optimize query to avoid index scan on these tables. Can split query into two.
linq query high cost
Check policyid for null or zero outside query and Optimize query to avoid index scan on these tables. Can split query into two.
large number request static resource homeaspx throughout application
Use Microsoft ASP.Net optimization framework to bundle .js and .css files into few requests. The bundle groups should be created based on page category.
multiple request initstringsjs page load homeaspx
Avoid multiple requests for the static resources in the same event.
multiple call embed4hhiuaccdoo page load homeaspx
Avoid multiple calls for same request in the same event.
multiple request stringsjs page load carinsuranceaspx
Avoid multiple requests for the static resources in the same event.
multiple request corejs page load carinsuranceaspx
Avoid multiple requests for the static resources in the same event.
multiple request analyticsjs page load carinsuranceaspx
Avoid multiple requests for the static resources in the same event.
multiple request jqueryuimincss file page load carinsuranceaspx
Avoid multiple requests for the static resources in the same event.
client side search every key input search make model field
Avoid search for make model at client side when user is typing. The search should be called only when user stops typing for 1 seconds similar to smartzone application.
multiple request jqueryspservice201401minjs clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request faqforcarjs clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request footablecorecss clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request rgifaviconico page load twowheelerinsuranceaspx
Avoid multiple requests for the static resources in the same event.
multiple request corejs page load twowheelerinsuranceaspx
Avoid multiple requests for the static resources in the same event.
empty catch block loadhomebanner method quickquotehomeascx
Log the errors in LoadHomeBanner using Utility.LogDataToFile as done in other methods.
unused variable function fillpolicydetails quickquotefourwheelerascx
Avoid initialiing the unused variables.
unnecessary initialiation entire datatable dtpolno load event quickquotehomeascx
Avoid initialiing entire DtPolNo datatable in the load event of QuickQuoteHome.ascx. Instead just fetch required policyno.
high fragmentation heap index database dbwebsite
For heaps create clustered index on table and for indexes rebuilt to remove fragmentations.
unncessary code execution responseredirect twowheeler method quickquotehomeascx
Exit function with return statement after response.redirect.
503 error trying perform search
Remove search ICON from the website page to prevent user from performing search.
multiple request corejs page load dashboardaspx
Avoid multiple requests for the static resources in the same event.
multiple request stringsjs page load carinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
unnecessary intitialization variable dtentry tsptotaltime logdatatofile method utility class
Avoid computing timespan and avoid to initialize variables dtEntry and tspTotalTime if not needed.
workflow delay
Each queries must have a proper exception handling clause with proper exception codes which will be followed across all the procedures
workflow delay
Remove synchronization blocks/methods where object is not being used in multi-threaded mode or when method is not accessing any class property. If a method or code blok is accesing only local variables there is no need for synchronization.
response time high
Use logging framework like log4j.
response time high
Use logging framework like log4j.
workflow delay
Use StringBuilder rather than string. This will be faster and will also have smaller memory footprint.
response time high
Access expesive resources only once and cache these in lcoal memory using Hashmap and return cached data subsequently.
workflow delay
Read and store a value before the loop starts and use this value inside a loop rather than calculating same value each time.
response time high
The audit entries should be made in an asynchronous manner so that it does not impact the live business transaction. Also, the call to audit entry be surrounded with try-catch block and all exceptions should be absorbed with a possible log entry. It is also advisble that Audit database is running on separate physical server so that it down not interfere with PROD server.
response time high
Read loop size once before the loop start.
response time high
Always use Radix when using parseInt in javascript.\nparseInt("020", 10);\nparseInt("237", 8);
workflow delay
Check for space on standby location & confirm standby loaction parameters
workflow delay
Allocate extra extents to LOB colum, But this is temporary fix,It is recommended to raise a service request with My SQL support & confirm if this has been a bug for which My SQL can recommend some patch.
response time high
A shell script has been provided, which will monitor the space in periodic interval and send a alert on mail if mount point is 80% full.
workflow delay
Moving redo logs to RAID 1+0 was recommended, during load testing itself
response time high
Raise a service call with My SQL support to confirm if there is any patch needs to be applied.
response time high
Contacts table need to be analyzed
workflow delay
Separate mount points for\n1. Tables Datafiles\n2. Index Datafiles\n3. Redo and comtrol files\n4. Tempfiles\n4. Undo datafiles
response time high
Autoextend should be set to OFF with maxsize defined as 4 GB. This will also help in I/O distribution and Less dataloss in case of recovery
response time high
DBA role should be revoked from application users and only required privilges should be assigned
response time high
Recreate temp files on different mount points with 8gb each
response time high
It is recommended to have RAID 1+0 storage for database files
response time high
Need to change application logic to execute the query or use order by clause
workflow delay
The initial extent needs to be set to 64K as that of current production.\nTable & its indexes have to be moved to new tablespace & recreate the constraints and analyze tabel
response time high
The initial extent needs to be set to 64K as that of current production.\nTable & its indexes have to be moved to new tablespace & recreate the constraints and analyze tabel
response time high
fn_categorylookup function has to be changed to have join on bank_id field on categories & category_lang tables
response time high
sga_max_size - 24G\npga_aggregate_target - 6G\njava_pool_size - 512M\ndb_cache_size - 10G\nshared_pool_size - 2048M\nlarge_pool_size - 256M
workflow delay
below parameters are changed.\nparallel_max_servers = 32                         \n_enable_NUMA_optimization = true               \n_undo_autotune    = false\n\n_db_block_numa ,_gby_hash_aggregation_enabled,INBOUND_CONNECT_TIMEOUT  parameters need not be changed, since 11g has given values as default.\n\ndb_cache_advice needs to set to OFF at end of PT.
response time high
Sales table needs to be moved to tablespace having maxsize of database files as 8 GB
response time high
Categories table needs to be moved to tablespace having maxsize of database files as 8 GB
workflow delay
Need to have proper indexes on queries and jvm needs to be run with  DMy SQL.jdbc.defaultNChar=false option to avoid implicit datatype conversion
memory error
Change/Add the value of following parameters in the JVM parameters file \n Parameters are provided in a separate mail
nodata
It is recommended to close the file object post usage . Finally block is recommended as follows \n finally {\n  if (fileObject != null) {\n    try {\n      fileObject.close();\n      catch(Exception e) {\n        log it -- do NOT rethrow\n      }\n    }\n  }
nodata
It is recommended to close all the artifacts related to connection .
nodata
It is recommended to add parameters in a SQL query via preparedstatement.set("") methods for correct datatype .
nodata
It is recommended to close all these artifacts only in a finally block with individual try catch blocks.
nodata
Need to increase the DB_CACHE_SIZE to around 20 GB from 3.5 GB which is minimum size and it is growing up to 12GB as of now on both the database nodes.
nodata
It is recommended to remove or comment out sysout. Recommended to use Logger with log level if necessary.
nodata
It is recommended to close all the connections in finally block only.
nodata
Reorganize the tables and rebuild the indexes on this table.\nPlease refer the list of tables from Fragmentation tab that need to be reorganized.
nodata
duplicate calls for same method needs to be removed.
nodata
Insured object list to be computed only in perform() and should be passed to the respective method
nodata
if/else condition should be used for productId comparison
nodata
the value for productId should be computed only once and set it to some long vlaue. So that productId will not be computed in all the blocks.
nodata
Recommendation to club  smaller operation steps in to one operation step which can reduce the calling of number of classes. Target should be to reduce the number of operation steps. This will also reduce the plumbing at the start of each class.
nodata
Loading of the policyBO should just be computed once. Recommendation to put that in FLowContext or some other existing persistent class or cache.
nodata
duplicate instantiation of policyBO object which is loading the PolicyBO multiple times. Recommended to revisit the code and remove it.
nodata
redundand code needs to be removed from the code base.
nodata
classes should be imported once below package definition of the class instead of defining the class definition each time the class is used.
nodata
Recommendation to create index on Policy_id column of table T_SBI_MEMBER_DTLS.
nodata
It is recommended to comment out dbms_outout package call in the procedures/funcations/packages which are part of production database. In UAT it is helpful for debugging.
improper use listsize  0
Substitute calls to size() == 0 (or size() != 0) with calls to isEmpty(). list.size()>0 slower than list.isEmpty().
large size css js file
Perform following.\n1. Remove comments from .js and .css files.\n2. Minify and compress  the .js and .css using minification tool.\nRefer to http://dean.edwards.name/packer/
unnecessary request rupeeforadianttf file reliancelifeinsuranceclassicplaniisinglehtm
Avoid request for rupee_foradian.ttf file if not needed
application using androidutillog resulting single large log file
Use custom logging to write the application logs on daywise custom log files so that application log size couldn't grow very large. Maintain separate logs for error and messages. Also implement log archival policy which is not possible to implement currently.  These log files can be accessed by support team for diagnostic purpose without taking the root access of android tab.
use stringindexof string
Use String.indexOf(char) when checking for the index of a single character; it executes faster.
misplaced null check
The correct way is to place the null check in front of the if statement. The second part of the statement will be evaluated only if the requestId variable is not null.
repeated request multiple static file loading reliancelifeinsurancesmartpensionplansinglehtm
Repeated requests should be avoided for the static contents
unnecessary call commonfunctionsdeletesession function method service1svc
Avoid calling method "CommonFunctions.deletesession" in below 36 methods in Service1.svc.\n(PayFive, Endown, Child, Term, FixedSavings, SRS, MoneyMulti, GMB, GMBPTS, GMBReverse, cp109, cp110,  imedateann, cfu113, HTP, HTRPC, Superedwn, sm117, sm2118, p1191, p1192, SMB, ERSSelectCalc1, ERSSelectCalc1, ERSSelectCalc2, Wkid,  income, supermoney, supermoneyReverse, supercashplus, supercashplus, supercashplus, ulip, DERS, r8, r9
repeated request multiple static file loading reliancelifeinsurancesupermoneybackplanhtm
Repeated requests should be avoided for the static contents
multiple request source xml data file reliancelifeinsurancedoubleeasyhtm
Avoid multiple calls to same source xml in same event.
repeated request multiple static file loading reliancelifeinsurancedoubleeasyhtm
Repeated requests should be avoided for the static contents
high cost index seek clustered index pkenagntrninputvalues
Avoid using ltrim and rtrim function on the column fieldcode to avoid clustered index scan on  index PK_en_agn_trninputvalues
large log file size mobilebi pdc database
Shrink the database log file size using DBCC SHRINKFILE command.
high limit grow mobilebi pdc database log file
Restrict the MobileBI and PDC database log file size to lower value ~500 MB.
multiple request jqueryuimincss file page load twowheelerinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request initstringsjs page load twowheelerinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request stringsjs page load twowheelerinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request corejs page load twowheelerinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
low autogrowth size active log file websiteaudit
Set autogrowth for log file between 100MB to 500 MB and keep max size as unlimited
multiple location static content
Map all static contents such as images , css, js and woff files to directly download  from akmai servers instead of IIS server to reduce the latency of downloading static contents
unnecessary call registerstartupscript redirect populatepaymentobject method buyfourwheelerascxcs class
Avoid calling RegisterStartUpScript if not needed.
unnecessary code execution responseredirect createproposalfortravel method buytravelascxcs class
Add return statement after response.redirect. Move InsertTravelLogger statement before the response.redirect.
query optimization
This module pertains to transaction creation through MTT routine. HP team to check on the usage of this module during business hours in RPT server and if possible execute it after business hours when all report extraction jobs are completed
configuration
Cache size to be set for sequences to improve the response time of transactions referencing to sequences. Also the patch details provided for the above issue holds good for this observation too
configuration
It is recommended to have RAID 1+0 storage at both DC and DR for improved storage performance
query optimization
Oracle has suggested a patch for oracle version 10.2.0.5 (Doc ID 1133845.1) to address this error. It is also recommended to upgrade database to oracle version 11gR2, which uses adaptive cursor sharing to addresses issues related to change in execution plan of the query.\n\nAlso the query was running from  rrbx4001 module, which is used for reporting purpose. Hence we recommend to check feasibility to run these reports from MIS server
slow response time
Network team to check the reason for 2 hops on the same IP and eradicate the same
slow response time
It is reccommended to migrate to the latest certified version for better performance
code review
The transaction creation process and message creation process can be bifurecated into two seperate steps.
code review
We recommend to increase the cache size to appropriate value which will reduce down the cache utilization levels and result in reduced "Cache write Pending" to improve the performance of core banking database IO system.\n\nAs confirmed with Pankaj, Cache size should be set to double of the current value. Also this reccomendation will assist in enabling direct I/O for redo log file system for database ( point 4 in database analysis)
code review
Feasibility of using a flashcopy to update the RPT server to be checked by the storage team
configuration
The necessary change for this is done in the load balancer by enabling  " Insert x-forwarding-for" to pass the client ip in the "x-forwarded-for" HTTP header. This change in the HTTP header needs to be accommodated in the Web servers also by installing ISAPI filters for "x-forwarded-for" HTTP header.
configuration
Fix the path to the static contents shared.
slow response time
Reduce the file size, by compressing, or create pdf files from optimized microsoft office word documents.
code review
Style sheets are in the body of the document rendered. This needs to be moved to head of the document which is flushed from the server. This would accelerate the page rendering.
code review
Javascripts blocks the content download while on head or body, currently we have observed that javascripts are in the document head/body, which needs to be moved to the bottom of the body. This would allow the browser to download all contents in the page in a non-blocking manner.
code review
"Components which doesn\u2019t change for a long time like css, js, images\ \ can be cached at the client side(Browser). The returning customers will benefit\ \ if this is enabled, since the pages would load faster and no additional requests\ \ would be made by the browser.\\nHeaders to be configured for static resources\ \ in Webserver IIS\\n1. Vary: Accept-Encoding\\n2. Expires on future date to be\ \ configured  for *.ico,*.gif,*.css,*.js\\n3. Configure FileETag as none"
code review
Further to investigate why the response was not sent/received by vendors for these transactions, we recommend to do the application debug testing and check at which point it is failing while responding back to vendors. From the Internet Banking team, we came to know that some customization is done by the bank team over the product for this application. We have requested for customization code from Internet Banking team to put debug statement in code.
query optimization
Please refer query list sheet for more details
query optimization
Please refer query list sheet for more details
maintenance
Reorganization and rebuilding activities needs to be performed in the indexes shared. Please refer Sheet "DB Fragmentation" for details of the objects which needs to be acted upon
query optimization
Please refer query list sheet for more details
configuration
Sepearate mount points to be allocated for Corporate Index files and Payaway database files.
query optimization
Application logic an be changed to loop back to find valid port and IP inside the C code. The config file can be read inside the while loop till a valid IP address and port can be found
query optimization
The program logic needs to be deeply analyzed to find out the reason for so much lower number of updates
query optimization
Check for the logic and take appropriate action
query optimization
Check for the logic and take appropriate action
code review
Application logic can modified to use the user hooks once and use the data simultaneously.
cursor pin
Avekshaa to review the AWR's with the new database version on AIX
query optimization
need to check application why it is locking
performance
Bank needs to look at their future volume and discuss with product vendor on a viable solution (either customisation or base product) so that volumes as projected by their business can be handled
query optimization
This can be changed with EXISTS clause for better performance as following\nSELECT ACID into :recCnt FROM CTD WHERE exists (SELECT ACID FROM CTD ACID=:acid AND TRAN_DATE=:tran_date  AND INSTRMNT_NUM=LPAD(:inst_num,16) AND TRAN_AMT=:tran_amount);
query optimization
Replace first query with second and use exist clause to check data in result set.\nselect count(*) into :icicnt from where EXISTS (select nvl(rej_type,'000') into :icirej from ICI where sol_id=:solId and zone_code=:zoneCode    and zone_date=:tran_date and zone_srl_num=:zone_srl_num and      inst_num=lpad(:inst_num,16))
query optimization
Analyzed Sql plan are fine and there no any issue observed
configuration
This has been shared and discussed with ICICI team. After discussion it has been decided that time.tbg log should not be modified and there should be a separate file name used for this logging. Log file name should be created day wise and log should include following information about batch execution \n1. Start date\n2. End date\n3. Volume of data processed\n4. Indicator name  \n5. Sol id
configuration
This prototype is designed to parse the log of any batch and shows analysis. This would be tool to view statistical data in readable format for batch performance analysis perspective.
configuration
Implementation of the parser tool in production for data collection
configuration
File name should be validated before  upload starts with database  and using AJAX . This has been shared and discussed with ICICI team. Solution Design and prototypes has been shared with ICICI team
configuration
No issues indentified. However, scope for analyzing code/design is minimal since most of it is product code.
configuration
This prototype is designed to parse the log of any batch and shows analysis. This would be tool to view statistical data in readable format for batch performance analysis perspective. EOD/BOD Batches process job using parrallel processing and currently log is recorded for starting of these no of job and finish time. This tool need to configure for no of jobs selected in each execution.
code review
Convert gifs to PNG files and use tools like pngcrush to optimize png files. Make code changes on all pages and replace .gif with .png.
configuration
'Increase TCP/IP buffer size to 64K.  This is an IBM recommended value for standard web app traffic. \nNote: On Wondows 2008 server it was not accepting  8388608. Hence set to 64K on UAT server. Same will be done on PROD server too.'
configuration
It is recommended to set this  value to \n -1 (unlimited) and let OS manage the upper limit.
configuration
Apply latest fix pack from IBM. This will address few important performance related issues and will take WAS version to the latest one in WAS 7. The new version should be 7.0.0.29.
configuration
Edit httpd.conf file on all 3 web servers\n\nAdd below section in httpd.conf file immediately after section "mod_mime_magic.c":\n\n<IfModule mod_mime.c>\n    AddType image/ico .ico\n</IfModule>\n\nAdd expiry period for ico files:\n\n<IfModule mod_expires.c>\nExpiresActive On\nExpiresByType image/ico "access plus 6 months"\nExpiresByType image/gif "access plus 1 year"\nExpiresByType image/jpeg "access plus 1 year"\nExpiresByType image/png "access plus 1 year"\nExpiresByType image/bmp "access plus 1 year"\nExpiresByType application/javascript "access plus 1 year"\nExpiresByType application/x-javascript "access plus 1 year"\nExpiresByType text/css "access plus 1 year"\nExpiresByType text/html "access plus 1 year"\n</IfModule> \n\nRestart web server after making above change.
code review
Move to V10 from V7.5 and leverage asynchronous invocation of the web trends API
storage
Storage team to coordinate with IBM for root cause of this behavior.
performance
Move data sanity checks and data preparation operations which do not need any data access to the java layer.
performance
The throughput of the Listener can be increased if each messages can be passed onto individual handler instance so as to leverage parallel processing. Need to check if the messages can be passed onto upstream handlers from the decoder.
slow response time
Use StringBuilder instead of StringBuffer if expensive thread-safe operations are not required. StringBuilders is faster than StringBuffer for strings concatenation.
slow response time
'Recommended to replace this type of condition in below pattern.\nCurrent: \nif(result != null || result.length() >0)\nRecommended:\nif(result != null && result.length() >0)'
slow response time
These are not required, removing this will improve performance
slow response time
Change the if condition to some variable flag rather than on pastpaynorep html element
slow response time
Remove one call.
slow response time
Remove these redundant calls
slow response time
'The thread pool setting on the machine.config needs to be reset to as follows :\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs \nThe same needs to be done on both web server as well as app server.'
slow response time
The spriting of images will ensure redundant calls on web server is avoided.
slow response time
Timeout needs to be defined at the web.config with not more than 10 mins, so that the users do not keep the session open for an infinite time.
unnecessary request rupeeforadian font file assuredreturn2htm
Avoid request for rupee_foradian font files if not needed
multiple request demoxml data file load event fixedsavings1htm
Multiple requests of demo.xml should be avoided in the same event.
objectlength used loop
It is recommanded to call Object.length once and store its value in another object and use the same object everywhere in the code.
large number failure file uploads
Recommended to increase timeout duration from existing 5 minutes to 30 minutes to avoid connection timeout in case of weak net connectivity.
large number string concatenation logscs class function
Use Strigbuilder class instead of performing direct string concatenation.
multiple call function commonfunctionsgetinputfile
Avoid calling CommonFunctions.getinputfile twice in a method if not needed(The logic in encrypted stored procedure needs to be analyzed)
unnecessary request rupeeforadian font file reliancelifeinsurancemoneymultiplierplanhtm
Avoid request for rupee_foradian font files if not needed
repeated request multiple static file loading reliancegarnteedmoneybackptshtml
Repeated requests should be avoided for the static contents
unnecessary call stored procedure initialize variable stored procedure getcashflownewplans
Avoid initializing variable @term in stored procedures if not needed.
unnecessary execution query set variable userid password stored procedure getinputfile
Avoid initializing variables @userid  and @password in stored procedures if not needed.
unnecessary initialization variable str str1 query
Avoid initializing variables @str  and @str1 in stored procedures if not needed.
unnecessary execution query initialize variable fcode dname
Avoid initializing variables @f_code and @d_name if not needed.
query high response time
1. Rebuild indices idx_ECS_INsured_details_policyno_hCardNO and IX_ECS_Insured_details to remove fragmentation.\n2. Instead of refreshing tables in ODS instance, move them to HCS prodution instance and refresh, this will reduce intercommunication time inbetween two instances.
thread contention ecsdalrepositorystatusstatusservicerepositorygetclclaimstatus
Following should be checked for GetCLClaimStatus or GetALClaimStatus.\n1. remove sub query if IVRSCode field is not needed.\n2. If IVRSCode is required then fetch its value using another linq query instaed of fetching this in select section of same query.
large size aspnet cache due large number object finaliser queue
1. For dynamic loader classes where reflection is used needs to implement dispose methods to effectively clear them.\n2. For unreleased data tables in memory we can do following in every instance of datacontext class of HCS and ODS databases.\n    - Set dataContext.ObjectTrackingEnabled to false if object tracking is not needed.\n    - call dataContext.ClearCache()
thread contention dynamicclassbuildupecsblcommunicationcommunicationbl
The constructor of CommunicationBL expects around 27 class objects and simply assigns them to local variables. The user functions in class hardly need more then one class objects.\nNo need to pass all 27 class instances to constructor as this makes CommunicationBL class heavy instead of this the functions should read class variables as parameter if needed or create them inside functions only when required.
thread contention dynamicclassbuildupecsblmastermasterbl
The constructor of MasterBL expects around 53 class objects and assigns them to local variables. The user functions in class hardly need more then on class objects.\nNo need to pass all 53 class instances to constructor as this makes MasterBL class heavy instead functions should read class variables as parameter if needed or create them inside functions only when required.
several unusable object initialized constructor business layer class service folder
The required objects should be passed into functions as parameter instead of initializig them in constructor.
thread contention ecsdalrepositorystatusstatusservicerepositorygetclaimsbypolicyno
Following should be done to make GetClaimsByPolicyNo function faster.\n1. Remove string concatenation for Output string.\n2. Remove logging if not needed
performance degradation due firewall app server db server
Keep the all application servers and database server in same zone either DMZ or corporate zone. There shouldn't be any firewall between application server and database server.
unnecessary call method policymanyfacturingmonthandyearnew document  ready function motorquotecshtml page
Remove call for method in Policy/ManyfacturingMonthAndYearNew in $(document).ready function if not needed.
unnecessary writing objecompensationblazeerrormessages disk file validateecblazeauthorities method
Avoid writing objECompensation.BlazeErrorMessages into disk file if not needed.
multiple request method motorgetdocuments page motormotor
Avoid multiple calls for a method in same event.
multiple request bundlesjquery v user click make payment button
Avoid multiple calls for a static resources in same event.
repeated request method mastergetrelationshipname relationnamechildrelations user click travel individual link
Avoid repeated calls to same methods in same event.
unnecessary query loop previous policy proof document savemotor function
Avoid calling query in loop for all previous policy proof document if not needed
unnecessary request motorpreviousinsurancedetail clicked save button motor policy new business
Call Motor/PreviousInsuranceDetail only in case of renewals.
unnecessary query initialize variable dbpayment fillpolicypayment function
Avoid query to initialize variable dbPayment if not needed. Avoid entire if block.
request motorncbreservingdetails saving motor quote even ncbreservingdetails hidden
Avoid request for Motor/NCBReservingDetails in all conditions when div "#divNCBReservingDetails" is hidden
unnecessary initialization variable businesstype fetchidv
Avoid initializing BusinessType variable if not needed.
unused variable controller method fetchidv
Avoid initializing unused variables.
unnecessary logging request response data blaze service tbllogxml table
Store single blaze request and response data for each policy in the tbllogxml table at the time of final save.
unnecessary passing parameter un home action method homecontrollercs
Avoid passing encrypted un (user name) value if not needed.
call getusertask home action method without verifying appname
Call to GetUserTask method only when required i.e. when appName is IMD.
update userid cookie retrieval user table getuserid function
Update the cookie with userid value after retrieval to avoid database call in next call of getUserId function.
unnecessary query table tblmasdeos set variable masdeoobj healthwise action method class healthwisecontroller
Avoid initializing variable masDEOObj if not needed.
large number connection created database even user connected smartone
Modify connection parameters to include connection pool with max connection size of 50.
unnecessary call controller method ncbreservingdetails click savecontinue button
Remove call for NCBReservingDetails if not needed
intermittent delay login page due either initial 302 200 request home controller
Consider expiring the IMD and other cookies used in application during load of login page or when user clicks on login button to avoid intermittent delays during login.
blocking due scan large tabllogxml table due regular select delete query
Perform following.\n1. Move tbllogxml and tbllog tables into audittrail database.\n2. Partition the major audittrail tables such as tbllogxml and tblatlogxml datewise.\n3. Optimize insert operations on audittrail database using simple recovery model .
multiple request conversionasyncjs page load homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request stringsjs page load homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request corejs page load homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request conversionasyncjs page load carinsuranceaspx
Avoid multiple requests for the static resources in the same event.
client side search make model even le 3 character entered
Avoid search  for make model at client side when number of characters entered is less then 3 characters.
high response premium estimate tried homeaspx
"Avoid multiple calculation of quotation and send necessary details such\ \ as motor model, years, email\u2026etc to insurance page directly (such as car-insurance.aspx)\ \ instead of performing premium calculation in home page."
multiple request footablemetrocss clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request bootstrapmincss clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request jquery1110mincss clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request stylecss clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request sharepointcss clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request jqueryuimincss file page load twowheelerinsuranceaspx
Avoid multiple requests for the static resources in the same event.
multiple request stringsjs page load twowheelerinsuranceaspx
Avoid multiple requests for the static resources in the same event.
unncessary code execution responseredirect fillpolicydetails method quickquotefourwheelerascx
Exit function with return statement after response.redirect.
unnecessary retrival multiple row datatable dtrtodetails twowheeler function quickquotehomeascx
Change stored procedure usp_GetRTOLocationByTextValue_Website to select top 1 row instead of retrieving many duplicate rows .
unnecessary retrival large datatable dtrtodetails fourwheeler function quickquotehomeascx
Change stored procedure usp_GetRTOLocationByTextValue_Website to select top 1 row instead of retrieving many duplicate rows .
risky autogrowth option database file dbwebsite
Update dbwebsite configuration to set autogrowth value to a fixed value(100 to 500 MB) instead of percentage.
multiple request initstringsjs page load carinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request jquerycreditcardvalidatorjs click next button carinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request jquery132minjs click next button homeaspx
Avoid multiple requests for the static resources in the same event.
unnecessary multiple time write disk file logdatatofile method utility class
Instead of using multiple writeline methods construct the entire message in stringbuilder class and write once to disk file using  the write method of TextWriterTraceListener class
multiple request analyticsjs page load twowheelerinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request method collect googleanalyticscom page load twowheelerinsurancepremiumcalculationaspx
Avoid multiple requests for same method in the same event.
multiple request conversionasyncjs page load twowheelerinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
maintenance
For these tables stats to be gathered in regular interval. Database should be monitored that no table goes for stale stats
design
These queries to be checked with the EOD team whether these pertains to any EOD functionality or can be avoided
design
"Rearranging the cluster sets with more number of sol\u2019s in each cluster\ \ and reduce the number of cluster"
design
It is recommended that compressed all .jpg images immeditely after scanning and before uploading to server 1st time. Sample file is shared with the team, where the original as well as the compressed image is shared. The entire process needs to be carried out on both the images to understand the response time improvement.
design
Indexes needs to e created on column ORN for tables TBL3IN1BANK,TBL3IN1DATA,TBL3IN1DP,TBL3IN1SIGNATURE
design
Indexes needs to be created on column ORN for table TBLDEMATDATA
design
Index on ORN needs to be created on tables tblbatchbdfmap ,\ntblDematADDR ,\nTBLDEMATBCKOFF,\ntblDematSignature,\ntblfinacleerrors ,\ntblHoldReason,\ntblLoanapplicationdata ,\ntblSBFinacleData ,\ntblSBInstaCustData ,\ntblCaseStatus ,\ntblDematData,
adhoc query running prod environment
Deliberate such cases accordingly and try to limit such maintenance activities to desired level as this creates an overhead on the regular operations.
design
Either remove the trunc function for both the tables, or create a functional indexes on TRUNC(CI_EXTRACT_DATE) on CSTM_INTEREST and TRUNC(CII_EXTRACT_DATE) on CSTM_INTEREST_INTEREST tables.
design
Either add index on this table for the column CDR_USER_BAND or modify the query to use any column which is already indexed.
design
Create  indexes on SPH_FROM_TIME and SPH_TO_TIME  columns or modify the query to use current indexes.
design
Duplicate indexes on payee_master table are observed one can be removed.( pmt_id , del_flg /del_flg,pmt_id).  defragmentation on pmts and payee_master table is required.
maintenance
PLOG table needs to be defragmented.
maintenance
customer_payee table needs to be defragmented.
maintenance
customer_payee table needs to be defragmented.
design
'Fetch static data outside the loop, do data modification there itself(if require) and store it in a new object for further processing.\n\nReference : Srl 6.\nInt primAccount;\nif(cm.getString("userAccountIndex") != null)\n{\nprimAccount = cm.getInt("userAccountIndex");\n}// if close\nfor(condition) // loop start\n//some code\nString refValue = Convert.ToString(primAccount); // code marked in red can be move before loop start inside if condition\n//some code\n} //loop end\n\nReferences : Srl 7.\nfor(condition) // loop start\n{\nfield125 = "SCH" + vo.getCIDN() + cache.getString("stdntRegId").PadRight(10) + cache.getString("schlid1").padRight(6) // code marked in red can be move before loop start\n} // loop end'
design
Such method calls needs to call first before loop starts rather than calling it inside loop.\nfor(int i = 0; i < ba.count; i++)\n{\nGUCTVO guctchallanvo = (GUCTVO)ba[i];\nDebitAcNo = guctchallanvo.getDEBT_ACID().ToString().Substring(0,4);\nBranchID = BranchCodeDescription.getDesc(userInfo.bankId(), solid, cache); // code marked in red can be move before loop start \nGuctchallanvo.setbranch_ID(BranchID);\nbaList.Add(guctchallanvo);\n}\n\nBranchID = BranchCodeDescription.getDesc(userInfo.bankId(), solid, cache);\nfor(int i = 0; i < ba.count; i++)\n{\nGUCTVO guctchallanvo = (GUCTVO)ba[i];\nDebitAcNo = guctchallanvo.getDEBT_ACID().ToString().Substring(0,4);\nGuctchallanvo.setbranch_ID(BranchID);\nbaList.Add(guctchallanvo);\n}
code
Application needs to be restructuring to more generalized/parameterized structure to avoid lots of code file creation and also to avoid more memory consumption.
code
Use StringBuilder.Append() method once to generate query. No need to call StringBuilder.Append() method 3 times on 3 different lines to generate query.
code
Order by clause not required in query to fetch data in ascending order. Default order is ascending.
code
Place one copy of faq page in Corporate domain and fetch the same from that location.
code
There should be an intermediary landing page, which should only show the details for the primary account (Saving Account), and there should be a link for the other schemes.\n On clicking this, it should highlight all the other accounts linked.
code
"a. The js functions are written inline in the aspx page. The js file should\ \ be written outside and should be called through a link in the aspx file. This\ \ will load the page faster.\\nb. Check why there are so many js validations done\ \ for a static page. Eg. For disclaimer page, there are only two buttons \u201C\ I Agree\u201D/\u201DI Disagree\u201D but there are multiple js validations written\ \ on the page.  \\nc. There are multiple js files being called sequentially one\ \ after another. This should be collated into a single file so that the on load\ \ of these js files happens just once. Eg. RetailShoppingMallLogin.aspx has multiple\ \ js files loaded sequentially one after another."
high cpu utilization
Only selective columns should be included in select query from product, this reduces the data transfer from DB to APP
process
As a standard practice username and password should not be a part of code. It should be moved to configuration file. Please refer DB_Credentials_Details sheet.
slow response time
Compression of images needs to be carried out. Please refer image_compression sheet for changes in size of images ( Sample images have been shared with team to validate pixcel quality )
slow rendering page
These needs to be moved to the bottom of the body. This would allow the browser to download all contents in the page in a non-blocking manner.
large size j file
"To improve the Response time of these pages,  below steps needs to be carried\ \ out\\n1. Compress js files, css files and images - Please refer below sheets for\ \ compression details:\\n1. CSS_Compression\\n2. JS_Compression\\n3. Image_Compression\\\ n\\n2. Enable caching for static elements which doesn\u2019t change for a long time\ \ like css, images.\\n\\n3. Remove unwanted links ( 404 errors ) from pages"
process
Need to change the log format to "LogFormat "%h %l %u %t \"%r\" %>s %b %T \"%{Referer}i\" \"%{User-Agent}i\"" combined"
high memory utilization
Apache version upgrade from 2.2 to 2.4 to use prefork mpm is recommended for multithreading. This needs application testing to be carried out
high memory swapping observed
use of php-fpm manager is recommended to server PHP requests and static contents will be served by apache
temporary table space identified db server
$usage of large hash joins and sorts = YES
bind variable used query
Hard coded input values are always causing the recursive SQL againt the data dictionary. To avoid this and to get the optimal performance use of Bind variables suggested.
maintenance
To execute with the best cost effective execution plan always suggested to  collect the stats for the stale tables.
high response time
Purgig policy should be defined for the transactional tables according to the requirement.
high memory utilization
Check with Avekshaa Memory Leak Tool for any connection leakage. (Cursors are not closed).
design
Run the long running queries in non business hours.
design
Optimize the SQL statement that initiated most of the waits. The goal is to minimize the number of physical and logical reads.
design
"Tune LGWR to get good throughput to\_ disk eg: Do not put redo logs on\_\ \ RAID5"
design
Increase the number of freelists. Use below command.\nAlter table table_name storage (freelists 10).
design
"\_Reduce the amount of redo being generated"
design
Check with netstat to ensure that your TCP/IP does not have bottlenecks.
design
Increase the size of the redo log.
design
Increase the size of shmmax parameter to optimum.
design
Reduce the reloads by increasing the shared pool size as the locks may take a long time if the pool is undersized.
design
Create password file using below command.\nOrapwd file=filename password=password
design
Increase pga_aggregate_target
design
Online the undo tablespace using below command.\nAlter tablespace UNDO online.
design
No. of threads needs to be reduced.Cache static pages.
design
Convert all the JPG/GIF images into PNG extension
design
Change is required at the machine.config file, where the maxconnection under connection management tag needs to be made as 65535.
design
Combine all the js files into one and reference it at the bottom of the html
maitenance
Update Table/Index statistics if it is not done so, so that it starts taking the latest execution plan.
design
Customization team to assess if these queries are necessary to be run during business hours and see if they can review these queries. Implicit functions used in the select is causing the query to take a lot of time.
maitenance
Check if the datafiles are being defragmented on a regular basis. Please defragment the datafiles of the tables involved in these views.
design
Comment out the lines in aspx where referencing to those objects are done which are not present
design
The comments from these two pages needs to be removed as these pages has the maximum hits.
design
The query once is being executed with status in the where clause and again without it. Please look at the logic of executing this query.
design
1.Defragment CUSR,IPAY tables\n2.Select on IPAY is having all columns, hence high read. Only use columns in select which is required.\n3. Implicit conversions used for NEFT_Payment_Requests should be avoided.
design
Disbale all script traces by below two options\n1. Comment out trace on from all the scripts.\n2. Enable Global Trace Off at the commonenv.com
design
Remove all the unwanted fatal and fatal_info logs. \nYou can run this command on a periodic basis to find and delete all fatal and fatal_info.logs.\nfind . -name *log|xrags rm fatal*log
design
Max RIST operations should be done before CEOD by handling max volume at ABH. (Approach shared seperately via mail).EAB GST needs to be run before to minimize the CEOD process timelines
bacup strategy
RMAN backup should be taken so that incremental backup is possible.
design
Parallelization required for 198 sols.(Approach shared seperately via mail).
multiple request corejs page load twowheelerinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
risky autogrowth option active log file dbwebsite
Set autogrowth for log file between 100MB to 500 MB and keep max size as unlimited
image compression image served akamaighost
Implement static compression for images on Akamai server.
unnecessary code execution responseredirect fillpolicy method buyfourwheelerascxcs class
Add return statement after response.redirect.
unnecessary code execution responseredirect fillpolicy method buyfwascxcs class
Add return statement after response.redirect.
configuration
It is recommended to enable direct i/o for redo log file systems in DC and DR
analysis
No issues has been found
high cpu utilization
Bifurecate the CRON jobs across all app servers so that the load is evenly distributed across all the app servers
query optimization
As a best practice COMMIT should always be present at the end of each logical unit of work. Also increase in the number of COMMITS will increase the average wait time of 'log file sync' event in the database.
maintenance
Please remove the safe copies and unwanted files from the customization directories. This will provide more space to the respective mountpoints
code review
On debugging the ENTERED transactions, it was found that for successful transactions the process sometimes take more than 25 secs. Since the process does an in-memory posting, the time taken for posting a single transaction is more. We have captured the timing taken for the user hook call to MTT transaction in the script traces and the record creation and posted time in DTD table. Request you to raise a call with Infosys with these details to probe the high time taken for posting a transaction.
network bandwidth
Compression of javascripts, css, jpegs, gifs
code review
Put the favicon ico at predefined URI which is relative to the server root
configuration
Sepearate mount points to be allocated for Corporate Index files and Payaway database files.
query optimization
"Application logic can be modified so that batch program loops back for\ \ more records and processes them instead of process getting killed after completion\ \ of data check. In case no records can be processed, it should go to sleep for\ \ a defined period of time and then start the processing again.  This would avoid\ \ excessive processing logic in the application. \\nThis also ensures that existing\ \ DB connections will be reused thus avoiding cost of creating and destroying new\ \ connections. So, 32 connections will be used instead of 2.4L in 30 mins. \\nThis\ \ will also ensure the process is continuous there by reducing the cost of creating\ \ new process and probably it also reduce the cost of ps \u2013fu being fired from\ \ shell scripts."
query optimization
Both sol_id and cust_id should be added to tables ICICI_ALERT_INFO and ICICI_ALERT tables.  These can be populated in ICICI_ALERT_INFO as part of insertion of records. \nQueries should be modified to use these values from these table instead of values from GAM.
query optimization
During the record selection, corresponding ROWID field should also be selected. This field should then be used during Update statement so that updates are fastest
query optimization
Exit handling needs to be provided in the program to hand the extreme conditions like.
query optimization
Comment the printf statements to avoid the cost of IO.
query optimization
"Usage of \u201CSelect IF Exists (sql query)\u201D will help gain performance\ \ as it is less costlier than count(*)."
query optimization
Check for the logic and take appropriate action
code review
This can be optimized by creating only one static scr files\nby utilizing UREX/Functions provided in Finacle there by avoiding creating and parsing of .SCR file for every 200 records.
configuration
This can be avoided by redistributing log files to faster disks..
query optimization
This needs to optimized. Need help with development team and DBA.
performance
Avekshaa to propose a design for instrumentation.
performance
Strategy has been already shared with ICICI. ICICI to get the changes implemented by Infosys.
performance
NoData
configuration
Implementation of the suggested design changes in production environment.
eod bod
As there is difficulty in recording volume for each job, so Avekshaa has suggested to record volumes for each day. And this number should be divided by no of branches to get volume of job processed for each job per branch. This is not accurate volume but at least this will help in instrumentation strategy. ICICI need to implement changes to record the data.
code review
Comment out or remove all lines in jsp/html files, which are referring to missing objects.
code review
Minifying/Compacting CSS code can save many bytes of data and speed up downloading and parsing time. Any open source tool like cssMin, YUI Compressor etc can be used to minify CSS files.\nFiles in a source code repository can remian as is (without minification), but before these files are deployed to production server these should be minified and then deployed to production server.
configuration
"To reduce such occurrences and increase overall response time and throughput\ \ of the system it is recommended that current\_statement\_cache\_value of 50 be\ \ increased to\_100."
configuration
"Currently, Nursery area is default which is 10% of max heap (200 MB).\_\ Setting Nursery size to 25% of max heap (25% of 2 GB = 500 MB)\_should trigger less\ \ frequent scavenger GCs and will improve overall throughput."
configuration
"Set initial heap size to 2 GB using             \u201C-Xms2048m\u201D option."
configuration
"Manually purge this  file  every week. Alternatively, set \u2013Xverbosegclog\ \ JVM option  from WAS Admin console. This will create  a new file for each GC cycle\ \ with following naming convention :\\nverbosegc.%Y%m%d.%H%M%S.%pid.txt"
configuration
Application should log only error messages to the log files  and debug information should  not be logged.
code review
Remove sysouts from the  code. If information needs to be logged it should be logged using a logger like log4j etc.
configuration
There should be a manual/auto archive and purge policy for the file. Since file is growing apporximatley at the rate of 400 MB per month, it is a good policy to manually / automatically archive and purge this file, once every month.
configuration
Edit httpd.conf file on all 3 web servers and \n\nadd below line:\nHeader set Cache-Control Public\n\nimmediately after line:\nHeader append Vary User-Agent env=!dont-vary\n\ninside below section:\n<IfModule mod_headers.c>\n\nRestart web server after making above change.
configuration
Edit httpd.conf file on all 3 web servers\n\nChange expiry period to 6 months from 1 year. \nReplace "1 year" with "6 months" in section <IfModule mod_expires.c>\n\nRestart web server after making above change.
query optimization
FILEDETAILSTABLE is doing FTS.Create Index /Rebuild existing index on FILEDETAILSTABLE table.
code review
Temporarily move to bottom of the page. Long term solution should be to move to V10 and also move the JS to bottom
query optimization
Indexes need to be re-built (>40% fragmentation) and re-organized (10-40% fragmentation)
code review
'Fix is provided by IBM for this issue: ( For Websphere version 8 ).  Fix pack to be applied'
performance
Remove the sleep from the SMSServerIdleHandler after sending the EXT message.
performance
Duplicate checks to be removed
slow response time
Recommended to remove the unwanted operations from the source file. This will help in faster execution of logical blocks and hence improve the performance. Also the objects created inside this block will get eliminate which result in low memory consumption.
slow response time
It is recommended to add finally block in source file and close all important resources inside it. Finally block will guarantee to close all resources if any exceptions thrown
slow response time
Recommended to write the code snippet in try/catch/finally and close the PrintWriter object in finally.
slow response time
It is recommended to turn this println off. Logging API can be used instead which can turn of debugging statements.
slow response time
It is recommended to call arrayList.size() once and store its value in another object and use the same object in the code.
slow response time
It is recommended to call Object.length() once and store its value in another object and use the same object everywhere in the code.
slow response time
Substitute calls to size() == 0 (or size() != 0) with calls to isEmpty().
slow response time
Need to log some messages to detailed out the exception.
slow response time
Avoid empty catch blocks. Capture specific type of exception and redirect user to common page with appropriate custom message, so that the specific event triggered by the user doesn't look unresponsive.
slow response time
Avoid the use of unused import statements to prevent unwanted dependencies.
slow response time
Avoid printStackTrace(); use a logger call instead. call printStackTrace() on an exception the trace is written to System.err and it's hard to route it elsewhere (or filter it). Instead of doing this use a logger call instead.
slow response time
Avoid using hard coded IP. Externalizing IP addresses is preferable.
slow response time
One choice to avoid these re-renders would be to instead use the visible binding on a container element around our section or on the individual elements.\nIf we prefer to use if binding in this case, then we need to make sure that it is only triggered when the number of items in our array moves between 0 and 1
slow response time
A better pattern is to get a reference to our underlying array, push to it, then call .valueHasMutated(). So that the subscribers will only receive one notification indicating that the array has changed.
slow response time
This will cause the operations to execute on every iteration. So it is recommended to store the calculated value into a variable and then use it within the for loop condition.
slow response time
Only one block should be used and all required data manipulation should be done within this block
slow response time
Consecutively calls to StringBuffer/StringBuilder .append should reuse the target object.
slow response time
It is recommended to use StringBuilder instead of String class where there are lot of concatenations used . StringBuffer can also be used in multithreaded environments
design
export LDR_CNTRL=MAXDATA=0x40000000 for the local session. After successful testing at UAT, please deploy the variable in production in /etc/environment.
design
The timeout parameter needs to be increased(The applet does not have any timeout parameters currently). \nAs a work around, you can process smaller batches of files, so that time in processing of records is less than the session timeout time.
design
The MIS related queries should be ported to MIS queries to provide headroom for the production DB server to be leverage optimal load.
configuration
The pga_aggregate_target needs to be increased from 1GB to 2GB
configuration
The DB_CACHE_SIZE should be increased from 1.47GB to 3GB for faster read process
configuration
Redo Log files can be moved to RAID 1+0 for better log synching.
design
While writing queries (select or update) always use columns in the where clause which already have an index on them.
design
Closing each connection (cursor) after it is used
maitenance
"Hash out all such queries which use tables which don\u2019t exist in the\ \ production database"
design
Replace sendunix with FTP/SCP process so that batch transfer happens instead of line by line copying.
hi io
The PGA_AGGREGATE_TARGET needs to be increased from to 2048MB to 2560MB.
maitenance
Possible Approaches :\n\n1. To eliminate such cases of having unwanted sessions on the database for a long time, we need to establish a threshold value which needs to be set, so that the session is timed out after the user is not doing anything on the system. \n\nThis needs to be set on resin.conf for the tag <session-config> with parameter as <session-timeout>\nEg :\n<session-config>\n        <session-timeout>10</session-timeout> -- This is set for 10 mins. Please confirm with the application team if this value is okay.\n\n2. The session parameter on the database is not correctly configured. The session value needs to be increased to 1.5 times the processes. Currently the processes value is 1200 and sessions value is 1325.  This will take care of high concurrency coming into the application. Please check on a periodic basis what is the concurrency achieved in GBM during peak load. Post this, the value should be estimated and setup.\n\n3. You can alternatively clean up all invalid sessions, by adding a timeout for the jdbc user by setting up a Idle_time value in the profile. This will ensure all the invalid sessions are terminated after the idle time threshold is reached.\n\nPlease find below the steps to do that :\n\n1. alter system set resource_limit = true;\n2. create profile idletime limit idle_time 30;  --- This should be established after concurrence with the product team.\n3. alter user system profile idletime;
maitenance
NoData
design
The query needs to be tuned to include the column which is indexed, or create an index on IS_DELETED.
design
The query needs to be tuned to include the column which is indexed, or create an index on IS_DELETED.
design
The query needs to be tuned to include the column which is indexed, or create an index on RCC_CODE.
design
Absolute value should be given instead of Like. Query processing will improve.
design
Eiether a procedure needs to be written to replace the logic of 4 nested selects or the query needs to be tuned to use indexed columns in the where clause.
design
Enable access.log for 2 days. This will also help in understanding if there are broken links/ other issues in the application which needs a fix.
design
Archive the stdout and stderr logs for a week to validate any issues in the application
maitenance
Please analyse the tables on daily basis and share the observations.
design
The query logic should be re-written to use the bind variables, or the CURSOR_SHARING_PARAMETER should be set as FORCE instead of EXACT, which is set currently. The application team can take a call to check on the feasibility of either of the two approach.
design
The referrer page should be modified to hash out the references to the objects which are not present.
design
Connection has to be closed at finally, otherwise the sessions will keep increasing on the database.
design
The DB_CACHE_SIZE needs to be increased from to 4096MB to 5600MB.
design
The query needs to be tuned to include the column which is indexed.
design
The query needs to be tuned to include the column which is indexed.
design
An index on foracid,inst_alpha and inst_num to be added.The TRIM function on the WHERE clause fields needs o be removed.
design
The result set which is joined between GAM and DHT should be less to reduce the high temp space utilization. Please check with the vendor as to why two WHERE clauses of the same nature (APPLICABLE DATE field) is present in the query.Also please check the feasibility of reducing the data fetched for JOIN by extracting data between two dates instead of extracting data which is less than a given data
design
Bank to check to check the functional index usage and recreate the index with the respective functional index on sol_id field
design
An additional sol_id condition by joining the GAM table with SST table for set_id ALL to be added in the WHERE clause
design
The INSERT,SELECT and DELETE query can be appended with a PARALLEL hint to enable ORACLE to parallely process the DML's .
design
The TRIM funtion in main WHERE clause needs to be removed, Subsequently the data storage of column TRAN_ID of AXIS_CREDIT_CARD should be left padded as in DTD table by using LPAD function. Currently this data is right padded
design
Increase parallelism for the job groups in the application. HSCOD parallelization to 60 and BJE jobs parallelization to 70 and common env parameter to 50 from current value of 40
design
Recreate the index with revise column position as per below.\nTO_NUMBER(SOL_ID),TRAN_DATE,SENT_FLG
design
Please check the functionality if SQL can re-write by removing SST from FROM clause and WHERE clause. This will reduce the Temp space utilization and SQL cost will reduced to 2900 approx.
cold backup used
We recommend to carry out a HOT backup (online flash copy) for database .
cpu intensive query
These queries to be checked with the EOD team whether these pertains to any EOD functionality or can be avoided
design
To make separate cloned jobs which will execute the functionality only for 2567 and 2568 seperately.
design
Only for job id ZTDAC, parallelization of 10 sols with each sol of 1000 records for ICBX4008 exe is recommended to be added in B2K_PreJibExecCheck.scr
design
We recommend to implement parallelization for these two exe's only for 002 sol in the script B2K_PreJobExecCheck.scr.
design
"Rearranging the cluster sets with more number of sol\u2019s in each cluster\ \ and reduce the number of cluster"
design
Calling URLs needs to be modified to comment out the lines calling non existing pages.
design
Calling URLs needs to be modified to comment out the lines calling non existing pages.
design
HP to internally probe why only opcle is CPU intensive while the other monitoring tools are not.
design
Infosys to make changes in the configuration so that the Lisrvrs are killed after completing the transaction.
design
As these are static files which can be picked from the client rather than the server when recalled, these files should be cached.
design
Images stored in PNG formats are the lightest extensions for images. All the images should be converted into PNG files
design
JS files needs to be placed at the bottom. Common js files called sequentially can be placed in a single js file and called.
design
Js files should be minified.
design
Use RAID 1 + 0  for transaction logs & Datafiles
design
Remove ToString.ToUpper method call for such cases.\nFor eg. (flag != null && flag.ToUpper().Equals("Y".ToString.ToUpper())) can be written as (flag != null && flag.ToUpper().Equals("Y"))
design
Instead compare can be used which will internally check for case sensitivity. (str1.ToString.ToUpper().Equals(str2.ToString.ToUpper())) can be written as (string.Compare(str1, str2, true) == 0), it will work well and efficiently.
design
All resources should be closed in finally block only.
design
Fetch static data from cache outside the loop.
maitenance
CUSR table needs to be defragmented.
design
index to be created on user_report_table table on columns act_code,access_channel
compilation setting webconfig
Please set this value to debug="false"
indexoutofrangeexception error log
Please add condition to check `ds.Tables.Count > 0` before the condition `ds.Tables[0].Rows.Count != 0` in `GetPendingApprovals` Method of `PendingApprovals.aspx.cs` Page.
threadabortexception error log
Please replace `Response.Redirect(strURL)` with `Response.Redirect(strURL, false)` , details are shared in the next sheet.
nodata
Please change the data type of variable `RewardsRisk` from String to StringBuilder.
nodata
Please throw exceptions in catch block.
nodata
Please implement Viewstate Compression in ASPX Pages. Reference http://www.codeproject.com/Articles/14733/ViewState-Compression
nodata
Index on tables Labeling_TermSheet, Labeling_Answers and Labeling_ClientMaster needs to be created. Index script is shared in the next sheet.
slow response time
The logs before the LB should be monitored for delays if any.
slow response time
The code/third party calls needs to be reviewed to check the bottleneck. This will be done in Phase 2 of the engagement.
query optimization
Remove TRUNC from the joining condition
query optimization
Remove unused objects from report
query optimization
Use filter to restrict Historical data or separate historical data to a new report with a link in existing dashboard. \nNeed to check with Business the need for Historical Data.
query optimization
Upgrading Microstrategy Version will help dashboards  having multiple datasets  with cubes to execute in Parallel.
code review
Build a cube on single dataset formed to reduce multiple database hits and  report runtime
code review
Recommended a design change by creating the cube with restricted data to reduces execution time\nView has been provided for the logic implementation\n\nViews have been provided for the same.\nAVE_TEST1\nAVE_TEST2\nAVE_TEST3\nAVE_TEST4_gainer\nAVE_TEST4_loser\nAVE_TEST5\n\nRefer Queries Q5-Q10 in worksheet "Queries" for DDLs.
code review
Recommended a design change by creating the cube with restricted data to reduces execution time\nView has been provided for the logic implementation\n\nViews have been provided for the same.\nAVE_TEST1\nAVE_TEST2\nAVE_TEST3\nAVE_TEST4_gainer\nAVE_TEST4_loser\nAVE_TEST5\n\nRefer Queries Q5-Q10 in worksheet "Queries" for DDLs.
code review
View provided for cube generations resolves this issue
code review
Remove unused objects
maintenance
Refresh statistics on the tables and the corresponding indexes
high cpu utilization
Create a passive application node, which will serve as failover instance.
code review
Weekly backup of Schema and Dashboards is required to avoid lost changes and reduce recovery time in case of failure
code review
Redesign to use only one dataset instead of 3. Redesign dashboard to reduce no. of datasets
query optimization
Create below indexes -\n1. Functional index ( trunc ) on value_date and creation_date \n2. Index on REQUEST_UUID column.
query optimization
Oracle comes with functionalities of Temporary Tables (GTT), which can be used instead of creating the tables and dropping them for temporary use.
code review
It is recommended to remove system.gc() calls from application code and let JVM handle the GC mechanism OR use GC command line option -Xdisableexplicitgc.
nodata
Recommended to gather stats on indusind_test schema.
query optimization
Create index on batch_name and value_julian columns on error_limit_log  table. (Need to validate from Calypso team if no. of executions are going to be high in production environment also as data grows execution time for query will be increased.)
code review
We recommend following things \n- Just fetch only 10 records to show on the Manual Intervention Page\n- Fix the links of previous and next when one returns from submitting a manual intervention transaction to the manual intervention list page. \n-Fetch only the columns needed to display the records on the screen . Table fpd_payment_in has 46 columns and we are fetching all of them even when we need to show just 10 columns. We recommend to fetch just the number of columns needed to display .
query optimization
It was observed application is sending integer datatype to column value, while datatype is varchar in database. Recommended to fix application code to send varchar datatype instead of integer so that index can be used by query.
query optimization
Create nonclustered Index  on table TBT_DO_Details on column Deal_No
query optimization
Create nonclustered Index  on table TBT_NOC_Outward on column Deal_No
code review
As discussed, this procedure is being used at multiple screens for fetching product code. Application logic needs to be investigated to check if there are any locks for holding record set.
nodata
create index non clustered index on request_no column of table TBD_Payments_List_Extract_Etransfer
nodata
Table tbt_deal is having duplicate index on column status_flag. One index can be dropped.
nodata
Create Nonclustered Index On Tbt_deal table on column Session_no and \nInclude (Deal_no,Product)
code review
It is recommended to make a single call with an Array of parameters and populate master dataset which can be used to validate each logical block. Changes in procedure need to be done accordingly.
code review
Populate a collection/array inside the for loop and then make a single call to the procedure with collection/array as an argument. Change the procedure accordingly.
code review
It is recommended to make a single call with an Array of parameters and populate master dataset which can be used to validate each logical block. Changes in procedure need to be done accordingly.
code review
All the User specific details should be loaded with a single procedure call during the login or on Load of respective module and should be kept in client application memory.
nodata
Create non-clustered index on TBT_Payments on columns Product,Maker_Location,PV_Date
query optimization
Need to validate if data can be fetched from local DB instead of PRODOX database.
code review
Data from one procedure  call can be stored and used for conditions rather than multiple database calls.
query optimization
Create Nonclustered Index \nOn Tbt_repayment_dt on columns (Deposit_number,Session_no,Serial_number,Pdc_date)
query optimization
Recommended to verify if data from 2004 needs to be scanned if not needed date can be changed to scan only required amount of data
code review
These multiple calls need to validated against functional requirement and need to minimized wherever possile. Please refer "Sp_Call_Count" sheet for more details
code review
Make sure all path returns
code review
Instead of break, use return, which will improve the instruction execution cycle
code review
Parentps.GetProperty can use to reduce the loop
code review
The 'if' condition is not in use. It could have kept for the feature use. Comment it along with if condition, it is  taking the execution instruction cycle unnecessarily. Given here is an example, like wise many if statements are not in use in this function
code review
Can try to use name index property to get the object of "Qnts WCIG City Pairs", instead of looping. If 'r' is greater number, it is unnecessarily loops. Likewise other loops also can be reduced.
code review
Relooking the pattern of execution cycle further in better way. \nFor example \nr = ExtSystemParent.GetChildCount();\nfor(i=0;i<r;i++)\n if(ExtSystemParent.GetChild(i).GetType()== "Qnts WCIG City Pairs")\n   Child =  ExtSystemParent.GetChild(i);\nOnce we have got the object required, then the comparison can be started\nif( Child != null)\n{\n if(oCabinClass == oEcoClass) { ... }\n if(oCabinClass == oFirstClass) {...}\n}\nThe above for loop also can be avoided by relook of using the name index pattern.\nif(ExtSystemParent.GetProperty('"Qnts WCIG City Pairs") != null)\nChild=ExtSystemParent.GetProperty('"Qnts WCIG City Pairs")\nThis way it help us to  reduce the internal looping.
code review
try using the name index pattern to get the object, avoid the for loop
code review
when the NoOfPass is null or empty, then the divide option will fire the DiveByZero Exception. Continue of this, code is checking the NoOfPass for empty and null, if so, the NoOfPass is assigned to 1.\nRelook at this, Should n't it be like following?\n  var oDefFlag = "N";\n  if(NoOfPass == "" || NoOfPass == null)\n   NoOfPass = 1;\ngNumberofPass = ToNumber(NoOfPass);\noFFPVal = oFFPVal/gNumberofPass;\nAvoid unnecessarily DiveByZero exception
code review
Append is called multiple times, logically invoke method is multiple times called in append function. The multiple invoke invocation can be avoided by passing the string of required object from the WCIG function.\nFor an example :\nAppend function\n\nvar oEcoClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS","Economy");\n var oFirstClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS","First");\n var oBClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS","Business");\n var oPEClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS","Premium Economy");\n\nInstead of the above\nvar oCmpClass = TheApplication().InvokeMethod("LookupValue","QNTS_WCIG_CABIN_CLASS",passingString);\nThe calling function WCIG\nwould have Append("Economy")\nAppend("First")\nThis reduces the multiple invocation firing in the append function. The WCIG called append method 4+4 = 8 times and in append method invocation is fired 4 times for each call. 4*8 = 32 times it is calling the invocation, which can be reduced to 8*1 = 8 times. We can save the execution cycle which helps us to improve the performance.
code review
As a best practice, in the finally block, the required global variables needs to be reinitialized.
code review
Avoid else
code review
Avoid else
code review
Avoid else
code review
deinitialize in finally block
code review
All path needs to return
code review
While(c<ct){\nDeleteRecord();\nc++;\n}  better coding for deadlock,  < is better than == checking
code review
if(QuoteProduct != "OneWorld")\n {\n   with(oTransactionBC)
code review
QuoteProduct = "Partner"; \nif(noClass!="Y")\n  {\n    if(IsOneWorldQuote == "Y")\n    {  \n     if(ToNumber(OneWorldQuoteSum) < ToNumber(PartnerQuoteSum)) //One World Quote   \n     {\n      QuoteProduct = "OneWorld";  \n     } \n  }\n}\n if(QuoteProduct == "OneWorld")\n  {  .......
code review
res = OMktPartnerArray[0].split("/");\n//without checking the length of the arrau res, it is dangerous of accessing array index 1\n// it should have checked something\nif(res.length < 2)\n{\n  // Exception should be handled for res[1] array index accessing when it misses it\n}\n    res1= res[0];//partner\n    mktprtnr = res1;\n    res2 = res[1];//distance
code review
Multiple place this type of code is used. Use always else if statement for this kind of comparison, which can improve the instruction execution time\nQFPartnerItinerary.SetProperty("Itinerary", QFPItineraryArray[a]);\n     QFPartnerItinerary.SetProperty("Class", QFPCabinClassArray[a]);\n     if(sftind == "E" || sftind == "" || sftind ==null)\n      QFPartnerItinerary.SetProperty("Points Excluding SFT", QFPPointsArray[a]); \n     else if(sftind == "I") \n      QFPartnerItinerary.SetProperty("Points Including SFT", ToNumber(QFPPointsArray[a]) + (sftvalue* ToNumber(NTripArray[i]))); \n     else if(sftind == "B")\n     {\n      QFPartnerItinerary.SetProperty("Points Including SFT", ToNumber(QFPPointsArray[a]) + (sftvalue* ToNumber(NTripArray[i]))); \n      QFPartnerItinerary.SetProperty("Points Excluding SFT", QFPPointsArray[a]); \n     }
code review
Logically, it is right way of breaking the for loop using the max count of ( I=gltiCnt-1). But this will allow for loop to check the conditional again then break. When use of break,  it breaks the loop interruptly with out comparing the for loop conditional
code review
deinitialize in finally block
code review
"use else if for sftind  to compare all it\u2019s value"
code review
also make sure  if(lItinerary != "" && lItinerary != null)
code review
In for loop , if condition checking for the 'i' count may not required. At the end of the loop, this activities can be performed. Logically, it's right but it takes the extra execution time. This can be avoided by performing at the end of the loop. It is checking for the last index, which can be directly accessed after the loop.
code review
deinitialize in finally block
slow response time
Avoid calling toString() on String objects; this is Unnecessary.
slow response time
Use equals() or equalsIgnoreCase() to compare strings instead of ''=='' or ''!=''
slow response time
Remove all such operations from code
slow response time
Remove all such operations from code
slow response time
Only one call is enough as the string is already trimmed.
slow response time
Change the if condition to some variable. And use the cached data.
slow response time
Change the if condition to some variable. And use the cached data.
slow response time
Change the if condition to some variable flag rather than accsum.length
slow response time
Change the if condition to some variable flag rather than cardlessPayeeList().length.
slow response time
This is not required and operationId itself can be used further.
slow response time
Remove these redundant calls
slow response time
"It is recommended not to create much of unused objects as it will result\ \ in memory consumption. This should be considered important when it\u2019s a mobile\ \ device code."
slow response time
Replace select * queries with the required column name.
slow response time
Put a null check on such objects (here goals) before performing any operations on it.
slow response time
Since HttpServeletRequest is immutable. So these attribute changes should be removed.\n\nThis need to be discussed with development team for understanding why this is being done. As no oveeriden method was found to map these immutable entries.
slow response time
Can this js be called at the bottom of the page so that it does not block other objects? If there are elements of the js which necessarily needs to be called at the top, lets bifurcate the js file into multiple files, so that the js file is not as heavy as it is today (149 KB) which takes time on a slower network.
slow response time
We need to add one more web server behind the LB. This will ensure that if we want to deploy a patch into production during business hours, one server can be pulled out, patch is deployed and the results monitored.
slow response time
The connection pool on the web.config needs to be reset to as follows :\nConnection Lifetime 0\nEnlist 'true' \nMax Pool Size 100\nMin Pool Size 0 \nPooling 'true'\nThe same needs to be done on both web server as well as app server.
code review
Rewrite the existing Talisma Life cube to include the aggregation.
query optimization
Refresh Statistics on the tables
code review
Remove unused objects from report
high cpu utilization
Hardware configuration for Application Server has to be increased  to minimize the CPU utilization and getting rid of server crash or failure in ETL data loading.
architecture
One standby instance of database server has to be added.
code review
Recommendation is to have dataset distributed across two groups:\nMovement Data - Where customer changes the group(e.g. 0-1L to 1L-3L. This data is limited and can be pushed to cube.\nView AVE_TEST11  (Refer query Q11) is created to give the logic for cube formation.\nNon Movement Data - This has high volume of data and will have to be kept as it is, as per the the user's need. These links will continue to hit database to fetch results as pushing millions of records in cube is not recommended.
code review
Recommendation is to limit the data shown to the user either thru Pagination or applying filter.
code review
All cubes need to be looked into to remove attributes which are  not required for dashboard to save space.
code review
Month's data is being feteched from daily table. Business logic and requirements needs to be validated against the code.
maintenance
Refresh Statistics on the tables
design
Create index on following columns and test for runtime performance.
query optimization
TRUNC needs to be removed from all the view for better performance.
code review
This cube needs to be decommissioned
code review
Replace all the existing queries with a single cube fetching single record each for each date. Remove existing date data sets from the report.\n\nView AVE_TEST_iw is provided for the same
code review
Build an individual cube for the datasets and pull data from it.
query optimization
Only selected columns should be included in select query, this helps to reduce data transfer between DB to APP server.
code review
It is recommended to use arraylist instead of vectors, since vectors use internal synchronization on every operation and lead to performance degradation. For thread safety in arraylist  "Collections.SynchrinizedList(new ArrayList<type>)" can be used.
code review
Use Position literals first in String comparisons for equals/equalsIgnoreCase. If the String is null you won't get a NullPointerException, it'll just return false.
query optimization
Check application logic to put where clause. (Need to validate from Calypso team if no. of executions are going to be high in production environment also as data grows execution time for query will be increased.)
query optimization
Create composite index on ers_limit_usage table on columns (version,julian_offset) as recommended earlier.
query optimization
Check application logic for commit on this update statement.
query optimization
Create the indices on the columns  which will reduce the CPU cost.\nTable - FPD_PAYMENT_IN | COLUMNS - INWARD_FILE_NAME,TXN_CODE,Q_STATUS\nTable - FPD_FILE_INOUT |COLUMN - BATCH_FILE_NAME\nTable - FPD_CBS_AC_ENTRIES | COLUMNS- PROCES_DATE,STATUS_CODE
query optimization
gather the tables stats with the option method_opt=> 'FOR ALL CLOUMNS SIZE AUTO' at regular interval on the following tables \nFPD_CBS_AC_ENTRIES\nFPD_PAYMENT_IN\nFPD_PAYMENT_OUT\nFPD_FILE_IN_OUT
query optimization
Create the new tablespace to hold the indexes on the tables.
code review
On Analysis of deadlock issues we observed that following things \n- Connections are not being closed in some classes\n- Connections artifact closing order is also incorrect .  \nA detailed mail is shared already .
configuration
We have already shared a mail pointing out the differences in both the databases. \nWe recommend to align UAT Database properties with production.
code review
We recommend to implement Auto refresh  in the menu section of the application . Currently it has a manual refresh button .
query optimization
Create nonclustered Index  on table TBT_PDC_Receipts on columns Deposit_Number
code review
Application code needs to fixed to avoid broken links
query optimization
Create non-clustered index on deal_no\non Tbt_Pdc_Pullout table
query optimization
Create Nonclustered Index On Tbm_customer_account on column (Maker_id])
code review
It is recommended to populate collection of Document_Number and Document_Amount inside for loop and pass them to the stored procedure
code review
Get required challan_number from DB and perform manupulation of string on client side.
code review
deinitialize it in finally block
code review
Avoid instruction execution cycle
code review
Instead of looping to get the properties, can use direct method like "GetProperty"\nvar sShipper = Inputs.GetProperty("Shipping Company");
code review
deinitialize it in finally
code review
use return to reduce the instruction execution cycle
code review
deinitialize in finally block
code review
origin & dest anything is null, it gets same error code. It would be good to have different value for origin and dest. Caller will not know the problem with origin or dest or both.
code review
deinitialize in finally block
code review
deinitialize in finally block
code review
deinitialize in finally block
code review
Dangerous with out checking the spl array length accessing the index of 2\nbefore accessing index of spl[2], check the size of the array\nif(spl.length <3)\nsp=sp1[2];
code review
deinitialize in finally block
code review
reconsider as \nif(vActivityDate!= "" && vActivityDate != null). Null is compared as string than null object or may required to check null as string would be better in following \nif(vActivityDate!= "" && vActivityDate != null && vActivityDate != 'null')
nodata
Please create a table to store mails. This table will be used by different schedulers to store the mails. And a common Mail Scheduler will process this table to send the mails.
404 error downgif
'Source Code should be corrected to remove reference path of down.gif. Following pages contains the reference: frmAuditTrail.aspx, frmDeletedReport.aspx, frmFwdContractDealReport.aspx, frmFwdContractDealsDetails.aspx and frmFwdUtilizedDealDetails.aspx'
httpexception event viewer
Please remove `Response.Cookies.Add...` line from `Session_End` Event of `Global.asax` File. Since when the session ends, HttpContext or Response Object is not available.
slow response frmdealsaspx page
In Procedure usp_DirectRates_GetDeal, Please Select only those columns in the query which are required in the business layer.
application code review frmdealdetailsaspxcs
Please replace `if` condition by `else if` condition.
application code review frmfwdutiliazationdealsaspx
'Please enable security on the `Upload` Folder, So that files cannot be accessible without Authentication.  Also please check the feasibility of Encryption for these files.\nReference: http://support.microsoft.com/kb/815152'
application code review frmfwdutiliazationdealsaspx
Please add unique names to the files, so that files cannot be overwritten. Below is Code Sample for Reference.\nFileName = FileName + "_" + Guid.NewGuid.ToString();
response time high
validate if the table can be created once and insert statement can be used to push data into the table. \nPlease refer create_Table_Query sheet.
response time high
As a standard practice username and password should not be a part of code. It should be moved to configuration file. Please refer DB_Credentials_Details sheet.
workflow delay
These need to be converted to js files. Which can be moved to bottom of body
response time high
Check if js and css files can be combined and compressed. For small background images CSS sprite can be used. ( Pt 5 to 11 apply for other webpages of portal application )
response time high
Load them asynchronously to reduce blocking of page rendering.
response time high
Fix paths or deploy documents to avoid 404 errors
workflow delay
It is recommended to have load balancing in place, so that the load is evenly distributed across all vm instances
workflow delay
Need to change the log format to "LogFormat "%h %l %u %t \"%r\" %>s %b %T \"%{Referer}i\" \"%{User-Agent}i\"" combined"
response time high
As confirmed by CNK team, direct value can be returned to SP and this will reduce the function execution time without affecting the functionality of application.
architecture
Implement security policies for file access (only required permissions should be given to particular user)
architecture
Only selective columns should be included in select query from product, this reduces the data transfer from DB to APP
architecture
Please refer Server_Slowness_Crash_Analysis.docx for RCA and recommendations
workflow delay
It was recommended to use memcache to store session data, instead of http process.
workflow delay
It was recommended to use memcache to store session data, instead of http process.
workflow delay
It is on by default and no need to enable it
high response time
such extra objects in database are not required to be maintained by dictionary. There is no need of view since columns can directly be selected from table.
architecture
ursor needs to be closed after it has finished its work else resources wont be released from server.
high response time
Apache version upgrade from 2.2 to 2.4 to use prefork mpm is recommended for multithreading. This needs application testing to be carried out
workflow delay
use of php-fpm manager is recommended to server PHP requests and static contents will be served by apache
architecture
Recommended to move cache build operation to log shipping server, which has 15 mins lag as compared to production and log shipping server should not be sharing the same LUN as that of production.\n- Optimal storage configuration should be given to database instance\n- Optimization of SP is required
architecture
Data needs to shard from avekshaa team
query optimization
Purging needs to be carried out on the BTNEFTPROCESSDET table.
high memory utilization
Set database connection pool size to same value across all the servers. Change hibernate.c3p0.max_size property in all application server Database.properties file.
configuration
As a short term fix, This value needs to be altered to have a headroom to accommodate the long running processes. As a long term fix, we suggest you to fix the issue from the root by finding out from different places in the source where the leak is happening. We have observed lot of connections being abruptly killed in the stack trace at stderr.log. Please share the logs with the product team for ready referemce who can validate such cases and close connections appropriately.
configuration
Change the parameter DEBUG=FALSE in the web.config file in the web server.
configuration
Use advanced logging techniques such as log4net so that file writing using multiple threads can be optimized.
configuration
Please fix the conversion errors in the Scheduler's Code.
maitenance
Such activities should be done only when the tables/indexes are not being used for operations.
query optimization
Analyse REP_MATURITY_REPORT table before generating this report.
query optimization
'1) The query needs to be modified to tune the view. \nAn index is already present on cbl_disc_date, however it is not being used because the column is being used in a decode function -- DECODE (cbl_tenor_id, ''B'', cbl_bill_date, cbl_disc_date).\n2) Functional index can be created on this function\n\nE.g :     create index temp2 on cfs_bill_log (DECODE (cbl_tenor_id, ''B'', cbl_bill_date, cbl_disc_date))'
query optimization
Either add index on this table for the column CDR_USER_BAND or modify the query to use any column which is already indexed.
query optimization
As the saving, current and cash credit scheme accounts are independent of each other, these schemes can be processed in parallel.  The smaller batches can be run in parallel while heavy batches could be run in isolation. Even if the smaller batches have to be run sequentially, these can be grouped with the other schemes.
query optimization
Create  indexes on CMH_FROM_TIME  and CMH_TO_TIME  columns or modify the query to use current indexes.
code review
We propose a multi-threaded Form1.cs instance which will be able to handle simultaneous change events.  See Flow 1 Analysis slides in the Analysis report.
code review
The proposed solution is to CLOSE the Pop-up page when the Dealers sign out of the Main Page. This will eliminate the un-necessary calls to CurrencyFromRIC_Ajax.aspx and further reduce the Logout.aspx invocation. \nThe changes have been implemented and will be deployed in Production in the next CR cycle. The IIS logs should be analyzed after the changes have been implemented.
code review
Can we store the session date in the main memory rather than in the database.(Development team was supposed to the analysis on this point by 3rd july).
query optimization
The CR has already been raised to have a position table created and the said SP has been changed. There is huge scope of improvement in the modified SP, and the indexes were missing in the position table being used. Suitable indexes have been created on two tables used in the SP.
code review
We should evaluate the possibility of having multiple threads (3-4) picking such sets (of 498) and processing them in parallel. This will add scalability and improve throughput.
code review
Change start-up script to provision 512 MB heap size (both minimum and maximum).  Suggestion has been implemented.
code review
No issues were identified
code review
Thread.sleep should be eliminated
code review
The operations can be eliminated to increase throughput.
code review
The operations can be eliminated to increase throughput.
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
query optimization
Appropriate Indexes needs to be applied
configuration
Recommended RAID configurations:\nRedo log & control files - RAID 1+0\n16k tablespace datafiles - RAID 1+0 preferred ( else RAID 5)\nother data files / archive logs - RAID 1+0 preferred ( else RAID 5)\nundo and temp files - RAID 1+0
configuration
Perform data file  movement to make some space available.
configuration
Change the way data is manipulated or the way it is declared in order that this does not violate the constraint. Since an alert log is polluted with this error there is a good change that some other error might get masked in future due to this.
code review
In httpd.conf (for both corporate & bank servers) append %T to the current list of options for LogFormat.\n\nThe LogFormat line should look something like:\nLogFormat "%h %l %u %t \"%r\" %>s %b %T" common
older version
From a compliance standpoint, it would be good to upgrade current Oracle Application Sever to 10g or better still to upgrade it to the latest version of more popular Oracle Weblogic server.
code review
Permanent fix for this issue is to reduce memory foot-print of the application. POI HSSF usermodel API is extremely memory hungry. Replacing this API with SXSSF (Streaming XSSF) will reduce memory foor-print by a big order. Change current excel generation logic a bit and make use of SXSSF API rather than HSSF one.
hop
'This needs to highlighted to network administrator for resolution as the response time will get affected. Following machines need to be analyzed: \n10.127.253.105 - > 53ms\n10.16.117.134 -  > 76ms\n10.16.117.130 -  > 40ms\n10.16.167.155 -  > 78ms\n10.16.58.151  -  > 64ms\n10.16.0.207   -  > 59ms\n10.16.58.67   -  > 108ms\n10.16.58.151  -  > 64ms\n10.16.167.155 -  > 78ms'
high cpu
CPU was saturating because of a while (true) loop in the Header.jsp file which is in-turn included in many other two JSP's.  As a workaround, we have introduced a small sleep in the loop to reduce the CPU cycles. This is a temporary work-around
configuration
Change heap size to  2 GB(min) and 2 GB (max).  Also suggested some high performance algorithm settings for garbage collection e.g. -Xconcurrentio, -XX:+UseParallelGC etc.
code review
'Code was changed to close the Connection, Sockets and IO objects after their use. As a work-around sleep introduced in the while(true) loop that consumed high CPU cycles. \nSee recommendation # 2, 8, 9, 10 and 11 for details.'
code review
deinitialize in finally block
code review
deinitialize in finally block
code review
deinitialize in finally block
code review
Not used any where, can be removed or commented
code review
Refactor the code
code review
Add logging inside catch block
code review
Object creation is expensive enough that you should avoid unnecessarily creating temporary or intermediate objects in situations where performance is an issue. Define instances outside the loop will solve this warning.
code review
Change statement with log statement
code review
Break the classes into multiple clasess
code review
break the method into mutiple methods
code review
Refactor the code
code review
Fix all variable that is not thread safe
code review
Reader class provides close() method and it should be invoked in the last.  It's very important to invoke in finally block, so it will be called even if an exception occurs.
code review
implement serealizable
code review
Use Buffered Input stream class instead of InputStream as following\nBufferedInputStream in = new BufferedInputStream(new FileInputStream(from Filename));\nBufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(to Filename));
code review
Log enabled status should be checked before calling the log util method for logging the message. By doing this unnecessary message string construction time can be saved.
code review
Add server VM option - The server VM option has been specially tuned to maximize peak operating speed. It is intended for executing long-running server applications, which need the fastest possible operating speed more than a fast start-up time or smaller runtime memory footprint
code review
As server side state saving option has been used, so limit the number of active views per session and configure it initially with 10 in web.xml. Monitor this value and increase the value as required\n<param-name>com.sun.faces.numberOfViewsInSession</param-name>\n<param-value>10</param-value>
code review
Catch the exception where it require to be handled. Also, handling the flow using Exception bring performance bottleneck.
code review
Code Review in progress. Solution- String to numeric value conversion.
code review
Remove sysout and use logger with log level where ever required.
code review
Consider replacing Vector usages with the newer java.util.ArrayList if expensive thread-safe operations are not required.
code review
Statistics need to be gathered on the tables for optimal execution plan of the queries.
concurrent io
"We recommend to implement the concurrent I/O feature for file systems on\ \ AIX  where database datafiles (.dbf) and redo logs resides .\\nTo mount a filesystemin\ \  with CIO Feature we can use below command\\n$ mount \u2013o cio /data"
index creation custcfcmmain
We recommend to either \n1) Create a new index on the table  CUST_CFCM_MAIN for column ENTITY_ID . \n2) Edit the existing composite index to shuffle the column place of ENTITY_ID column to the first place on the left . We recommend this only afer carefull evaluation of the existing index usage.
batch job parallelization
We recommend to increase to parallelization to imrpove the utilization of the available hardware . In the first increment we recommend it to increase it 30 . Post change obseration may lead to further fine tuning of this parameter.
index creation iapsmstxn
We recommend to create an index on the STATS column of the table to avoid full table scan.
audit query
We recommend to analyze the running of Audit queries during EOD/BOD time frame . These queries if necessary can be moved out of EOD/BOD window .
scheduled job
We recommend to analyze the running of DBMS schedular during EOD/BOD process. These scheduled jobs  if necessary can be moved out of EOD/BOD window .
table fragmentation
We recommend to degragment the tables which are shared in a separate mail .
full table scan
We recommend to create new composite index on LA_ACCT_MAST_TABLE table with columns (DMD_SATISFY_MTHD,OP_ACID).
configuration
Start mongo DB server under numactl as below:\nnumactl --interleave-all /path/to/mongo/db/mongod -f /etc/mondo.conf
code review
'Use String.indexOf(char) when checking for the index of a single character; it executes faster then String.indexOf(String).\nReference:  int lastIndex = s.lastIndexOf("/");\nRecommanded: int lastIndex = s.lastIndexOf(''/'');'
code review
Many DB calls are made in model classes to fetch the same object from Db. Make one DB call and store result locally in Map.
code review
Make Jackson parse call once and store it in local variable. Later use local variable.
code review
Replace find and findById methods with Morphia query calls as shown below:\nList<Issue> users = MorphiaDatastoreWrapper.getInstance().ds.createQuery(Issue.class).filter("_id", 32).asList();
code review
Check Morphia devloper documentation and API to check feasibility of adding projections in queries.
code review
Jio News client developers should evaluate JSON reponse from the server and list down redundant objects in the response tree. Server devs to drop redundant Db calls to fetch these redundant objects.
code review
Transparent huge pages to be disabled. The below commands to be executed for disabling transparent huge pages    echo never > /system/kernel/mm/redhat_transparent_hugepages/enabled    echo never > /system/kernel/mm/redhat_transparent_hugepages/defrag.   This needs to be added in rc.local file also
code review
Check Morphia developer documentation/API so that max "_id" is fetched from the Favorite collection wihout having to fetch all records.
code review
Is it necessary to populate the cache here? Can the cache be not populated during first access? This is again a hot cache update and I think we should avoid it. \n\nIn any case, it is querying Favorite and ordering based on date. You need to add index on date in collection Favorite.
code review
Policy configuration changed on the environment.
code review
Following changes done on F5 Load Balancer:\n1. TCP Timer set to 30 seconds\n2. SSL Offloading Implemented\n3. Multiplexing Enabled
code review
Setting following in sysctl.conf on all the Seco Nodes:\nnet.core.rmem_default = 262144\nnet.core.wmem_default = 262144\nnet.core.optmem_max = 40960\nnet.ipv4.tcp_rmem = 262144 262144 8388608\nnet.ipv4.tcp_wmem = 262144 262144 8388608\nnet.ipv4.tcp_mem = 8388608 8388608 8388608\nnet.ipv4.tcp_fin_timeout = 10
code review
sysctl.conf file synched from the Seco Nodes to the Mysql Database.
code review
Defragmentation is required for those tables.
code review
Add the file /etc/security/limits.d/99-ssg-appliance.conf with the contents below:\n# Layer 7 Limits (SSG-8322)\n# gateway user value based on /proc/sys/kernel/pid_max\n*               hard    maxlogins    10\n*               hard    core    0\n*               soft    nproc   5120\n*               hard    nproc   16384\n*               soft    nofile  4096\n*               hard    nofile  63536\ngateway         soft    nproc   31768\ngateway         hard    nproc   31768\n# End Layer 7 Limits
code review
Raising up the thread limits. These settings are configurable through the Policy Manager -> Tasks -> Manage Cluster Wide Properties\nio.httpCoreConcurrency - 500\nio.httpMaxConcurrency - 750\n\nAs the concurrency values are increase we also need to take into consideration the number of concurrent databases connections for auditing and other related tasks. The default value is 260 connections so increasing value should be httpCore + 100 so for 500 we need to set the value to 600. Further to this depending on the number of nodes in the cluster you will need to look at whether the max pool size X Number of nodes will be over 2625 and if so use the procedure below to control the value in the my.cnf file.\n\nModify /opt/SecureSpan/Gateway/node/default/etc/conf/node.properties\n\nadd the line\nc3p0DataSource.maxPoolSize=600
code review
Additions to the Cluster Wide Properties\nprincipalSessionCache.maxPrincipalGroups to 1000 principalSessionCache.cache to 1000 ldap.group.searchMaxResults to 1000 ldap.searchMaxResults to 1000
nodata
The ulimit -n parameter needs to be increased to a high value for the server to accept high concurreny. The ulimit -n is set as 1000001.
code review
The memcache connect() was changed to pconnect() to use persistent connect to reduce the connect on the memcache.
code review
Code change needs to be done to include the else condition, where the requests should do not die if the memcache service is down.
code review
Bonding was removed and a dedicated 10Gbps network line was introduced. (Max network throughput currently is 500 Mbps, 10 Gbps line is sufficient).
code review
The net.netfilter.nf_conntrack_max was set as 256000 to accommodate these many max connections on the API Server.
code review
Replace date(date) by date in the query
code review
echo 2048 >/sys/block/sda/queue/nr_requests\necho 1024 >/sys/block/sda/device/queue_depth
code review
For table playlist_master , the primary index needs to have userid and playlistid in the columns instead of playlistid alone. A secondary index needs to be created on playlistname. Allow filtering should be removed from the query.
code review
For table playlist_master ,the primary index needs to have userid and playlistid in the columns instead of playlistid alone. A secondary index needs to be created on playlistname. For table playlist_details_new the primary index needs to have userid, playlistid and songid in the columns. Remove allow filtering from the query.  Allow filtering should be removed from the query.
code review
For table user_likes, secondary index needs to be created to status column, and allow filtering should be removed from the query.
code review
This should be limited by pagination.
code review
user_likes table needs to be recreated with primary key on userid,srno,songid, with clustering order by (srno desc,songid asc). A secondary index needs to be created on status column.
code review
A logical call needs to be taken to have the cassandra connect call in blocks where cassandra queries are being called.
code review
Extra hit on the new release should be avoided.
code review
Rename playlist needs to be refreshed immediately.
code review
Add limit 2 to the query fired on user_likes.
thread contention ecsdalrepositoryodsecspolicydetailrepositorygetpolicy
Do following steps.\n1. Instead of applying EntityFunctions.TruncateTime function on EndorsementDate column use variable side value without time.\n2. Create Index for EndorsementDate column in ECSPolicyDetails table.
slowness application due sudden load various interface
Use following approach to resolve this.\n1. Assign more connections using <system.net> configuration in web.config of HCS services application to ips of interfaces dedicated for various services to avoid slowness in web request processing.\n\nOr\n2. Divide logically services across multiple worker processes to avoid slowness due sudden rise of load from any of the interface.
thread contention ecsdalrepositoryglobalsearchclsearchrepositorygetcldetailcount
Following should be checked to make GetCLDetailCount query faster.\n1. Remove EntityFuctions.TruncateTime from table columns.\n2. In select section just one column is enough.\n3. GroupBy clause is unnecessary as just count is needed.
thread contention ecsblsavvionreferencergiclhcswsserviceupdateandcompleteclflowtask
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
several unusable object initialized constructor business layer class service folder
The required objects should be passed into functions as parameter instead of initializig them in constructor.
thread contention ecsdalrepositoryglobalsearchalsearchrepositorygetaldetailscount
Following should be checked to make GetALDetailCount query faster.\n1. Remove EntityFuctions.TruncateTime from table columns.\n2. In select section just one column is enough.\n3. GroupBy clause is unnecessary as just count is needed.\n4. Review Query if same logic can be accomplished with less number of joins
thread contention ecsdalrepositorystatusstatusservicerepositorygetclaimsbypolicyno
Following should be done to make GetClaimsByPolicyNo function faster.\n1. Remove string concatenation for Output string.\n2. Remove logging if not needed
thread contention constructor dynamicclassbuildupecsblblclaimcommondocumentdetailsbl
The required objects should be passed into functions as parameter instead of initializig them in constructor.
currently antivirus software installed db server
If any antivirus software is installed on the SQL Server computer then disable real time scanning of SQL Server data and SQL Server transaction files (.mdf, .ldf).
method code line formated
It is recommended to fromat code lines insied the  Methods.
using net profiler
It is recommended to regularly use .Net Profiler.
database connection pooling
set following keys in connectionstring \nConnection Lifetime 0\nEnlist 'true'\nMax Pool Size 100\nMin Pool Size 0\nPooling 'true'
remove browser waiting time waiting script received
Move all the script tags and script references to the end of the page in the files in the Views folder.
null checking input parameter integer method controller done without setting integer nullable
NoData
created new class input parameter method 5 input parameter
It is recommended to create new class for input parameters where the methods have more than 5 input parameters.
hard coded value found
Its recommended to fetch hard code values from config files.
enum used
Its recommended to use Enum and call Enum for hardcoded values. Also hardcoded values should be fetch from config files.
handling null value string variable
It is recommended to assigned the string variables to local variables using Convert.ToString() instead of .ToString()
validation missing
It is recommended to do null check for IdataReader object before fetching data from that object.
hard coded value found
Its recommended to fetch hard code values from config files.
found unused commented code
Its recommeded to remove unused commented code.
method header comment missing
Its recommended to give Header Comments above all the Methods.
validation missing
It is recommended to do null checking of the variables before assigning their values.
hard coded value found
Its recommended to fetch hard code values from config files.
multiple class found single c file
It is recommended that one class should be present in a single file.
database design code review
Need to test and rectify the code and design issue identified in the production database.
sqlid 5v2jrmvmjzhk6
The execution of the pakages (begin ONL_MSGTIMEOUT.AutoReverseException; end;;)
observed stream object writer closednexample serversocketthreadjava
It is recommended to close the Stream objects .
observed logger log4j used log information info level
It is recommended to set the log level to debugging since this all information is used during debugging . Log level 'info' is used for highlighting the progress of the application .
observed critical information stored variable passed stringnexample relationshipdetailsmanagerjava bankconfirmationvojava customerdetailsmbeanjava many place
It is recommended to not use straight forward variable names like user , password , proxy , ip , port.  It is also recommended to enCode Recommendations these values for security reasons
observed system property used global variable
It is not recommended to use System.get/set property for storing global variables. Instead one global class with static getters should be used by reading all properties at startup time.
observed stringbuffer used many class even though used single threaded environment
Its recommended to use StringBuilder instead of StringBuffer after careful evaluation of multithreadedness of the piece of Code Recommendations.
observed servername port number various type hard code recommendationsd value usedncustomerdetailsmbeanjava adauthenticationjava etc
It is recommended to put application configuration specific values from applicationconfig.properties file
observed string used many class usage operator nexample bankaccountstatementmbeanjava  chequeleafmbeanjava etc
It is recommended to use Stringbuilder instead of String class where there are lot of concatenations used . Stringbuffer can also be used in multithreaded environments
observed lengthsize method used inside loop add unnecessary processing iteration loopnexample accountdetailjava  eodbalancejava etc
It is recommended to compute the length/size value at the start of the loop and assign it to a variable . This variable then can be used in the loops
observed exception consumed empty catch blocksnexample quickkillsjava cardetailsmbeanjava many
It is recommended to log / process an exception .
observed generic exception catch exception e  caught place
It is recommended to catch specific exceptions e.g. Catch (FileNotFoundException e), SQLException etc
observed string literal used application frequentlynexample iviewauthorizationutilityjava
it is recommended to use String constants rather literals.
observed hashtable class used
it is recommended to use concurrenthashmap class over hashtable class.
obseved bean class derived serializable class
It is recommended to derive bean class from serializable class
observed xml response stored two dimensional array string compare item string constant right hand side present almost class
it is recommeded to take string constants as string final string and check constant.compare(string)
observed various reqxxxx class used without interface even method
It is recommended to use interface and put getXml(), getXmlHeader(),setDate() and getXmlFooter() functions in it and all Reqxxxx classes should implement this interface
observed customexceptionhander class created used code recommendation
It is recommeneded to make custom exception handler with product name and use that wherever needed ex. ICICIIViewException
observed oops concept used iview code recommendationsbase
it is recommended to use interfaces and abstract base classes for better Code Recommendations maintainability
observed function header written
It is recommended to use javadoc specifications for function headers so that dynamically help can be built and used for reference purposes
observed class variable settersgetters provided
it is recommended to check this carefully and provide only required getters/setters
observed many util package used
It is recommended that in Web Application we should follow Model/View/Controller packages and move all data structure in Model and all xhtml into View and all controller classes in controller packages
observed code recommendation aligned properly
It is recommended to prepare proper checkstyle for Code Recommendations formatting and use eclipse checkstyle feature for formatting the Code Recommendations
observed proper code recommendation commenting done entire code recommendationsbase
It is recommended to put proper Code Recommendations comment so that any other developer can understand it
observed variable upper case camel case
it is recommended to use lower case in .properties file
observed unwanted import package seen many file
it is recommended to run organise import command in eclipse
observed junit test case present code recommendationsbase
it is recommended to write Junit test cases for each class for Unit Testing
observed main method kept several class
it is recommended to remove all main methods and make another name method
observed tostring  method implemented
It is recommended to override toString() method for pretty print of object for debugging point of view
heavy usage xml payload interact source system carry additional overhead latency memory footprint application talk source system slowly data exchanged via lighter json formatnin interim eai convert message format xml json vice versa
A POC needs to be carried out to on XML versus JSON messages to ascertain the overhead of XML over JSON.
general suggestion
Application static images and JS/ CSS files will be cached at web server.
general suggestion
The setup/infra for BB and CC channels should be separate and independent.
custom logging used need changed log4j
For audit trail, the asynchronous logging needs to be looked at rather than current blocking based logging.
sax based xml parsing used manually pojo created xml parsing
JAXB based XML parsing needs to be considered rather than current SAX based parsing approach.
application used call center branch operational efficiency important
"We are proposing to use a recommender system (similar to Social media sites)\ \ help to show screens/ functions as per user behavior. Screens/ functionalities\ \ can be re-arranged based on what end-users use most.\_"
incident dated 02032017 high cpu utiization observed 10504945 app server causing slowness fluctuation iview admin console
Proper JVM tuning is required. One Production servers full day GC log is requried.
currently avg disk queue length parameter monitored apm tool
To capture Avg Disk Queue Length (% wait in Solaris) in monitoring software.
found response time analysis ii log
Around 8 Recommendations given to improve the reponse times on various pages of LOP application.
code review
reconsider null is compared as string than null object\nif(vBookingDate!= "" && vBookingDate != null)
code review
reconsider null is compared as string than null object\nif(vflightDate!= "" && vflightDate != 'null')
code review
reconsider null is compared as string than null object\nif(vProcessDate != "" && vProcessDate !='null')
code review
reconsider null is compared as string than null object\nif(vTrnsdate != "" && vTrnsdate != 'null')
code review
reassigning can be avoided using direct call like\n oJoinDt = new Date( Inputs.GetProperty("QntsDateofJoining"));
code review
deinitialize in finally block
code review
recheck  sPromopoint is not using anywhere. If not required, this line can be commented
code review
Global variables are used. May required some of the important variable to be reinitialize here
code review
Not used any where, can be removed or commented
code review
Not used any where, can be removed or commented
code review
Return directly value where asigning to temporary variable
code review
Change statement with log statement
code review
Try to minimize the cyclomatic complexity
code review
Change with StringBuffer append
code review
Refactor the dead code
code review
Parameter binding should always be used for better performance.
code review
String concatenation should be avoided and use only StringBuilder or StringBuffer instead of String concatenation using (+) operator for better performance.
code review
Create this InputStream instance before instantiating the Properties and use the created instance. Also this InputStream should be closed in the finally block.
code review
If you didn't create instance of OutputStream, then you don't need to close it yourself. Here OutputStream is getting from response and web container are responsible to close it. But call flush() method to commit the response.
code review
InputStream class provides close() method. It should be invoked in the last.  It's very important to invoke in finally block, so it will be called even if an exception occurs.
code review
Change to instance variable or best define as local variable.
code review
Infinite while loop always avoided as it eats most of the CPU cycles. Code is not getting much advantage of the same and while loop can be removed with little modification of the code.
code review
This option enables caching of commonly allocated strings.
code review
Also, reduce the Logical Views for server side state saving to 10 initially. Monitor this value and increase the value as required\n<param-name>com.sun.faces.numberOfLogicalViews</param-name>\n<param-value>10</param-value>
code review
To understand the hibernate performance, configure this setting. \nhttp://raibledesigns.com/wiki/Wiki.jsp?page=HibernateJMX
code review
Recommended to use of hibernate 2nd level caching using EHCache. Second level cache stores entities between sessions and scope is SessionFactory. It tells cache provider how many objects it should store and when/why they should be invalidated.
code review
Avoid the use of unused import statements to prevent unwanted dependencies
code review
Avoid using printStackTrace(), use a logger call instead
code review
Use StringBuilder instead of StringBuffer. StringBuilder is faster than StringBuffer for strings concatenation.
code review
Remove/comment all unused local variables
redo log file member reside mount point
We recommend that  Redo log file members should be on different mount points
row lock contention
We recommend to analyze the application logic causing this issue.
query optimization
We recommend to analyze the usage of order by clause . Incase its not necessary it can excluded from the queries.
sga size optimization
We recommend to increase SGA value from 14336 Mb to 24576 Mb. But due to limitations on the hardware size we recommend to increase the SGA size to what ever max RBL can . Based on the further observations we will take a calf we we need to further increase the value.
exe level granular parallelization
We will keep recommending settings for global parallelization and exe level parallelization on a regular basis till we get rid of the sinusoidal cpu utililization .
flawed dispatching logic fibeeapplication
Currently the logic of distributing the requests between servers is done by a simple rule to check request ID as even or odd. This logic is flawed and we propose a flag based approach to distribute requests amongst 2 application servers for more even distribution .
long time bigger sol
We recommend to parallelize sols 0121, 0169, 0114,0117 for exe 4012 and  0121 , 0169 fo exe Asor5002 further to reduce time of running for these exe's.
long running latef job
Since jobs with lower prority(ADEMP -850) than Latef (prio 900) are non blocking in nature we can move up the Job to reduce the running time for the job in PSBKD batch job group .
code review
It should be started in a PROD mode.
configuration
Change thread stack size in /etc/system/limits/limits.conf to 1 MB from 10 MB.
configuration
Change the number of process and number of file descriptors to 64000
code review
Make MongoDB call once and store it locally.
code review
Make MongoDB call once and store it locally.
code review
Invoke logic from batch job rather than from front-end.
code review
Consider replacing Vector usages with the newer java.util.ArrayList if expensive thread-safe operations are not required.
code review
Remove unused StringBuffer objects from code.
code review
Add finally block in source and close all important resources inside it.
code review
Remove/Comment all System.out.print calls
code review
'Singleton objects are not synchronized. Non-thread safe singletons can result in bad state changes. In highly concurrent load, this will cause NullPointerException.\nReference: public static ComplexPreferences getComplexPreferences(Context context, String namePreferences, int mode)'
code review
Readahead value needs to be reduced to 32. Execute the below command to reduce and also add the same in rc.local file                                                                                 sudo blockdev --setra 32 <device>
code review
Do not check whether the refID in Favorite class is present in Edition collection. This will reduce one query per user to fetch all Editions from the collections.
code review
Use HashMap rather than Vector to search Ids. HashMap gives constant-time fetch.
code review
Set buffer size of 1 MB so that download can happen in much less time. Earlier it was taking few minutes to download single PDF. With above buffer size set, file is now getting downloaded in few seconds (35 MB PDF in less than 2 seconds).
code review
Move batch queue management to mysql database.
code review
Move nginx_cache folder to RAM disk (tmpfs mount point) so that Disk write will be avoided and cache will be picked up from RAM.\n\nAdd below line to nginx.conf:\nfastcgi_cache_path /dev/shm/nginx_cache levels=1:2 keys_zone=microcache:1000m max_size=90000m inactive=60m;\n\nCreate folder nginx_cache in /dev/shm
code review
Maintain seprate issue_today table which will contain issue details data for a given day's ingestion batch only. This will get rid of order by clause.
code review
Optimized code deployed on the Seco VM Nodes.
nodata
Selinux parameter needs to be changed from enforcing to disabled.
code review
All API's are changed to have PDO implemented for it to use prepared connection.
code review
The max_connection has been increased to 20000. The max_user_connection is reaching 1300 as of now. In the mixed load testing, with all scripts running together, the max_user_connection will be evaluated, and then the final max_connection parameter will be set.
code review
These tables were altered to InnoDB storage engine.
code review
Master Slave Tsung configuration was replaced with 2 physical servers firing independent transactions onto the API server with 15 VIP's each.
code review
Composite index created on userid and songid
code review
composite index created on userid and playlistname
code review
change socket code as following\n       Socket connection = null;\n       try {\n         connection = ....\n         ---------\n       }catch (IOException e) {}\n       finally {\n         try {\n           if (connection != null) connection.close(  );\n         }catch (IOException e) {}          \n       }\nAlso close BufferedReader in jsp sendrequest on line 19, BufferedWriter in PrimaryCC on line 296
code review
Java 1.5 provides java.util.concurrent package to provide thread pool. Also a sun recommended design for pool implementation has been shared with team.
code review
Ajax implemented application should be rigorously tested to deal with the idiosyncrasies of different browsers, platforms and usability issues. jQuery is lightweight  and plug-in based javascript framework and well known tools in building an efficient Ajax based application. As application is already using jQuery in application, so jQuery can be used in implementation of Ajax.
code review
Fix all these exception from Pramati log file (SERVER_TXTservermsg ). Ideally this file should be free from exception/error
code review
Keep all Ajax variables name different as following \n\nvar xmlHttpRelation;\nfunction relation(){\n  var input_val = document.getElementById("mainval").value;\n  if (typeof XMLHttpRequest != "undefined") {\n        xmlHttpRelation = new XMLHttpRequest();\n   ...\n\nvar xmlHttpCross;\nfunction cross_time(){\n  var input_val = document.getElementById("mainval").value;\n  if (typeof XMLHttpRequest != "undefined") {\n        xmlHttpCross = new XMLHttpRequest();
query optimization
Apply relevant oracle patch and review AWR Report
query optimization
Fix all queries for full table scan and analyze AWR report for these queries
query optimization
Fix read by other session
network latency
The primary database is possibly configured with a standby database. \nARCH wait on SENDREQ monitors the amount of time spent by all archiver processes to write the received redo to disk as well as open and close the remote archived redo logs, so optimization of the network needs to be done here, possibly in association with network administrators, and with network monitoring tools. After the network has been optimized the DBA team can perhaps see the results at the log and tracefile levels, or can modify appropriate parameters in Oracle configuration files, to further enhance the network.
query optimization
Full table scan has been observed in few queries, Need to fix these.
configuration
'The common components of the SGA are: \n(a) Data buffer cache - cache data and index blocks for faster access. \n(b) Shared pool - cache parsed SQL and PL/SQL statements. \n(c) Dictionary Cache - information about data dictionary objects. \n(d) Redo Log Buffer - committed transactions that are not yet written to the redo log files. \n(e) Java pool - caching parsed Java programs. \n(f) Streams pool - cache Oracle Streams objects. \n(g) Large pool - used for backups, UGAs, etc. \n\nWhen automatic shared memory management is enabled, Oracle will adjust the memory parameters dynamically on the fly. \nTo see currently allocated sizes at runtime, one can query the appropriate views.\nIf automatic Shared Memory Management is enabled, the sizes of the different SGA components are flexible and can adapt to the needs of a workload without requiring any additional configuration. The database automatically distributes the available memory among the various components as required, allowing the system to maximize the use of all available SGA memory. Oracle Database remembers the sizes of the automatically tuned components across instance shutdowns if you are using a server parameter file (SPFILE). As a result, the system does need to learn the characteristics of the workload again each time an instance is started. It can begin with information from the past instance and continue evaluating workload where it left off at the last shutdown.\nAgain, the default granule size of the particular version of Oracle one is using, plays an\nimportant role in SGA sizing policies.\nAll SGA components allocate and deallocate space in units of granules. Granule size is determined by total SGA size. \nOn most platforms, if the total SGA size is equal to or less than 1 GB, then granule size is 4 MB. For SGAs larger than 1 GB, granule size is 16 MB. Some platform dependencies may arise. For example, on 32-bit Windows NT, the granule size is 8 MB for SGAs larger than 1 GB. One can consult the operating system specific documentation for more details, or query the V$SGAINFO view to see the granule size that is being used by an instance. The same granule size is used for all components in the SGA.\nIf you specify a size for an SGA component that is not a multiple of granule size, the Oracle database will round the specified size up to the nearest multiple. For example, if the granule size is 4 MB and you specify DB_CACHE_SIZE as 10 MB, the database actually allocates 12 MB.\nIt may be a better practice to leave default values for the less important components of the SGA\nlike java_pool_size,large pool_size or streams_pool_size, unless your applications are using them substantially.\nFor instance, an increased value of java_pool_size will be justified in case of heavy java activity on the database.'
query optimization
Apply index based on aggregate function used in query
configuration
Need to do redo log deployment analysis
configuration
Please set this value to debug="false"
configuration
Please replace `Response.Redirect(strURL)` with `Response.Redirect(strURL, false)` , details are shared in the next sheet.
configuration
Please change the data type of variable `mailtable` from String to StringBuilder.
configuration
Index on tables Labeling_TermSheet, Labeling_Answers and Labeling_ClientMaster needs to be created. Index script is shared in the next sheet.
configuration
Integration of all schedulers into one common scheduler will help in solving the problem. Recommended Architecture is described in the next sheet.
query optimization
Please use configuration file to store the database schema name.
code review
Please enable security through configuration on the `UploadFiles` Folder, So that files cannot be accessible without Authentication.
code review
For case HtmlControls, `Disabled` property should be true.
code review
Please move `SortGrid` Method to common class and call them on all the pages.
code review
Please remove the Session["dtNonCIB"] assignment from the Method `GetDataSource`
code review
Code Refactoring is required to identify repeated code through out the application and move them to common shared methods. Please start this from top 15 pages, especially for Setting Response, Sort Grid, Excel/ CSV Download Functionality.
code review
Please implement session check in `Page_Load` Event of all the Pages.
code review
Please remove the delete command from the Procedure at Murex's end. Recommended Interface is shared in the next sheet.
response time high
Minify .css files to reduce size.
response time high
Please fine tune the query which searches for the first/last name text in the database . \nCurrently the text is searched with "like %text%"  syntax.\nWe recommend to used "like text%" . \nSpecifics have been discussed with the team .
response time high
Implement updates to query grids at the server side using libraries like Node.js
workflow delay
Change the value of batch size to 50.
workflow delay
Limit the call for DisabilityType to once.
workflow delay
Limit the call for pageimage.json to once.
response time high
Limit the call for ButtonActionMessages.json to once.
workflow delay
Limit the call for ButtonActionMessages.json to once.
workflow delay
Retrieve ViewExpeditionHelp.html when user clicks on expedition icon.
response time high
Call to FindDuplicateUser and GenerateUserName only when values in field are changed.
response time high
It is recommended to use just the UNION clause instead of union all with distinct.
response time high
Limit the call for ViewAwardDetails.html to once.
response time high
It is recommended to add a covering index for user id and password since password is never queried in isolation .
response time high
Avoid request for jquery.jqgrid.min.js in load event of Participant\MyDofeLevel page.
workflow delay
Avoid request for jquery.jqgrid.min.js in load event of Participant\ExpeditionSection page.
workflow delay
Limit the call for ViewAwardDetails.html to once.
workflow delay
Avoid request for jquery.jqgrid.min.js in load event of Participant\ViewEvidence page.
response time high
Limit the call for GetUserLocations to once.
response time high
Limit the call for GetParticipantList to once.
workflow delay
Limit the call for GetUserLocations to once.
response time high
It is recommended to use varchar instead of Nvarchar . Nvarchar is only needed for internationalization .
response time high
It is recommeded to switch to varchar(n)  if interntionalization is not needed and if needed switch to nvarchar(n) .
response time high
It is recommended to to use Int instead instead of BigInt if the data is known to not increase to mamoth proportions. Range for INT is 214 crore which we think is enough for most columns .
response time high
Limit calls for GetMenuOnSubmission to once.
response time high
Avoid call to DDLData.json in ParticipantProfile page if not needed.
workflow delay
Limit calls for InvitationStatus to once
response time high
Create the index on the required column . Existing index on User Award table can also be edited to include the new column .
response time high
Avoid call to GAP/GAPAllRegionsforYpTab in GAP/EventOverview page load event if not needed.
response time high
Create the index on the required column .
response time high
Limit call of bundles\GenericLocationFilter to once.
response time high
Avoid calling GetCommunicationSummary on click search event of LeaderShipRecorded/Physical.
response time high
Move google analytics script at the end of layout pages after page rendering.
workflow delay
Avoid call to AcontStatus in Participant/QueriedAwards if not needed.
response time high
Limit requests for ViewAwardDetails.html to once
response time high
Avoid call to AcontStatus in Participant/LeaderApproved if not needed.
response time high
Limit call for GetSubmenuOnPermission to once.
response time high
Limit the call for GetBasicUserInfo to once.
response time high
Limit the call for GetParticipantDetailforViewAward to once.
disk heavily use
Defragment all disks in the LOP production environment on a regular basis.
currently cpu ram utilization monitored scom business transaction
It is recommended to use APM Tools for Business Transactions monitoring.
currently 1 network card available production server
Usage of 2 Network Cards
currently hard disk utilization monitored
To capture Avg Disk Queue Length
currently method level reponse detail moinitored
To monitor LOP Application using APM Tool
machineconfig
'Thread pool settings in Machine.config\nMaxconnection 12* #CPUs\nMaxioThreads 100\nMaxWorkerThreads 100\nMinFreeThreads 88 * #CPUs\nMinLocalRequestFreeThreads 76 * #CPUs'
code optimization
For LOP Website and Bank Bazzar App, it is recommended to use Oracle Connection object in single file only, i.e inside the OracleHelper.cs file only.\nFor SMS App it is recommended to use OracleHelper class, so that the connection object is used only in single class only.
database connection closed
It is recommended to close the connection by use of [using  block] or in [finally method of the try, catch block].
inline query used
It is recommended to use store procedures instead of in-line queries.
return type dataset used maximum method
It is recommended to use return type as DataTable instead of return type as DataSet, wherever possible.
commandtypetext used instead commandtypestoredprocedure
It is recommended to use CommandType.StoreProcdeure where the SP are used for database purposes.
release webconfig configuration
It is recommended to set compilation debug="false" in the web.config of production environment.
throwing exception throw satement used variable name
It is recommended to use throw statement without specifying the original exception.
unused commented code found
It is recommended to remove un-used commented code.
single point failure
To avoid single point of failure, follow given below basic high level recommendations.\n1. All production servers should have at least 2 Network Interface Cards\n2. All Production servers should have same operating system version and build version.\n3. All production servers if virtualized then should be derived from different base server.
documentation
All Use Cases with concurrent users and average response document should be prepared from application knowledge point of view.
undersized buffer cache
Increase the size of buffer cache as it is showing undersize in AWR and in Buffer Pool Advisory\nIncrease the buffer cahche(Current 5G) to 10GB and also increase the SGA Max 14G and set SGA target 13G Current SGA is 7,472M
queryn9f97fs7zt38vn
Use index hint CS_USER.IND_OFFER_MST_ACT_FG, there is index on\ncolumn ACTIVE_FG on table CS_LB_OFFER_MASTER
queryn02kb5xfs00bmn
Create composite index on column CD_USER_CD and CD_REF_NO on\ntable LOP_CUST_DETAIL to avoid FTS
bundling script file done
Grouping of multiple script files in one single bundle.
image size compressed
It is recommeded to reduce the imge size.
image embeded style sheet
'It is recommended to embed image files in the Style Sheet. Note : Apply only to images less than 30 kb in size'
cache expiration header missing static file image script style sheet
It is recommeded to add Cache expiration header to static files for enabling caching
database server alert available
APM Tool should include alerts for Database servers
bottleneck disk measured
The parameter 'Avg Disk Queue Length' should be monitored on all the servers
ram utilization database server 1 10509054  maxing
Upgrade the Server RAM
query goin ft
Create index on \nColumn CBD_BATCH_ID\nAnd cbd_process_flag
query goin ft
Create index on \nColumn cam_ins_date\ncam_inst_code\n&\ncam_agnt_idon \nTable cms_agent_hist\n& stats are old \nThis avoid FTS
query consiming high cpu
Number of execution are very high around 11700 and rows \nProcessed are zero with CPU utilization reaching 60%\nNeed to check with Oracle
query goin ft
Create index on \nColumn CAP_INST_CODE,CAP_CUST_CODE,\nCAP_ACTIVE_DATE & CAP_ACCT_NO  on \nTable CMS_APPL_PAN\nThis avoid FTS also stats on table are very old \nSep 27, 2016 4:23:50 AM
query goin ft
Create index on column CBD_BATCH_ID on table \nCMS_BATCHUPLD_DETL .\nOr\nTry using any hint for a composite index \nPCMSPRD.IDX_INST_BATCH.\nTry it in Uat .\nThis will avoid FTS and reduce the Phisical reads
query goin ft
Create index on \nColumn CBD_BATCH_ID or use index\nHint in query to hit the indexes\nThis avoid FTS
query goin ft
Old Stats Jul 10, 2016 6:24:58 AM\nCreate index on \nColumn CXL_RRN\nThis avoid FTS
query goin ft
Create index on column CTL_INST_CODE on table \nCMS_TRAVLPURP_LMT_SUMMRY to avoid FTS on table.\nUse index hint PCMSPRD.IDX_CCM_ID_NUM1 on colum \nCCM_ID_NUMBER1 table CMS_CUST_MAST\n\nCreate composite index on column CTL_TRVLPURPOSE_CODE and \nCTL_INST_CODE to avoid FTS on table CMS_TRAVLPURP_LMT_DTLS
disabling unwanted operating system service
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
logging
It is recommended to use Log4j.debug for logging debug statements . These can then be turned off during production by keeping the logging levels as Warn/Error .
stream closed
It is recommended to close the Stream objects . It is also recommended to close all stream objects in finally block only
logger debug level set info
It is recommended to set the log level to debugging since this all information is used during debugging . Log level 'info' is used for highlighting the progress of the application .
use systemproperties
It is not recommended to use System.get/set property for storing global variables. Instead one global class with static getters should be used by reading all properties at startup time.
use stringbuffer
Its recommended to use StringBuilder instead of StringBuffer after careful evaluation of multithreadedness of the piece of Code Recommendations.
use string concatenation
It is recommended to use Stringbuilder instead of String class where there are lot of concatenations used . Stringbuffer can also be used in multithreaded environments
consuming exception
It is recommended to log / process an exception .
coding standard
It is recommended to derive bean class from serializable class
generic exception catching
It is recommended to catch specific exceptions e.g. Catch (FileNotFoundException e), SQLException etc
string literal
it is recommended to use String constants rather literals.
use third party jar
It is recocmmended to review this process time to time and after reading the release notes of latest version we should include latest jars into our library folder
run code findbugs
it is recommended to run findbugs with entire Codebase to address all unit level issues
string comparision constant
it is recommeded to take string constants as string final string and check constant.compare(string)
everytime new socket connection used
It is recommended to use HashMap of Sockets and use them as and when required
function header missing
It is recommended to use javadoc specifications for function headers so that dynamically help can be built and used for reference purposes
removal unwanted setter getters
it is recommended to check this carefully and provide only required getters/setters
removal commented code recommendation
It is recommended that commented Code Recommendations should not go into production Code Recommendationsbase.
usage checkstyle
It is recommended to prepare proper checkstyle for Code Recommendations formatting and use eclipse checkstyle feature for formatting the Code Recommendations
code commenting
It is recommended to put proper Code Recommendations comment so that any other developer can understand it
property file variable naming convention
it is recommended to use lower case in .properties file
organize import
it is recommended to run organise import command in eclipse
missing junit test case
it is recommended to write Junit test cases for each class for Unit Testing
removal main method
it is recommended to remove all main methods and make another name method
missing tostring  method
It is recommended to override toString() method for pretty print of object for debugging point of view
migration code recommendation latest java version
It is recommended to use java 1.7 or 1.8 for better performance
continuous integration
It is recommended to use jenkins or any other open continuous tools for build, unit test and deployment purposes
using single application configuration file
It is recommended to combine all properties configurations into one file and use it in entire application via one singleton application config class
use deprecated apis
It is recommended to use latest provided API of given third party jars
design
A POC needs to be carried out to on XML versus JSON messages to ascertain the overhead of XML over JSON.
code review
Redundant index songdetails_id needs to be dropped.
code review
Redundant index idx_user_song needs to be dropped.
code review
'"if" should be replaced by "else if" for $_GET[''category''] to optimize the code execution path.\nThe same is applicable for $_POST[''playlistid'']'
code review
A global file needs to be created which will be called from all php files.
code review
Duplicate check should be there in createplaylist.php file.
code review
t is recommended to add curl_close, this will close curl object and free up system resources.
code review
Use GraphicMagics for transoding server
code review
'Changes in the request made from the PHP-FPM server : Listen.backlog = 65535. This should be less than the maxsoconn value set at sysctl.conf file.'
code review
Changes in the sysctl.conf to make change in net.core.somaxconn value to 65536
code review
Changes in the sysctl.conf to make change in net.core.netdv_max_backlog value to 65536
code review
Remove duplicate songid from the where condition in the query
code review
Remove "use index (idx_comp_album)" and "use index (idx_comp_song)" from the query
code review
Index created on column userid
code review
Index created on column songid
code review
Index created on column songid
code review
Index created on column date
code review
Index created on column songid
code review
Composite index created on columns username and songid
code review
Change the API to GET requests, so that all the most accessed pages are served from the Nginx cache. For any like list demanded by the user, the redirected API can be called which can fetch the liked status from the DB.
code review
innodb_buffer_pool_size =20048M;\ninnodb_buffer_pool_instance=2;\ninnodb_log_file_size=256M;\ninnodb_log_buffer_size=16M;\ninnodb_flush_log_at_trx_commit=2;\ninnodb_thread_concurrency=800;\ninnodb_support_xa=0;\ninnodb_concurrency_ticket500;\ninnodb_commit_concurrency=0;\ninnodb_thread_sleep_delay=1;\ninnodb_adaptive_max_sleep_delay=100000
code review
40 Gbps network line will be required per server to cater to 1.2 lacs concurrent users.
code review
The spinning wheel movement should be reduced from 500 ms to 250 ms as all the pages on the backend are coming in less than 200 ms.
code review
Multi Threading replication process is supported in 5.7.3 and has been tested in Test server. Also, the updates happening on songdetails for counters of likes should be moved to cassandra. This will help in lesser incremental updates on Master DB, helping in lesser load at replication
code review
The Keep-alive-timeout parameter should be set as 15 for non streaming server and 30 for streaming server.
code review
Cluster of php-fpm needs to be created for scaling. 3 pools created. Refernces for the same is mapped in nginx.conf
code review
The communication (upstream/downstream) between Nginx and php-fpm should be socket based for higher scaling.
code review
This issue was happening because the persistent connections configured at the Client code, was receiving responses which was timing out. Thus, the persistent connection at the client code is done away with.
code review
'On Master DB :\nIn my.cnf : Change parameters\nmax_binlog_size =5M\ninnodb_flush_log_at_trx_commit=2\nOn Slave DB :\nsync_binlog =1\ninnodb_buffer_pool_load_at_startup=ON\ninnodb_buffer_pool_dump_at_shutdown=ON'
code review
Remove the for loop for userplaylist fetching and fetch image on a call of swipe.
thread contention ecsdalrepositorywebportalwebportalrepositorygetfamilydetails
NoData
query high response time
Create non-clustered index on jobtype and status columns of BatchJobs tables.
large volume hit static content
Enable browser side caching on application server. This will also result in bandwidth reduction for static contents on application server
large number 404 erros due broken link
Fix 404 errors due to broken links using below steps.\n- Search all instances of url mentioned in excel in application code.\n- Provide correct path for the missing resource"
thread contention ecscommonintegrationsavvionservicesavvionwrappergetassignedtasklistforpolicyendorsementflow
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
thread contention ecsdalrepositorystatusstatusservicerepositorygetclclaimstatus
Following should be checked for GetCLClaimStatus or GetALClaimStatus.\n1. remove sub query if IVRSCode field is not needed.\n2. If IVRSCode is required then fetch its value using another linq query instaed of fetching this in select section of same query.
use entityfunctionstruncatetime function table column
Apply  EntityFunctions.TruncateTime function on compare variables instead of table columns.
thread contention systemnetunsafenclnativemethods
NoData
thread contention dynamicclassbuildupecsblcommunicationcommunicationbl
The constructor of CommunicationBL expects around 27 class objects and simply assigns them to local variables. The user functions in class hardly need more then one class objects.\nNo need to pass all 27 class instances to constructor as this makes CommunicationBL class heavy instead of this the functions should read class variables as parameter if needed or create them inside functions only when required.
thread contention dynamicclassbuildupecsblmastermasterbl
The constructor of MasterBL expects around 53 class objects and assigns them to local variables. The user functions in class hardly need more then on class objects.\nNo need to pass all 53 class instances to constructor as this makes MasterBL class heavy instead functions should read class variables as parameter if needed or create them inside functions only when required.
thread contention ecsdalrepositoryclaimsclcasedetailsrepositorygetcldetails
Consider to modify query using joins instead of using includes.
default session limit wshttp request hcf service
Increase connection limit from current 20 to 30 in <System.Net> and session limit from current default 10 to 30 using below settings in web.config of HCF services.\n<behaviors> \n  <serviceBehaviors> \n    <behavior name="defaultServiceBehavior"> \n      <serviceThrottling maxConcurrentCalls="30" \n           maxConcurrentInstances="30"  maxConcurrentSessions="30"/> \n    </behavior>\n  </serviceBehaviors>\n</behaviors>\n\nIf this works fine then attempt to gradually increase limit upto 100.
thread contention ecsblsavvionreferencergiclhcswsserviceassignorkeeptask
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
thread contention ecsdalrepositoryclaimscldetailsrepositorygetcldetailsqueue
NoData
high response time login page
NoData
caching master table
Implement Database level caching using sql server notification by associating SQLDependency class with linq.
unused index database
Use below approach.\n1. For small tables Remove UnUsed indexes.\n2. For large tables optimize queries to utilize indexes or drop the indexes.
'24 hour analysis permon data eai app server hydeaibts02 hydeaibts03t1 counter physical disk idle time continously le 20  indicates physical disk heavily use '
Use fast disk for BizTalk Database System
disk heavily use
Defragment all disks in the BizTalk Server environment on a regular basis.
observed heavy ram utilization eai app server hydeaimom01 eai db server hydeaic01
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
currently cpu ram utilization monitored scom business transaction
It is recommended to use APM Tools for Business Transactions monitoring.
best practice
Daily ensuring successful completion of SQL Agent Job - Purging and Archiving of Tracking Data.
global configuration using razor view engine done
It is recommended to add below 2 lines in global.asax.cs in method Application_Start(), as application uses only RazorViewEngine :\nViewEngines.Engines.Clear();\nViewEngines.Engines.Add(new RazorViewEngine());
hyperlink edit detail delete index page view working
NoData
validation missing
It is recommended to do null checking.
method header comment missing
Its recommended to give Header Comments above all the Methods.
multiple class found single c file
It is recommended that one class should be present in a single file.
method header comment missing
Its recommended to give Header Comments above all the Methods.
deprecated feature
Need to remove these deprecated parameters if they are in use in any module.
incident dt 20112016 1930 2015 transaction getting declined reason code 251 incorrect authorization request cryptogram  99 authorization message expired
Currently the zipping process are done by cron jobs between 7.30 pm to 8.15 pm.It is recommended to shift the timings for zipping process to late night time so that during peak hours (9 am to 9 pm) the system resources can fully be utilized for iCards Online4 transactions purposes only.
observed icards online4 db server 21 around 130 active o service also requested o service data app server 51 63 feel 130 o service count icards online4 server higher side
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
found icards online4 alert alert dt 20170124 onlinereports21 usedsizeper actualvalue 900 thresholdvalue 800
Regularly remove unwanted data, logs from i-Cards Online4 Production Servers. We recommend to use APM Tool Forensic Feature.
per icards online4 performance report ram db server 21 highly utilized
'Current Hardware Up-gradation :  Purely based on RAM utilization, we need to increase the RAM for better performance. If it is not possible to increase the RAM then it is recommended to add one more DB Server.'
currently avg disk queue length parameter monitored apm tool
To capture Avg Disk Queue Length (avgqu -sz in Linux ) , (% wait in Solaris) in monitoring software.
best practice
Keep firmware, Logical Domains Manager, Solaris and Linux up to date.
workflow delay
Avoid call to AcontStatus in Participant/ApprovedAwards if not needed.
workflow delay
Limit call for GetSubmenuOnPermission to once.
response time high
Avoid call to GetCommunicationSummary if not needed
response time high
Avoid call to GetCommunicationSummary if not needed
response time high
Avoid call to GetCommunicationSummary if not needed
response time high
Limit the call for GetCommunicationSummary to once.
workflow delay
'Avoid calling "Select * from #UserResultTable order by id"  in stored procedure GetEmails_UsersbyName if not needed'
response time high
Avoid using Begin Transaction for select statements.
response time high
Avoid using Begin Transaction for select statements.
query optimization
The constants and hardcoded strings should be explicitly defined in correct case instead of applying upper function on them.
configuration
Allocate separate mount point for UNDO table space and create UNDO datafiles on those mount points.
query optimization
Create indexes on table MD_FX_RATE_REP for columns M_NUMERATOR, M_DENUMERAT
query optimization
Update query Q004 to Q0041 in  stored procedures PROC_TEMS1_DATAPROCESSING and PROC_TEMS1_DATAPROCESSING_OLD
query optimization
Update query Q005 to Q0051 in  stored procedure PROC_TEMS_FETCH_INTERFACE
query optimization
Update query Q006 to Q0061 in  stored procedure PROC_KPLUS_MUERX_EXP_TEMS and PROC_TEMS_MUREX_KPLUS_EXPO
query optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_ALL_CPTYLIMITSSUMMARY,TEMS_PROJ24DETAILS,TEMS_CPTYGRP,TEMS_PURPOSEWISE_SUMM,TEMS_REASONMASTER,TEMS_PENDING_CONF,TEMS_MANUALENTRY,TEMS_FAVOURITE_CPTYGRPID
query optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_TEMS1SETTL_UTILIZATION,TEMS_TEMS1SETTLE_UTIL_BUCKET,LIMITS_GLOBAL_TEMP_TEMS1
query optimization
Create indexes for column CPTYGRP_ID in tables  TEMS_CPTYLIMITDEALWISE_HIST,TEMS_CPTYLIMITCANCHARGES_HIST,TEMS_TEMSTAB_NOTIONAL
query optimization
Update query Q009 to Q0091  in  stored procedure CRM_PROC_INTERFACE. Query doesn't use any base table
query optimization
Create indexes on table TEMS_PURPOSEWISE_SUMM_HIST  for columns REPORTDATE
query optimization
Create indexes for column CPTYGRP_ID in tables LIMITS_DAILY_PPDETAILS,LIMITS_EXPOIMPO_VALIDTY
404 error
Create indexes for columns  CCY in table  NP_LEVEL_1_ASALIBG_EOD
404 error
Create functional indexes for columns  NTID in table  NP_LEVEL_2_ASAL_PEAK
404 error
Create functional indexes for columns  SDEALER and NTID in table  NP_LEVEL_3_ASAL_PEAK
404 error
Create indexes for columns  SDEALER in table  tableNP_PPR_LEVEL_1234
404 error
Create functional indexes for columns  SDEALER and NTID in table  table NP_LEVEL_2_ASAL_EOD_DOM
query optimization
Call Get_CRM_Country only once and assign values to both variables. I don't see any need of defining two variables here.  With this I am able to save 15 seconds on development server itself. On production saving will be of sevaral minutes.
query optimization
Replace delete commands with truncate commands in stored procedure CRM_EXPO_IMPORT_PROC_3. Also put commit after every insert. In development server I was able to about 2 minutes. In production it could be around 18 minutes about 75%.
query optimization
Replace delete commands with truncate commands in stored procedure PROC_NOOP_FILLSNAP
query optimization
Remove call to stored procedure PROC_NOOP_FILLSNAP from stored procedure proc_refresh_newpos
query optimization
Use truncate command instead of delete whereever whole data is deleted from the tables.
query optimization
Remove all trim functions and update referred table columns with trim  functions at beginning of stored procedure.
query optimization
Create functional index for column ntid in table np_level_1_asal_peak
query optimization
Create functional index for column Trim(CurrencyPairRic) in table RTS_GetMaturityRics
query optimization
Remove trunc function on Addedon field of RTS_MaturityMatrix table in all where clauses.
query optimization
Either use trim function in all comparisons or avoid using trim function and create normal index for fwhl_riccode to improve the performance. While inserting TRIM function is not used in select query and also during delete many places trim function is used for comparing column fwhl_riccode and many places not.
query optimization
Create index for FK_UM_UserID in table rts_User_GroupMapping2
query optimization
Create index for UM_LoginID in table RTS_UserMaster
query optimization
Create index for ApprovalId in table FX_BreachedDealsApproval
query optimization
Create index for DEALNO in table RTS_BREACHDEALS
query optimization
Create index for DEALNO in table RTS_MARGINBREACHDEALS
query optimization
Create index for IsActive in table RTS_BREACHDEALS
query optimization
Create functional index TRIM(UPPER(portfolio)) for table RTS_BREACHDEALS
query optimization
Avoid settings for temp tables where records gets deleted on any commit. This will allow to use truncate command freely where all records from tables needs to be deleted.
string used many class usage  operator
It is recommended to use Stringbuilder instead of String class where there are lot of concatenations used . Stringbuffer can also be used in multithreaded environments
observed exception consumed empty catch block
It is recommended to log / process an exception .
many warning shown unwanted variable function available code
it is recommended to run findbugs with entire Code Recommendationsbase to address all unit level issues
various property file used
It is recommended to combine all properties configurations into one file and use it in entire application via one singleton application config class
blocking socket apis used required separate thread handling different client
It is recommended to use Netty framework for Asynchronous client handling
unwanted import package seen many file
it is recommended to run organise import command in eclipse
java 16 used
It is recommended to use java 1.7 or 1.8 for better performance
jsp html java written
It is recommended to separate Java Code Recommendations in Java Bean so that it can be used by other jsp also and also for easy Code Recommendations maintainability
high io
POC to be created for evaluating frameworks with high IO capabilities like Netty. This will be essential if the Performance validation runs on the current architecture. Will need EAI to support NIO.
design
The entire re-design of the Code Recommendations should be carried out to make Code Recommendations more readable and maintainable. To start with Code Recommendations package and class structures can be re-designed so that duplicate/redundant Code Recommendations can be eliminated.  Following are the top areas to focus:\n1. Packages re-naming.\n2. Proper Code Recommendations commenting at various decision points required in entire Code Recommendations base for maintainability point of view\n3. Usage of checkstyle for Code Recommendations formatting for better understanding\n4. Removal of redundant Code Recommendations\n5. Removal of redundant third party jar files\n6. Usage of latest third party jars \n7.Addition of JavaDoc comments in entire Code Recommendations base so that proper documentation can be created for newcomers in the system and it is required for better understanding and maintainability
soa architecture used
"The back end services can choke this application if they don\u2019t perform,\ \ to avoid this issue we are proposing to create micro services for the back-end\ \ system to scale on-demand and improve resiliency. \\nSecondly, can CAR can remove\ \ certain functionality in case some backend services are not performing well or\ \ unavailable rather than choking the entire system."
custom approach used sftping file
Custom file uploading to sftp is written which can be standardized by using JSCH open source framework (http://www.jcraft.com/jsch/)
xsltxml used making report
We are proposing to use Jasper Framework for generating MIS Reports (https://sourceforge.net/projects/jasperreports/?source=typ_redirect)
automatic building tool used
It is recommended to use Maven or Ant build tool for automatic building and running the test cases.
unwanted service running production server
It is observed that unwanted services are running in production servers which should be stopped immediately and proper documentation should be maintained of required services for running the CAR application.\n\nAll Required Services should be checked in UAT Environment and accordingly enabling the these services in Production Environment and proper document should be prepared for this.\n\nAlert should be created in Appnomix for required services so that if anyone enable any unwanted service then support team should get an alert.
document updated per current infrastructure
We propose to regularly update all documents whenever new hardware or software is added to the application.
network parameter captured car application
'To capture Network Related Parameters :  It will help in the analysis of network utilization.\nWe recommend to use Riverbed tool for Network monitoring which currently available in ICICI.'
35 server required ram processing 2x load per analysing current baselining
It is recommended to increase RAM in 35 Server
nodata
Create index and test on column CC_STATUS need for table CARTBL_CUSTOMERS\nCreate composite  Index on with all three colum CC_NET_USER_ID, \nCC_STATUS and CC_FSID for table CARTBL_ACCESS_DETAILS \nVery old statistics on the tables and indexes
nodata
create index on columnn \nCFL_REG_STAT on table CARTBL_FEDID_LOOKUP
design
POC to be created for evaluating frameworks with high IO capabilities like Netty. This will be essential if the Performance validation runs on the current architecture. Will need EAI to support NIO.
design
Application static images and JS/ CSS files will be cached at web server.
design
Following are the top areas to focus for code re-structuring.\n1. Packages re-naming.\n2. Proper code commenting at various decision points required in entire code base for maintainability point of view\n3. Usage of check-style for code formatting for better understanding\n4. Removal of redundant code\n5. Removal of redundant third party jar files\n6. Usage of latest third party jars \n7.Addition of JavaDoc comments in entire code base so that proper documentation can be created for newcomers in the system and it is required for better understanding and maintainability\n8. JUnit Test cases of each class should be prepared for unit level testing\n9. Profiler reports should be prepared after running each use case in UAT environment for finding slow methods\n10. FindBugs should be used for unit level coding issues findings.
design
Axis 1.4 is an old framework for web services and now a days a lot of new web services framework are available which are much faster then Axis so we recommend to use Apache CXF or Spring WS Web services framework instead of using Axis because spring framework is already used in existing codebase.
coding guideline
Non Function Document (NFR) should be prepared for application\nbenchmarking for future performance testing. Template shared with pocket team for the same.
load testing
It is recommended to do load testing of Pocket application using HP Load Runner for better performance and high load testing and also capturing the benchmarking of application.
performance tuning system
It is recommended to do a performance tuning exercise for the system.
hardware cpu upgradation
It is recommended to upgrade these servers.
hardware disk upgradation
It is recommended to increase the Disk capacity on Production servers.
currently network related parameter monitored
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
currently hard disk utilization monitored
To capture Avg Disk Queue Length
observed unwanted operating system service enabled
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
update jvm heap memory setting
It is recommended to keep the same settings for JVM Heap Memory for parameters Xmx and Xms.
currently unwanted datalogs size removed automatically
Usage of APM Tool Forensic Feature
currently 1 network card available production server
Usage of 2 Network Cards
currently base server different pocket prooduction server
It is recommended that all Pockets Production servers if virtualized, should use different Base Server to avoid Single Point of Failure.
currently application inactive session monitored apm tool
It is recommended to add alerts in APM tool for monitoring inactive sessions.
high elapsed time  181fts
Create composite index on column CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID and funtional index CUSTOMER_TRANDATE \nor second option is remove to_date funtion from column CUSTOMER_TRANDATE and put it on right side of value and create once composite index CUSTOMER_TRANDATE,CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID before implementing on prod test on UAT
high elapsed time  109fts
Create index on column SECRET_TOKEN there is composite index on it in order to avoid the   Full table scan  and reduce the cost of the query. Table is ICICI_DIGIBANK_REGISTRATION  There is already an index on the user_id  column and the function in the where clause we should create a functional index on the column in order to avoid the   Full table scan  and reduce the cost of the query.
high elapsed time  164fts
Create composite index on CUSTID,REQCODE,RESPCODE and functional index on CAPTUREDATE or Remove to char funtion from column CAPTUREDATE and create one composite index on  CUSTID,REQCODE,RESPCODE ,CAPTUREDATE
high physical read due ft
Create composite index on column CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID and funtional index CUSTOMER_TRANDATE \nor second option is remove to_date funtion from column CUSTOMER_TRANDATE and put it on right side of value and create once composite index CUSTOMER_TRANDATE,CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID before implementing on prod test on UAT.
high physical read sue ft
Create composite index on column CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID and funtional index CUSTOMER_TRANDATE \nor second option is remove to_date funtion from column CUSTOMER_TRANDATE and put it on right side of value and create once composite index CUSTOMER_TRANDATE,CUSTOMER_TRANTYPE,CUSTOMER_TRANID and CUSTOMER_DEVICEID before implementing on prod test on UAT
high physical read sue ft
Create composite index on table icici_digibank_sa_towallet_log column custid and reqcode
high elapsed time  due ft
create index on column SECRET_TOKEN
high elapsed time  due ft
Create composite index on MOBILE_NUM and SECRET_TOKEN on table ICICI_DIGIBANK_REGISTRATION
high elapsed time  due ft
Create composite Index on Respcode  and Reqcode .We have already suggested creation of functional index on column CAPTUREDATE for sql_id 166p7jnmtv120
high elapsed time  due ft
Plan need to be check was not available on OEM
high elapsed time  due ft
Plan need to be check was not available on OEM
high elapsed cpu resource consumption
Check if the execution can be reduced from application team .
high elapsed cpu resource consumption
Check if the execution can be reduced from application team .
high elapsed cpu resource consumption
Check if the execution can be reduced from application team .
cuurently alert provided monitoring user wise transaction consumption limit
It is recommended to add alert in APM Tool for notifying expiration dates for user wise transactions consumption limit.
per pocket ppt report slide 44 rca incident dated 15072016 available change done vendor end documented
It is resolutions should be properly documented.
per pocket ppt report slide 45 incident dated 21102016 jvm parameter directly updated production environment without testing uat environment
It is recommended to test all JVM parameters in UAT environment and then accordingly make changes in the Production environments.
per pocket ppt report slide 47 incident dated 22122016 planned dr activity communicated respective team involved issue occurred
It is recommended to inform all the respective teams before performing planned DR activity.
per pocket ppt report slide 47 incident dated 23122016 issue occurred parameter configuration npci done beyond permissible limit
It is recommended to do properly documentation for all the parameters from NPCI and accordingly test in UAT environment and then in Production environment.
currently load balancer ubps system
Usage of Load Balancer
currently message queuing system used ubps system
Usage of Message Queuing System - We are proposing IBM WebSphere Message Queuing to avoid port to port manual connections in UBPS. Extended Architecture can also be used where two phase commit is used and MQ and Database is involved. (In Extended Archictecture message is deleted from MQ when it is persist in Database so there is no need of recovery if EA is used, it is widely used in Real Time Systems in large banks). We can either use Load Balancer or MQ but anyone is required to avoid manual interventions and also for high availablility of system.
currently found disk io read activity task going day time peak hour 10 3 pm ubps app server 213 214215216218 222 223
Timings for Disk IO Read Activity Tasks in UBPS App Servers -  Found no relation between current UBPS transactions and Disk IO Read Activity Tasks. So it is recommended to shift the Disk IO Read Activity Tasks from day time to night time.
'found ubps app server alert alert 1 ubps 215 usedsizeper actual value 81 threshold value 80 alert 2 ubps 213 usedsizeper actual value 81 threshold value 80 alert 3   ubps 216 usedsizeper  actual value 81  threshold value 80  '
Regularly remove unwanted data, logs from UBPS App Servers. We recommend to use APM Tool Forensic Feature.
currently avg disk queue length parameter monitored apm tool
To capture Avg Disk Queue Length (% wait in Solaris) in monitoring software.
currently produciton server using different base server
Usage of different Base Server - All UBPS Production Servers if virtualized, it should use different Base Server to avoid Single Point of Failure.
best practice
Keep firmware, Logical Domains Manager and Solaris up to date.
query 4mxkkxfd5cvjb
Gather the fresh stats on the table
high execution queriesndate 9th december 2016nna 3fxatuj5jdhzu nb fb4hvrd9g44sanc 1bhkm76p82uzdnd 2gzfkfv52rry0ne g9t2tuana15nn
Performnace Improvement
high cpu utilization
Core dump on LISVR to be analyzed.
performance
Message broker needs to be tuned for the required load. SoftwareAG to change the configuration as per the load.
query optimization
Q005 - This query is going for an FTS even though the Indexes are present on the search condition. Thiscontains an implicit data type conversion on\n  indexed column "USER_ID". This implicit data type conversion prevents the\n  optimizer from selecting indices on table "SSOADM"."SSO_RESOURCE_ACCESS_TBL".
query optimization
Drop the index if it is not required
nodata
If the changes in properties files are not expected to change very often then it is not necessary to load the file every time. The same ResourceBundle can be used across requests. It can be controlled through a Singleton
query optimization
The package needs to be tuned by Infosys. Any optimization in the package will reduce the time spent on the DB. \nProcedure - MIGADM.SP_ADDRESS_MIG_CHECK \nPACKAGE - MIGADM.PREVALIDATION_CATEGORY.SEARCHCATEGORY#2
query optimization
Removal of un-wanted logging. Currently all incomming messages, messages processed at ESB and response messages from Finacle and converted messages are stored in database. Recommended softwareag to remove all these unnecessary loggings and to keep the messages stored only in case there are any failures or timeouts.
configuration
NoData
query optimization
Concurrency in accessing the accounts could cause a lock on the account. The debit accounts for the failed transactions should be looked at, and if it is hitting the same account, the number of accounts should be increased.
query optimization
1. Reduce the no. of concurrent users from a single zone.\n2. Multiple zone codes, sol id combination for the same.\n3. Alternatively, the product vendor can look at the possibility of having a NOWAIT after update.
query optimization
Correct mapping of Schme Code and GL Sub Head Combination needs to be done. Infosys has to fix the issue of FIN_LISTVAL getting killed.
configuration
Napi error - W0205 encountered. The test is executed sucessfully if it is run for a single user, but fails during load(concurrency). Infosys needs to investigate from code, the reason for the exception encountered.
query optimization
1. Max value for this sequence can be set to higher in order to avoid such issues in future.\n        2. This also could be handled during EOD run (Finacle to confirm on this) in this case the data to be flushed out in the relevant table and reset the next value to 1.
configuration
1. NOSTRO/USD combination is notmaintained in SRGPM parameters because of which there are NAPI errors.\n2. General exception error are happening because of concurrency of data selection for the query mentioned. Need to have more data sets so that concurrency is avoided(the data accessed is shared with Priyadarshi), or Infosys can provide an alternative solution.
query optimization
"There are queries which are running on CNMA, not utilizing the index. Create\ \ index CRMUSER.IDX_ADDRESS_TEST on CRMUSER.ADDRESS(\u201CBANK_ID\u201D,\u201DORGKEY\u201D\ ,\u201DADDRESSCATEGORY\u201D)\\nAlso analyse the table after creating the index."
query optimization
Changes in the query to not include predicate in the query, as this will not use the index on addr_id.The procedure needs to be reviewed  to fix all such cases where wrong predicate is used.
configuration
Need to check with application logic behind running such queries concurrently. Also nowait can be appended to 'select for update' query to reduce row lock contention.
query optimization
a.            Increase freelists  of table & its indexes to 5 (no can be increased if event occurs again).  (using multiple free lists may cause some empty blocks to go unused, causing the segment to extend. Multiple free lists can be used to improve concurrent access, possibly at the expense of additional space used.)\n\nb.            Table & corresponding indexes can be moved to larger block size tablespace of 16K. The inserts would become faster.
configuration
The root cause of the performance issue is that there are lot of transaction on the frozen accounts which are going into entered state. Infosys will internally explore this further. If the transactions are posted for these frozen accounts without the need of proxy posting, there is a huge time and effort saved on this batch program which will lead to reduction of total TAT of the EOD process.
nodata
1)Create index on column CTA_FCRM_SR_NO on table CARTBL_TEMP_ACCOUNTS\n2) Create Index on CFPC_STATUS on table CARTBL_FILE_PRCS_CTRL\n3)Create index on CFCL_FILE_NAME on table CARTBL_FCRM_LINKING_LOG.\n4) Stats on the tables are old
response time high
Compress the javascripts and deploy only the compressed copy of javasctipt to the application server. Keep a copy of uncompressed source for any changes or CRs in future in Source control.
workflow delay
Change in design, if wait/notify can be used instead.
workflow delay
Provide index hint IDX_ACCTMAST_ACCTNUMBER for this query so that the database optimizer would pickup the index mentioned and would reduce the query execution time.\nAdd javascript validation to accept minimum of four to five characters from front end for performing this operation.
response time high
The application Design has to be changed to handle the report generation process to use minimal memory resources. \nFew recommendations are \n1. Persist the report on the disk and flush the report in chunks to disk in predefined size and append. Later provide the report to the user as a downloadable option.\n2. Perform the excel report generation in batches and append the report. This would reduce the memory foot print of reportgeneration process.
response time high
Remove all the debug insert into table C statements from the code base.
workflow delay
Disable the button at front end once the user clicks the button.
response time high
The hard coded values to be changed to bind variables
response time high
When only one row is expected as output , the orw num condition needs to be removed and any exception cases should be handled through exception handling
workflow delay
Insertion to these temporary debug tables to be removed or to be done using bind variables
workflow delay
All resources should be closed in finally block only.
workflow delay
All sockets should be closed in finally block only.
workflow delay
Use below notation:\nvar myArray = [];
response time high
Sessions responsible for high temp usage were identified, which were not running from application.
workflow delay
Need to pass bind variables in where clause instead of literals
workflow delay
Change the initrans of table to 10 and its indexes to 20
response time high
Need to pass bind variables in where clause instead of literals
response time high
Disable disk I/O pacing for redo log mount points. Currently redo logs are distributed over /FCRM101 & /fcrmdata01 mount points but /fcrmdata01 mount  point also contains datafiles, So we can disable I/O pacing for /FCRM101 mount point only & check the improvements. For better performance we   recommended to have redo logs & controlfiles on seperate mount points with disabled I/O pacing for them.
workflow delay
Cache for below sequences has been set to 3000\n1. ACTIVITYID \n2. AUDITID\n3. INTXNID\n4. INCIDENTID\n5. FORMOPTIONSINFOID
response time high
Below are the details of index creation \n1. BIZCENTERGROUP - IDX_GIDBIDISA\n2. INCIDENTS - IDX_LIDBIDGID\n3. OBJECT_CONFIG_DETAILS - IDX_OCD_ATTRNAME\n4. STEPMASTER -  IDX_STPMASTER_ID_SNO \n5. TEMPLATEINFO - IDX_TINFO_FUD\n6. INCIDENTS - IX_INCIDENTS_SERVICEREQTYPE\n7. INCIDENTS - IX_STOPPRBNKID
nodata
It is recommended to change the logging levels in production to Error and move all debug statements to logger.debug statements.
nodata
It is recommended to use StringBuilder in case multithreading is not required for the objects.
nodata
getAgeCountMI() needs to be verified and see what  PRC_INS_AGE_COUNT is doing.
nodata
Conditions need to be changed so that it does not need to go through multiple for loops for fetching the same result.
nodata
Data can be fetched once and stored in parameters and the same parameter values can be used in update statements instead of calculation separately each time.\n\nFor updates on similar filter critera, all sqls can be merged to one and all fields can be updated in one pass.\n\nSimilar for other updated statements as well
nodata
Recommended to create composite index on table T_SBI_MEMBER_DTLS_LOG with columns enddo_id and backup_flag. GENERALSYSTEM.T_SBI_MEMBER_DTLS_LOG ("ENDO_ID","BACKUP_FLAG")
nodata
Recommended to create composite index on table T_SBI_TRAVELLER_DTLS_LOG with columns enddo_id and backup_flag. GENERALSYSTEM.T_SBI_TRAVELLER_DTLS_LOG ("ENDO_ID","BACKUP_FLAG")
nodata
It is recommended to add parameters in a SQL query via pstmt.set("") methods for correct datatype and the datatype conversion at runtime will not be happened.
nodata
Recommended to use PreparedStatement.\nPrepared statements are much faster than Statement.
nodata
Recommended to use Batch Insert/ Batch Update of PreparedStatement for better performance.\nRecommended to use executeBatch() instead of executeUpdate().\nPerformance issue if you are try to insert many records, let say 1000 records, because every executeUpdate() will hit database once. For batch update process, it hits database when executeBatch() is called.
nodata
'Recommended not to use HashtableCacheProvider in production. As it does not release objects at all. Not even after a while. \nThis can be considered as a memory leak,\nsource of OutOfMemoryError,\nout of date : caches not aware of changes made to the persistent store by another application. Instead use EHCache.'
nodata
Recommended to use select NVL(MAX(A.PROCESS_ID),0) into V_MAX_PROCESS_ID instead of cursor.
nodata
It is recommended to remove the cursor C1,C2,C3 and use SELECT INTO to hold the vaules. First loop will be able to combine 4 SELECT statements into single SELECT statement and 2nd loop will be able to combine 3 SELECT statements into single SELECT statement for the  UPDATE.
'improper use stringequals  method '
Substitute calls to String.equals("") with calls to isEmpty(). String.equalsIgnoreCase("") is actually a bit slower than just an isEmpty() call.
older android api framework version 22 api level 8
We need to upgrade the current api to the minimum supported and acceptable android api version. This is also needed to implement recommendations 7 and 8.
multiple call demoxml load event reliancechildplanhtm
Ensure that request for demo.xml is sent once.
multiple call demoxml load event reliancelifeinsuranceguarantedmoneybackplanhtm
Ensure that request for demo.xml is sent once.
normal asmx web service file upload
Create a separate WCF svc service using wshttp binding and MTOM encoding for document upload and host it on a separate virtual directory running on separate worker process.
continuous logging debugging
Set configuration for mode of logging and perform logging based on configured logging mode.
caching android client
Set following seeting on each instance of webview control and test entire application on UAT.\nwebSettings.setAppCacheEnabled(true)\nwebSettings.setAppCacheMaxSize(4*1024*1024)\nwebSettings.setCacheMode(WebSettings.LOAD_CACHE_ELSE_NETWORK) \nwebSettings.setAppCachePath(path to the application cache files)
high fragmentation database
ReOrganize all indexes where Percent_Fragmentation is high.
use string concatenation
It is recommended to use Stringbuilder instead of String class where there are lot of concatentations used . Stringbuffer can also be used in multithreaded environments
unnecessary request rupeeforadianttf file relianceimmediateannuityhtm
Avoid request for rupee_foradian.ttf file if not needed
repeated request multiple static file loading reliancelifeinsurancesuperendowmentplanhtm
Repeated requests should be avoided for the static contents
multiple request source xml data file reliancelifeinsurancesmartpensionplansinglehtm
Avoid multiple calls to same source xml in same event.
hardcoded dynamic file name c txtfl across function commonfunctioncs
Use unique file names for the file to avoid conflict such as file name ending with session id or GUID. Create file in some temporary folder within virtual directory so that Network Service has access to it without any special privilege.
stream closed inside finally
It is recommended to add finally block in source file and close all important resources inside it. Finally block will guarantee to close all resources if any exceptions thrown
unnecessary request rupeeforadian font file incomeadvantagesolutionhtm
Avoid request for rupee_foradian font files if not needed
multiple request source xml data file reliancelifeinsurancesupermoneybackplanhtm
Avoid multiple calls to same source xml in same event.
unnecessary request rupeeforadian font file reliancelifeinsurancesupermoneybackplanhtm
Avoid request for rupee_foradian font files if not needed
multiple request demoxml data file load event reliancelifeinsurancesmartcashplusplanhtm
Multiple requests of demo.xml should be avoided in the same event.
multiple request source xml data file uliphtm
Avoid multiple calls to same source xml in same event.
unsafe string concatenation creating sql query
Recommend to pass values using sql parameters instead constructing query with string concatenation.
high table scan table input attributes mobilebi database
Create non clustered index on table Input _Attributes for columns PlanNo, Sequence, AttributeName and Type.
white flicker navigation screen android client
Recommended to set the background color of webview control to transparent to avoid any flickering effect during navigation.
repeated request multiple static file loading fixedsavings1htm
Repeated requests should be avoided for the static contents
multiple request demoxml data file load event securedretirementsolutionhtm
Multiple requests of demo.xml should be avoided in the same event.
multiple request source xml data file securedretirementsolutionhtm
Avoid multiple calls to same source xml in same event.
repeated request multiple static file loading securedretirementsolutionhtm
Repeated requests should be avoided for the static contents
unnecessary request rupeeforadian font file reliancelifeinsurancepayfiveplanhtm
Avoid request for rupee_foradian font files if not needed
wrong coding practice
Fix following throuout the android client code.\n- Avoid empty if statements\n- Avoid empty catch/finally blocks\n- Avoid printStackTrace(); \n- Avoid the use of unnecessary return statements\n- Avoid the use of unused import statements to prevent unwanted dependencies.
unnecessary code initializing str variable print command stored procedure getcashflownewplans
Avoid initializing variable @str and print command in stored procedures if not needed.
thread contention ecscommonintegrationsavvionservicesavvionwrappergetassignedtasklistforpolicyendorsementflow
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
use entityfunctionstruncatetime function table column
Apply  EntityFunctions.TruncateTime function on compare variables instead of table columns.
sqlid fq6xm94bbat78
The query  is  executed in the production database ,this can be fetched\n from the  fall back if presents
sqlid au4gfnrk20p8t
Need to understand the logic of the packages
sqlid 39q34gvpy14w6
Very old statistics on the tables and indexes
sqlid ft65jxtafjcaq
Will use of already existing function index index Avoid the FTS
sqlid acd5pdv7ystam
Need to fix the plans for the query as there are two plan check the appendix
sqlid 3abfvwa95p3yb
Check the execution of the query as there are zero rows processed\n even after 200,000 executions
sqlid au4gfnrk20p8t
The execution of the pakages ( begin exp_fileupd.FileUpdate; end;)
observed everytime data fetch call new socket connection madenexample xmlsenderjava custsegjava dcmscardblockjava many
It is recommended to use HashMap of Sockets and use them as and when required
observed heavy used custom buffer used seperated seperatornexample quickkillsjava  authenticationmbeanjava many
It is recommended instead of custom buffer use xml or json for faster parsing using standard frameworks like jaxb and json library
observed repetitive code recommendation used entire code recommendationsbase almost xxxmain type function type code recommendation used
It is recommended to put repetitive Code Recommendations into Utility class as static functions
observed old version jar used various third party tool
It is recocmmended to review this process time to time and after reading the release notes of latest version we should include latest jars into our library folder
observed many warning shown unwanted variable function available code recommendation
it is recommended to run findbugs with entire Code Recommendationsbase to address all unit level issues
observed error code recommendation used code recommendation hard code recommendationsdnexample debitcardaccountmbeanjava
it is recommended to use enumerator of error Code Recommendationss so that it can be addressed via using switch instead of if
observed utility class created closing various type stream used code recommendation
it is recommeneded to use these functions in finally block respectively
observed request new db connection created
It is recommeneded to use db pool for better performance
observed continuous integration used
It is recommended to use jenkins or any other open continuous tools for build, unit test and deployment purposes
observed various property file used
It is recommended to combine all properties configurations into one file and use it in entire application via one singleton application config class
observed mvc framework used code recommendation
It is recommended to use MVC Pattern in web application for better categorisation of Code Recommendations and for better maintanability
observed depericated api still use
It is recommended to use latest provided API of given third party jars
observed many code recommendation commented
It is recommended that commented Code Recommendations should not go into production Code Recommendationsbase.
observed java 16 used
It is recommended to use java 1.7 or 1.8 for better performance
since interaction source system happening via eai system eaiother system reconfigured provide server socket nonblocking io java nio netty etc
POC to be created for evaluating frameworks with high IO capabilities like Netty. This will be essential if the Performance validation runs on the current architecture. Will need EAI to support NIO.
proper hearbeat mechanism used either ping hb
Heart beat mechanism used for Weblogic cluster and Loadbalancer needs to be reviewed to ensure that it meets the performance and availability related NFRs.
observed soa approach used fetching data backend
The back end services can choke this application if they dont perform, to avoid this issue we are proposing to create microservices for the back-end system to scale on-demand and improve resiliency.\n\nSecondly, can IView remove certain functionality in case some backend services are not performing well or unavailable rather than choking the entire system.
sqlid  0bxpmgmr3w5c6
There is already an index on the user_id  column and the function in\n the where clause we should create a functional index on the column in order to avoid the  \nFull table scan  and reduce the cost of the query.
observed app server 45 110 o service active app server 46 110 o service active db server 102 25 o service active
Its recommended to enable only required OS services by cross checking in UAT environment. We also recommend to create alert in APM Tool for fixed number of services monitoring.
currently apm tool forensic feature used
Usage of APM Tool Forensic Feature
oracle database connection pooling
set following keys in oracle connectionstring\nConnection Lifetime 0\nEnlist 'true'\nMax Pool Size 100\nMin Pool Size 0\nPooling 'true'
unused coding found
It is recommended to remove un-used code.
parameter index wrongly assigned
It is recommended to give index 3 in the variable arrParameter.
found hard coded value file
It is recommended that wherever possible to set hard coded values in the config files and then read the data from config files wherever needed.
unit test project present solution
It is recommended to add Unit Test Projects which should have unit tests for all important class files and use cases.
string variable checked null value
It is recommended to use string.IsNullOrEmpty(string variable name) rather than (sring varaible != null)
getting value session viewstate variable session variablename tostring viewstate   variablename   tostring   used
It is recommended to use Convert.ToString(Session["variablename"]) instead of .ToString()  and  Convert.ToString(ViewState["variablename"]) instead of .ToString()
method header comment missing
It is recommended to use Method header comments.
unused class using statement found
It is recommended to remove un-used using statements
class method 5 input parameter using seperate class file input parameter
The class methods with more than 5 input parameters should use seperate class file as input parameter
dr fallback server available lop application
It is recommended to setup separate Disaster Recovery and Fallback Systems for LOP for availability and scalability point of view.
lop application using net 40 version old version new feature available newer version net
It is recommended to migrate LOP Application code to latest .Net Version 4.5 for better performance improvements.
logging
For audit trail, the asynchronous logging needs to be looked at rather than current blocking based logging. Log4Net can be used for this purpose. By default Log4net is synchronous but by overriding its appender interface asynchronous logging feature can be achieved.
query optimization
Infosys to investigate the issue
configuration
Identify connection leak from livsvr processes , since DB has defined parameter to 2000, which worked fine in earlier tests with 10K users
nodata
The SAF Replay needs to be reconfigured to use parallelization even with hash number configuration.
design
Same java script files are referenced multiple times in the same jsp files.\nMod_exprires needs to be enabled on I H S servers and a far longer expiry time needs to specified for static files.
observed high number thread configured container generalnguidelines ibm set number number cpu 5 using math number wasncontainer thread configured high also observed thread dump aix commandsnthat given time close 90 thread idle
Number of threads configured for WAS container should be reduced . This will help WAS manage\nincoming requests in lesser of threads\nAs a starting point max number of WAS container threads were reduced from 200 to 100 .\nPost this change it was observed that even with lesser threads the response time was unchanged and\nWAS was managing incoming requests in roughly half the number of threads .
'logic us heavy regex processing matching based expression without using pattern compile inefficient incur compilation cost time parsingnexample hlifeworkspacehlifemodotcsrccomhlifeotcbizotcvalidatefilebizprocessorjava method getrequestobject nregex used many place flow '
Current Code:\nif(cellVal.matches("([a-zA-Z]){3}\\s([a-zA-Z]){3}\\s([0-9]){2}\\s(\\d\\d:\\d\\d:\\d\\d)\\s[a-zA-Z]{3}\\s(\\d){4}")))\n\nRecommended code:\nPatern pattern = Pattern.compile(regexPattern); //Do this once in a static code block so that compilation happens only once.\nMatcher matcher = pattern.matcher(value)\nif(matcher.matches)
'method private jsonobject formatrequestobj jsonobject reqobj throw jsonexception sort unnecessary array built using ben id generated loop already ordered state ncollectionssort proddtlsarray ncollectionssort borrowerarray  ncollectionssort  benarray  '
Collections.sort needs to be remove from the places where data is already sort while creation.
'logging concatenated string guarded isdebugenabled check unnecessarily incur cost string conatenation put burden gc '
Debug logging that involves string concatenation should be guarded with isDebugEnabled() checks. The framework class AppLog needs to have methods like isDebugEnabled\isInfoEnabled etc to be used as a guard before logging string concatenated (or any expensive operation) log messsages.
stringindexof string used actual indexing character rather string relatively slower operation
Use String.indexOf(Char). This is relatively faster than indexing against a String.
'call collection s size mehtod used check emptiness le performant '
Substitute calls to size() == 0 (or size() != 0, size() > 0, size() < 1) with calls to isEmpty() or ! isEmpty().
multiple update select query going ft sraudittable high cost causing high execution time ndetails mentioned sql sheet
We suggest to create index on table SR_AUDIT_TRIAL with column SR_NO.
'detailed observation n1 logging invoke method otcvalidatefilebizprocessor class found calling invoke log hslotcpar2 1060628n2 logging invoke method otcvalidatefilebizprocessor class found calling invoke log hslotcpar1 1060627n3 last trace otcvalidatefilebizprocessorinvoke method log hslotcpar2 1060628 found 06sep2017nnthese observation indicates following n1 invoke method otcvalidatefilebizprocessor class working hslotcpar2  1060628 subsequent attempt file got processed hslotcpar1  1060627 '
Please verify deployment/configuration of JMS MessageListener (BulkFileProcessingBean) on Partner App Server 28. Or at least try to restart the listener service.
uneven soa cpu utilization
"Change load balancer scheduling algorithm to \u2018Cyclic\u2019"
source code package included project source code avoided unless change implemented librariesncomsunmailhandlers comsunmailimap comsunmailimapprotocol comsunmailpop3 comsunmailsmtp comsunmailutil class decompiled included source list
NoData
currently xml used transferring data different component system data sent json would huge impact performance perspective json commonly used adopted technology size data sent using json much smaller xml
Replacing JSON instead of XML
currently response time mwi home page le 3 second accessed anywhere india reduced implementing front end optimization technique
Front End Optimization for MWI component continued..
'table trndetails data type column trnrefnum char 25 due additional space coming stored data avoid ltrim rtrim used everywhere query stored procedure  operation resource intensive '
Data type of column "TRnRefNum" of table "TrnDetails" needs to be changed to varchar(25). Additional space characters should be removed one time by an update query.\n\nLTRIM and RTRIM needs to be removed from the queries and stored procedures.
observed query running database high elapsed time due inadequate index
We suggest to create index on trnDetails table with  EnteredDt, Status,Valuedate column with include Amount column.
'intermittently found select query high elapsed time '
We suggest to use 'NOLOCK' in select * into query syntax.
observed query running idspfilelevelauth procedure going ft temp table
It is suggested to create index on '#tblTmpTrnDetails' table with TrnRefNum column.
'observed entereddt converted varchar used condition query operation resource intensivenncurrent code nconvert varchar 10 entereddt120  20171201 '
Input value should be converted to date before calling the procedure.\n\nCode should be:\nentereddt >= '2017-12-01 00:00:00'
observed query running procedure bcspvalidatelimit high elapsed time due inadequate index
We suggest to create index on Det_FinYearRefNo table with  CustRefNum, CustomerID column. This index is not present in the UAT Database but it is available on Production Database.
observed query running procedure bcsplimitrecheck high elapsed time due inadequate index
We suggest to create index on svc_stg_txn table with  customerid,reserve5,trn_status column.
attached unused index list indusdirect database
We suggest you to monitor the usage of the mentioned indexes and drop the unused indexes.
string variable used inside loop use string variable inside loop resource intensive performance impact complete list instance code shared string optimization sheet
String varaible needs to be replaced by StringBuilder DataType. And should be disposed after use.
error violation unique key observed insert query procedure bbpsfetchbillrequest load bill payment
It is recommended to insert unique id such as SPID or GUID on column "Req_RefNo" instead of NULL value.
observed query running table transactiontypecustomerlink going ft procedure svcspprocesstxn
We suggest to create index on column custId with transactiontype_customer_link table.
'observed entereddt converted varchar used condition query operation resource intensivenncurrent code nconvert varchar 10 entereddt120  20180129 '
Comparision in date-time fields should be used using operators such as >=, <=, between.\n\nCode should be:\nEnteredDt >= '2018-01-29 00:00:00.000' AND EnteredDt <= '2018-01-29 23:59:59.999'
head section retailsignonjsp snippet
The code was removed from the jsp which removed the delay of downloading the capicom.cab file and octget.dll from different Microsoft mirror sites. SignonScript.js was an external Javascript file which had functionalities for CAPICOM, this javascript was also removed for this fix.
deviceprintjsp used functionality nthe retaillogin page resource intensive ninline javascript blocking page rendering
This jsp was excluded from the Retail Login Page as this snippet was for supporting RSA and IndusInd E-Banking solution is not using RSA. Hence the blockage of rendering caused by this javascript was completely removed
bank reported retail login page take close 15 minute ndelay first access day
The issue was studied from all layers, All networking components were studied using \ntracert to see if the issue is with any of the components in the network. The \nRoot cause analysis uncovered that the virus scan is causing the delay as \nFinEcEcApplet.jar which is the applet used for retail login forces McAfee OnAccess \nscan to scan even the base class files and archive files in class path which ended up in \n1.5 minutes of delay in Response of Retail Login Page access for first time. Discussion \nwith Infosys product team and architecture team was done and a solution which \nwould exclude the applet was provided which solved the 1.5 minutes of response \ntime issue completely
header setting webserver setup properly handle static ncontent caching
Header was enabled in IBMHTTP server to add a far date for expiration for static \ncontent served for internet banking application
memory error
By setting JAVA parameters we can avoid this memory error and application restart will be avoided. Which is the case currently in every 2-3 days
automation rejection code
Automation of some rejection code is suggested. By atomizing below rejection codes we can reduce the manual intervention by 30%. Which will also helpful to less manual intervention when transactions increased.\nBelow Error codes can be removed and clearance directly rejected.\nNo such account.\nAccount closed or transferred.\nA/C Inactive.\nKYC documents pending.\nDormant account.\nAccount holder expire.
connection pooling observed
Use pooled connection. A pooled connection instance represents a single physical connection to a database, remaining open during use by a series of logical connection instances. \nThis will improve the time to connect to database and also execution time of queries will improve by 20%
connection made connect 24 closed inside finally block
Introduce finally block and close connection inside it. This will guarantee all the resources get released in case if there is any exception occurred and program control not reached the close statement inside try block.
'synchronized block inside finally block object lbatchfilebeannnsynchronized lbatchfilebean n long lsuccessrecordcount lbatchfilebeanaddandgetsucessrecordcount lsuccesscount n long lerrorrecordcount lbatchfilebeanaddandgeterrorrecordcount lerrorcount n long lprocessedrecordcount lsuccessrecordcount lerrorrecordcount n lbatchfilebeangettotalcount longvalue lprocessedrecordcount n batchfilebeanstatussuccesslongequals lbatchfilebeangetstatus n lbatchfilebeansetsuccesscount lsuccessrecordcount n lbatchfilebeanseterrorcount lerrorrecordcount n lbatchfilebeansetstatus batchfilebeanstatussuccesslong n lbatchfilebeansetendtime new timestamp systemcurrenttimemillis n batchfiledaoupdateusingprepared connection lbatchfilebean n connectioncommit n loggerinfo  n loggerinfo   processed batch number   lbatchfilebeangetbatchnumber     success   n  lbatchfilebeangetsuccesscount     error    lbatchfilebeangeterrorcount     n loggerinfo                                              n  n '
Since the IBatchFileBean object has a local scope and is eventually picked up from a queue.poll() call, there is no way more than 1 thread will access this object. Hence the synchronization is not needed in this case. Remove this synchronized block.
observed one query running high execution count cmpanno column used twice condition column different value query give output
Please check from your end the requirement of this query. If this query is not required then we can eliminate this query which is consuming the unnecessary resources.\nOr We can remove the duplicate condition.
nodata
Enable this job along with any other strategy of stats gather as it runs on non-peak hours(10pm from mon to fri ; 6pm on sat & sun) and gather stats for only those objects which have stale statistics. Regular gathering of statistics is helpful for overall db performance
nodata
Approximately 50 to 100 record sets are opening and closing while the application is logging in. it needs to be as minimum as possible.
nodata
Use same login connection to complete the login steps
nodata
MaxConcurrentRequestsPerCPU set 0\nHKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\ASP.NET\2.0.50727.0 \n\n%windir%\Microsoft.NET\Framework64\v2.0.50727\aspnet.config\n\nNeed to add the following section under "configuration" section (here I used default values) - don't forget change maxConcurrentRequestsPerCPU to 5000.\n\n< system.web>\n    < applicationPool \n        maxConcurrentRequestsPerCPU="12" \n        maxConcurrentThreadsPerCPU="0" \n        requestQueueLimit="5000" />\n< /system.web>
nodata
NoData
nodata
NoData
nodata
NoData
nodata
"1. \u201CuspMergeClients_maker\u201D procedure needs to be improved to\ \ gain the performance of the application.\\n2. Use  client side validation"
nodata
"1. Implement application caching for lookup data.\\n2. Avoid nested table\ \ tags\\n3. Use more on div\\n4. Avoid Server side validation\\n5. Use JQuery to\ \ validate the client side.\\n6. Improvement required on \u201CAddCall\u201D function.\ \ ~20 parameters are required, can move to stored procedure, this can ease the fetch\ \ calls used for 'AddCall' and improve on insert."
overall response time entire si component bad
After monitoring connections made between SI & STUB, identified that only 1 connection is made. Recommended to make config changes to make multiple connections
hard coded input value used causing recursive sql againt data dictionary
No Hard Coded values should be used in the query.
maximum open cursor exceeded
There should not be ORA-01000 error in the alert log file.
query execution time high indexe missing
NoData
memory leak identified application server
"Bypass Stateless api\u2019s to avoid memory leak."
connection pooling implemented redis
Recommended to  implement the connection pooling on redis.
high availability
"Horizontally scale the JVM\u2019s i.e. add more number of JVM components\ \ to sustain the load on both application server 1 and application server 2.\\nMove\ \ Money2India database to a different base machine."
high availability
Currently XML is used for transferring data to different components in the system. Data when sent as JSON would have huge impact from performance perspective. JSON is now commonly used and adopted by all technologies. The size of the data sent using JSON is much smaller than that by XML
high availability
Currently Payment Gateway uses EJB2.1, Upgrading EJB 2.1 to EJB will improve performance
high availability
Combine images to image maps or sprites.\nCompress html, css and Javascript used in MWI pages\nCombine all Javascript files to a single file\nEnable cache at webserver for far expiry date for static content like images, javascript and css files.\nConfigure E-tags which would improve performance of the static resource rendering for some of the browsers used by the merchants.
high availability
"Currently the JDK version used is 4. JDK has improved over the time with\ \ performance and functional capabilities\\nLots of external api\u2019s and libraries\ \ are used in Payment Gateway currently. Newer versions of JDK has these integrated\ \ and normalized for performance. Using the latest JDK would improve performance"
limited allocated storage space application server
It is recommeded to allocate enough space for Application server. Also a log moving/shipping policy/cron to be in place to move logs to a drive where space isnt a constraint . Above this we also recommend to keep alerts for Storage utilization of the application server so that action can be taken before full utilization
jasper report consuming memory
It is recommended to update Jasper report version from 3.0 to 6.x .
jasper report consuming memory
We recommend use of Jasper Virtualization feature . Either JRGzipVirtualizer  or JRSwapFileVirtualizer  can be used for Virtualization\nMore information can be found at http://jasperreports.sourceforge.net/sample.reference/virtualizer/
non pact impact
We recommend performance analysis of the other applications that are sharing the environment with PACT since sub-optimal tenant applications can impact performance levels of the over-all system
uneven node hit
We recommend to find out the root cause of this behavior and take correct actions (change of settings / taking up with SAP).
application availability one server
We recommend to review the settings for this behavior since this is not an expected behavior. We expect the CI/Web dispatcher to continue working even if one node/server is down . \nWe recommend to to find the root cause of this behavior and take correct actions (change of settings / taking up with SAP)
slowness application due sudden load various interface
Use following approach to resolve this.\n1. Assign more connections using <system.net> configuration in web.config of HCS services application to ips of interfaces dedicated for various services to avoid slowness in web request processing.\n\nOr\n2. Divide logically services across multiple worker processes to avoid slowness due sudden rise of load from any of the interface.
thread contention ecsdalrepositoryglobalsearchclsearchrepositorygetcldetailcount
Following should be checked to make GetCLDetailCount query faster.\n1. Remove EntityFuctions.TruncateTime from table columns.\n2. In select section just one column is enough.\n3. GroupBy clause is unnecessary as just count is needed.
thread contention ecsblsavvionreferencergiclhcswsserviceupdateandcompleteclflowtask
The thread is waiting for Savvion web service which is a third party tool used in HCS for workflow. The same is shared with multiple applications along with HCS. Team needs to check on below areas.\n1. Network speed.\n2. Identification of performance issues in Savvlon web service.
thread contention ecsdalrepositoryglobalsearchalsearchrepositorygetaldetailscount
Following should be checked to make GetALDetailCount query faster.\n1. Remove EntityFuctions.TruncateTime from table columns.\n2. In select section just one column is enough.\n3. GroupBy clause is unnecessary as just count is needed.\n4. Review Query if same logic can be accomplished with less number of joins
thread contention ecsdalrepositoryclaimsclcasedetailsrepositorygetcldetails
Consider to modify query using joins instead of using includes.
thread contention constructor dynamicclassbuildupecsblblclaimsclinwarddetailsbl
The required objects should be passed into functions as parameter instead of initializig them in constructor.
default session limit wshttp request hcf service
Increase connection limit from current 20 to 30 in <System.Net> and session limit from current default 10 to 30 using below settings in web.config of HCF services.\n<behaviors> \n  <serviceBehaviors> \n    <behavior name="defaultServiceBehavior"> \n      <serviceThrottling maxConcurrentCalls="30" \n           maxConcurrentInstances="30"  maxConcurrentSessions="30"/> \n    </behavior>\n  </serviceBehaviors>\n</behaviors>\n\nIf this works fine then attempt to gradually increase limit upto 100.
thread contention ecsdalrepositoryclaimscldetailsrepositorygetcldetailsqueue
NoData
high response time login page
NoData
unused index database
Use below approach.\n1. For small tables Remove UnUsed indexes.\n2. For large tables optimize queries to utilize indexes or drop the indexes.
dynamic compression setting configuration smartzone app server withouout dynamic server role component installed
Disable the dynamic content compression in web.config.
unnecessary retrieval agent score card detail getscorecard action method
Change logic to just retrive required rows from DashboardDWHClient in GenericScoreCardDetails function.
unnecessary parameter lastupdated getgenericscorecarddetails
Change procedure to remove parameter LastUpdated if not needed.
unnecessary code remove  character user name getuserid loginmodelcs
Remove the code to remove "\\" character if not needed.
late rendering bundlesmotorquote irpascss static file motorpartialquoteproducttypes
Place all render commands and reference of static files together on the top of the pages to download them quickly.
compression failure due content scan firewall
Add production servers IP to rule on firewall that excludes added servers from content scan.
repeated request several static bundle resource load event motorpartialquoteproductypes
Avoid repeated requests for same static resources in same the same event.
unnecessary request action method mastergetvehiclemakemodelvariancecc user key input motorquotecshtml
Avoid sending request on each key input instead use below logic to send request when user stops typing. \n1. On each key input on autocomplete control initialie the timer for 1 seconds. The timer will call the function at the end which is responsible for sending request for Master/GetVehicleMakeModelVarianceCC.\n2. On subsequent inputs if timer is already initialied then reinitialize it.\nRefer to below link.\n http://stackoverflow.com/questions/4220126/run-javascript-function-when-user-finishes-typing-instead-of-on-key-up
high response time form authentication
Avoid forms authentication if not needed and persist the userid instead of retrieving from database each time.
multiple request file webrupeev20ttf saving proposal page motormotor
Avoid multiple calls for a static resources in same event.
multiple request bundlesirpasscript1 bundlesirpasscript2 user click travel individual link
Avoid multiple calls for a static resources in same event.
unnecessary overwriting xml file xmlfilesagentretention v14xml xsd schema file xmlfilesagentretention v14xsd agentretentiondetails function
Keep the pre-generated xml file and load xmldocument directly from xml file without dynamically generating it from xsd file every time.
multiple request getuserid request
Avoidmultiple requests for userid by persisting user id at session level or at request level
multiple request contentirpasscript1 contentirpasscript2
Avoid multiple requests for static resources in single event.
unnecessary call function checkforaddressequality savemotor function
Update values of filledaddress instead of fillableaddress or avoid calling method checkForAddressEquality if not needed
unnecessary query initialize variable dbcovers fillcoversforsave function
Avoid query to initialize variable dbCovers if not needed.
unnecessary call function getproductid set value variable productid function savemotor
Avoid calling GetProductid method to set variable productid if not needed.
unnecessary query lstdetails set variable quoteres fetchidv function
Check the missing code to set value for strDetails or remove entire code for setting objPolicy.isMotorQuote.
unnecessary query homegetproposalinfo method set several property variable obj type rpaslogin proposaldetails proposalstatusid value 12
Perform check for the value of valid ProposalStatusId at the beginning of for loop  followed by  checks for ProposalStageStatusId to avoid several unnecessary queries on tables tblpolicy and tblMasProducts before setting properties of RPASLogin object.
unnecessary call action method riskdetailsread loading healthwisehealthwise
Avoid request for action method RiskDetails_Read if not needed
unnecessary query fetch paidpolicies method getclientcartdetails
Avoid query to set value for paidPolicies if not needed
failure dynamic compression json response
Install IIS administration pack on app server and follow steps mentioned in below url.\nhttp://stackoverflow.com/questions/17321131/compression-filter-for-web-api/17331627#17331627
unnecessary query user table fetch userid instead using getuserid function
Avoid fetching userid from database instead call getuserid function.
low disk space
'Increase disk space on d: to atleast by 20 GB.'
logout session expiry
Handle session expiry gracefully on each controller and redirect user to login page.
unnecessary call function loginmodelgetusername initialie local valiable
Avoid intialiing variable currentUserName if not needed.
frequent app pool restart due error application set value failover protection
Change failover protection configuration of iRPAS app pool to avoid frequent restart.
unnecessary join table subagentname method getpolicyseastar class seastarlogic
Avoid oin on table SubAgentName to optimize the query cost.
unnecessary join table tblpolicymarineextns method getpolicyseastar class seastarlogic
Avoid oin on table tblPolicyMarineExtns to optimize the query cost.
high cost query store procedure uspgetexshowroompricewebsite
Create index with below command.\nCreate nonclustered index IDX_NAME on mom.tblmasmodel(veh_type_id_fk, model_arc) include (model_id_pk,make_id_fk,model_name,variance,CC)
multiple request watchas3swf page load homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request initstringsjs page load carinsuranceaspx
Avoid multiple requests for the static resources in the same event.
multiple request scriptresourcevxd clicked get quote button homeaspx
Avoid multiple requests for the static resources in the same event.
multiple request conversionasyncjs page load twowheelerinsuranceaspx
Avoid multiple requests for the static resources in the same event.
multiple request initstringsjs page load twowheelerinsuranceaspx
Avoid multiple requests for the static resources in the same event.
repeated 401 error authenticateaspx edit formaspx allitemsaspx ii log
Remove any reference of these pages from website application and any other application regularly accessing the website resources.
unnecessary code execution responseredirect fillpolicydetails method quickquotetwowheelerascx
Exit function with return statement after response.redirect.
unnecessary code execution responseredirect fillpolicydetails method quickquotehealthascx
Exit function with return statement after response.redirect.
'location ldf current mdf partiition file drive dbwebsite database '
Put ldf file on a separate dedicated drive then the mdf files drive.
multiple request initstringsjs page load dashboardaspx
Avoid multiple requests for the static resources in the same event.
multiple request stringsjs page load dashboardaspx
Avoid multiple requests for the static resources in the same event.
multiple request jqueryuimincss file page load dashboardaspx
Avoid multiple requests for the static resources in the same event.
slow content download content delivery network cdn
Review and consider moving all static contents on cdn servers to reliance server for better and consistent performance.
static compression failing image
Add static type image/* in the httpcompression module of both web servers to enable compression for images.
multiple request analyticsjs page load carinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request conversionasyncjs page load carinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request 511169434rupeeforadianeot page load carinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
multiple request corejs page load carinsurancepremiumcalculationaspx
Avoid multiple requests for the static resources in the same event.
frequent slowness downloading http webengagecomblankhtm home page load
Review the need for the file and avoid downloading if not needed.
unnecessary code execution responseredirect fourwheeler method buyfourwheelerascxcs class
Add return statement after response.redirect.
unnecessary call registerstartupscript redirect populatepaymentobject method buyfwascxcs class
Avoid calling RegisterStartUpScript if not needed.
unnecessary code execution responseredirect generatefopurwheelerxml method buyfwascxcs class
Add return statement after response.redirect.
unnecessary code execution responseredirect bindpremiumbreakupxml method buyfwascxcs class
Add return statement after response.redirect.
unnecessary call registerstartupscript redirect bindpremiumbreakupxml method buyfwascxcs class
Avoid calling RegisterStartUpScript if not needed.
db callback notification
It is recommended to use ODP.Net framework for database handling in LOP Codebase. This also provides callback notifications which can be consumed by LOP Application and it will be notified whenever any CRUD operations happened so that LOP can take further action based on that.
capacity setting
We recommend to review the settings and set the capacity in accordance to the Memory/CPU available to the VM .
sap vm upgrade
We recommend to upgrade the VM version to 1.6
logging framework
We recommend usgae of Apache Log4j
memory error
Change/Add the value of following parameters in the JVM parameters file \n Parameters are provided in a separate mail
hard parsing query
Use bind variables instead of literals
nodata
No. of threads needs to be reduced. Cache static pages.
nodata
Convert all the JPG/GIF images into PNG extension
nodata
Value of maxconcurrentrequestspercpu needs to be increased to a higher value for the threads to be processed
nodata
Comment out the lines in aspx where referencing to those objects are done which are not present
nodata
Update Table/Index statistics if it is not done so, so that it starts taking the latest execution plan.
nodata
Please defragment the datafiles of the  tables involved in these views.
nodata
ii.Select on IPAY is having all columns, hence high read. Only use columns in select which is required.
nodata
iii.Implicit conversions used for NEFT_Payment_Requests should be avoided.
nodata
Set tcp_tw_recycle=1 and tcp_tw_reuse=1 in sysctl.conf
nodata
Set max_thread=400 in server.xml
nodata
Disable response time logging in server.xml
nodata
Apache Tomcat is replaced by node.js
nodata
Setting following in sysctl.conf:\nkernel.msgmnb= 100000\nkernel.msgmax= 100000
nodata
Set open files to 1000001 in ulimit
nodata
Setting the network configuration to use 10 Gbps network card
nodata
Setting following in sysctl.conf:\nnet.ipv4.ip_local_port_range=4096 65535\nnet.ipv4.tcp_congestion_control=cubic
nodata
Started service irqbalance
nodata
Changing following in the TopologyConf.props:\nBEGIN_SPOUT_CNT=25\nEND_SPOUT_CNT=25\nEVENT_SPOUT_CNT=25\nCRASH_SPOUT_CNT=25\nHDFS_BWRITERS=30\nHDFS_EWRITERS=30\nHDFS_CWRITERS=10\nHDFS_EVTWRITERS=30
nodata
Setting parameters to following in http2Kafka.ini file:\nPorts = 20\nPartitions = Begin-60, End-60, Event-120, Crash30\nBrokers = 2
nodata
Create a separate reporting database server for all reporting data or use of stand alone database server for all reporting purpose
nodata
Orphan records were deleted from queue tables to reduce no of executions.
nodata
Blank Search criteria has to be restricted to avoid high cpu utilization. This is a training that needs to be provided to the users as discussed with Aris Global team.
nodata
Staging tables will be used for moving data from the source system to the new application. Scheduled Batch jobs will be used to transfer the data between the 2 systems
nodata
While there are various workflow and BPM engines available, we recommend that the workflow be custom developed through a MVC framework given that the workflows are not very complex. The Applications in general follows a data view/ modify activities in a Maker-Checker mode and involves 2-3 steps in the workflow at the most. For such complexity levels, a custom workflow mechanism will be both easily maintainable as well as quick to implement (given that other workflows will have a learning curve).  \nHowever, a set of commonly used workflow engines has been provided. These may be useful in the future if there is a need for a comprehensive workflow engine to replace the custom workflow mechanism. All the options are fairly close in their feature list - specific call can be taken once requirements for the Workflow engine/ BPM is defined.
nodata
"User management will be a part of the administration module which will\ \ help in maintaining the system. This module will take care of \u2013 \\n1. User\ \ creation\\n2. Role creation\\n3. Associating privileges with Roles\\n4. Credential\ \ management and recovery\\n\\nWe recommend that a custom module (based on Spring\ \ MVC, Hibernate and JSP) be developed to address this requirement. \\nSpring security\ \ (as mentioned above) can be leveraged for the actual authentication and authorization\ \ requirements."
nodata
We recommend that Spring MVC be used instead of Struts in the application.
nodata
We recommend that Spring be used in the business layer as the framework for developing the application
nodata
"Amortize requests, wherever possible:- Introduce asynchronous processing\ \ at the app server layer (wherever possible)\\n Leads to faster response for end\ \ users\\n Better worker thread availability (as threads are released faster)\\\ n Threads don\u2019t block if end point is not responsive\\n Throttle requests based\ \ on end-point availability/ performance. \\n Add/ Reduce queue Listeners as well\ \ as Queues, as required."
nodata
Data shards:-Database outage can be \ncatastrophic and will bring\ndown the entire system for\nall users till the back up \ntakes over \nLimit impact of downtime\nto a sub-set of users only\nby creating db shards based\non account numbers.
nodata
Using caching servers to reduce load on Session Db:-Use combination of session API provided by Web container and Distributed memory\nCache to build a scalable Http session solution. \n Eliminate heavy db io operations by working on data sets in Memory rather than on disk\n Write session data to multiple cache servers for redundancy in case some cache servers have to be shut down \n Disadvantage is that synchronizing sessions with cache has to be handled by app.
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
unnecessary code execution responseredirect proposalcreationbundlepa method buyfwascxcs class
Add return statement after response.redirect.
unnecessary call registerstartupscript redirect proposalcreationbundlepa method buyfwascxcs class
Avoid calling RegisterStartUpScript if not needed.
unnecessary code execution responseredirect checkuservalidity method buytravelascxcs class
Add return statement after response.redirect.
unnecessary call registerstartupscript redirect proposalcreationbundlepa method buytravelascxcs class
Avoid calling RegisterStartUpScript if not needed.
unnecessary code execution responseredirect createstudentuser method buytravelascxcs class
Add return statement after response.redirect.
configuration
It is recommended to move the redo log storage RAID configuration to RAID 1+0 for both DC and DR instances
configuration
'After analyzing the issue, we have found out this is bug with oracle version 10.2.0.5. There are two separate patches provided by oracle on this issue                                                                                                                                    - Bug 5749075 - High Requests on dc_rollback_segments. latch / US enqueue  contention (Doc ID 5749075.8) \n - Bug 14226599 - Increase dc_rollback_segs hash buckets to reduce ''latch:  row cache objects'' waits (Doc ID 14226599.8)                                     We recommend to open a service request with oracle to get confirmation on applying the patch.'
code review
Some of the below recommnedations can be implemented quickly to Imporve the page performance.\n1. Compressing resources with gzip or deflate can reduce the number of bytes sent over the network.\n2. Minifying landing HTML will reduce its size by 2.3KiB (50% reduction)\n3. Enabling caching will reduce the page rendering time.\n4. No character set specified in HTTP headers. Specifying a character set in HTTP headers to speed up browser rendering.
slow response time
The slow response time only on Saturday's can be attributed to the same observation on the above point. The same reccomendation for the above point holds good for this too.
memory analysis
For the present transaction load the memory utilization is fine. However for increased branches, users and transaction additional memory will be required. If the HP team can provide the future plans of increase in the load, then a proper hardware augumentation can be done
code review
The RTGS bulk upload process which is run as a background process to be seperated from the 'laps' process script and executed in a seperate script with desired parallel processing
code review
Another main reason for transaction going into ENTERED status is locking of records, i.e multiple process using the same records at the same time which results in resource busy error for process which are waiting for the record to be released. This can be overcome by an inbuilt parameter provided in FINACLE called INTV_LOCK_POST (env variable). This has to be configured in micro seconds. The default value if not configured is 500000 micro seconds which is 0.5 secs. If a process finds that the record it requires for processing is locked by another process, then the process will try to acquire the record 60 times(hard coded in the product) with 0.5 secs ( the parameter which is defined) time gap between each iteration. So totally a process will wait for 30 secs (60 x 0.5) to acquire a record and if it doesnt after 30 seconds the process will throw a resource busy error. This value can be configured to a higher value if a single transaction takes a long time in posting and the record is not available for other process. This parameter will affect the entire FINACLE application and hence care and proper testing needs to be done before applying this parameter. Better is to bifurecate RTGS to a seperate server if this parameter is going to be applied. We can check on the usage of this parameter, based on the response from Infosys on the call which will be raised for the above point
code review
Convert these GIF files to PNG.
code review
Fix the path in application code to these objects.
code review
"To minimize the Response time of these pages,  below steps needs to be\ \ carried out\\n1. Compress js files and images \_ \\n2. Enable caching for static\ \ elements\\n3. Remove unwanted links ( 404 errors ) from pages\\n4. css should\ \ be moved out of body tag from pages"
code review
"To improve the Response time of these pages,  below steps needs to be carried\ \ out\\n1. Compress js files and images \_ \\n2. Enable caching for static elements\\\ n3. Remove unwanted links ( 404 errors ) from pages\\n4. css should be moved out\ \ of body tag from pages"
code review
Below steps were taken by HP team to resolve the issue.\n1. Few new patches provided by Infosys has been deployed in Mobile Banking application.\n2. Timeout period has been reduced from 14 secs to 8 secs in Mobile Banking application and from 14 secs to 6 secs in core.\n3. Seperate uniser service created in core for Mobile Banking application.\n4. Number of office accounts has been increased from 1 to 10 in core.
configuration
Sepearate mount points to be allocated for Corporate Index files and Payaway database files.
maintenance
Reorganization and rebuilding activities needs to be performed in the indexes shared. Please refer Sheet "DB Fragmentation" for details of the objects which needs to be acted upon
maintenance
Reorganization and rebuilding activities needs to be performed in the indexes shared. Please refer Sheet "DB Fragmentation" for details of the objects which needs to be acted upon
query optimization
Only one select should be done for one table and all the fields of the table should be cached in local memory for usage during the program.
query optimization
Strategy has been already shared with ICICI
code review
Recommendations needs to be incorporated
code review
Application logic can be modified to avoid opening and closing of files multiple times by putting the data in memory/cache.
cursor pin
DBA to verify and deploy necessary patches
query optimization
Avekshaa to review the AWR's with the new database version on AIX
query optimization
There were no alarming PL/SQL issues or optimization opportunities
configuration
NoData
configuration
Implementation of the parser tool in production after making changes to the code for logging volume data
query optimization
After discussion with ICICI team for this query they highlighted that this query will be removed from production from 6th February'12 and, so no need to do anything.
nodata
Analyzed Sql plan are fine and there no  issue observed
configuration
Scripts mentioned in previous slide should be used to write log for instrumentation with following information. Each information should be 1. separated with | (pipe)\n2. Starting and ending the execution indicator e.g. STARTING AT, ENDING AT etc.\n3. Script execution start time\n4. Script execution end time\n5. Menu option and script name\n6. Sol id\n7. User ID\n8. Volume (No of records) processed\nAny other information about transaction. e.g. Olats51 has been generated\nCreate a new com script to write this log. Call this script in starting and finishing of execution in all scripts mentioned in previous slide\nLog file name should indicate about module/menu option  and user id e.g. user1_hgbmpan.log
configuration
It was analyzed that  query execution is not taking more than 3-4 secs for large data sets. To analyze further on the application side, logs need to be introduced at various points in the code. As per discussion the development team will put the required logs by Monday (13th Feb).
configuration
Cache static content JS, CSS, images so that network bandwidth utilization comes down and web server has to take lesser amount of load.
code review
Combine all js files on a page into one JS file (wherever it is not too disruptive) and reference it at the bottom of the bodey tag in html/JSP.
code review
Minifying/Compacting JavaScript code can save many bytes of data and speed up downloading, parsing, and execution time. Any open source tool like JSMin, YUI Compressor etc can be used to minify JS files.\nFiles in a source code repository can remian as is (without minification), but before these files are deployed to production server these should be minified and then deployed to production server.
code review
Statement should be replaced with PreparedStatments. Statements are slower to run than PreparedStatements. Also, statements are vulnerable to SQL Injection attack.
code review
Hashtable is synchronised and runs slower than Hashmap due to overhead of synchronizations. Unncessary use of Hashtable will have adverse impact on performance.
code review
The possibls issue could be due to Arcot service per se or the connectivity between the end-client and the service. Arcot is a closed source third-party tool and can't be dug deeper. Will have to take this up with Arcot. Also, it is an interaction that heppens betwenn end-client and Aroct service which the CIB app has no control over. The interaction is not happening via CIB server.
configuration
QK should cache below static content types:\n\n.ico \n.gif\n.jpeg \n.png \n.bmp \n.javascript \n.css \n.html
query optimization
Create Non-Clustured cover index OR Create included column Non-Clustered index on CORPORATE_USER and BENEFICIARY_REGISTRATION_REQUEST_* tables
code review
"Add \u2018Link\u2019 to the CSS instead of Including in the body so that\ \ the CSS can be cached"
404 error
Remove calls to files that are leading to 404 errors. \nCreate favicon.ico image file on the default web folder and cache ico files.
configuration
We suggest that Transaction logs be moved to RAID 1+0 for better write performance
query optimization
Create cluster index on BANK_ID, BAY_USER_ID, CORP_USER of CUSR table.
query optimization
Create non-clustered index on bank_id, br_scr_hdr columns of DIRECTTAXPAYMENTS table. Avoid using 'like' condition in where clause of the query.
query optimization
Create covering indexes for faster execution of select queries.
query optimization
Query is performing full table scan on RqstHistoryTable table of size 8.5 GB.\n(Reference Query Q001 - see next sheet)\nCREATE NONCLUSTERED INDEX index_name ON RqstHistoryTable (Action_By,R_Cre_Time) INCLUDE (Request_Type,Request_Id,Request_Srl_Num,Action_Code,Remarks);
query optimization
Query is performing full table scan on FILEDETAILSTABLE table of size 600 MB.(Reference Query Q002 - see next sheet)\nCREATE NONCLUSTERED INDEX index_name ON FILEDETAILSTABLE (corp_id,r_mod_time)  INCLUDE (file_sequence_num);
performance
Make the function getPipeId 'static' so that multiple threads will not get access to the pipe id concurrently. This will impact performance to some extent since only one thread can get the monitor but is necessary to address the functionality. \nAlternatively add a synchronized block around the pipe id variable and remove synchronized keyword from the function.
performance
Synchronize the function smsReqResWrite in GlobalFunc class. \nPerformance might be compromised if multiple threads try to get access to the synchronized block and IO operations are initiated for every call. This is a likely case since given that the volume of SMS's will increase with time. \nConsider asynch logging using loggers like Log4J.
performance
These operations must be executed before retrieving the connection, to optimize the connection hold time within the thread.
slow response time
Recommended to remove the unwanted operations from the source file. This will help in faster execution of logical blocks and hence improve the performance. Also the objects created inside this block will get eliminate which result in low memory consumption.
slow response time
'Use Position literals first in String comparisons for equals/equalsIgnoreCase. \nExample: obj.equalsIgnoreCase("AnyString"); // should be "AnyString".equalsIgnoreCase(obj)'
slow response time
Comment out the unwanted instance of StringBuffer object.
slow response time
Split the String directly with "@" character.
slow response time
The map will be empty after this call returns. - This is not required as map is already empty. Performance overhead.
slow response time
Add below block inside finally block. \nparser = null; \nparser is reference to WebServiceResponseParser class. Above block will make sure that in any case normal/exceptional parser object reference to null and can be garbage collected.
slow response time
This is not required and may cause issues in content-targeting. So proper user-agent value should be passed as the application is targeted to Android and iOS platforms.
slow response time
These are not required, removing this will improve performance
slow response time
Remove the method call.
slow response time
Check the else condition and if not required remove the call made to generateFailureResponse
slow response time
Validate the logic here and remove the if condition as it seems to be Unnecessary
slow response time
The replace is not required. It is recommended to call split on PvtDataField125 directly.
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
application running debug mode create overhead response time resource intensive execution speed compromised load increase higher impact
It is recommended to set  'DEBUG' mode as false in the Production Environment.
expensive activity opening closing connection database operation connecting database server typically consists several timeconsuming step physical channel socket connection established initial handshake db server occurs connection string information get parsed connection authenticated server check run enlisting current transaction done every time coneection established degrades response time heavy resource utilisation
'It is recommended to use Database Connection Pooling.\nSet following keys in connectionstring: \nConnection Lifetime 0\nEnlist ''true'' \nMax Pool Size 50\nMin Pool Size  25\nPooling ''true'''
static content downloded server unwanted hit go server avoided putting static content configuration setting age currently proposed 365 day application run continuously 24x7 365 day
It is recommended to set Static Content Caching as -\n<staticContent>\n      <clientCache cacheControlMode="UseMaxAge" cacheControlMaxAge="365.00:00:00" /> \n    </staticContent>
writing log using systemiofile synchronous create problem handling concurrent user request
It is recommended to use ascynhronous logging using Log4Net framework.
writing log console recommended production environment
It is recommended to use ascynhronous logging using Log4Net framework.
unwanted memory consumed variable class
It is recommended to remove unused references, classes, methods, variables from the Code.
recompilation code done hard coded value changed need system downtime production environment
It is recommended to read the hard coded values from the Config files.
difficult trace end user journey logging pattern followed
'It is recommended to use given below logging pattern:\n\n<DATE TIME> <LOGLEVEL> <THREAD ID> <CLASS NAME> <REQUEST SENDING TO> <COMPONENT-NAME> <REQUEST DATA WITH MOBILE AND CUSTOMER ID/PASSPORT NO> <TIME TAKEN IN PROCESSING REQUEST> <TIME IN SECONDS>\n\n<DATE TIME> <LOGLEVEL> <THREAD ID> <CLASS NAME> <RESPONSE RECEIVED FROM> <COMPONENT-NAME> <RESPONSE DATA WITH MOBILE AND  CUSTOMER ID/PASSPORT NO > <TIME TAKEN IN PROCESSING RESPONSE> <TIME IN SECONDS>\nNOTE: Exception should be printed completely in all logs, also logs path is hard coded in code files also which should be removed.'
io operation increased drive simultaneously also c drive get full system processing impacted
'It is recommended to write all the application logs in D: drive only with proper purging and backup policies'
memory heap size increased slowly every end user call lead system hang time
It is recommended to dispose the WebClient object after use for avoiding memory leaks.
encryption decryption cpu intensive operation
It is recommended to avoid un-necessarily  use of encryption - decryption methods in all the codebase.
difficult anlyze issue error log issue time available
It is recommended  to do backup the error logs location alternate day.
parallel execution query restricted defined value
It is suggested to set the value of max degree of parallelism to 0. With this sql server will detect the best degree of parallesim to use for the query execution.
equally load distributed among node blocker application scalability
It is recommended to use distributed cache management system for session management
high count query execution utilize resource server
It is recommended to check the requirement of the queries and reduce the execution count of the queries.
high cost query cause high cpu utilization high execution time query
It is recommended to create below nonclusted index on AllocationForCenter table.\nCREATE NONCLUSTERED INDEX <Index_Name>\nON [dbo].[AllocationForCenter] ([CenterId],[VisaGroupId])\nINCLUDE ([Id],[Date],[MissionId],[TimebandId],[AllocationCategoryId],[TotalSeats],[RemainingSeats],[BlockedSeats],[ConfirmedSeats],[Createdby],[CreatedDate],[Modifiedby],[ModifiedDate])
memory heap size increased slowly every end user call lead system hang time
It is recommended to dispose the WebClient object after use for avoiding memory leaks.
unwanted db call increase system utilization decrease response time method
It is recommended to remove unwanted DB calls from the Codebase.
high elapsed time login page
We recommend to remove upper function from the query and handle the same from application end.
user could log respected mission get 403 error
It is highly recommend to implement  appNeura APM tool across pages to monitor the user experience and to track the errors so that corrective action to be taken.
unwanted db call increase system utilization decrease response time method
It is recommended to remove unwanted DB calls from the Codebase.
parallel execution query restricted defined value
It is recommended  to set the value of max degree of parallelism to 0. With this sql server will detect the best degree of parallesim to use for the query execution.
impact performance query consuming storage
It is highly recommended to defragment the table and indexes so performance of related query will not impact.
difficult distribute balanced load across different node
It is recommended to use same server configurations across all the nodes to get the optimal performance for the application.
everytime processing db call page increase system utilization also increase response time method
It is recommended to store the output value for GetLocalizedBannerText() inside the Session variable or internal cache.
consumption system resource increase
It is recommnded to remove all unwanted websites from GA production environment.
difficult trace network related issue lack proper network monitoring tool
It is recommended to use proper network monitoring tool.
many index overhead database impact performance insert update statement
It is recommended to remove the indexes which are not scanned by any queries.
lead utilize space storage end took time resource backing database
It is recommended to remove the duplicate / backup tables from the GA database.
lead utilize space storage end took time resource backing database
It is recommended to remove the tables with zero counts  from the GA database.
expensive activity opening closing connection database operation connecting database server typically consists several timeconsuming step physical channel socket connection established initial handshake db server occurs connection string information get parsed connection authenticated server check run enlisting current transaction done every time coneection established degrades response time heavy resource utilisation
'It is recommended to use Database Connection Pooling.\nSet following keys in connectionstring: \nConnection Lifetime 0\nEnlist ''true'' \nMax Pool Size 50\nMin Pool Size  25\nPooling ''true'''
currently autoconfig option ii used ii take default configuration handling concurrent request le handling concurrent request headroom available server per hardware kpi detail increased per recommendation handling concurrent user
'It is recommended to disable autoconfig and use custom thread pooling  setting in Machine.config as given below for handling more concurrent requests, below settings needs to be tested in UAT environment in high load before moving into production, it will be further tuned based on performance testing results. \n\nautoconfig : false\nmaxconnection    12 * #CPUs \nmaxIoThreads    100 \nmaxWorkerThreads   100 \nminFreeThreads   88 * #CPUs \nminLocalRequestFreeThreads   76 * #CPUs \nminIoThreads 50\nminWorkerThreads 50'
static content downloded server unwanted hit go server avoided putting static content configuration setting age currently proposed 365 day application run continuously 24x7 365 day
It is recommended to set Static Content Caching as -\n<staticContent>\n      <clientCache cacheControlMode="UseMaxAge" cacheControlMaxAge="365.00:00:00" /> \n    </staticContent>
unused object increase memory consumption application
It is recommended to remove unused objects.
encryption decryption method cpu intensive task
It is recommended to use Encryption - Decryption only wherever necessary in the application.\nAlso we have confirmed with Gobinath and he agreed that currently Encryption is not required in the method GetTreeData.
connecting database server typically consists several time consuming step connection pool used application unnecessary open db connection
It is recommended to create a static GetConnection() method that returns a new open connection. Use this within a using Statement so it can be closed and returned to the connection pool as soon as possible. Below is example :\nusing (var con = Database.GetConnection())\n{\n //query the data as per requirement\n}
memory heap size increased slowly every end user call lead system hang time
It is recommended to dispose the WebClient object after use for avoiding memory leaks.
difficult trace network related issue lack proper network monitoring tool
It is recommended to use proper network monitoring tool, we would recommend to use Riverbed Network Monitoring tool.\n\nhttps://www.riverbed.com/in/products/steelcentral/network-performance-management.html
unwanted consumption resource wesbsites relevent lidpro
It is recommnded to move all unwanted websites in other environment
imapcting quering performance
Deadlocks are bound to occur if the resources are not processed in a well defined order. To minimize deadlocks, all the concurrent transactions should access objects in a well defined orders.\nThere are update and insert statement on BatchHistory table and update is causing the deadlock issue in the database
impacting multiple query performance causing high lock wait event
There are indexes on the table BatchHistory where we can see there are columns which are getting frequently updates with update query , it is recommended not to index columns which are keep on updating it will impact the performance of query. Like in BatchHistory table column ConnectionStatus, type columns are indexed
placing data log file device cuase contention disk resulting poor performance
It is recommended to use different disks for data and log files.
difficult anlyze issue error log issue time available
It is recommended  to do backup the error logs location alternate day.
writing log console recommended production environment
It is recommended to remove Console.WritLine from the application and to use Ascynchronous logging using Log4Net.
'unwanted execution recordsave method consume system resource unnecessarily '
It is recommended to use [ record.save() ] only once in a method.
unused object increase memory consumption application
It is recommended to remove unused objects.
'unwanted execution commandexecutereader consume system resource unnecessarily '
It is recommened to use command.ExecuteScalar() for methods returning bool objects i.e to check if record exists or not.
slow response time
We should only be calling the objects which are required to paint the page. The GTM calls should be working asynchronously at the bottom of the page. It should not be a part of the header. This should be implemented across all pages.
slow response time
The list of images are provided in the sheet which needs to be optimised.
code review
Build a cube by merging 3  date queries to calculate \nOther Leads Date \nMeetings Date \nTalisma Date \nwill reduce execution time to less than minute
query optimization
Remove TRUNC from the joining condition
query optimization
Merge all 5 datasets by including all the metrics into a single dataset
code review
Redesign the panel to reduce rendering time. Recommended to have one panel display and provide option to switch. Need to test the feasibility and business acceptance.
high cpu utilization
ETL job needs to be optimized as the hardware configuration is already upgraded.
code review
Using Parallel Hints in VLDB Settings can fasten the query response time
code review
Redesigned the cube to select required data only
code review
Code review need to be carried out to fix the high cpu utilization.( Code review of these methods was not carried out due to unavailability of product code base )
nodata
25% of cache is used by custom_postinglog object, Creation of recommended indexes will help to improve the cache hit ratio.
nodata
It can be further optimized by creating composite index on ers_limit_usage table on columns (version,julian_offset)
code review
It is recommended to remove the synchronization for better throughput.
code review
This pattern is having high occurrences through the code. Use enhanced for loops to iterate or store value in a variable and use it inside condition.
code review
Database Connections and Input/Output streams should be closed by introducing  finally block , so that in case of exception it releases the lock on the file/stream and close the respective connection
code review
Use StringBuilder instead of StringBuffer if expensive thread-safe operations are not required. StringBuilder is faster than StringBuffer for strings concatenation.
query optimization
On Futher analysis of the issue we have found out that the delay configured for camel consumer is on the lower side . We recommend to increase that value \nA detailed mail is shared already
query optimization
We recommend the vendor to monitor and debugg the connection pool mechanism .\nA detailed mail explaining the situation with data is already shared .
query optimization
Create composite index on pay_bank_code and Q_status columns of fpd_payment_in table.
code review
We have recommended a single query which will bring all the data required to be displayed on the pages . Separate mail with all the details has been shared .
code review
We recommend multi threading of processing of transactions . We propose use of Executor framework for forming a thread pool and processing transaction in a block .
design
We recommend to use a different table space (already created but not used) to store indexes
query optimization
Create nonclustered Index  on table TBT_Payments on columns Maker_Location,PV_Date
maintenance
Drop duplicate indexes in database, as these are overhead for insert/update operations. This will also help to reclaim space on disk
query optimization
We shall need storage monitoring reports for further analysis
code review
Only one call should be made to get the collective data for all the entry codes. And the procedure should return the complete dataset which then can be processed on client side.
code review
Insert data directly into master table since there are no where clauses used for select statement. Also use of truncate is recommended instead of delete, since all data is getting deleted from *_inter tables
query optimization
Create Nonclustered Index on Tbt_eligible_refinance on column (Deal_no)
configuration
It is recommended to set max server memory for SQL server to 58 GB and min server memory to 8 GB
code review
Avoid non use of variable in cache block
code review
Avoid execution cycle
code review
deinitialize it in finally block
code review
sCurrency is not declared while comparing the sUTN. Check is it logically accepted having the empty value for sCurrency,
code review
Instead of looping to get the properties, can use direct method like "GetProperty"\nvar sShipper = Inputs.GetProperty("Shipping Company");
code review
deinitialize it in finally block
code review
if findchild do nt have record, then ListOfAlternatePhoneps may end of throwing the exception while accessing the GetChildCount. It's always better to check the object instance exists before accessing their property
code review
dereference it in finnally
code review
deinitialize in finally block
code review
if(sftind == "E" || sftind == "" || sftind ==null)\n    {\n      OneWorldResponse.SetProperty("Total Redemption Cost", ToNumber(OneWorldQuoteSum));\n      OneWorldResponse.SetProperty("Promotion Discount", ToNumber(gOWPromoPoints));\n      OneWorldResponse.SetProperty("Promotion Name", PromotionName);\n    }\n    else if(sftind == "B")\n    {\n   //  OneWorldResponse.SetProperty("SFT Cost", (sftvalue* ToNumber(count)));\n     OneWorldResponse.SetProperty("SFT Cost", "SFT NOT VALID FOR THIS ITINERARY");\n   //  OneWorldResponse.SetProperty("Total Redemption Cost Including SFT", ToNumber(OneWorldQuoteSum)+(sftvalue* ToNumber(count)));\n     OneWorldResponse.SetProperty("Total Redemption Cost", ToNumber(OneWorldQuoteSum));\n     OneWorldResponse.SetProperty("Promotion Discount", ToNumber(gOWPromoPoints));\n     OneWorldResponse.SetProperty("Promotion Name", PromotionName);\n    }\nelse if(sftind == "I")\n    { \n     OneWorldResponse.SetProperty("SFT Cost", "SFT NOT VALID FOR THIS ITINERARY");\n     OneWorldResponse.SetProperty("Total Redemption Cost", ToNumber(OneWorldQuoteSum)+(sftvalue* ToNumber(count)));\n     OneWorldResponse.SetProperty("Promotion Discount", ToNumber(gOWPromoPoints));\n     OneWorldResponse.SetProperty("Promotion Name", PromotionName);\n    }
code review
deinitialize in finally block
code review
deinitialize in finally block
code review
reconsider null is compared as string than null object\nif(vEndDate!= "" && vEndDate != 'null')
code review
reconsider null is compared as string than null object\nif(vMemberJoinDate !="" && vMemberJoinDate != 'null')
code review
Reconsider to improve the execution time like following\n if(oAbvDate > oToday && oExeFlag == "N")\n    {\n     oCurrYear = oCurrYear - '1';\n     oAbvDate = splitMonth + "/" + splitDay + "/"+ oCurrYear;\n     oAbvDate = new Date(oAbvDate);\n    }
code review
StatusBonusPoints is declared as block level variable and used out side the block, which is dangerous. Declare it as local variable than block variable
code review
sSCRExpiryDate is not been used anywhere. Recheck if it is not using anywhere, why wanted to do this operation. Recheck
code review
Global variables are used. May required some of the important variable to be reinitialize here
code review
Not used any where, can be removed or commented
code review
Not used any where, can be removed or commented
code review
Not used any where, can be removed or commented
code review
Not used any where, can be removed or commented
code review
FileWrite class provides close() method and it should be invoked in finally block, so it will be called even if an exception occurs.
code review
This need to be confirmed with team that why these static code has been introduced. If there is no any purpose then these code need to be fixed.
code review
This need to be confirmed with team.
code review
Default value of fetch size is 10, configure it based on average rows number is returning from queries.
high availability
Create a passive application node, which will serve as failover instance.
high availability
Since database is on standard edition, oracle data guard feature can not be leveraged. However manual standby server can be setup by sending archives via ftp or rsync on remote location and recovering database on periodic basic. This will have lag in data sync depending upon frequency of archive transfer.
design
Recommended to have separate tablespaces for indexes and tables
design
It is recommended to have multiple files in one tablespace with size of 4g or 8g depending upon size of mount point with autoextensible off. This helps for read and write operations in distributed fashion, instead of scanning one large file of 32 GB.
design
It is recommended to have separate mount points spread across multiple disks for temp,undo,redo,table tablespace and index tablespace
code review
Need to investigate application logic if these many executions are required in an hour. However as confirmed with application team these queries are not related to PAC application.
code review
As confirmed with application team these queries are not related to PAC application.
code review
Avoid hardcoded values. Use Constants for any kind of hard coded values.
code review
The main implication of close() is the release of resources - make sure you always close and never outside of finally block.
code review
Use equalsIgnoreCase()instead of using equals("String".toUpperCase()/toLowerCase()) \nequalsIgnoreCase() is faster than using toUpperCase/toLowerCase().equals()
maintenance
Perform defragmentation of tables and indexes for optimal access of datablocks.
configuration
Set cache size to 20 for the sequences.
code review
The mechanism of fetching data from database for single page should be changed. Development team is looking into it.
code review
Implement Paginations when displaying any list of records, that gives you the obvious benefit of faster subsequent page loads
code review
This has been discussed with the dev team.
code review
Below  parameters are recommended to further improve GC mechanism. \nXX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
select operation pqt table
We recommend to carry out purging/truncation on this table on a regular basis. We recommend to  set the  purge policy based on bank 's requirement of the reports to be kept on every individual's tray.
uneven utilization
We recommend to look into the list of processes running on both the machines and even out the CPU utlization.
index optimization
We recommend to create a new index onTD_TRAN_TABLE table with columns (TRAN_ID,TRAN_DATE,BANK_ID).Further we recommend to monitor the existing index IDX_TD_TRAN_TABLE,  which can be dropped if it has no other usage.
long running astcl sascl
We recommend to move both the jobs with Priority 935,940 to anywhere between 900-920 for reduced batch timings in BKCOP.
code review
Set play core pool size to number of cores +1 (33 in this case).
code review
Invoke logic from batch job rather than from front-end.
code review
Make getInstance() methods synchronized.
code review
Used StringBuilder instead of StringBuffer. StringBuilders is faster than StringBuffer for strings concatenation.
code review
Store jsonNode.size() value in a variable and use the same throughout the class instead of invoking jsonNode.size() multiple times.
code review
'Avoid calling toString() on objects already known to be string instances; this is unnecessary.\nReference:  String tok = tokens[1].toString();'
code review
Make entire Ingestion flow right from download, to merge, to thumbnail generation upto final uplaod multi-threaded. Use Executor Pool service at App.java so that entire Ingestion flow is parallel.
code review
atime needs to be disabled by adding the command noattime for the data file partition in fstab file
code review
Mysql server upgraded to 16 CPU and 32 GB RAM.
code review
Query Cache should be enabled as it was observed that there are 30%  of the queries contributing to READ queries.
code review
Modify /opt/SecureSpan/Gateway/node/default/etc/conf/system.properties\n\nadd the lines\n\ncom.l7tech.message.httpParamsMaxFormPost=2147483647\ncom.l7tech.http.maxParameterLength=1000000\norg.apache.tomcat.util.http.ServerCookie.ALLOW_EQUALS_IN_VALUE=true
code review
/opt/SecureSpan/Gateway/runtime/etc/profile.d/appliancedefs.sh\n1)Comment out the entire if/fi block.\n2) Change the multiplier value from 2/3 to 1/2
code review
The limit in 90-nproc.conf was set to 100001
code review
memcache dependent class files missing as memcache.ini and memcache.so were missing in the memcache deployment.
code review
The log level was changed to warning, to capture relevant data.
code review
Changes in the connection parameters :\n1. pm =static\n2. pm.max_children=50
code review
As the volume is increasing and these tables are write intensive , it is suggested to move these tables to NOSQL DB.
code review
Changes needs to be done on addtoplaylist_v1.php to update the image URL and songid to playlist master for the first song.
code review
The heap size should be changed to 16GB. Make the changes in cassandra-env.sh and run the same so that the change is reflected in cassandra.yaml
code review
make changes in the cassandra.yaml to reconfigure the paths to separate disk for better i/o performance.
code review
Concurrent Reads=128;Concurrent Writes =32
code review
The php needs to be tuned to point to Cassandra DB.
query high response time
1. Rebuild indices idx_ECS_INsured_details_policyno_hCardNO and IX_ECS_Insured_details to remove fragmentation.\n2. Instead of refreshing tables in ODS instance, move them to HCS prodution instance and refresh, this will reduce intercommunication time inbetween two instances.
large size aspnet cache due large number object finaliser queue
1. For dynamic loader classes where reflection is used needs to implement dispose methods to effectively clear them.\n2. For unreleased data tables in memory we can do following in every instance of datacontext class of HCS and ODS databases.\n    - Set dataContext.ObjectTrackingEnabled to false if object tracking is not needed.\n    - call dataContext.ClearCache()
thread contention constructor dynamicclassbuildupecsblblclaimsclinwarddetailsbl
The required objects should be passed into functions as parameter instead of initializig them in constructor.
currently network related parameter monitored
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
validation missing
Its recommended to do NULL checking and array length checking for string[] backendValues variable before assigning its value to other variables.
validation missing
Its recommended to do NULL checking for  string rootNode variable before assigning its value to other variables.
validation missing
Its recommended to do NULL checking and array length checking for string[] messageParameters variable before assigning its value to other variables.
hard coded value found
Its recommended to fetch hard code values from config files.
region used
Its recommended to use Regions so that all the methods are kept inside the regions.
duplicate code found
Its recommended to remove duplicate code.
method header comment missing
Its recommended to give Header Comments above all the Methods.
enum used
Its recommended to use Enum and call Enum for hardcoded values. Also hardcoded values should be fetch from config files.
found unused commented code
Its recommeded to remove unused commented code.
unwanted method found
It is recommended to remove unwanted Methods.
unwanted variable found inside method
It is recommended to remove unanted Varibles from Methods.
unit test project added
It is recommended to add Unit Test Projects so that Unit Tests can be done easily.
new string set stringempty
It is recommended to set new string as string.Empty
ii setting
It is recommended to set Managed Pipeline Mode to Integrated and .Net CLR Version to set to latest .Net Version in the IIS in the Production Environment.
found variable name declared twice single method
It is recommended that varible namely bool authorize should be declared only once and then assigned values to variable authorize as required.\nIt is recommended the values of ViewBag should be written in seprate method and that method should be used as required.
hard coded value found
Its recommended to fetch hard code values from config files.
region used
Its recommended to use Regions so that all the methods are kept inside the regions.
found unused commented code
Its recommeded to remove unused commented code.
unit test project added
It is recommended to add Unit Test Projects so that Unit Tests can be done easily.
disposible field disposed
It is recommened to disopose or close the fileds which are of Idisposible type in Dispose method.
found unused commented code
Its recommeded to remove unused commented code.
unused variable found
It is recommended to remove un used variable.
found unused commented code
Its recommeded to remove unused commented code.
high io space wastage
Need to dfragment these tables and also for other big tables need to do a periodic maintenance and purge un-wanted data.
incident dt 03062016 low success rate observed online nrca issue reported linux team hence involved analysis
'We doubt there might be memory leakages in the Application. We have requested following details from the Online4 vendor : 1, Memory Leakage Analysis report for Online4 Application, using open source projects like Valgrind which can be used in Linux, Solaris environments for C, C++ applications for memory analysis.2, Profiler reports for Online4 Application, using open source projects like GPROF which can which can be used in Linux, Solaris environments for C, C++ applications for profiling.'
sqlid 5569bw7dmrbnr
Need the explain plan not available on OEM
sheet tablestatsdetails
The list of tables which have stale statistics  which need to be fixed and \nchecked daily in order to have latest statistics on them.
attached sheet candidatesfragmentation currently fragmented
The list of table updated in the Candidates_Fragmentation experience\n heavy DML activities. \nThus qualifying them for stale statistics and Fragmentation .\n Currently Fragmented Database shows fragmented tables
sqlid d8ab0m7vz11xn
Try Index Hint inorder to encourage the use of index access instead of FTS.  .
filesystemoption database parameter
Set the parameter to setall
incident dt 02012017 primary node server 10165851 went hung modenrca itcc update per redhat hardware log analysis nt find relevant errrors issue occurrence hence linux team unable provide rca issue informed application team well team update issue o hardware side however redhat suggested command output taken reoccur
'We doubt there might be memory leakages in the Application. We have requested following details from the Online4 vendor : 1, Memory Leakage Analysis report for Online4 Application, using open source projects like Valgrind which can be used in Linux, Solaris environments for C, C++ applications for memory analysis.2, Profiler reports for Online4 Application, using open source projects like GPROF which can which can be used in Linux, Solaris environments for C, C++ applications for profiling.'
incident dt 08122016 credit card transaction getting declined nrca received workaround imdsystems caused process go high cpu usage due appliaction service got impacted cand stopped funcitoning
'We doubt there might be memory leakages in the Application. We have requested following details from the Online4 vendor : 1, Memory Leakage Analysis report for Online4 Application, using open source projects like Valgrind which can be used in Linux, Solaris environments for C, C++ applications for memory analysis.2, Profiler reports for Online4 Application, using open source projects like GPROF which can which can be used in Linux, Solaris environments for C, C++ applications for profiling.'
'incident dt 21012017 timeouts observed credit card transaction nrca team faced issue due mc advice team received wrong sub element 4863 trace id tag value length proper length sub element 4864 proper therefore caused autheng reduced 27 4 per tsys recommended parameter disable duplicate length check '
'We doubt there might be memory leakages in the Application. We have requested following details from the Online4 vendor : 1, Memory Leakage Analysis report for Online4 Application, using open source projects like Valgrind which can be used in Linux, Solaris environments for C, C++ applications for memory analysis.2, Profiler reports for Online4 Application, using open source projects like GPROF which can which can be used in Linux, Solaris environments for C, C++ applications for profiling.'
'incident dt 06022017 0900 0930 timeouts observed credit card transaction nrca due logging dump file node caused io wait search application got impacted '
Currently the logging in dump file was done between 9 am to 9.30 am. It is recommended to shift the timings for logging in dump file process to late night time, so that during peak hours (9 am to 9 pm) the system resources can fully be utilized for iCards Online4 transactions purposes only.
observed many systemoutprintln used debugging nexample accountdetailjava quickkillsjava ptlfdetailsmbeanjava  tlfdetailsmbeanjava many
It is recommended to use Log4j.debug for logging debug statements . These can then be turned off during production by keeping the logging levels as Warn/Error .
observed request responces various server done using xml
It is recommended to make xsd of request and responces and use either jaxb for xml to pojo conversion instead of parsing xml manually. Also there is a paid tool xml booster which is world fastest static xml parser tool which converts .java file from xsd and does the xsd validation also and provide pojo object from xml during runtime
java documentation properly added code recommendation
Code Recommendations base needs to be accompanied with in-Code Recommendations documentation (javadocs etc) so that the application logic is more readable and maintainable.
sqlid 83vs1160r9dz2
Need to create index on the userid   column of the table \nIVIEW.IVW_ACTIVE_SESSION in order to reduce the cost .
sqlid cp9q0y1qprt7q
Need to create index on the userid   column of the table \nIVIEW.IVW_ACTIVE_SESSION  in order to reduce the cost .\nAlso function used in the where clause need to be removed in\n order to take advantage of the above index.
currently iview db server 102 1 nic card also nic card data app server requested
Its recommended that all production servers should have atleast 2 network interface cards to avoid network failure if one cards gives any issues in real time.
currently apm tool feature instrumentation java inclusive monitoring used
Usage of APM Tool Feature - Instrumentation / Java inclusive monitoring.
currently network related parameter monitored
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
currently iview monitored apm tool
To monitor i-Vew Application using APM Tool
best practice
Keep firmware, Logical Domains Manager, Solaris, AIX up to date.
observed heavy ram utilization eai app server hydeaimom01 eai db server hydeaic01
Disable unused operating system services - It is recommended to enable only required OS services by cross checking in UAT environment.
currently network related parameter monitored
To capture Network Related Parameters. We recommend to use Riverbed Tool for Network monitoring which is currently available in ICICI.
currently unwanted datalogs size removed automatically
Usage of APM Tool Forensic Feature
currently method level reponse detail moinitored
Usage of Call-Graph Feature on APM Tool
unnecessary declaration variable
It is recommended to directly use the input parameter to avoid the unnecessary typecasting.
dataset object dispose
It is recommended to dispose of Dataset object in the finally section
using specfic exception catch satement
It is recommended to use specific exception in catch statements wherever possible.
'new string variable declared '
It is recommended to declare new string variable as string.Empty.
profiling application
It is recommended to run Profiling using App dyanmics or PerfView tools at different time intervals and also before releasing any CR into production. It will give you report of method performance timing.
unit testing
It is recommended to use xunit framework for generating the Unit Tests.\nhttps://xunit.github.io/
database handling
"It is recommended to make single API for doing the select operations in\ \ all 7 databases, this way direct DB connections won\u2019t be required and other\ \ interfaces also could use this API, it will also be good for maintainability point\ \ of view and also it will reduce a lot of code in application."
rendering engine
It is recommended to use Razer rendering engine with .Net MVC Framework for better maintainability of code and also Razer rendering engine is faster then aspx rendering engine.
code commenting
Code base needs to be accompanied with in-code documentation so that the application logic is more readable and maintainable. It can be add using doxygen code commenting guidelines which can further be used for generating html and pdf help of applications for better understanding of code.
mi report
It is recommended  to use Jasper Framework for generating MIS Reports (https://sourceforge.net/projects/jasperreports/?source=typ_redirect)\nOr\nCrystel Reports can also be used for generating MIS Reports
build automation
It is recommended to use NAnt or MSBuild tool for automatic building and running the test cases.
nfr document
Non Function Document (NFR) should be prepared for application benchmarking for future performance testing.
documentation
It is recommended to prepare all High Level Design/Detailed Level Design/Use Cases documents and time to time these should be updated based on new CRs.
devops
Dev-Ops tools should be used like Bamboo (https://www.atlassian.com)  should be used for continuous integration, deployment and release management purposes.
fast rendering
We can use asp.net 4.5 framework bundle feature for minification of css and js files. Also suggested generic recommendation for this item.
undersized pga
Increase the size of PGA(Curremt 2000M) to 6G as it is showing undersize in AWR and in PGA Advisory
high execution query almost zero row proceednbg10qfjspbkvcn1nzxvmg2vxvaun4ky0zu2358pjj
Need to check these queries and validations of these queries
queryn9tq94m78yy14c
Kindly check the system load I.e(CPU and Memory) before executing this query because it can lead to unnecessary resource\nconsumption during peak business hour.
queryndwy43ajdzj381
Kindly check the system load I.e(CPU and Memory) before executing this query because it can lead to unnecessary resource\nconsumption during peak business hour.
queryng7217t4mnkph6
Procedure\nCreate composite index on column hitdate,offercode,channel and userid on\ntable lop_page_hits\nAnd functional index on column pagename as there is no indexes on\nthis column or remove upper function from\npagename column and aligned this column with above\nComposite index(hitdate,offercode,channel and userid)\nas there is already function on right side on column in where condition\nWhere as no of rows in this table is almost 2.5lakhs
querynfww7rw6htdruz
Create composite index on column hitdate,offercode,channel and userid\nOn table lop_page_hits\nAnd functional index on column pagename as there is no indexes on\nthis column or remove upper function from\npagename column and aligned this column with above\ncomposite index(hitdate,offercode,channel and userid)\nas there is already function on right side on column in where\nCondition as there is no indexes on this column to avoid FTS
queryn8c8urqnk5gv1b
Create index on column dest_code on both table cs_no_offer_dtl and table cs_final_offer\nCreate index functional index on cpcs_flag on table cs_final_offer\nCreate index on SUPPRESS_FLAG on table cs_final_offer
minification script file done
'Reduction in Javascript file size through: \nRemoval of blank spaces and lines\nUse of smaller variables'
script script reference end page
It is recommended to move scripts and script references to end of page.
minificaiton bundling cs style sheet
It is recommended to do the minification and bundling for CSS style sheets.
web server utilization metric available
APM Tool should include Web servers for monitoring
bottleneck network measured
Ping statistics to be captured for all servers
response time 12 transaction iciciavekshaapcmsperformancereportv10 pcms degrading
Performance Tuning of these transactions are required
query goin ft
Create index on \nColumn CSL_TRANS_TYPE,\nTXN_FEE_FLAG,&\nCSL_PAN_NO_ENCR on \nTable cms_statements_log\nThis avoid FTS
query goin ft
Create index on \nColumn CCM_INST_CODE and another functional index on\nColumn CCM_ID_TYPE1,\nCCM_ID_NUMBER1,\nCCM_ID_TYPE2 &\nCCM_ID_NUMBER2\nTable CMS_CUST_MAST\nThis avoid FTS
query goin ft
Create index on column CBD_PROCESS_FLAG,\nCBD_TOPU_STAT& CBD_LUPD_DATE  of table\nCMS_BATCHUPLD_DETL. \n\nAnd \n\nCreate index on column CBS_BATCH_TYPE,\nCBS_CORP_ID for table CMS_BATCHUPLD_SUMMARY
per pocket ppt report slide 47 incident dated 23122016 issue occurred deployment done rib server impacted funtionality problem pocket system
It is recommended that respective teams should be clearly communicated for any new deployments in any of the layers in Pockets System.
queryn11wv66yu716r0u fixed object v sysstatn2c9umxngkc3byq fixed object v sqlmonitor v sysreportstatsn33ds81aj0fzq85 fixed object v sqlmonitor
Need to gather fixed objects stats
high execution queriesndate 28th nov 2016nna 3fxatuj5jdhzu nb fb4hvrd9g44sanc 1bhkm76p82uzdnd 2gzfkfv52rry0ne g9t2tuana15nn
Performnace Improvement
high cpu utilization
'Very high CPU utilization (~100%) observed. Query resulting in Full table scan on GAM identified. \nQuery to be optimized by service provider. \nRefer: Q001 in SQL_QUERIES'
configuration
Change the MQ Channel manager count to 1000 (CFSMGRCHL Manager)
configuration
We have analyzed that WebMethods Admin threads are blocked by an operation which is converting ISO messages to XMLs.\nThe stack trace is -\nIndusInd_ISO8583/utils.convertISOToXML(utils.java:89)\nSource code to be analyzed
query optimization
Avekshaa has shared the details of the queries along with the recommendations with the bank.\nQ003 - This query is going for an FTS (on "WASADM"."SESSIONS") even though the Indexes are present on the search condition. \nQuery fired from WAS.
configuration
Option 1 - It is proposed to use IP aliases to resolve the IP stickness configured on the Load Balancer.\nOption 2 - IP stickiness between WAS and Finacle App server.\nOption 2 was implemented.
query optimization
Update GEC and RCL table for corresponding columns
memory analysis
We had earlier recommended Singleton usage for  Resource Bundles loading. This issue has to be fixed before SVS tests can be resumed.
configuration
The CPU utilization on ESB has come down to acceptable limits. To assess where is the time being spent, Avekshaa's has suggested softwareAG to log the time spent on ESB.
configuration
Infosys to rvert back on what is 99 mapped to in Finacle
configuration
Disable logging in the Uniser and CBC configuration files.Also script traces should be disabled.
configuration
Evaluate useage of lpad,rpad. Pasting the query below for your ready reference.
query optimization
Query to be tuned
configuration
The credit account was not mapped as the settlement account because of which the script was throwing an error.
query optimization
Query to be tuned
configuration
The transaction should be processed by the same node in entirety, the avg. response time would be much lower than when it is processed by both the ESB nodes.
configuration
Inode which is shared across all app servers got full, which is why there were fatal logs generated. The inode was increased from 3lacs to 6lacs. Traces needs to be off which is eating up the disk space.
query optimization
Stats gathering needs to be done judiously. (Stats gathering should not be done during peak hours)
configuration
Confirm from Infosys team and remove DBA roles and assign only required privileges to users. This will help in better security measures for the database. (User List is shared with Suman)
query optimization
Row lock contention on  fiusb_message_table. Probably a case of Duprec happening. Infosys to explore if the commit interval can be reduced.
design
There are lots of comments which are sent in xsl, javasctipt files which are served to the client which add to page weight and time. The comments needs to removed from js, css and xsl files which would reduce the page weight and would improve the performance.
high response time
Thread Pool configuration was increased from 10 to 50. Validated the CPU available which allows the thread pool to be increased to 50
high cpu utilisation high io writes
Logging is removed from iteration of code
los database awr report analyzed show stopper identified analysisntotal 2 full table scan query identified listed appendix b
Hints for using the index were provided which would optimally use the index.
"found data uploaded partner portal 6sep2017 took 5 hour validate\ \ process 330 record high detail mentioned sheet upload statistic n ndetailed observation\ \ n1 analyzing awr report wrt date time issue found \u201C row lock contention \u201D\ \ issue segment \u201C savedenginemessagebt \u201D n2 wait event consuming 95 percent\ \ total db time segment \u201C update \u201D statementn3 query select pkid piid\ \ creationtime reason enginemessages enginemessagel versionid psbpcdssavedenginemessagebt\ \ pkidhextoraw 1 updaten4 found \u201C update \u201D statement running 1015 1815\ \ 6sep2017 could found similar statement running dayn5 row lock contention wait\ \ occurs transaction try update delete row currently locked another transaction "
Detailed approach to solve the problem:\n1. Use of "FOR UPDATE" should be avoided in the code.  \n2. If it is required then test with adding 'WAIT 10'  for the 'FOR UPDATE'  statement, this will wait for 10 seconds for the lock on row to be released.\n This will eliminate to  wait indefinitely for a lock to be released.\n3. The new statement will be as below.\nSELECT PKID, PIID, CREATION_TIME, REASON,ENGINE_MESSAGE_S,ENGINE_MESSAGE_L,VERSION_ID FROM PSBPCDS.SAVED_ENGINE_MESSAGE_B_T WHERE (PKID=HEXTORAW(:1)) FOR UPDATE WAIT 10;
static resource like image cs j etc found multiple time access log shared indicates web server level caching used static resource incur exta cost fetching static resource server client put burden network avoidable high concurrency could potentially stress network already threshold level netwrok log ascertain whether currently case
As part of the web best practices, the static resources should be set with appropriate expiry times so that clients can cache these resources at their end. Since we are still awaiting web server cofig file, we are unable to provide with exact caching/expiry constructs. Shall do so once we get web server config files.
found one update query high execution count upload process going ft table otcaccounthierarchyinfo causing high cost query otc database
We suggest to create index on table OTC_ACCOUNT_HIERARCHY_INFO with column ACCOUNT_NO.
found one update query high execution count upload process going ft table sraudittrial causing high cost query otc database
We suggest to create index on table SR_AUDIT_TRIAL with column CRM_REFERENCE_CD.
file record inserted otc database 100record batch make call soa member addition service pass filerk among thing since content file uploaded sent soa service inefficient make soa webservice call 100 record incur unnecessary cost establishing discarding http connection soa call example file 20k record establish discard http connection 200 time
Since only file_rk is sent to the SOA, there is no reason for batching to be implemented. Get rid of batching logic and insert all rows in the file into OTC database and make only one call to SOA Member Addition service. This will reduce number of HTTP connections to be established with SOA server.
'row inside file validated processed inserted otc database single jvm thread need keep processing singlethreaded restrict throughput file processing engine scale well since cpu utiliation seen nmon log shared far seems 25 good scope improve upon design '
'Process rows inside a file in a multi-threaded manner. It is recommended to use Java''s Executor service to multi-thread file processing logic. Since most, if not all , of validation engine and data insertion logic is independent of rows within the file, this entire logic can, and should, be multi-threaded. Validate and insert all rows in  a file, using Java''s Executor service.\n\nBased on NMON logs shared with us, we do not see CPU pressure on any of the servers, and hence multi-threading OTC validation and data insertion flow should improve throughput of the end-to-end flow. (This is assuming SOA layer and GA already process data in a multi-threaded manner, which is most likely the case). \n\nTo start with, the Executor service''s max thread pool size can be set to 5. Based on CPU headroom analysis on all serevrs, this number can be increased further.\n\n(As pointed out in receommendation #15 above, since batching logic is unnecessary and inefficient in this flow, if that is gotten rid of first, the multi-threading of the file proecessing will be that much less cumbersome).'
multiple update select query going ft cspsexceptionsretry high cost causing high execution time ndetails mentioned sql sheet
We suggest to create composite index on table CSPS_EXCEPTIONS_RETRY with column FAILED_SR_NO and RECORD_CREATED_DT.
uneven portal web server hit
"Change load balancer scheduling algorithm to \u2018Cyclic\u2019"
"need introducing contemporary database access framework \u2013\ \ \u2018 dbconnectionbroker \u2019 library used database access connection pooling\ \ nthis opensource library updated since past 10 year although library appropriate\ \ fit platform 10 year back advancement application server connection pooling availability\ \ extremely stablescalable data access framework like hibernatejpa etc prompt rethink\ \ choice"
Review introduction of a contemporary database access framework. Ideally de-couple the View and the Model before introduction of a new framework.
"old library used application \u2013 nclasses12 jdbc driver 2001\ \ common logging 2002 dom xml parser 2001 mail 2001 servlets 2004 smtp 2000 jce\ \ crypto 2001 activation \u2013 1999nimprovements release library jdk version leveraged "
Replace libraries with latest versions.
"large java script embedded jsp \u2019 observed 700 loc njava\ \ script jsp rendered inline html script cached compressed reduce response time "
Extract and add Java Script code in a separate Script file so that it can be compressed and cached on client side.
currently payment gateway us ejb21 upgrading ejb 21 ejb improve performance
Upgrade from EJB2.1 to EJB3
combine image image map spritesncompress html cs javascript used mwi pagesncombine javascript file single filenenable cache webserver far expiry date static content like image javascript cs filesnconfigure etags would improve performance static resource rendering browser used merchant
Front End Optimization for MWI component
"currently jdk version used 4 jdk improved time performance functional\ \ capabilitiesnlots external api \u2019 library used payment gateway currently newer\ \ version jdk integrated normalized performance using latest jdk would improve performance"
Upgrade JDK 4 to JDK 5/6
table trndetails used majorly transaction multiple select update query run table file upload process transaction
Create partition on 'EnteredDt"  column on monthly basis with creating file groups on multiple disks and to create the clustered index on EnteredDt and CustomerId column. (As this is discussed together with DBA team.)
observed procedure bcspvalidatelimit running transaction process going ft table
It is suggested to create index on 'Svc_Stg_Txn' table with RESERVE4,RESERVE5,Txnmode columns with include Amount,BENE_ACNO,BENE_IFSC_CODE,Trn_Status
'file reportsthaccountstatementnmethod exportaccountsumamrynstring variable used inside loop use string variable inside loop resource intensive performance impactnreference dim tr string '
String varaible needs to be replaced by StringBuilder DataType. And should be disposed after use.
'following error observed application log object reference set instance object nnsession check nothing missing performing operation session object due application throw exception pfb file method listnnbeneficiarybeneficiarymaintenancegetbeneficiarydetails nftpaytrnconfirmdisplaydetails   ntransactionsftotherbanknewtrnbenrtgspageload   ntransactionsauthtrnfillproducttype  '
Session check for nothing needs to be implemented before performing operations on the session object.
observed delete temp statement used deleting data temp table procedure idspfilelevelauth expensive operation
It is suggested to use truncate statement for record deletion.
observed query running table trndetails high cost
We suggest to create index on TrnDetails table with column CustomerID,Status,ValueDate with include Amount. (Before partition it was present on production database.)
request time error authorizing file containing 100000 record
'Request Execution Time should be increased from 120 seconds to 200 seconds in web.config file.\nReference: executionTimeout="200" in httpRuntime Tag'
showing sqlnet data client top wait event awr report
We have tested on local database and found by setting the array size with sample size 1000 , we could see an improvement of 50% reduction in response time on local database. Hence advised to change the array size with 1000 in the UAT environment .
itrates biddetails arraylist fetch biddetailsbean using pbidreferencenumber optimal design espeically ahs iterate long list
Store BiDDetailsBean in a Hashmap rather than Arraylist. Use BidReferenceNumber as key and ASBAApplicationBidDetailsBean as a value.
'validates file extension using string indexof also accept wrong file extension example file extension c sv accepted nalso allowedfiletypestouppercase neede string initialized upper case already '
1. Use HashMap with file extension as keys. \n2. Remove unnecessary calls to toUpperCase().
handcoded logic splitting given string using given delimiter 2pass phase needed
Use Java String's split method to split a given string using a given delimiter.
'access log shared day 8th dec 267k http request come back http code 404 '
Either place missing resources on Web serevr at appropriate location or remove calls to these resoucres:\nfavicon.ico\n/eipo/bidux/fonts/HelveticaNeueLTStd\n/apple-touch-icon-120x120-precomposed.png\napple-touch-icon-precomposed.png\n/eipo/bidux/images/loading.gif\n/wp-login.php\n/eipoadmin/bids/css/images/orange_top.jpg \n/issueforms/html/images/blockbg.jpg
analysis production server monitoring live ipo observared memory leak database server memory utilization going beyond 80
'We need to upgrade Windows Server OS & MS-SQL Server to the latest version for following reasons:\n1) To fix the memory leak issue on DB server\n2) Windows 2008 R2 OS support from microsoft got over in 4/9/13\n3) SQL Server 2008 R2 mainstream support ended on 7/8/14\nNote: Application functionality to be tested on UAT Server before Production Migration'
nodata
'Increase APP Server CPU from 4 to 8  Expected Improvement: Response Time will come down by half'
nodata
'Increase APP Server Memory from 4 GB to 8 GB.\nExpected Improvement: Response Time will come down by half'
nodata
'Increase initial heap size to 2000 MB\nExpected Improvement: Response Time will come down'
nodata
'Increase Max heap size to 2000 MB\nExpected Improvement: Response Time will come down'
nodata
Repeating the login steps needs to be avoided.
nodata
Login statement looping should be avoided.
nodata
Enable client caching for jpg, gif,  other images
nodata
Enable client caching for css (*.css)
nodata
In a day 48K requests are not been server by web application because of 404. If this links are not in use, please remove from the application.
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
aspx page faworkstationallrecordsaspx faworkstationcallhistoryaspx  faworkstationcallsearchaspx page general observation
"1. Implementation caching for recurrence of accessed data.\\n2. \u201C\ Select isnull(birthdayalert,7O) birthdayalerdays from tblfp_parameters\u201D such\ \ a statement should be avoided in all the pages. This SQL statement is note executed\ \ by a procedure call. This is hard coded in the pages. If it is not a valid default\ \ values is applying which can be taken care by application itself rather executing\ \ the SQL function. Again this can be avoided by the caching\\n3. Avoid the nested\ \ table html design\\n4. Use always client side validation\\n5. Use JQuery more\ \ on client side.\\n6. Inline javascript always perform below the page."
nodata
1. Implement caching for the lookup values which is used by pages\n2. Implement SQL dependent caching for SQL lookup tables \n3.  Avoid Server side validation and provide wherever possible client side validation\n4.  tblfp_parameters is the general for application which is frequently used more. Such a rarely unchanged data to be cached by application server.\n5. Use Ajax wherever is possible.\n6. Try use JQuery\n7. Avoid inline query and move to js  file\n8. Use minimize technique for JS files\n9. Use minimize technique for CSS files
nodata
We suggested defragmenting these indexes by rebuilding each index used for this table. This will improve both selects as well as inserts onto the tables, improving the offline report generation as well as improving the online transactions, leading to reduction in timeout instances.
nodata
Either remove CONVERT function or put the conversion logic in application layer rather than database layer.     2.We have gathered execution plans without using CONVERT function for heavy load generating reports like Show transaction , Analyze transaction and Search Cases.
number record cache different record received stub
Some keys maintained for each Supplier were not valid
total breakdown multiple request hit till encountered desired number record cache
After correction, it was observed that on 5th,6th request we received desired number of records- hence identified that performance issue with Coherence implementation.
total breakdown multiple request hit till encountered desired number record cache
Loggers were introduced in the deployment on our suggestion & identified - The operation of Putting records in CACHE is SYNCHRONOUS process, suggested to be concurrent
total breakdown multiple request hit till encountered desired number record cache
The records received were not product specific, but supplier specific, hence suggested to introduce Product as a key too
total breakdown multiple request hit till encountered desired number record cache
Error handling for long time running leads to Thread blocked, suggested to handle it by introducing TRY - CATCH block
total breakdown multiple request hit till encountered desired number record cache
Huge time was taken for getting records from CACHE, introduced milliseconds delay in the test runs, identified JSON conversion issue - taking more time
query execution time high due large size table
Table size should be adequate.
query started taking time execution
Need to check new parameters and its recommended values before upgrade.
'blocked thread observed loggerinfo method '
Set logging level to error
observed 7 8 minute delay stage processing order
Recommneded to increase the threads from 1 to 5.
version control tool used
"Better patch deployment management \u2013 Use Version control tools like\ \ TortoiseSVN."
high availability
Deploy the reporting webserver component on web server 1 and webserver 2 as well. Start these additional instances only if there is a failure on the reporting server.\nHave additional JVM instances running on the application server 1 or 2 which can be started when the primary application server is unavailable.
high availability
Currently the response time of MWI home page is not less than 3 seconds when accessed anywhere from India. This can be reduced by implementing Front End Optimization techniques
heap memory value changed
Values were changed after being brought to notice
addition node server 432
We recommend adding 1 extra node for server 2/4 . Additionally 1 extra node can be added to server 3 since its memory has been increased .
code review
We recommend to implement all the code review points.
uneven server hit
We recommend to find out the root cause of this behavior and take correct actions (change of settings / taking up with SAP).
nodata
Customization team to assess if these queries are necessary to be run during business hours . Implicit functions used in the select is causing the query to take a lot of time.
nodata
i.Defragment CUSR,IPAY tables
nodata
Set tcp_fin_timeout to 10 secs in sysctl.conf
nodata
Creating multiple instances (5) of Apache Tomcat
nodata
Disable response time logging in server.xml
nodata
C Library changed to LibUV in HttptoKafka
nodata
Changing Partitions of all the Topics from 30 to 60 in Kafka
nodata
"Configuration of DSR will help to \u2013 \\nAvoid manual intervention to\ \ start the VM instance        in case of failover.\\nAutomated Resource Balancing"
nodata
Removal of one log file member from each group had reduced log file sync wait event database time by 35-40 %.
nodata
During load test undo retention was set to 25000 which was on the higher side. DB team has changed it to 1800.
nodata
Hard parsing queries in application needs to be fixed, which will help to reduce CPU utilization on database server.
nodata
Using DB link avoided for same database.
nodata
A combination of front end (browser level) and back end (server side) validations is proposed. Java open source community offers a good set of options for data validation frameworks. \n1. We recommend that either Hibernate Validator OR Spring Validator be used for Data validation on the server side. \n2. Posabsolute can be used as a validation framework for the front end (browser) forms.
nodata
We recommend using Jasper as the reporting framework for the application
nodata
We suggest that the available logging framework be customized for persisting critical events in the application. Log4J (recommended logging framework) provides an option of persisting the log details in a database. Custom logger classes can be created and used at points in the application where auditing information is to be captured. \nCustom UI screens can be developed to extract the auditing information from the relevant database tables for compliance checks/ auditing needs
nodata
"Monitor service end-point performance:- Define SLA\u2019s at the end points.\ \ \\n Monitor end-point performance vis-\xE0-vis SLA\u2019s\\n If thresholds are\ \ consistently breached \u2013 \\n Raise alerts\\n Mark down end-points \\n Selectively\ \ disable features that require these end-points\\n Control request amortization\ \ levels (See next slide)"
nodata
Optimize Connections:- Avoid creating a fresh TCP connection for every request and alleviate connection \nmanagement overhead.  \n Build connection pools for different systems and re-use the connections amongst \nmultiple requests
nodata
"Web server machine failure can add severe load on the other operational\ \ server:- Consider adding a web server to reduce load on the operational server\ \ in case of \\nmachine outage. \\n Web servers are currently functioning as reverse\ \ proxy\u2019s without any heavy \\nprocessing. Instead of adding high end servers\ \ that can run multiple server nodes \\nevaluate the possibility of introducing\ \ multiple low cost rack servers that can run\\none or two nodes. \\n This will\ \ increase redundancy and reduce impact of outage of any server"
nodata
DevicePrint.jsp\nIssue\nDevicePrint.jsp was not used for any functionalities on \nthe RetailLogin Page but had very resource intensive \ninline Javascript which was blocking the page rendering
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
nodata
NoData
